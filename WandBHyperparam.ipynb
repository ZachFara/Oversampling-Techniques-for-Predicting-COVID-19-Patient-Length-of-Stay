{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "F1E-DfqSlcjd",
        "outputId": "1a593501-6e78-4666-ffe9-46070a2f2cd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 15.6 MB/s \n",
            "\u001b[?25hCollecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.7.2-py2.py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 25.2 MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 85.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=214a6c6c48b8d7e912c794694926b0d940f48ad9c4fd741ae436fc6cbe4282a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.7.2 setproctitle-1.2.3 shortuuid-1.0.9 smmap-5.0.0 wandb-0.12.21\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "qzqTUlC_ogbj",
        "outputId": "7619fbce-45bd-4ee3-dbdd-9dd56cee84be"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ae6b39ac68ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wandb'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nivPygR2jXtB",
        "outputId": "07c73cd4-9e65-474c-e008-bcce3cd85053"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Note: using Google CoLab\n",
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "#Packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "#Google drive\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False\n",
        "#Helpful functions    \n",
        "def set_random_seed(seed):\n",
        "    tf.random.set_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "def load_data():\n",
        "    #File extention if Colab or not\n",
        "  if COLAB:\n",
        "    file_ext = '/content/drive/MyDrive/Colab Notebooks/Data/'\n",
        "  else:\n",
        "    file_ext = 'Data/final_dataset/'\n",
        "  x_train = pd.read_csv(file_ext+'x_train.csv',index_col = 'patient_num')\n",
        "  y_train = pd.read_csv(file_ext+'y_train.csv',index_col = 'patient_num')\n",
        "  x_val = pd.read_csv(file_ext+'x_val.csv',index_col = 'patient_num')\n",
        "  y_val =   pd.read_csv(file_ext+'y_val.csv',index_col = 'patient_num')\n",
        "  x_test =   pd.read_csv(file_ext+'x_test.csv',index_col = 'patient_num')\n",
        "  y_test =   pd.read_csv(file_ext+'y_test.csv', index_col = 'patient_num')\n",
        "  return x_train, y_train, x_val, y_val, x_test, y_test\n",
        "def load_smote_data():\n",
        "    #File extention if Colab or not\n",
        "  if COLAB:\n",
        "    file_ext = '/content/drive/MyDrive/Colab Notebooks/Data/'\n",
        "  else:\n",
        "    file_ext = 'Data/final_dataset/'\n",
        "  x_smote = pd.read_csv(file_ext+'x_smote.csv')\n",
        "  y_smote = pd.read_csv(file_ext+'y_smote.csv')\n",
        "  x_smote = x_smote.drop(labels=\"Unnamed: 0\",axis = 1)\n",
        "  y_smote = y_smote[\"Severity\"]\n",
        "  return x_smote, y_smote\n",
        "\n",
        "set_random_seed(13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrN7SQXYlTqd"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_val, y_val, x_test, y_test = load_data()\n",
        "x_smote, y_smote = load_smote_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abzMzbH49fxX"
      },
      "source": [
        "Feature importances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spFLcQ5Ua3Io",
        "outputId": "9f05ceb8-1c35-483b-9534-f837afceb307"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "selector = SelectKBest(mutual_info_classif, k = 20)\n",
        "x_best = selector.fit_transform(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQwAh2u94F08"
      },
      "outputs": [],
      "source": [
        "dictionary = dict(zip(selector.feature_names_in_,selector.scores_))\n",
        "sorted_keys = sorted(dictionary, key=dictionary.get, reverse=True)\n",
        "sorted_dict = {}\n",
        "for w in sorted_keys:\n",
        "    sorted_dict[w] = dictionary[w]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG-FCCEe9Xna",
        "outputId": "619253b3-a89c-46a9-c5bd-f58e86883145"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Anticoagulants', 'Magnesium',\n",
              "       'TherapeuticprophylacticordiagnosticinjectionspecifysubstanceordrugeachadditionalsequentialintravenouspushofthesamesubstancedrugprovidedinafacilityListseparatelyinadditiontocodeforprimaryprocedure',\n",
              "       'Criticalcareevaluationandmanagementofthecriticallyillorcriticallyinjuredpatientfirst3074minutes',\n",
              "       'Therapeuticactivitiesdirectoneononepatientcontactuseofdynamicactivitiestoimprovefunctionalperformanceeach15minutes',\n",
              "       'IntravenousinfusionfortherapyprophylaxisordiagnosisspecifysubstanceordrugeachadditionalhourListseparatelyinadditiontocodeforprimaryprocedure',\n",
              "       'Subsequenthospitalcareperdayfortheevaluationandmanagementofapatientwhichrequiresatleast2ofthese3keycomponentsAdetailedintervalhistoryAdetailedexaminationMedicaldecisionmakingofhighcomplexityCounselingandorcoor',\n",
              "       'MAGNESIUMBLOOD',\n",
              "       'Subsequenthospitalcareperdayfortheevaluationandmanagementofapatientwhichrequiresatleast2ofthese3keycomponentsAnexpandedproblemfocusedintervalhistoryAnexpandedproblemfocusedexaminationMedicaldecisionmakingofmoder',\n",
              "       'Culturebacterialbloodaerobicwithisolationandpresumptiveidentificationofisolatesincludesanaerobiccultureifappropriate',\n",
              "       'GasesbloodanycombinationofpHpCO2pO2CO2HCO3includingcalculatedO2saturationwithO2saturationbydirectmeasurementexceptpulseoximetry',\n",
              "       'POCHESTPAORAP', 'IPCONSULTFORVASCULARACCESSTEAM',\n",
              "       'Intravenousinfusionfortherapyprophylaxisordiagnosisspecifysubstanceordrugadditionalsequentialinfusionofanewdrugsubstanceupto1hourListseparatelyinadditiontocodeforprimaryprocedure',\n",
              "       'IPCONSULTTONUTRITIONALSERVICES',\n",
              "       'Radiologicexaminationchestsingleview', 'CULTUREBLOOD_x',\n",
              "       'Lactatelacticacid', 'CULTBLOOD', 'MAGNESIUMQuantitative_na'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "selector.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-QP09Vr8fV1",
        "outputId": "ed696fe6-b69b-490f-cdd9-deb73068a032"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Subsequenthospitalcareperdayfortheevaluationandmanagementofapatientwhichrequiresatleast2ofthese3keycomponentsAdetailedintervalhistoryAdetailedexaminationMedicaldecisionmakingofhighcomplexityCounselingandorcoor',\n",
              " 'Criticalcareevaluationandmanagementofthecriticallyillorcriticallyinjuredpatientfirst3074minutes',\n",
              " 'Intravenousinfusionfortherapyprophylaxisordiagnosisspecifysubstanceordrugadditionalsequentialinfusionofanewdrugsubstanceupto1hourListseparatelyinadditiontocodeforprimaryprocedure',\n",
              " 'IntravenousinfusionfortherapyprophylaxisordiagnosisspecifysubstanceordrugeachadditionalhourListseparatelyinadditiontocodeforprimaryprocedure',\n",
              " 'CULTBLOOD',\n",
              " 'GasesbloodanycombinationofpHpCO2pO2CO2HCO3includingcalculatedO2saturationwithO2saturationbydirectmeasurementexceptpulseoximetry',\n",
              " 'Lactatelacticacid',\n",
              " 'POCHESTPAORAP',\n",
              " 'Anticoagulants',\n",
              " 'Magnesium',\n",
              " 'Radiologicexaminationchestsingleview',\n",
              " 'MAGNESIUMQuantitative_na',\n",
              " 'Subsequenthospitalcareperdayfortheevaluationandmanagementofapatientwhichrequiresatleast2ofthese3keycomponentsAnexpandedproblemfocusedintervalhistoryAnexpandedproblemfocusedexaminationMedicaldecisionmakingofmoder',\n",
              " 'IPCONSULTFORVASCULARACCESSTEAM',\n",
              " 'IPCONSULTTONUTRITIONALSERVICES',\n",
              " 'Culturebacterialbloodaerobicwithisolationandpresumptiveidentificationofisolatesincludesanaerobiccultureifappropriate',\n",
              " 'TherapeuticprophylacticordiagnosticinjectionspecifysubstanceordrugeachadditionalsequentialintravenouspushofthesamesubstancedrugprovidedinafacilityListseparatelyinadditiontocodeforprimaryprocedure',\n",
              " 'Therapeuticactivitiesdirectoneononepatientcontactuseofdynamicactivitiestoimprovefunctionalperformanceeach15minutes',\n",
              " 'MAGNESIUMBLOOD',\n",
              " 'CULTUREBLOOD_x']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(sorted_dict.keys())[0:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "nuVbezT_89Qp",
        "outputId": "ae7257d3-eb1e-49da-9d18-e1be6050ad28"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATPElEQVR4nO3df7RdZX3n8fdnkjFFWWILV+3ww+AQ2xWs7UgMM7Ns7UjVpFoiGpToVJyhg7rIdFrttDjjQqR2TXHVUjukVhQswrSBQalpjaJTlqs/hqEEf2AjohFRQmsJP5YuOkKMfOePs8OcHm+4+5z7+8n7tdZdOXvv53n295zc8zn7PGeffVNVSJLa9U8WuwBJ0vwy6CWpcQa9JDXOoJekxhn0ktS4lYtdwKhjjjmmVq9evdhlSNKycuutt95XVVPTbVtyQb969Wp27dq12GVI0rKS5OuH2ubUjSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNW7JfTP2oH3vvXrsPlNv+rfzUIkkLW8e0UtS4wx6SWqcQS9JjesV9Ek2JLkjyZ4k50+z/aeSfCbJgSSbR7adneQr3c/Zc1W4JKmfGYM+yQpgG7ARWAtsSbJ2pNk3gNcDfzjS94eAtwOnAuuBtyf5wdmXLUnqq88R/XpgT1XdWVX7ge3ApuEGVXVXVd0GPDrS9yXAp6rqgap6EPgUsGEO6pYk9dQn6I8F7h5a3tut66NX3yTnJtmVZNe+fft6Di1J6mNJfBhbVZdV1bqqWjc1Ne1fwpIkTahP0N8DHD+0fFy3ro/Z9JUkzYE+QX8LsCbJiUmeAJwF7Og5/g3Ai5P8YPch7Iu7dZKkBTJj0FfVAWArg4C+Hbi2qnYnuSjJ6QBJnpdkL3Am8L4ku7u+DwC/zuDF4hbgom6dJGmB9LrWTVXtBHaOrLtg6PYtDKZlput7BXDFLGqUJM3CkvgwVpI0fwx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1LheQZ9kQ5I7kuxJcv4021cluabbfnOS1d36f5rkyiRfSHJ7krfObfmSpJnMGPRJVgDbgI3AWmBLkrUjzc4BHqyqk4BLgIu79WcCq6rqx4BTgDccfBGQJC2MPkf064E9VXVnVe0HtgObRtpsAq7sbl8HnJYkQAFPSrISOALYD3x7TiqXJPXSJ+iPBe4eWt7brZu2TVUdAL4FHM0g9P8B+DvgG8BvVdUDoztIcm6SXUl27du3b+w7IUk6tPn+MHY98D3gnwEnAm9J8szRRlV1WVWtq6p1U1NT81ySJB1e+gT9PcDxQ8vHdeumbdNN0xwF3A+8BvhEVX23qu4F/gpYN9uiJUn99Qn6W4A1SU5M8gTgLGDHSJsdwNnd7c3AjVVVDKZrXgiQ5EnAvwS+NBeFS5L6mTHouzn3rcANwO3AtVW1O8lFSU7vml0OHJ1kD/Bm4OApmNuAI5PsZvCC8cGqum2u74Qk6dBW9mlUVTuBnSPrLhi6/TCDUylH+z003fqF8s33vnPsPk9/09vmoRJJWjx+M1aSGmfQS1LjDHpJapxBL0mN6/Vh7OHqS9tGr/TQz4+e99E5rkSSJmfQz7NPv/+lE/X76f/wsTmuRNLhyqkbSWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcV7rZhm47oMbxu6z+d99Yh4qkbQceUQvSY3ziP4w8b6rXjJ2nzf8/A3zUImkheYRvSQ1zqCXpMYZ9JLUOOfo1cuF144/xw9w4av+/zz/xo++cqIxPr7pw4/d/tnr3zl2/51nvG2i/Uqt8Ihekhpn0EtS45y60WHnpR9579h9PvaKN81DJdLCMOilMb3suv8xUb8/3fzaOa5E6sepG0lqnEf00iI4/bo/majfjs0/N8eV6HBg0EvL1Bkf/sux+1z/yuf/o+VXf2TP2GNc84qTxu6jxdUr6JNsAN4DrAA+UFW/ObJ9FfAh4BTgfuDVVXVXt+05wPuAJwOPAs+rqofn6g5IWjzbrv/7ifqdd8bT5rgSPZ4Z5+iTrAC2ARuBtcCWJGtHmp0DPFhVJwGXABd3fVcCVwNvrKqTgZ8Gvjtn1UuSZtTniH49sKeq7gRIsh3YBHxxqM0m4MLu9nXApUkCvBi4rao+D1BV989R3ZIa8fFr7hu7z8ZXHzMPlbSrT9AfC9w9tLwXOPVQbarqQJJvAUcDzwIqyQ3AFLC9qt41uoMk5wLnApxwwgnj3gdJh7nPfuDesfv8i1946jxUsjTN9+mVK4HnA6/t/j0jyWmjjarqsqpaV1Xrpqam5rkkSTq89Dmivwc4fmj5uG7ddG32dvPyRzH4UHYv8OdVdR9Akp3Ac4E/m2XdkjSn/u5do7E2sx/+1WMfu/33v3PrRPt92i+dMlG/cfQJ+luANUlOZBDoZwGvGWmzAzgbuAnYDNxYVQenbH41yROB/cALGHxYK0kace+lnxy7z1O3vnjGNjMGfTfnvhW4gcHplVdU1e4kFwG7qmoHcDlwVZI9wAMMXgyoqgeT/DaDF4sCdlbVx8a+J5KkifU6j76qdgI7R9ZdMHT7YeDMQ/S9msEplpKkReC1biSpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJalyvoE+yIckdSfYkOX+a7auSXNNtvznJ6pHtJyR5KMmvzE3ZkqS+Zgz6JCuAbcBGYC2wJcnakWbnAA9W1UnAJcDFI9t/G/j47MuVJI2rzxH9emBPVd1ZVfuB7cCmkTabgCu729cBpyUJQJKXA18Dds9NyZKkcfQJ+mOBu4eW93brpm1TVQeAbwFHJzkS+DXgHY+3gyTnJtmVZNe+ffv61i5J6mG+P4y9ELikqh56vEZVdVlVrauqdVNTU/NckiQdXlb2aHMPcPzQ8nHduuna7E2yEjgKuB84Fdic5F3AU4BHkzxcVZfOunJJUi99gv4WYE2SExkE+lnAa0ba7ADOBm4CNgM3VlUBP3mwQZILgYcMeUlaWDMGfVUdSLIVuAFYAVxRVbuTXATsqqodwOXAVUn2AA8weDGQJC0BfY7oqaqdwM6RdRcM3X4YOHOGMS6coD5J0iz5zVhJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhrXK+iTbEhyR5I9Sc6fZvuqJNd0229Osrpb/6Iktyb5QvfvC+e2fEnSTGYM+iQrgG3ARmAtsCXJ2pFm5wAPVtVJwCXAxd36+4Cfq6ofA84GrpqrwiVJ/fQ5ol8P7KmqO6tqP7Ad2DTSZhNwZXf7OuC0JKmqz1bV33brdwNHJFk1F4VLkvrpE/THAncPLe/t1k3bpqoOAN8Cjh5p80rgM1X1yOgOkpybZFeSXfv27etbuySphwX5MDbJyQymc94w3faquqyq1lXVuqmpqYUoSZIOG32C/h7g+KHl47p107ZJshI4Cri/Wz4OuB54XVV9dbYFS5LG0yfobwHWJDkxyROAs4AdI212MPiwFWAzcGNVVZKnAB8Dzq+qv5qroiVJ/c0Y9N2c+1bgBuB24Nqq2p3koiSnd80uB45Osgd4M3DwFMytwEnABUk+1/08dc7vhSTpkFb2aVRVO4GdI+suGLr9MHDmNP3eCbxzljVKkmbBb8ZKUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktS4XkGfZEOSO5LsSXL+NNtXJbmm235zktVD297arb8jyUvmrnRJUh8zBn2SFcA2YCOwFtiSZO1Is3OAB6vqJOAS4OKu71rgLOBkYAPwe914kqQF0ueIfj2wp6rurKr9wHZg00ibTcCV3e3rgNOSpFu/vaoeqaqvAXu68SRJCyRV9fgNks3Ahqr6hW7554FTq2rrUJu/6drs7Za/CpwKXAj8n6q6ult/OfDxqrpuZB/nAud2iz8C3DFD3ccA9/W5g/PUv6UxlkINS2WMpVDDUhljKdSwVMZYCjX0GeMZVTU13YaVs9zxnKiqy4DL+rZPsquq1k26v9n2b2mMpVDDUhljKdSwVMZYCjUslTGWQg2zHaPP1M09wPFDy8d166Ztk2QlcBRwf8++kqR51CfobwHWJDkxyRMYfLi6Y6TNDuDs7vZm4MYazAntAM7qzso5EVgD/PXclC5J6mPGqZuqOpBkK3ADsAK4oqp2J7kI2FVVO4DLgauS7AEeYPBiQNfuWuCLwAHgvKr63hzU3XuaZ576tzTGUqhhqYyxFGpYKmMshRqWyhhLoYZZjTHjh7GSpOXNb8ZKUuMMeklq3LIK+iQvT1JJfnTC/t9L8rkkn0/ymST/eoIxnp5ke5KvJrk1yc4kz5qght1dHW9JMvb/w9A4B3++79IUE4yxesz+T0vyh0nu7B6Lm5KcMUb/h0aWX5/k0nFqONRYCz3GcN8kP5vky0mesYD7ryRXDy2vTLIvyZ9OMM67h5Z/JcmFY45xXJKPJvlK9zx5T3cixzhjHPzd/Jsk/zPJE2dRw51JLk2yahY1/EmSp4zTf2ic/9o932/rxjt1jL5HDz0/v5nknqHl3o/psgp6YAvwl92/k/hOVf1EVf048Fbgv43Tufu27/XAp6vqn1fVKd04T5ughpOBFzG4tMTbx6ljZJyDP785B2Pc1bdj91j8MfDnVfXM7rE4i8EptIetJKcBvwtsrKqvL+Cu/wF4dpIjuuUXMdmpzI8Ar0hyzCRFdL8XHwH+uKrWAM8CjgR+Y8yhDv5uPhvYD7xxFjWsAY4A3jWLGh4AzhuzP0n+FfAy4LlV9RzgZ4C7+/avqvsPPj+B3wcuGXq+7u87zrIJ+iRHAs9ncF2ds+ZgyCcDD47Z598A362q3z+4oqo+X1V/MUkBVXUvg28Eb+1+OZeTFwL7Rx6Lr1fVf1/EmhZVkp8C3g+8rKq+uggl7ARe2t3eAvzRBGMcYHB2xy9PWMMLgYer6oMA3Vl2vwz8+3GPyof8BXDSHNTwui5HJnETcOwE/X4YuK+qHulqua+q/nbCGia2bIKewXVzPlFVXwbuT3LKBGMc0b3l+RLwAeDXx+z/bODWCfZ7SFV1J4PTVp86Ztcj8o+nXV49we6Hx7h+zL4nA5+ZYJ+H2v/ngItmOd5iWsXgHc7Lq+pLi1TDdgbfW/kB4DnAzROOsw14bZKjJuh7MiPPkar6NvANxgtr4LEvYG4EvjAHNdw1YQ0rgNP4/u8P9fFJ4PhuKu/3krxggjFmbUlcAqGnLcB7utvbu+VxQ/c73Vugg2+pPpTk2bU8zzF97L4s8hgAJNnG4B3X/qp63iT7T/J6YFZfE19E3wX+N4N3nP9pMQqoqtu6z1m2MDi6n3Scbyf5EPCLwHfmprqxHdG9+MPgiP7yRazhWOB24FPjDlBVD3UHpT/JYEbgmiTnV9UfzGmlM1gWR/RJfojB27EPJLkL+M/Aq2Yz3VFVNzG4SNC0FwE6hN3AJO8kDinJM4HvAffO5bgLYDfw3IMLVXUeg6OecR7PljwKvApYn+S/LGIdO4DfYrJpm2G/w+BF60lj9vsiI8+RJE8GTmBw9dq+hj8/+o/jzEc/Tg1PZ+YLJn5fDcAzgDDBHD0Mpo6q6tNV9XZgK/DKScaZjWUR9Awuq3BVVT2jqlZX1fHA1xi8Sk4kgzN3VjC4Jk9fNwKrMrja5sFxnpNkojqSTDH4gOXSZfiu4kbgB5K8aWjdpHOwTaiq/8tgjvy1Sc5ZpDKuAN5RVeNMdXyfqnoAuJZB2I/jz4AnJnkdPDbt8W7gD7rHZyEcqoZLq2rsdyhd3b8IvKWbSuotyY8kWTO06ieAhfyQHlg+Qb+Fwdkuwz7M+GffPDYnDFwDnD3OJRm6MD4D+JnutLHdDM7c+eYENewG/heDObx3jNF/dJyDP5OcdTOx7rF4OfCCJF9L8tcM/ibBry1kHXOlewI/MttxuoDcALwtyeljdn9ikr1DP2+eYP97q+p3x+13CO9m8K53nP0ffI6cmeQrwJeBh4EFe5czVMPmrob7gUeratwzf4bH/CxwG+NnzpHAlUm+mOQ2Bn+86cJJ65iUl0CQgCQ/Dry/qvzDOI3J4PsyfwScUVWzPYFgWTLoddhL8kYGb81/qao+udj1SHPNoJekxi2XOXpJ0oQMeklqnEEvSY0z6CWpcQa9JDXu/wGaqOHh+pG70wAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "sns.barplot(x = list(string.ascii_uppercase[:20]), y = list(sorted_dict.values())[0:20])\n",
        "plt.savefig('feature_importances.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRyRJe_Wsq0v"
      },
      "outputs": [],
      "source": [
        "names[0] = \"Feature 1\"\n",
        "names[1] = \"Feature 2\"\n",
        "names[2] = \"Feature 3\"\n",
        "names[3] = \"Feature 4\"\n",
        "names[5] = \"Feature 6\"\n",
        "names[10] = \"Feature 11\"\n",
        "names[12] = \"Feature 13\"\n",
        "names[15] = \"Feature 16\"\n",
        "names[16] = \"Feature 17\"\n",
        "names[17] = \"Feature 18\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHEKmUfypA2Y"
      },
      "outputs": [],
      "source": [
        "#from imblearn.over_sampling import SMOTENC\n",
        "#sampler = SMOTENC(categorical_features=indeces,k_neighbors=3)\n",
        "#x_res,y_res = sampler.fit_resample(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ofur5Qu7CQWP"
      },
      "outputs": [],
      "source": [
        "#from imblearn.over_sampling import RandomOverSampler\n",
        "#sampler = RandomOverSampler()\n",
        "#x_res,y_res = sampler.fit_resample(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVEYS6fknkB7"
      },
      "outputs": [],
      "source": [
        "#from imblearn.under_sampling import RandomUnderSampler\n",
        "#sampler = RandomUnderSampler()\n",
        "#x_res,y_res = sampler.fit_resample(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lngXoin9mAnG"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    'method':'bayes'\n",
        "}\n",
        "\n",
        "metric = {\n",
        "    'name':'val_f1',\n",
        "    'goal':'maximize'\n",
        "}\n",
        "\n",
        "sweep_config['metric'] = metric\n",
        "\n",
        "parameters_dict = {\n",
        "    'optomizer': {\n",
        "        'values': ['adam', 'nadam', 'adamax', 'rmsprop', 'adagrad', 'adadelta']\n",
        "    },\n",
        "    'num_layers': {\n",
        "        'values': [1, 2, 3, 4, 5]\n",
        "    },\n",
        "    'num_neurons': {\n",
        "        'values':[1000, 1500, 2000, 2500, 3000,3500,4000,4500,5000]\n",
        "    },\n",
        "    'dropout_rate': {\n",
        "        'distribution': 'q_uniform',\n",
        "        'q': .1,\n",
        "        'min': 0,\n",
        "        'max': .5\n",
        "    },\n",
        "    'learning_rate': {\n",
        "        'values':[0.01, 0.005, 0.001, 0.0005, 0.0001, 5e-05, 1e-05,5e-06, 1e-06,5e-07, 1e-07,5e-08, 1e-08]\n",
        "    },\n",
        "    'regularization_factor': {\n",
        "        'values':[0.01, 0.005, 0.001, 0.0005, 0.0001, 5e-05, 1e-05,5e-06, 1e-06,5e-07, 1e-07,5e-08, 1e-08]\n",
        "    },\n",
        "    'regularization_type': {\n",
        "        'values': ['l1', 'l2', 'l1_l2']\n",
        "    },\n",
        "    'activation_function': {\n",
        "        'values': ['relu', 'leaky_relu', 'elu', 'selu', 'prelu', 'gelu', 'swish']\n",
        "    },\n",
        "    'alpha_value':{\n",
        "        'distribution': 'uniform',\n",
        "        'min': 0,\n",
        "        'max': .5\n",
        "    },\n",
        "    'epochs':{\n",
        "        'values':[100]\n",
        "    }\n",
        "}\n",
        "sweep_config['parameters'] = parameters_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgckgSjrrTEU",
        "outputId": "63ddec9f-bb53-4aaf-c31a-840611b8b2ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: 3yaw2lxr\n",
            "Sweep URL: https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr\n"
          ]
        }
      ],
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"keras_covid_project_smote\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZ8pHs2XtZ3h"
      },
      "outputs": [],
      "source": [
        "##Metrics\n",
        "from keras import backend as K\n",
        "\n",
        "#AUC\n",
        "from tensorflow.keras.metrics import AUC\n",
        "auc = AUC()\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HN8sxoxPuFdF"
      },
      "outputs": [],
      "source": [
        "##Swish\n",
        "#Swish activation function\n",
        "from keras.backend import sigmoid\n",
        "def swish(x, beta = 1):\n",
        "    return (x * sigmoid(beta * x))\n",
        "\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras.layers import Activation\n",
        "  \n",
        "get_custom_objects().update({'swish': Activation(swish)})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJkifwkQuSci"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adagrad, Adam, Adamax, Nadam, RMSprop, Adadelta\n",
        "def choose_optimizer(model,optimizer,learning_rate):\n",
        "  if optimizer == 'adagrad':\n",
        "      model.compile(optimizer=Adagrad(learning_rate),\n",
        "          loss='binary_crossentropy',metrics=[f1,auc,'accuracy'])\n",
        "  if optimizer == 'adadelta':\n",
        "      model.compile(optimizer=Adadelta(learning_rate),\n",
        "          loss='binary_crossentropy',metrics=[f1,auc,'accuracy'])\n",
        "  if optimizer == 'rmsprop':\n",
        "      model.compile(optimizer=RMSprop(learning_rate, momentum = .9),\n",
        "          loss='binary_crossentropy',metrics=[f1,auc,'accuracy'])\n",
        "  if optimizer == 'adam':\n",
        "      model.compile(optimizer=Adam(learning_rate),\n",
        "          loss='binary_crossentropy',metrics=[f1,auc,'accuracy'])\n",
        "  if optimizer == 'nadam':\n",
        "      model.compile(optimizer=Nadam(learning_rate),\n",
        "          loss='binary_crossentropy',metrics=[f1,auc,'accuracy'])\n",
        "  if optimizer == 'adamax':\n",
        "      model.compile(optimizer=Adamax(learning_rate),\n",
        "          loss='binary_crossentropy',metrics=[f1,auc,'accuracy'])\n",
        "  return model\n",
        "\n",
        "      \n",
        "from keras.layers import Dropout,Dense,LeakyReLU,PReLU,Activation\n",
        "def create_layers(model,dropout_rate,act_func,num_layers,num_neurons,regularization,alpha):\n",
        "  for i in range(num_layers):\n",
        "        if act_func == 'relu':\n",
        "            model.add(Dropout(dropout_rate))\n",
        "            model.add(Dense(num_neurons, kernel_regularizer=regularization))\n",
        "            model.add(Activation('relu'))\n",
        "        if act_func == 'leaky_relu':\n",
        "            model.add(Dropout(dropout_rate))\n",
        "            model.add(Dense(num_neurons, kernel_regularizer=regularization))\n",
        "            model.add(LeakyReLU(alpha=alpha))\n",
        "        if act_func == 'prelu':\n",
        "            model.add(Dropout(dropout_rate))\n",
        "            model.add(Dense(num_neurons, kernel_regularizer=regularization))\n",
        "            model.add(PReLU())\n",
        "        if act_func == 'selu':\n",
        "            model.add(Dropout(dropout_rate))\n",
        "            model.add(Dense(num_neurons ,\n",
        "                kernel_initializer='lecun_normal',\n",
        "                kernel_regularizer=regularization))\n",
        "            model.add(Activation('selu'))\n",
        "        if act_func == 'elu':\n",
        "            model.add(Dropout(dropout_rate))\n",
        "            model.add(Dense(num_neurons ,\n",
        "                kernel_initializer='lecun_normal',\n",
        "                kernel_regularizer=regularization))\n",
        "            model.add(Activation('elu'))\n",
        "        if act_func == 'gelu':\n",
        "            model.add(Dropout(dropout_rate))\n",
        "            model.add(Dense(num_neurons ,\n",
        "                kernel_regularizer=regularization))\n",
        "            model.add(Activation('gelu'))\n",
        "        if act_func == 'swish':\n",
        "            model.add(Dropout(dropout_rate))\n",
        "            model.add(Dense(num_neurons ,\n",
        "                kernel_regularizer=regularization))\n",
        "            model.add(Activation('swish'))\n",
        "  return model\n",
        "\n",
        "from keras.regularizers import l1,l2,l1_l2\n",
        "def regularization_wrapper(reg_type, reg_factor):\n",
        "    if reg_type == 'l2':\n",
        "        return l2(reg_factor)\n",
        "    if reg_type == 'l1':\n",
        "        return l1(reg_factor)\n",
        "    if reg_type == 'l1_l2':\n",
        "        return l1_l2(reg_factor,reg_factor)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_02brDxlsBXl"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "def train(config = None):\n",
        "  from keras.layers import Dropout,Dense,LeakyReLU,PReLU,InputLayer, Activation\n",
        "  from keras.regularizers import l1,l2,l1_l2\n",
        "  from tensorflow.keras.optimizers import Adagrad, Adam, Adamax, Nadam, RMSprop, Adadelta\n",
        "  from keras.models import Sequential\n",
        "  from wandb.keras import WandbCallback\n",
        "  # Initialize a new wandb run\n",
        "  with wandb.init(config=config):\n",
        "      config = wandb.config\n",
        "      num_columns = 25008\n",
        "      model= Sequential()\n",
        "      model.add(InputLayer(input_shape = (num_columns)))\n",
        "      model = create_layers(model,config.dropout_rate,config.activation_function,config.num_layers,\n",
        "                    config.num_neurons,\n",
        "                    regularization_wrapper(config.regularization_type,config.regularization_factor),\n",
        "                    config.alpha_value)\n",
        "      model = choose_optimizer(model,config.optomizer,config.learning_rate)\n",
        "      model.add(Dropout(config.dropout_rate))\n",
        "      model.add(Dense(1,activation='sigmoid'))\n",
        "      print(model.summary())\n",
        "      model.fit(x_smote,y_smote,epochs = config.epochs,\n",
        "                callbacks = [WandbCallback()],\n",
        "                validation_data=(x_val,y_val))\n",
        "      del model\n",
        "      gc.collect()\n",
        "      \n",
        "      \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "147f6db5ed964e47998a9eabb38ee630",
            "0627bd48064748e8a458f6d0842056d3",
            "047be678707344ccbceb2a2740be51a4",
            "a5ab169cd3624b7baed9ead3c49f0bdf",
            "8c20640a38cb40aeacdccff54535d6fb",
            "4aa51e713c2a4f69952e4409c2c545dc",
            "5890aa2c3a6f4356a8aa0aad5823d1d4",
            "221f05b1263b4f6cb4903b6040e2d613",
            "b814ca6c413a42eca069224122360bcd",
            "933032410d84441488f9e80f56cff944",
            "672ffa62ecb040779fd42336dcd51640",
            "383c74abcc7b4228bb759b6c4a507499",
            "d81b0e8882c24ab4997cabed3f2af7f7",
            "bf408c930cbd46e98e945eb415cb5ad3",
            "c0221487d8104b19be66a3c770fd7ab4",
            "e2dbda7b2ddf439496e803b7880907eb",
            "4f9295dab18e4f4681f85824b79f8e95",
            "33d54a6948da4af794050ede0f0b1c96",
            "fd003816ba49410fafd8927cea07a103",
            "d686ab381ea340f5ada4ca69de62bf9b",
            "b8d7b044a5614a5abb7463bc0aaa4eeb",
            "7fadf3018b2e412b8e1df86d937b951d",
            "e955c6a610214907b94507ee631403db",
            "2c5b1e9034914a07bc3cce8e91c5f5aa",
            "656423f5b93549a9b3ff088eac96d1a3",
            "dbba3d8d3e8c4c88bea9c3a108122197",
            "a5a269f56b2e45379c962b469b57d246",
            "f023046112d24eb39383fb4fcba7b784",
            "c0b612939aaa4130be0a3aa9641e5c8d",
            "c15ab0c3d260486ea401151be534d522",
            "daa182b8727048e59ae9b96dcb76e22d",
            "b64662943a954a149d327d59525adc9d",
            "d78ed3cdf26c4919ab928b79936a8d26",
            "746be641f4eb4336810a370937529ec3",
            "fb3307f0a6054589ad2bd7e8ba75091a",
            "65094cf336644ebc9f09b8b80abbcfce",
            "80e4c88a3fcd404a856986326c30841c",
            "44d8224562bd4a928229c2884c056414",
            "8a694d4988f445899c738d1dcd332d5d",
            "22416b49de2343539ea2226d7492ace6",
            "aa5ef451cf1b41ee89fe659d6eaf2ca9",
            "8eb32e380189472bb1124be188eb6fba",
            "af3fec8c40a2439baceb6862f7f3ad5f",
            "984022d453294177915a103822b1b221",
            "22c7c56dece94dfe9f4991a39a8946c0",
            "8501b1e875024a45a85bdcaa7dea7713",
            "c7bb658bb2a543cba63af1d7ee02e24c",
            "031eecda2a3a49aeb1502a6a0a656900",
            "886b94f6e0f040d19a097498370fb909",
            "4c3ea7c97f814a53aa4f358a90c769d0",
            "d2dbb4fbd77649aaaa067da91d855284",
            "304ec67ad5c1499c87c1b7d75d8f5378",
            "03c0dd3ebb25497d91f54de838a1bd90",
            "8422b371fb5e410fb6ae489de906d6b5",
            "0aecb94ed7f24cf98b1c15eef520882e",
            "429885073d27410e81a0b2517ee80fd4",
            "50e11e8588b54904853d446c2b47f0f1",
            "8c6e281e67584b76bc944607085c4f24",
            "c8c4915b1b364314ba6e454e034b843d",
            "a2bc251ff7594fa6b038b2e1dd106262",
            "02283f4cd4834f569561e1d1407b1192",
            "b83779855373437a92ddc30ec78173bc",
            "70cc82d0b6204eb48d261491d547386c",
            "26c8f85d4d03426f8378d063ea206ea7",
            "ef42712a0646452abf974574a0b857a3",
            "e640ed38938f4bb69b54c0b8ef2a682a",
            "1f2c3d2dc2de4e90a2b813b9969329dc",
            "63137b1d4e5d4723aebccb2eba4bf5f7",
            "2a8632fed7a14bc09ccd964a1da71ddc",
            "1c80390371ce412f9405dcfd78d818c6",
            "b0e3f703d2614c39bf0eea030a788078",
            "0f0b1a48e4fc48aa8582c4c1f99e1a40",
            "01a9c1ddd0c84be2b03fbb9cdf63d5e2",
            "6f48d4a57f994260be0b31e834500ff8",
            "2b5e70e579d143ee8c0721b6b4f9e137",
            "cf6c4fd7721d4026ba3d4ebd85ab7dc4",
            "fdfafeb8cfed436f96273dc83209a98c",
            "67977e64e1d244538c3b82631486d4b7",
            "58d11786d32d4fbdbf0a2a1241c015f3",
            "aa478e4da1ef4a5b897af4d92a071bbb",
            "2e46da6294a249679a80abc9a88bb57f",
            "8ee1a27640aa4a48a70900d5e672f011",
            "04e77dc689054672b237c279c4352787",
            "8acf3909cabe4ffd8bd6e27592158aee",
            "691318705c7049beac18cc35c9384842",
            "e7064a75f959434b9980e989e39c063d",
            "1a97f6c86cfc4d47b1afade750017f3b",
            "46728db06ac6404b84def61490dca40b",
            "a58bc5bb5ecd48c6b1cd9e21f2af7e07",
            "cfc5cdfc034d4b6aa5186c5191e04376",
            "2cd8cabe28c346c69abde5aaf98fe76a",
            "97f0b47eec9c418b8239b28326034c8b",
            "328cf0d6f7e14dfbb2328414ab928c91",
            "d0e562ddf8644f9f8f3a4935ad3109a9",
            "45adcf8bbffc40de812824ded8ca2ff0",
            "dee339902dcf46a381f0af0d3fff2d7a",
            "bc19544654fd4ec5a1570f30e61ae58e",
            "3395603d8d954854847bbabd92a439c1",
            "cd994673e05e44dc92e9e78de8211f6c",
            "cafb262aaade4926a3233e70930f42eb",
            "4bd6b4028642412abb13c51888a628d7",
            "28ca99c6d9244cdd9071fc4379d32529",
            "3d999e27b3a54b0f95e8f68627b31ae3",
            "5137676b8917446183104dc3d4647755"
          ]
        },
        "collapsed": true,
        "id": "nsAYTnUHOgOo",
        "outputId": "f8fc2dc5-fa57-46e7-ad1f-51eaee6c055f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sbukasbv with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: gelu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_value: 0.4921595360924587\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons: 5000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptomizer: adadelta\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_factor: 0.0005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_type: l1_l2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.19"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220627_165743-sbukasbv</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/sbukasbv\" target=\"_blank\">wise-sweep-1</a></strong> to <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 25008)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5000)              125045000 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 5000)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5000)              25005000  \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 5000)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5000)              25005000  \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 5000)              0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5000)              25005000  \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 5000)              0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 5001      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 200,065,001\n",
            "Trainable params: 200,065,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "Epoch 1/100\n",
            "380/380 [==============================] - 26s 61ms/step - loss: 904.0198 - f1: 0.7032 - auc: 0.7087 - accuracy: 0.6380 - val_loss: 894.2480 - val_f1: 0.3549 - val_auc: 0.8367 - val_accuracy: 0.4355 - _timestamp: 1656349088.0000 - _runtime: 25.0000\n",
            "Epoch 2/100\n",
            "380/380 [==============================] - 26s 69ms/step - loss: 884.5775 - f1: 0.7546 - auc: 0.8410 - accuracy: 0.6890 - val_loss: 874.8990 - val_f1: 0.3644 - val_auc: 0.8664 - val_accuracy: 0.4611 - _timestamp: 1656349111.0000 - _runtime: 48.0000\n",
            "Epoch 3/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 865.3349 - f1: 0.7585 - auc: 0.8648 - accuracy: 0.6942 - val_loss: 855.7782 - val_f1: 0.3719 - val_auc: 0.8695 - val_accuracy: 0.4794 - _timestamp: 1656349137.0000 - _runtime: 74.0000\n",
            "Epoch 4/100\n",
            "380/380 [==============================] - 23s 62ms/step - loss: 846.3238 - f1: 0.7628 - auc: 0.8749 - accuracy: 0.7030 - val_loss: 836.8864 - val_f1: 0.3813 - val_auc: 0.8729 - val_accuracy: 0.4983 - _timestamp: 1656349161.0000 - _runtime: 98.0000\n",
            "Epoch 5/100\n",
            "380/380 [==============================] - 23s 62ms/step - loss: 827.5416 - f1: 0.7704 - auc: 0.8801 - accuracy: 0.7159 - val_loss: 818.2231 - val_f1: 0.3850 - val_auc: 0.8755 - val_accuracy: 0.5128 - _timestamp: 1656349184.0000 - _runtime: 121.0000\n",
            "Epoch 6/100\n",
            "380/380 [==============================] - 24s 62ms/step - loss: 808.9889 - f1: 0.7777 - auc: 0.8848 - accuracy: 0.7285 - val_loss: 799.7891 - val_f1: 0.3939 - val_auc: 0.8763 - val_accuracy: 0.5328 - _timestamp: 1656349208.0000 - _runtime: 145.0000\n",
            "Epoch 7/100\n",
            "380/380 [==============================] - 27s 70ms/step - loss: 790.6661 - f1: 0.7829 - auc: 0.8873 - accuracy: 0.7365 - val_loss: 781.5841 - val_f1: 0.4036 - val_auc: 0.8773 - val_accuracy: 0.5534 - _timestamp: 1656349231.0000 - _runtime: 168.0000\n",
            "Epoch 8/100\n",
            "380/380 [==============================] - 24s 62ms/step - loss: 772.5724 - f1: 0.7921 - auc: 0.8909 - accuracy: 0.7505 - val_loss: 763.6085 - val_f1: 0.4139 - val_auc: 0.8779 - val_accuracy: 0.5740 - _timestamp: 1656349258.0000 - _runtime: 195.0000\n",
            "Epoch 9/100\n",
            "380/380 [==============================] - 26s 69ms/step - loss: 754.7083 - f1: 0.7963 - auc: 0.8921 - accuracy: 0.7579 - val_loss: 745.8619 - val_f1: 0.4225 - val_auc: 0.8781 - val_accuracy: 0.5907 - _timestamp: 1656349282.0000 - _runtime: 219.0000\n",
            "Epoch 10/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 737.0729 - f1: 0.7999 - auc: 0.8940 - accuracy: 0.7639 - val_loss: 728.3441 - val_f1: 0.4326 - val_auc: 0.8789 - val_accuracy: 0.6096 - _timestamp: 1656349308.0000 - _runtime: 245.0000\n",
            "Epoch 11/100\n",
            "380/380 [==============================] - 25s 67ms/step - loss: 719.6668 - f1: 0.8063 - auc: 0.8959 - accuracy: 0.7722 - val_loss: 711.0547 - val_f1: 0.4387 - val_auc: 0.8791 - val_accuracy: 0.6218 - _timestamp: 1656349332.0000 - _runtime: 269.0000\n",
            "Epoch 12/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 702.4894 - f1: 0.8108 - auc: 0.8960 - accuracy: 0.7808 - val_loss: 693.9943 - val_f1: 0.4461 - val_auc: 0.8787 - val_accuracy: 0.6346 - _timestamp: 1656349357.0000 - _runtime: 294.0000\n",
            "Epoch 13/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 685.5410 - f1: 0.8161 - auc: 0.8989 - accuracy: 0.7882 - val_loss: 677.1627 - val_f1: 0.4551 - val_auc: 0.8797 - val_accuracy: 0.6502 - _timestamp: 1656349381.0000 - _runtime: 318.0000\n",
            "Epoch 14/100\n",
            "380/380 [==============================] - 24s 62ms/step - loss: 668.8212 - f1: 0.8200 - auc: 0.9003 - accuracy: 0.7939 - val_loss: 660.5591 - val_f1: 0.4662 - val_auc: 0.8802 - val_accuracy: 0.6685 - _timestamp: 1656349405.0000 - _runtime: 342.0000\n",
            "Epoch 15/100\n",
            "380/380 [==============================] - 24s 62ms/step - loss: 652.3304 - f1: 0.8238 - auc: 0.9016 - accuracy: 0.7995 - val_loss: 644.1837 - val_f1: 0.4756 - val_auc: 0.8804 - val_accuracy: 0.6824 - _timestamp: 1656349429.0000 - _runtime: 366.0000\n",
            "Epoch 16/100\n",
            "380/380 [==============================] - 26s 68ms/step - loss: 636.0675 - f1: 0.8266 - auc: 0.9030 - accuracy: 0.8053 - val_loss: 628.0368 - val_f1: 0.4837 - val_auc: 0.8805 - val_accuracy: 0.6941 - _timestamp: 1656349452.0000 - _runtime: 389.0000\n",
            "Epoch 17/100\n",
            "380/380 [==============================] - 23s 62ms/step - loss: 620.0334 - f1: 0.8303 - auc: 0.9043 - accuracy: 0.8105 - val_loss: 612.1177 - val_f1: 0.4922 - val_auc: 0.8801 - val_accuracy: 0.7058 - _timestamp: 1656349478.0000 - _runtime: 415.0000\n",
            "Epoch 18/100\n",
            "380/380 [==============================] - 25s 65ms/step - loss: 604.2272 - f1: 0.8341 - auc: 0.9069 - accuracy: 0.8162 - val_loss: 596.4273 - val_f1: 0.4968 - val_auc: 0.8803 - val_accuracy: 0.7136 - _timestamp: 1656349501.0000 - _runtime: 438.0000\n",
            "Epoch 19/100\n",
            "380/380 [==============================] - 25s 65ms/step - loss: 588.6508 - f1: 0.8355 - auc: 0.9077 - accuracy: 0.8199 - val_loss: 580.9651 - val_f1: 0.5014 - val_auc: 0.8803 - val_accuracy: 0.7225 - _timestamp: 1656349526.0000 - _runtime: 463.0000\n",
            "Epoch 20/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 573.3018 - f1: 0.8383 - auc: 0.9091 - accuracy: 0.8234 - val_loss: 565.7310 - val_f1: 0.5070 - val_auc: 0.8802 - val_accuracy: 0.7319 - _timestamp: 1656349550.0000 - _runtime: 487.0000\n",
            "Epoch 21/100\n",
            "380/380 [==============================] - 25s 66ms/step - loss: 558.1826 - f1: 0.8426 - auc: 0.9104 - accuracy: 0.8277 - val_loss: 550.7257 - val_f1: 0.5135 - val_auc: 0.8803 - val_accuracy: 0.7392 - _timestamp: 1656349574.0000 - _runtime: 511.0000\n",
            "Epoch 22/100\n",
            "380/380 [==============================] - 24s 62ms/step - loss: 543.2913 - f1: 0.8435 - auc: 0.9121 - accuracy: 0.8313 - val_loss: 535.9495 - val_f1: 0.5198 - val_auc: 0.8800 - val_accuracy: 0.7475 - _timestamp: 1656349599.0000 - _runtime: 536.0000\n",
            "Epoch 23/100\n",
            "380/380 [==============================] - 25s 67ms/step - loss: 528.6290 - f1: 0.8453 - auc: 0.9132 - accuracy: 0.8329 - val_loss: 521.4019 - val_f1: 0.5193 - val_auc: 0.8796 - val_accuracy: 0.7497 - _timestamp: 1656349623.0000 - _runtime: 560.0000\n",
            "Epoch 24/100\n",
            "380/380 [==============================] - 25s 65ms/step - loss: 514.1949 - f1: 0.8471 - auc: 0.9149 - accuracy: 0.8347 - val_loss: 507.0820 - val_f1: 0.5235 - val_auc: 0.8791 - val_accuracy: 0.7558 - _timestamp: 1656349648.0000 - _runtime: 585.0000\n",
            "Epoch 25/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 499.9902 - f1: 0.8480 - auc: 0.9167 - accuracy: 0.8390 - val_loss: 492.9927 - val_f1: 0.5246 - val_auc: 0.8791 - val_accuracy: 0.7581 - _timestamp: 1656349673.0000 - _runtime: 610.0000\n",
            "Epoch 26/100\n",
            "380/380 [==============================] - 27s 70ms/step - loss: 486.0140 - f1: 0.8502 - auc: 0.9179 - accuracy: 0.8413 - val_loss: 479.1312 - val_f1: 0.5231 - val_auc: 0.8788 - val_accuracy: 0.7625 - _timestamp: 1656349697.0000 - _runtime: 634.0000\n",
            "Epoch 27/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 472.2660 - f1: 0.8523 - auc: 0.9199 - accuracy: 0.8430 - val_loss: 465.4992 - val_f1: 0.5226 - val_auc: 0.8787 - val_accuracy: 0.7642 - _timestamp: 1656349724.0000 - _runtime: 661.0000\n",
            "Epoch 28/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 458.7460 - f1: 0.8538 - auc: 0.9217 - accuracy: 0.8452 - val_loss: 452.0938 - val_f1: 0.5220 - val_auc: 0.8784 - val_accuracy: 0.7675 - _timestamp: 1656349748.0000 - _runtime: 685.0000\n",
            "Epoch 29/100\n",
            "380/380 [==============================] - 26s 69ms/step - loss: 445.4540 - f1: 0.8557 - auc: 0.9230 - accuracy: 0.8482 - val_loss: 438.9166 - val_f1: 0.5243 - val_auc: 0.8782 - val_accuracy: 0.7714 - _timestamp: 1656349771.0000 - _runtime: 708.0000\n",
            "Epoch 30/100\n",
            "380/380 [==============================] - 25s 65ms/step - loss: 432.3911 - f1: 0.8540 - auc: 0.9241 - accuracy: 0.8483 - val_loss: 425.9675 - val_f1: 0.5251 - val_auc: 0.8781 - val_accuracy: 0.7742 - _timestamp: 1656349798.0000 - _runtime: 735.0000\n",
            "Epoch 31/100\n",
            "380/380 [==============================] - 24s 62ms/step - loss: 419.5550 - f1: 0.8574 - auc: 0.9259 - accuracy: 0.8503 - val_loss: 413.2458 - val_f1: 0.5283 - val_auc: 0.8777 - val_accuracy: 0.7792 - _timestamp: 1656349822.0000 - _runtime: 759.0000\n",
            "Epoch 32/100\n",
            "380/380 [==============================] - 24s 62ms/step - loss: 406.9481 - f1: 0.8579 - auc: 0.9266 - accuracy: 0.8526 - val_loss: 400.7532 - val_f1: 0.5248 - val_auc: 0.8775 - val_accuracy: 0.7792 - _timestamp: 1656349846.0000 - _runtime: 783.0000\n",
            "Epoch 33/100\n",
            "380/380 [==============================] - 24s 62ms/step - loss: 394.5676 - f1: 0.8597 - auc: 0.9280 - accuracy: 0.8534 - val_loss: 388.4878 - val_f1: 0.5267 - val_auc: 0.8776 - val_accuracy: 0.7809 - _timestamp: 1656349870.0000 - _runtime: 807.0000\n",
            "Epoch 34/100\n",
            "380/380 [==============================] - 26s 67ms/step - loss: 382.4141 - f1: 0.8619 - auc: 0.9291 - accuracy: 0.8558 - val_loss: 376.4472 - val_f1: 0.5250 - val_auc: 0.8774 - val_accuracy: 0.7814 - _timestamp: 1656349893.0000 - _runtime: 830.0000\n",
            "Epoch 35/100\n",
            "380/380 [==============================] - 25s 66ms/step - loss: 370.4870 - f1: 0.8639 - auc: 0.9307 - accuracy: 0.8590 - val_loss: 364.6374 - val_f1: 0.5250 - val_auc: 0.8774 - val_accuracy: 0.7814 - _timestamp: 1656349919.0000 - _runtime: 856.0000\n",
            "Epoch 36/100\n",
            "380/380 [==============================] - 24s 62ms/step - loss: 358.7881 - f1: 0.8628 - auc: 0.9314 - accuracy: 0.8582 - val_loss: 353.0517 - val_f1: 0.5254 - val_auc: 0.8771 - val_accuracy: 0.7825 - _timestamp: 1656349944.0000 - _runtime: 881.0000\n",
            "Epoch 37/100\n",
            "380/380 [==============================] - 25s 65ms/step - loss: 347.3149 - f1: 0.8658 - auc: 0.9326 - accuracy: 0.8609 - val_loss: 341.6932 - val_f1: 0.5236 - val_auc: 0.8771 - val_accuracy: 0.7831 - _timestamp: 1656349968.0000 - _runtime: 905.0000\n",
            "Epoch 38/100\n",
            "380/380 [==============================] - 24s 62ms/step - loss: 336.0686 - f1: 0.8648 - auc: 0.9337 - accuracy: 0.8600 - val_loss: 330.5604 - val_f1: 0.5261 - val_auc: 0.8770 - val_accuracy: 0.7859 - _timestamp: 1656349992.0000 - _runtime: 929.0000\n",
            "Epoch 39/100\n",
            "380/380 [==============================] - 27s 70ms/step - loss: 325.0489 - f1: 0.8647 - auc: 0.9345 - accuracy: 0.8611 - val_loss: 319.6538 - val_f1: 0.5290 - val_auc: 0.8771 - val_accuracy: 0.7892 - _timestamp: 1656350016.0000 - _runtime: 953.0000\n",
            "Epoch 40/100\n",
            "380/380 [==============================] - 24s 64ms/step - loss: 314.2560 - f1: 0.8672 - auc: 0.9354 - accuracy: 0.8623 - val_loss: 308.9733 - val_f1: 0.5313 - val_auc: 0.8768 - val_accuracy: 0.7925 - _timestamp: 1656350043.0000 - _runtime: 980.0000\n",
            "Epoch 41/100\n",
            "380/380 [==============================] - 24s 62ms/step - loss: 303.6886 - f1: 0.8687 - auc: 0.9364 - accuracy: 0.8640 - val_loss: 298.5212 - val_f1: 0.5318 - val_auc: 0.8772 - val_accuracy: 0.7931 - _timestamp: 1656350067.0000 - _runtime: 1004.0000\n",
            "Epoch 42/100\n",
            "380/380 [==============================] - 24s 62ms/step - loss: 293.3474 - f1: 0.8689 - auc: 0.9372 - accuracy: 0.8659 - val_loss: 288.2939 - val_f1: 0.5336 - val_auc: 0.8771 - val_accuracy: 0.7948 - _timestamp: 1656350090.0000 - _runtime: 1027.0000\n",
            "Epoch 43/100\n",
            "380/380 [==============================] - 25s 65ms/step - loss: 283.2334 - f1: 0.8694 - auc: 0.9373 - accuracy: 0.8657 - val_loss: 278.2928 - val_f1: 0.5318 - val_auc: 0.8773 - val_accuracy: 0.7942 - _timestamp: 1656350114.0000 - _runtime: 1051.0000\n",
            "Epoch 44/100\n",
            "380/380 [==============================] - 24s 62ms/step - loss: 273.3439 - f1: 0.8707 - auc: 0.9378 - accuracy: 0.8663 - val_loss: 268.5167 - val_f1: 0.5318 - val_auc: 0.8775 - val_accuracy: 0.7942 - _timestamp: 1656350139.0000 - _runtime: 1076.0000\n",
            "Epoch 45/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 263.6798 - f1: 0.8714 - auc: 0.9388 - accuracy: 0.8670 - val_loss: 258.9678 - val_f1: 0.5313 - val_auc: 0.8778 - val_accuracy: 0.7937 - _timestamp: 1656350163.0000 - _runtime: 1100.0000\n",
            "Epoch 46/100\n",
            "380/380 [==============================] - 25s 65ms/step - loss: 254.2418 - f1: 0.8723 - auc: 0.9397 - accuracy: 0.8679 - val_loss: 249.6423 - val_f1: 0.5322 - val_auc: 0.8779 - val_accuracy: 0.7948 - _timestamp: 1656350186.0000 - _runtime: 1123.0000\n",
            "Epoch 47/100\n",
            "380/380 [==============================] - 25s 65ms/step - loss: 245.0303 - f1: 0.8725 - auc: 0.9399 - accuracy: 0.8684 - val_loss: 240.5440 - val_f1: 0.5311 - val_auc: 0.8783 - val_accuracy: 0.7942 - _timestamp: 1656350211.0000 - _runtime: 1148.0000\n",
            "Epoch 48/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 236.0429 - f1: 0.8740 - auc: 0.9407 - accuracy: 0.8705 - val_loss: 231.6718 - val_f1: 0.5313 - val_auc: 0.8788 - val_accuracy: 0.7937 - _timestamp: 1656350236.0000 - _runtime: 1173.0000\n",
            "Epoch 49/100\n",
            "380/380 [==============================] - 25s 65ms/step - loss: 227.2808 - f1: 0.8722 - auc: 0.9416 - accuracy: 0.8690 - val_loss: 223.0211 - val_f1: 0.5306 - val_auc: 0.8788 - val_accuracy: 0.7937 - _timestamp: 1656350259.0000 - _runtime: 1196.0000\n",
            "Epoch 50/100\n",
            "380/380 [==============================] - 24s 64ms/step - loss: 218.7450 - f1: 0.8751 - auc: 0.9417 - accuracy: 0.8710 - val_loss: 214.5962 - val_f1: 0.5312 - val_auc: 0.8790 - val_accuracy: 0.7953 - _timestamp: 1656350284.0000 - _runtime: 1221.0000\n",
            "Epoch 51/100\n",
            "380/380 [==============================] - 26s 68ms/step - loss: 210.4345 - f1: 0.8729 - auc: 0.9418 - accuracy: 0.8690 - val_loss: 206.3985 - val_f1: 0.5304 - val_auc: 0.8797 - val_accuracy: 0.7942 - _timestamp: 1656350308.0000 - _runtime: 1245.0000\n",
            "Epoch 52/100\n",
            "380/380 [==============================] - 25s 65ms/step - loss: 202.3486 - f1: 0.8751 - auc: 0.9423 - accuracy: 0.8711 - val_loss: 198.4259 - val_f1: 0.5311 - val_auc: 0.8800 - val_accuracy: 0.7948 - _timestamp: 1656350334.0000 - _runtime: 1271.0000\n",
            "Epoch 53/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 194.4884 - f1: 0.8759 - auc: 0.9428 - accuracy: 0.8726 - val_loss: 190.6808 - val_f1: 0.5303 - val_auc: 0.8808 - val_accuracy: 0.7937 - _timestamp: 1656350359.0000 - _runtime: 1296.0000\n",
            "Epoch 54/100\n",
            "380/380 [==============================] - 25s 67ms/step - loss: 186.8524 - f1: 0.8756 - auc: 0.9431 - accuracy: 0.8730 - val_loss: 183.1579 - val_f1: 0.5312 - val_auc: 0.8813 - val_accuracy: 0.7937 - _timestamp: 1656350383.0000 - _runtime: 1320.0000\n",
            "Epoch 55/100\n",
            "380/380 [==============================] - 24s 64ms/step - loss: 179.4416 - f1: 0.8759 - auc: 0.9433 - accuracy: 0.8729 - val_loss: 175.8586 - val_f1: 0.5330 - val_auc: 0.8819 - val_accuracy: 0.7953 - _timestamp: 1656350408.0000 - _runtime: 1345.0000\n",
            "Epoch 56/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 172.2566 - f1: 0.8748 - auc: 0.9429 - accuracy: 0.8723 - val_loss: 168.7850 - val_f1: 0.5336 - val_auc: 0.8826 - val_accuracy: 0.7959 - _timestamp: 1656350432.0000 - _runtime: 1369.0000\n",
            "Epoch 57/100\n",
            "380/380 [==============================] - 24s 64ms/step - loss: 165.2957 - f1: 0.8754 - auc: 0.9430 - accuracy: 0.8716 - val_loss: 161.9375 - val_f1: 0.5386 - val_auc: 0.8833 - val_accuracy: 0.7964 - _timestamp: 1656350456.0000 - _runtime: 1393.0000\n",
            "Epoch 58/100\n",
            "380/380 [==============================] - 24s 64ms/step - loss: 158.5589 - f1: 0.8755 - auc: 0.9427 - accuracy: 0.8721 - val_loss: 155.3123 - val_f1: 0.5379 - val_auc: 0.8838 - val_accuracy: 0.7964 - _timestamp: 1656350481.0000 - _runtime: 1418.0000\n",
            "Epoch 59/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 152.0464 - f1: 0.8758 - auc: 0.9428 - accuracy: 0.8716 - val_loss: 148.9131 - val_f1: 0.5371 - val_auc: 0.8850 - val_accuracy: 0.7948 - _timestamp: 1656350505.0000 - _runtime: 1442.0000\n",
            "Epoch 60/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 145.7577 - f1: 0.8762 - auc: 0.9425 - accuracy: 0.8731 - val_loss: 142.7373 - val_f1: 0.5403 - val_auc: 0.8855 - val_accuracy: 0.7953 - _timestamp: 1656350529.0000 - _runtime: 1466.0000\n",
            "Epoch 61/100\n",
            "380/380 [==============================] - 25s 65ms/step - loss: 139.6935 - f1: 0.8757 - auc: 0.9426 - accuracy: 0.8719 - val_loss: 136.7856 - val_f1: 0.5441 - val_auc: 0.8863 - val_accuracy: 0.7970 - _timestamp: 1656350553.0000 - _runtime: 1490.0000\n",
            "Epoch 62/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 133.8533 - f1: 0.8765 - auc: 0.9423 - accuracy: 0.8726 - val_loss: 131.0558 - val_f1: 0.5450 - val_auc: 0.8870 - val_accuracy: 0.7981 - _timestamp: 1656350578.0000 - _runtime: 1515.0000\n",
            "Epoch 63/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 128.2364 - f1: 0.8763 - auc: 0.9418 - accuracy: 0.8719 - val_loss: 125.5507 - val_f1: 0.5471 - val_auc: 0.8875 - val_accuracy: 0.7981 - _timestamp: 1656350602.0000 - _runtime: 1539.0000\n",
            "Epoch 64/100\n",
            "380/380 [==============================] - 32s 83ms/step - loss: 122.8433 - f1: 0.8757 - auc: 0.9409 - accuracy: 0.8721 - val_loss: 120.2689 - val_f1: 0.5485 - val_auc: 0.8885 - val_accuracy: 0.7987 - _timestamp: 1656350626.0000 - _runtime: 1563.0000\n",
            "Epoch 65/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 117.6738 - f1: 0.8752 - auc: 0.9402 - accuracy: 0.8701 - val_loss: 115.2126 - val_f1: 0.5525 - val_auc: 0.8892 - val_accuracy: 0.7970 - _timestamp: 1656350657.0000 - _runtime: 1594.0000\n",
            "Epoch 66/100\n",
            "380/380 [==============================] - 25s 65ms/step - loss: 112.7284 - f1: 0.8746 - auc: 0.9387 - accuracy: 0.8706 - val_loss: 110.3763 - val_f1: 0.5523 - val_auc: 0.8898 - val_accuracy: 0.7964 - _timestamp: 1656350681.0000 - _runtime: 1618.0000\n",
            "Epoch 67/100\n",
            "380/380 [==============================] - 26s 69ms/step - loss: 108.0048 - f1: 0.8746 - auc: 0.9385 - accuracy: 0.8699 - val_loss: 105.7665 - val_f1: 0.5513 - val_auc: 0.8905 - val_accuracy: 0.7937 - _timestamp: 1656350706.0000 - _runtime: 1643.0000\n",
            "Epoch 68/100\n",
            "380/380 [==============================] - 24s 64ms/step - loss: 103.5055 - f1: 0.8720 - auc: 0.9365 - accuracy: 0.8674 - val_loss: 101.3765 - val_f1: 0.5518 - val_auc: 0.8908 - val_accuracy: 0.7937 - _timestamp: 1656350732.0000 - _runtime: 1669.0000\n",
            "Epoch 69/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 99.2273 - f1: 0.8716 - auc: 0.9362 - accuracy: 0.8662 - val_loss: 97.2092 - val_f1: 0.5526 - val_auc: 0.8913 - val_accuracy: 0.7942 - _timestamp: 1656350756.0000 - _runtime: 1693.0000\n",
            "Epoch 70/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 95.1721 - f1: 0.8689 - auc: 0.9342 - accuracy: 0.8644 - val_loss: 93.2636 - val_f1: 0.5487 - val_auc: 0.8916 - val_accuracy: 0.7914 - _timestamp: 1656350780.0000 - _runtime: 1717.0000\n",
            "Epoch 71/100\n",
            "380/380 [==============================] - 26s 70ms/step - loss: 91.3375 - f1: 0.8696 - auc: 0.9336 - accuracy: 0.8646 - val_loss: 89.5406 - val_f1: 0.5497 - val_auc: 0.8915 - val_accuracy: 0.7914 - _timestamp: 1656350804.0000 - _runtime: 1741.0000\n",
            "Epoch 72/100\n",
            "380/380 [==============================] - 24s 62ms/step - loss: 87.7244 - f1: 0.8693 - auc: 0.9320 - accuracy: 0.8643 - val_loss: 86.0369 - val_f1: 0.5491 - val_auc: 0.8916 - val_accuracy: 0.7909 - _timestamp: 1656350830.0000 - _runtime: 1767.0000\n",
            "Epoch 73/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 84.3302 - f1: 0.8666 - auc: 0.9313 - accuracy: 0.8616 - val_loss: 82.7519 - val_f1: 0.5480 - val_auc: 0.8916 - val_accuracy: 0.7892 - _timestamp: 1656350854.0000 - _runtime: 1791.0000\n",
            "Epoch 74/100\n",
            "380/380 [==============================] - 25s 67ms/step - loss: 81.1472 - f1: 0.8676 - auc: 0.9299 - accuracy: 0.8628 - val_loss: 79.6536 - val_f1: 0.5514 - val_auc: 0.8917 - val_accuracy: 0.7909 - _timestamp: 1656350878.0000 - _runtime: 1815.0000\n",
            "Epoch 75/100\n",
            "380/380 [==============================] - 24s 62ms/step - loss: 78.0947 - f1: 0.8673 - auc: 0.9281 - accuracy: 0.8616 - val_loss: 76.6348 - val_f1: 0.5502 - val_auc: 0.8915 - val_accuracy: 0.7898 - _timestamp: 1656350903.0000 - _runtime: 1840.0000\n",
            "Epoch 76/100\n",
            "380/380 [==============================] - 27s 70ms/step - loss: 75.1078 - f1: 0.8690 - auc: 0.9281 - accuracy: 0.8642 - val_loss: 73.6794 - val_f1: 0.5499 - val_auc: 0.8914 - val_accuracy: 0.7898 - _timestamp: 1656350927.0000 - _runtime: 1864.0000\n",
            "Epoch 77/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 72.1846 - f1: 0.8659 - auc: 0.9268 - accuracy: 0.8616 - val_loss: 70.7853 - val_f1: 0.5528 - val_auc: 0.8909 - val_accuracy: 0.7914 - _timestamp: 1656350954.0000 - _runtime: 1891.0000\n",
            "Epoch 78/100\n",
            "380/380 [==============================] - 26s 67ms/step - loss: 69.3212 - f1: 0.8664 - auc: 0.9273 - accuracy: 0.8608 - val_loss: 67.9537 - val_f1: 0.5519 - val_auc: 0.8909 - val_accuracy: 0.7909 - _timestamp: 1656350977.0000 - _runtime: 1914.0000\n",
            "Epoch 79/100\n",
            "380/380 [==============================] - 26s 69ms/step - loss: 66.5205 - f1: 0.8641 - auc: 0.9254 - accuracy: 0.8606 - val_loss: 65.1818 - val_f1: 0.5504 - val_auc: 0.8909 - val_accuracy: 0.7909 - _timestamp: 1656351003.0000 - _runtime: 1940.0000\n",
            "Epoch 80/100\n",
            "380/380 [==============================] - 24s 64ms/step - loss: 63.7782 - f1: 0.8661 - auc: 0.9253 - accuracy: 0.8604 - val_loss: 62.4701 - val_f1: 0.5518 - val_auc: 0.8906 - val_accuracy: 0.7914 - _timestamp: 1656351029.0000 - _runtime: 1966.0000\n",
            "Epoch 81/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 61.0967 - f1: 0.8651 - auc: 0.9247 - accuracy: 0.8590 - val_loss: 59.8166 - val_f1: 0.5519 - val_auc: 0.8905 - val_accuracy: 0.7920 - _timestamp: 1656351054.0000 - _runtime: 1991.0000\n",
            "Epoch 82/100\n",
            "380/380 [==============================] - 27s 70ms/step - loss: 58.4740 - f1: 0.8640 - auc: 0.9249 - accuracy: 0.8590 - val_loss: 57.2252 - val_f1: 0.5545 - val_auc: 0.8902 - val_accuracy: 0.7931 - _timestamp: 1656351078.0000 - _runtime: 2015.0000\n",
            "Epoch 83/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 55.9116 - f1: 0.8664 - auc: 0.9247 - accuracy: 0.8613 - val_loss: 54.6927 - val_f1: 0.5548 - val_auc: 0.8900 - val_accuracy: 0.7937 - _timestamp: 1656351104.0000 - _runtime: 2041.0000\n",
            "Epoch 84/100\n",
            "380/380 [==============================] - 26s 68ms/step - loss: 53.4093 - f1: 0.8658 - auc: 0.9237 - accuracy: 0.8614 - val_loss: 52.2189 - val_f1: 0.5541 - val_auc: 0.8898 - val_accuracy: 0.7937 - _timestamp: 1656351128.0000 - _runtime: 2065.0000\n",
            "Epoch 85/100\n",
            "380/380 [==============================] - 26s 68ms/step - loss: 50.9664 - f1: 0.8627 - auc: 0.9235 - accuracy: 0.8590 - val_loss: 49.8057 - val_f1: 0.5523 - val_auc: 0.8897 - val_accuracy: 0.7914 - _timestamp: 1656351154.0000 - _runtime: 2091.0000\n",
            "Epoch 86/100\n",
            "380/380 [==============================] - 24s 64ms/step - loss: 48.5825 - f1: 0.8632 - auc: 0.9228 - accuracy: 0.8583 - val_loss: 47.4490 - val_f1: 0.5535 - val_auc: 0.8894 - val_accuracy: 0.7948 - _timestamp: 1656351180.0000 - _runtime: 2117.0000\n",
            "Epoch 87/100\n",
            "380/380 [==============================] - 26s 67ms/step - loss: 46.2582 - f1: 0.8657 - auc: 0.9223 - accuracy: 0.8609 - val_loss: 45.1547 - val_f1: 0.5524 - val_auc: 0.8894 - val_accuracy: 0.7931 - _timestamp: 1656351204.0000 - _runtime: 2141.0000\n",
            "Epoch 88/100\n",
            "380/380 [==============================] - 24s 64ms/step - loss: 43.9932 - f1: 0.8624 - auc: 0.9210 - accuracy: 0.8585 - val_loss: 42.9172 - val_f1: 0.5487 - val_auc: 0.8891 - val_accuracy: 0.7931 - _timestamp: 1656351229.0000 - _runtime: 2166.0000\n",
            "Epoch 89/100\n",
            "380/380 [==============================] - 24s 62ms/step - loss: 41.7871 - f1: 0.8636 - auc: 0.9216 - accuracy: 0.8594 - val_loss: 40.7413 - val_f1: 0.5471 - val_auc: 0.8887 - val_accuracy: 0.7920 - _timestamp: 1656351254.0000 - _runtime: 2191.0000\n",
            "Epoch 90/100\n",
            "380/380 [==============================] - 25s 67ms/step - loss: 39.6399 - f1: 0.8631 - auc: 0.9211 - accuracy: 0.8590 - val_loss: 38.6232 - val_f1: 0.5471 - val_auc: 0.8885 - val_accuracy: 0.7920 - _timestamp: 1656351277.0000 - _runtime: 2214.0000\n",
            "Epoch 91/100\n",
            "380/380 [==============================] - 25s 66ms/step - loss: 37.5515 - f1: 0.8653 - auc: 0.9216 - accuracy: 0.8609 - val_loss: 36.5643 - val_f1: 0.5476 - val_auc: 0.8885 - val_accuracy: 0.7925 - _timestamp: 1656351303.0000 - _runtime: 2240.0000\n",
            "Epoch 92/100\n",
            "380/380 [==============================] - 24s 62ms/step - loss: 35.5230 - f1: 0.8631 - auc: 0.9205 - accuracy: 0.8584 - val_loss: 34.5645 - val_f1: 0.5468 - val_auc: 0.8883 - val_accuracy: 0.7925 - _timestamp: 1656351328.0000 - _runtime: 2265.0000\n",
            "Epoch 93/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 33.5524 - f1: 0.8634 - auc: 0.9208 - accuracy: 0.8600 - val_loss: 32.6239 - val_f1: 0.5462 - val_auc: 0.8877 - val_accuracy: 0.7931 - _timestamp: 1656351351.0000 - _runtime: 2288.0000\n",
            "Epoch 94/100\n",
            "380/380 [==============================] - 31s 81ms/step - loss: 31.6424 - f1: 0.8615 - auc: 0.9196 - accuracy: 0.8569 - val_loss: 30.7427 - val_f1: 0.5468 - val_auc: 0.8875 - val_accuracy: 0.7937 - _timestamp: 1656351375.0000 - _runtime: 2312.0000\n",
            "Epoch 95/100\n",
            "380/380 [==============================] - 25s 65ms/step - loss: 29.7912 - f1: 0.8624 - auc: 0.9189 - accuracy: 0.8583 - val_loss: 28.9186 - val_f1: 0.5422 - val_auc: 0.8874 - val_accuracy: 0.7942 - _timestamp: 1656351406.0000 - _runtime: 2343.0000\n",
            "Epoch 96/100\n",
            "380/380 [==============================] - 24s 64ms/step - loss: 27.9974 - f1: 0.8607 - auc: 0.9193 - accuracy: 0.8562 - val_loss: 27.1541 - val_f1: 0.5432 - val_auc: 0.8872 - val_accuracy: 0.7953 - _timestamp: 1656351430.0000 - _runtime: 2367.0000\n",
            "Epoch 97/100\n",
            "380/380 [==============================] - 24s 64ms/step - loss: 26.2640 - f1: 0.8592 - auc: 0.9185 - accuracy: 0.8560 - val_loss: 25.4487 - val_f1: 0.5431 - val_auc: 0.8871 - val_accuracy: 0.7959 - _timestamp: 1656351455.0000 - _runtime: 2392.0000\n",
            "Epoch 98/100\n",
            "380/380 [==============================] - 26s 68ms/step - loss: 24.5893 - f1: 0.8610 - auc: 0.9180 - accuracy: 0.8586 - val_loss: 23.8032 - val_f1: 0.5433 - val_auc: 0.8866 - val_accuracy: 0.7959 - _timestamp: 1656351479.0000 - _runtime: 2416.0000\n",
            "Epoch 99/100\n",
            "380/380 [==============================] - 25s 65ms/step - loss: 22.9733 - f1: 0.8602 - auc: 0.9174 - accuracy: 0.8572 - val_loss: 22.2160 - val_f1: 0.5448 - val_auc: 0.8862 - val_accuracy: 0.7970 - _timestamp: 1656351504.0000 - _runtime: 2441.0000\n",
            "Epoch 100/100\n",
            "380/380 [==============================] - 26s 70ms/step - loss: 21.4159 - f1: 0.8602 - auc: 0.9170 - accuracy: 0.8561 - val_loss: 20.6872 - val_f1: 0.5445 - val_auc: 0.8862 - val_accuracy: 0.7981 - _timestamp: 1656351529.0000 - _runtime: 2466.0000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "147f6db5ed964e47998a9eabb38ee630",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='2289.624 MB of 2289.624 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▄▄▅▅▆▆▇▇▇▇▇▇████████████████████████▇▇</td></tr><tr><td>auc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇██████████████████▇▇▇▇▇▇▇▇▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇▇█████████████████████▇▇▇▇</td></tr><tr><td>loss</td><td>██▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▃▄▅▅▆▆▇▇▇▇████████████████████████████</td></tr><tr><td>val_auc</td><td>▁▅▆▆▆▆▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇████████████▇▇▇</td></tr><tr><td>val_f1</td><td>▁▂▂▃▄▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>val_loss</td><td>██▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.85608</td></tr><tr><td>auc</td><td>0.91705</td></tr><tr><td>best_epoch</td><td>99</td></tr><tr><td>best_val_loss</td><td>20.68717</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>f1</td><td>0.86016</td></tr><tr><td>loss</td><td>21.41592</td></tr><tr><td>val_accuracy</td><td>0.79811</td></tr><tr><td>val_auc</td><td>0.88619</td></tr><tr><td>val_f1</td><td>0.54455</td></tr><tr><td>val_loss</td><td>20.68717</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">wise-sweep-1</strong>: <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/sbukasbv\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/runs/sbukasbv</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220627_165743-sbukasbv/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f9lsv4ai with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: gelu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_value: 0.4478597005019634\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons: 3500\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptomizer: adadelta\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_factor: 5e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_type: l2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.19"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220627_174005-f9lsv4ai</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/f9lsv4ai\" target=\"_blank\">efficient-sweep-2</a></strong> to <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 25008)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3500)              87531500  \n",
            "                                                                 \n",
            " activation (Activation)     (None, 3500)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 3500)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 3501      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87,535,001\n",
            "Trainable params: 87,535,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "380/380 [==============================] - 14s 33ms/step - loss: 0.9601 - f1: 0.7248 - auc: 0.7796 - accuracy: 0.6796 - val_loss: 0.9729 - val_f1: 0.4307 - val_auc: 0.8524 - val_accuracy: 0.6123 - _timestamp: 1656351619.0000 - _runtime: 14.0000\n",
            "Epoch 2/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.9071 - f1: 0.8049 - auc: 0.8675 - accuracy: 0.7781 - val_loss: 0.9329 - val_f1: 0.4712 - val_auc: 0.8660 - val_accuracy: 0.6852 - _timestamp: 1656351631.0000 - _runtime: 26.0000\n",
            "Epoch 3/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.8667 - f1: 0.8230 - auc: 0.8917 - accuracy: 0.8030 - val_loss: 0.8972 - val_f1: 0.4891 - val_auc: 0.8694 - val_accuracy: 0.7208 - _timestamp: 1656351639.0000 - _runtime: 34.0000\n",
            "Epoch 4/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.8343 - f1: 0.8349 - auc: 0.9021 - accuracy: 0.8212 - val_loss: 0.8715 - val_f1: 0.5014 - val_auc: 0.8704 - val_accuracy: 0.7369 - _timestamp: 1656351648.0000 - _runtime: 43.0000\n",
            "Epoch 5/100\n",
            "380/380 [==============================] - 10s 27ms/step - loss: 0.8081 - f1: 0.8437 - auc: 0.9089 - accuracy: 0.8320 - val_loss: 0.8493 - val_f1: 0.5038 - val_auc: 0.8708 - val_accuracy: 0.7453 - _timestamp: 1656351657.0000 - _runtime: 52.0000\n",
            "Epoch 6/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 0.7867 - f1: 0.8428 - auc: 0.9132 - accuracy: 0.8339 - val_loss: 0.8303 - val_f1: 0.5098 - val_auc: 0.8707 - val_accuracy: 0.7547 - _timestamp: 1656351667.0000 - _runtime: 62.0000\n",
            "Epoch 7/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.7699 - f1: 0.8486 - auc: 0.9157 - accuracy: 0.8399 - val_loss: 0.8122 - val_f1: 0.5155 - val_auc: 0.8701 - val_accuracy: 0.7636 - _timestamp: 1656351679.0000 - _runtime: 74.0000\n",
            "Epoch 8/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.7540 - f1: 0.8510 - auc: 0.9193 - accuracy: 0.8428 - val_loss: 0.7985 - val_f1: 0.5174 - val_auc: 0.8695 - val_accuracy: 0.7692 - _timestamp: 1656351687.0000 - _runtime: 82.0000\n",
            "Epoch 9/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.7405 - f1: 0.8544 - auc: 0.9219 - accuracy: 0.8479 - val_loss: 0.7890 - val_f1: 0.5174 - val_auc: 0.8693 - val_accuracy: 0.7703 - _timestamp: 1656351696.0000 - _runtime: 91.0000\n",
            "Epoch 10/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.7291 - f1: 0.8564 - auc: 0.9242 - accuracy: 0.8511 - val_loss: 0.7790 - val_f1: 0.5219 - val_auc: 0.8690 - val_accuracy: 0.7753 - _timestamp: 1656351705.0000 - _runtime: 100.0000\n",
            "Epoch 11/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.7199 - f1: 0.8598 - auc: 0.9260 - accuracy: 0.8539 - val_loss: 0.7698 - val_f1: 0.5220 - val_auc: 0.8685 - val_accuracy: 0.7786 - _timestamp: 1656351714.0000 - _runtime: 109.0000\n",
            "Epoch 12/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.7098 - f1: 0.8600 - auc: 0.9284 - accuracy: 0.8550 - val_loss: 0.7629 - val_f1: 0.5186 - val_auc: 0.8682 - val_accuracy: 0.7781 - _timestamp: 1656351723.0000 - _runtime: 118.0000\n",
            "Epoch 13/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 0.7041 - f1: 0.8598 - auc: 0.9279 - accuracy: 0.8541 - val_loss: 0.7574 - val_f1: 0.5203 - val_auc: 0.8680 - val_accuracy: 0.7798 - _timestamp: 1656351731.0000 - _runtime: 126.0000\n",
            "Epoch 14/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 0.6970 - f1: 0.8614 - auc: 0.9305 - accuracy: 0.8569 - val_loss: 0.7533 - val_f1: 0.5218 - val_auc: 0.8679 - val_accuracy: 0.7814 - _timestamp: 1656351743.0000 - _runtime: 138.0000\n",
            "Epoch 15/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.6885 - f1: 0.8645 - auc: 0.9333 - accuracy: 0.8612 - val_loss: 0.7484 - val_f1: 0.5225 - val_auc: 0.8677 - val_accuracy: 0.7831 - _timestamp: 1656351754.0000 - _runtime: 149.0000\n",
            "Epoch 16/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.6845 - f1: 0.8651 - auc: 0.9324 - accuracy: 0.8605 - val_loss: 0.7408 - val_f1: 0.5261 - val_auc: 0.8671 - val_accuracy: 0.7887 - _timestamp: 1656351763.0000 - _runtime: 158.0000\n",
            "Epoch 17/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.6773 - f1: 0.8678 - auc: 0.9352 - accuracy: 0.8632 - val_loss: 0.7361 - val_f1: 0.5314 - val_auc: 0.8668 - val_accuracy: 0.7937 - _timestamp: 1656351772.0000 - _runtime: 167.0000\n",
            "Epoch 18/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.6715 - f1: 0.8684 - auc: 0.9366 - accuracy: 0.8647 - val_loss: 0.7333 - val_f1: 0.5314 - val_auc: 0.8670 - val_accuracy: 0.7937 - _timestamp: 1656351781.0000 - _runtime: 176.0000\n",
            "Epoch 19/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.6667 - f1: 0.8697 - auc: 0.9380 - accuracy: 0.8665 - val_loss: 0.7307 - val_f1: 0.5322 - val_auc: 0.8669 - val_accuracy: 0.7942 - _timestamp: 1656351790.0000 - _runtime: 185.0000\n",
            "Epoch 20/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.6630 - f1: 0.8676 - auc: 0.9381 - accuracy: 0.8652 - val_loss: 0.7269 - val_f1: 0.5253 - val_auc: 0.8667 - val_accuracy: 0.7942 - _timestamp: 1656351799.0000 - _runtime: 194.0000\n",
            "Epoch 21/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.6573 - f1: 0.8708 - auc: 0.9404 - accuracy: 0.8696 - val_loss: 0.7233 - val_f1: 0.5269 - val_auc: 0.8665 - val_accuracy: 0.7964 - _timestamp: 1656351807.0000 - _runtime: 202.0000\n",
            "Epoch 22/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.6551 - f1: 0.8705 - auc: 0.9399 - accuracy: 0.8684 - val_loss: 0.7200 - val_f1: 0.5223 - val_auc: 0.8661 - val_accuracy: 0.7964 - _timestamp: 1656351816.0000 - _runtime: 211.0000\n",
            "Epoch 23/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.6491 - f1: 0.8741 - auc: 0.9420 - accuracy: 0.8713 - val_loss: 0.7165 - val_f1: 0.5253 - val_auc: 0.8659 - val_accuracy: 0.7992 - _timestamp: 1656351825.0000 - _runtime: 220.0000\n",
            "Epoch 24/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.6476 - f1: 0.8716 - auc: 0.9417 - accuracy: 0.8701 - val_loss: 0.7161 - val_f1: 0.5269 - val_auc: 0.8663 - val_accuracy: 0.7998 - _timestamp: 1656351834.0000 - _runtime: 229.0000\n",
            "Epoch 25/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 0.6441 - f1: 0.8748 - auc: 0.9430 - accuracy: 0.8735 - val_loss: 0.7139 - val_f1: 0.5264 - val_auc: 0.8660 - val_accuracy: 0.8003 - _timestamp: 1656351843.0000 - _runtime: 238.0000\n",
            "Epoch 26/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 0.6399 - f1: 0.8748 - auc: 0.9447 - accuracy: 0.8732 - val_loss: 0.7090 - val_f1: 0.5214 - val_auc: 0.8655 - val_accuracy: 0.8009 - _timestamp: 1656351855.0000 - _runtime: 250.0000\n",
            "Epoch 27/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.6354 - f1: 0.8786 - auc: 0.9457 - accuracy: 0.8764 - val_loss: 0.7073 - val_f1: 0.5183 - val_auc: 0.8655 - val_accuracy: 0.7998 - _timestamp: 1656351866.0000 - _runtime: 261.0000\n",
            "Epoch 28/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.6343 - f1: 0.8776 - auc: 0.9452 - accuracy: 0.8763 - val_loss: 0.7044 - val_f1: 0.5210 - val_auc: 0.8653 - val_accuracy: 0.8020 - _timestamp: 1656351875.0000 - _runtime: 270.0000\n",
            "Epoch 29/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.6310 - f1: 0.8783 - auc: 0.9464 - accuracy: 0.8772 - val_loss: 0.7038 - val_f1: 0.5192 - val_auc: 0.8653 - val_accuracy: 0.8020 - _timestamp: 1656351884.0000 - _runtime: 279.0000\n",
            "Epoch 30/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.6293 - f1: 0.8771 - auc: 0.9463 - accuracy: 0.8758 - val_loss: 0.7030 - val_f1: 0.5192 - val_auc: 0.8655 - val_accuracy: 0.8020 - _timestamp: 1656351893.0000 - _runtime: 288.0000\n",
            "Epoch 31/100\n",
            "380/380 [==============================] - 9s 24ms/step - loss: 0.6272 - f1: 0.8792 - auc: 0.9471 - accuracy: 0.8780 - val_loss: 0.7002 - val_f1: 0.5213 - val_auc: 0.8651 - val_accuracy: 0.8037 - _timestamp: 1656351902.0000 - _runtime: 297.0000\n",
            "Epoch 32/100\n",
            "380/380 [==============================] - 9s 24ms/step - loss: 0.6257 - f1: 0.8784 - auc: 0.9471 - accuracy: 0.8767 - val_loss: 0.6987 - val_f1: 0.5211 - val_auc: 0.8654 - val_accuracy: 0.8042 - _timestamp: 1656351911.0000 - _runtime: 306.0000\n",
            "Epoch 33/100\n",
            "380/380 [==============================] - 9s 24ms/step - loss: 0.6235 - f1: 0.8800 - auc: 0.9476 - accuracy: 0.8791 - val_loss: 0.6967 - val_f1: 0.5228 - val_auc: 0.8649 - val_accuracy: 0.8059 - _timestamp: 1656351920.0000 - _runtime: 315.0000\n",
            "Epoch 34/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.6190 - f1: 0.8824 - auc: 0.9497 - accuracy: 0.8814 - val_loss: 0.6955 - val_f1: 0.5222 - val_auc: 0.8652 - val_accuracy: 0.8059 - _timestamp: 1656351929.0000 - _runtime: 324.0000\n",
            "Epoch 35/100\n",
            "380/380 [==============================] - 9s 24ms/step - loss: 0.6163 - f1: 0.8831 - auc: 0.9506 - accuracy: 0.8825 - val_loss: 0.6945 - val_f1: 0.5230 - val_auc: 0.8652 - val_accuracy: 0.8065 - _timestamp: 1656351937.0000 - _runtime: 332.0000\n",
            "Epoch 36/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.6134 - f1: 0.8834 - auc: 0.9515 - accuracy: 0.8832 - val_loss: 0.6927 - val_f1: 0.5252 - val_auc: 0.8652 - val_accuracy: 0.8081 - _timestamp: 1656351946.0000 - _runtime: 341.0000\n",
            "Epoch 37/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.6135 - f1: 0.8809 - auc: 0.9509 - accuracy: 0.8805 - val_loss: 0.6899 - val_f1: 0.5206 - val_auc: 0.8649 - val_accuracy: 0.8098 - _timestamp: 1656351955.0000 - _runtime: 350.0000\n",
            "Epoch 38/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.6100 - f1: 0.8842 - auc: 0.9519 - accuracy: 0.8827 - val_loss: 0.6892 - val_f1: 0.5213 - val_auc: 0.8648 - val_accuracy: 0.8109 - _timestamp: 1656351964.0000 - _runtime: 359.0000\n",
            "Epoch 39/100\n",
            "380/380 [==============================] - 9s 24ms/step - loss: 0.6099 - f1: 0.8824 - auc: 0.9516 - accuracy: 0.8819 - val_loss: 0.6877 - val_f1: 0.5170 - val_auc: 0.8646 - val_accuracy: 0.8098 - _timestamp: 1656351973.0000 - _runtime: 368.0000\n",
            "Epoch 40/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.6054 - f1: 0.8859 - auc: 0.9533 - accuracy: 0.8856 - val_loss: 0.6864 - val_f1: 0.5213 - val_auc: 0.8645 - val_accuracy: 0.8126 - _timestamp: 1656351982.0000 - _runtime: 377.0000\n",
            "Epoch 41/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.6046 - f1: 0.8863 - auc: 0.9532 - accuracy: 0.8873 - val_loss: 0.6852 - val_f1: 0.5241 - val_auc: 0.8647 - val_accuracy: 0.8148 - _timestamp: 1656351991.0000 - _runtime: 386.0000\n",
            "Epoch 42/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.6030 - f1: 0.8865 - auc: 0.9536 - accuracy: 0.8865 - val_loss: 0.6845 - val_f1: 0.5247 - val_auc: 0.8648 - val_accuracy: 0.8154 - _timestamp: 1656352000.0000 - _runtime: 395.0000\n",
            "Epoch 43/100\n",
            "380/380 [==============================] - 7s 17ms/step - loss: 0.6027 - f1: 0.8876 - auc: 0.9532 - accuracy: 0.8884 - val_loss: 0.6846 - val_f1: 0.5273 - val_auc: 0.8650 - val_accuracy: 0.8159 - _timestamp: 1656352009.0000 - _runtime: 404.0000\n",
            "Epoch 44/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.5997 - f1: 0.8866 - auc: 0.9547 - accuracy: 0.8862 - val_loss: 0.6824 - val_f1: 0.5299 - val_auc: 0.8650 - val_accuracy: 0.8187 - _timestamp: 1656352015.0000 - _runtime: 410.0000\n",
            "Epoch 45/100\n",
            "380/380 [==============================] - 11s 28ms/step - loss: 0.6014 - f1: 0.8853 - auc: 0.9535 - accuracy: 0.8858 - val_loss: 0.6803 - val_f1: 0.5283 - val_auc: 0.8649 - val_accuracy: 0.8192 - _timestamp: 1656352024.0000 - _runtime: 419.0000\n",
            "Epoch 46/100\n",
            "380/380 [==============================] - 9s 25ms/step - loss: 0.5997 - f1: 0.8890 - auc: 0.9540 - accuracy: 0.8887 - val_loss: 0.6789 - val_f1: 0.5301 - val_auc: 0.8644 - val_accuracy: 0.8215 - _timestamp: 1656352035.0000 - _runtime: 430.0000\n",
            "Epoch 47/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.5964 - f1: 0.8907 - auc: 0.9551 - accuracy: 0.8901 - val_loss: 0.6794 - val_f1: 0.5316 - val_auc: 0.8648 - val_accuracy: 0.8204 - _timestamp: 1656352045.0000 - _runtime: 440.0000\n",
            "Epoch 48/100\n",
            "380/380 [==============================] - 9s 24ms/step - loss: 0.5968 - f1: 0.8887 - auc: 0.9545 - accuracy: 0.8884 - val_loss: 0.6781 - val_f1: 0.5330 - val_auc: 0.8647 - val_accuracy: 0.8215 - _timestamp: 1656352051.0000 - _runtime: 446.0000\n",
            "Epoch 49/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 0.5905 - f1: 0.8910 - auc: 0.9571 - accuracy: 0.8906 - val_loss: 0.6776 - val_f1: 0.5312 - val_auc: 0.8647 - val_accuracy: 0.8215 - _timestamp: 1656352060.0000 - _runtime: 455.0000\n",
            "Epoch 50/100\n",
            "380/380 [==============================] - 10s 27ms/step - loss: 0.5912 - f1: 0.8928 - auc: 0.9565 - accuracy: 0.8932 - val_loss: 0.6763 - val_f1: 0.5334 - val_auc: 0.8645 - val_accuracy: 0.8242 - _timestamp: 1656352072.0000 - _runtime: 467.0000\n",
            "Epoch 51/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.5909 - f1: 0.8912 - auc: 0.9566 - accuracy: 0.8912 - val_loss: 0.6752 - val_f1: 0.5315 - val_auc: 0.8646 - val_accuracy: 0.8242 - _timestamp: 1656352082.0000 - _runtime: 477.0000\n",
            "Epoch 52/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.5905 - f1: 0.8924 - auc: 0.9562 - accuracy: 0.8924 - val_loss: 0.6746 - val_f1: 0.5293 - val_auc: 0.8645 - val_accuracy: 0.8248 - _timestamp: 1656352091.0000 - _runtime: 486.0000\n",
            "Epoch 53/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 0.5898 - f1: 0.8886 - auc: 0.9567 - accuracy: 0.8892 - val_loss: 0.6737 - val_f1: 0.5240 - val_auc: 0.8644 - val_accuracy: 0.8242 - _timestamp: 1656352100.0000 - _runtime: 495.0000\n",
            "Epoch 54/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.5853 - f1: 0.8939 - auc: 0.9584 - accuracy: 0.8940 - val_loss: 0.6723 - val_f1: 0.5290 - val_auc: 0.8641 - val_accuracy: 0.8281 - _timestamp: 1656352112.0000 - _runtime: 507.0000\n",
            "Epoch 55/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.5844 - f1: 0.8930 - auc: 0.9587 - accuracy: 0.8931 - val_loss: 0.6714 - val_f1: 0.5241 - val_auc: 0.8645 - val_accuracy: 0.8287 - _timestamp: 1656352120.0000 - _runtime: 515.0000\n",
            "Epoch 56/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.5843 - f1: 0.8931 - auc: 0.9583 - accuracy: 0.8938 - val_loss: 0.6726 - val_f1: 0.5302 - val_auc: 0.8647 - val_accuracy: 0.8270 - _timestamp: 1656352129.0000 - _runtime: 524.0000\n",
            "Epoch 57/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.5854 - f1: 0.8900 - auc: 0.9574 - accuracy: 0.8905 - val_loss: 0.6693 - val_f1: 0.5269 - val_auc: 0.8641 - val_accuracy: 0.8309 - _timestamp: 1656352136.0000 - _runtime: 531.0000\n",
            "Epoch 58/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.5809 - f1: 0.8954 - auc: 0.9589 - accuracy: 0.8954 - val_loss: 0.6689 - val_f1: 0.5269 - val_auc: 0.8644 - val_accuracy: 0.8309 - _timestamp: 1656352145.0000 - _runtime: 540.0000\n",
            "Epoch 59/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.5785 - f1: 0.8987 - auc: 0.9600 - accuracy: 0.8992 - val_loss: 0.6695 - val_f1: 0.5251 - val_auc: 0.8646 - val_accuracy: 0.8298 - _timestamp: 1656352154.0000 - _runtime: 549.0000\n",
            "Epoch 60/100\n",
            "380/380 [==============================] - 10s 27ms/step - loss: 0.5810 - f1: 0.8936 - auc: 0.9586 - accuracy: 0.8942 - val_loss: 0.6680 - val_f1: 0.5276 - val_auc: 0.8643 - val_accuracy: 0.8315 - _timestamp: 1656352160.0000 - _runtime: 555.0000\n",
            "Epoch 61/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.5770 - f1: 0.8968 - auc: 0.9603 - accuracy: 0.8968 - val_loss: 0.6675 - val_f1: 0.5276 - val_auc: 0.8644 - val_accuracy: 0.8315 - _timestamp: 1656352170.0000 - _runtime: 565.0000\n",
            "Epoch 62/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.5757 - f1: 0.8950 - auc: 0.9607 - accuracy: 0.8957 - val_loss: 0.6670 - val_f1: 0.5276 - val_auc: 0.8643 - val_accuracy: 0.8315 - _timestamp: 1656352179.0000 - _runtime: 574.0000\n",
            "Epoch 63/100\n",
            "380/380 [==============================] - 9s 24ms/step - loss: 0.5770 - f1: 0.8945 - auc: 0.9597 - accuracy: 0.8959 - val_loss: 0.6667 - val_f1: 0.5268 - val_auc: 0.8645 - val_accuracy: 0.8315 - _timestamp: 1656352188.0000 - _runtime: 583.0000\n",
            "Epoch 64/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.5745 - f1: 0.8940 - auc: 0.9610 - accuracy: 0.8943 - val_loss: 0.6654 - val_f1: 0.5269 - val_auc: 0.8641 - val_accuracy: 0.8326 - _timestamp: 1656352197.0000 - _runtime: 592.0000\n",
            "Epoch 65/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.5725 - f1: 0.8968 - auc: 0.9616 - accuracy: 0.8965 - val_loss: 0.6640 - val_f1: 0.5285 - val_auc: 0.8639 - val_accuracy: 0.8337 - _timestamp: 1656352206.0000 - _runtime: 601.0000\n",
            "Epoch 66/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.5741 - f1: 0.8962 - auc: 0.9606 - accuracy: 0.8976 - val_loss: 0.6648 - val_f1: 0.5269 - val_auc: 0.8644 - val_accuracy: 0.8326 - _timestamp: 1656352214.0000 - _runtime: 609.0000\n",
            "Epoch 67/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.5739 - f1: 0.8985 - auc: 0.9604 - accuracy: 0.8988 - val_loss: 0.6650 - val_f1: 0.5304 - val_auc: 0.8647 - val_accuracy: 0.8326 - _timestamp: 1656352221.0000 - _runtime: 616.0000\n",
            "Epoch 68/100\n",
            "380/380 [==============================] - 10s 25ms/step - loss: 0.5741 - f1: 0.8964 - auc: 0.9600 - accuracy: 0.8960 - val_loss: 0.6628 - val_f1: 0.5291 - val_auc: 0.8644 - val_accuracy: 0.8343 - _timestamp: 1656352228.0000 - _runtime: 623.0000\n",
            "Epoch 69/100\n",
            "380/380 [==============================] - 12s 33ms/step - loss: 0.5710 - f1: 0.8969 - auc: 0.9609 - accuracy: 0.8970 - val_loss: 0.6623 - val_f1: 0.5275 - val_auc: 0.8645 - val_accuracy: 0.8343 - _timestamp: 1656352237.0000 - _runtime: 632.0000\n",
            "Epoch 70/100\n",
            "380/380 [==============================] - 9s 24ms/step - loss: 0.5725 - f1: 0.8967 - auc: 0.9605 - accuracy: 0.8974 - val_loss: 0.6617 - val_f1: 0.5275 - val_auc: 0.8644 - val_accuracy: 0.8343 - _timestamp: 1656352250.0000 - _runtime: 645.0000\n",
            "Epoch 71/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.5675 - f1: 0.9003 - auc: 0.9625 - accuracy: 0.9007 - val_loss: 0.6617 - val_f1: 0.5275 - val_auc: 0.8645 - val_accuracy: 0.8343 - _timestamp: 1656352259.0000 - _runtime: 654.0000\n",
            "Epoch 72/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.5685 - f1: 0.8972 - auc: 0.9620 - accuracy: 0.8981 - val_loss: 0.6619 - val_f1: 0.5297 - val_auc: 0.8648 - val_accuracy: 0.8343 - _timestamp: 1656352268.0000 - _runtime: 663.0000\n",
            "Epoch 73/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.5700 - f1: 0.8979 - auc: 0.9610 - accuracy: 0.8982 - val_loss: 0.6609 - val_f1: 0.5173 - val_auc: 0.8645 - val_accuracy: 0.8331 - _timestamp: 1656352274.0000 - _runtime: 669.0000\n",
            "Epoch 74/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.5652 - f1: 0.9007 - auc: 0.9632 - accuracy: 0.9011 - val_loss: 0.6608 - val_f1: 0.5163 - val_auc: 0.8647 - val_accuracy: 0.8326 - _timestamp: 1656352283.0000 - _runtime: 678.0000\n",
            "Epoch 75/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.5645 - f1: 0.8994 - auc: 0.9633 - accuracy: 0.9005 - val_loss: 0.6607 - val_f1: 0.5195 - val_auc: 0.8648 - val_accuracy: 0.8331 - _timestamp: 1656352292.0000 - _runtime: 687.0000\n",
            "Epoch 76/100\n",
            "380/380 [==============================] - 12s 30ms/step - loss: 0.5627 - f1: 0.9006 - auc: 0.9636 - accuracy: 0.9019 - val_loss: 0.6601 - val_f1: 0.5203 - val_auc: 0.8647 - val_accuracy: 0.8343 - _timestamp: 1656352300.0000 - _runtime: 695.0000\n",
            "Epoch 77/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 0.5651 - f1: 0.8992 - auc: 0.9626 - accuracy: 0.8994 - val_loss: 0.6583 - val_f1: 0.5105 - val_auc: 0.8644 - val_accuracy: 0.8331 - _timestamp: 1656352312.0000 - _runtime: 707.0000\n",
            "Epoch 78/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 0.5616 - f1: 0.9030 - auc: 0.9637 - accuracy: 0.9044 - val_loss: 0.6578 - val_f1: 0.5105 - val_auc: 0.8642 - val_accuracy: 0.8331 - _timestamp: 1656352323.0000 - _runtime: 718.0000\n",
            "Epoch 79/100\n",
            "380/380 [==============================] - 7s 17ms/step - loss: 0.5605 - f1: 0.9010 - auc: 0.9640 - accuracy: 0.9034 - val_loss: 0.6585 - val_f1: 0.5134 - val_auc: 0.8646 - val_accuracy: 0.8337 - _timestamp: 1656352335.0000 - _runtime: 730.0000\n",
            "Epoch 80/100\n",
            "380/380 [==============================] - 7s 17ms/step - loss: 0.5634 - f1: 0.9004 - auc: 0.9629 - accuracy: 0.9019 - val_loss: 0.6586 - val_f1: 0.5165 - val_auc: 0.8645 - val_accuracy: 0.8343 - _timestamp: 1656352342.0000 - _runtime: 737.0000\n",
            "Epoch 81/100\n",
            "380/380 [==============================] - 7s 17ms/step - loss: 0.5602 - f1: 0.9017 - auc: 0.9642 - accuracy: 0.9026 - val_loss: 0.6583 - val_f1: 0.5114 - val_auc: 0.8645 - val_accuracy: 0.8331 - _timestamp: 1656352348.0000 - _runtime: 743.0000\n",
            "Epoch 82/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.5624 - f1: 0.9011 - auc: 0.9628 - accuracy: 0.9024 - val_loss: 0.6577 - val_f1: 0.5095 - val_auc: 0.8646 - val_accuracy: 0.8326 - _timestamp: 1656352355.0000 - _runtime: 750.0000\n",
            "Epoch 83/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.5631 - f1: 0.9010 - auc: 0.9624 - accuracy: 0.9027 - val_loss: 0.6561 - val_f1: 0.5080 - val_auc: 0.8644 - val_accuracy: 0.8343 - _timestamp: 1656352363.0000 - _runtime: 758.0000\n",
            "Epoch 84/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.5586 - f1: 0.9025 - auc: 0.9643 - accuracy: 0.9033 - val_loss: 0.6553 - val_f1: 0.5062 - val_auc: 0.8644 - val_accuracy: 0.8337 - _timestamp: 1656352372.0000 - _runtime: 767.0000\n",
            "Epoch 85/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.5610 - f1: 0.8998 - auc: 0.9633 - accuracy: 0.9003 - val_loss: 0.6551 - val_f1: 0.5076 - val_auc: 0.8643 - val_accuracy: 0.8348 - _timestamp: 1656352381.0000 - _runtime: 776.0000\n",
            "Epoch 86/100\n",
            "380/380 [==============================] - 7s 17ms/step - loss: 0.5577 - f1: 0.9006 - auc: 0.9644 - accuracy: 0.9022 - val_loss: 0.6554 - val_f1: 0.5066 - val_auc: 0.8648 - val_accuracy: 0.8343 - _timestamp: 1656352389.0000 - _runtime: 784.0000\n",
            "Epoch 87/100\n",
            "380/380 [==============================] - 7s 17ms/step - loss: 0.5572 - f1: 0.9030 - auc: 0.9646 - accuracy: 0.9046 - val_loss: 0.6552 - val_f1: 0.5066 - val_auc: 0.8644 - val_accuracy: 0.8343 - _timestamp: 1656352396.0000 - _runtime: 791.0000\n",
            "Epoch 88/100\n",
            "380/380 [==============================] - 7s 17ms/step - loss: 0.5577 - f1: 0.9025 - auc: 0.9644 - accuracy: 0.9032 - val_loss: 0.6555 - val_f1: 0.5066 - val_auc: 0.8648 - val_accuracy: 0.8343 - _timestamp: 1656352402.0000 - _runtime: 797.0000\n",
            "Epoch 89/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.5551 - f1: 0.9032 - auc: 0.9649 - accuracy: 0.9042 - val_loss: 0.6546 - val_f1: 0.5066 - val_auc: 0.8647 - val_accuracy: 0.8343 - _timestamp: 1656352409.0000 - _runtime: 804.0000\n",
            "Epoch 90/100\n",
            "380/380 [==============================] - 11s 28ms/step - loss: 0.5541 - f1: 0.9048 - auc: 0.9655 - accuracy: 0.9063 - val_loss: 0.6526 - val_f1: 0.5055 - val_auc: 0.8646 - val_accuracy: 0.8359 - _timestamp: 1656352418.0000 - _runtime: 813.0000\n",
            "Epoch 91/100\n",
            "380/380 [==============================] - 7s 17ms/step - loss: 0.5579 - f1: 0.9011 - auc: 0.9640 - accuracy: 0.9024 - val_loss: 0.6541 - val_f1: 0.5028 - val_auc: 0.8652 - val_accuracy: 0.8337 - _timestamp: 1656352428.0000 - _runtime: 823.0000\n",
            "Epoch 92/100\n",
            "380/380 [==============================] - 7s 17ms/step - loss: 0.5529 - f1: 0.9055 - auc: 0.9656 - accuracy: 0.9061 - val_loss: 0.6527 - val_f1: 0.5033 - val_auc: 0.8649 - val_accuracy: 0.8343 - _timestamp: 1656352435.0000 - _runtime: 830.0000\n",
            "Epoch 93/100\n",
            "380/380 [==============================] - 7s 17ms/step - loss: 0.5549 - f1: 0.9015 - auc: 0.9649 - accuracy: 0.9032 - val_loss: 0.6532 - val_f1: 0.5028 - val_auc: 0.8651 - val_accuracy: 0.8337 - _timestamp: 1656352441.0000 - _runtime: 836.0000\n",
            "Epoch 94/100\n",
            "380/380 [==============================] - 7s 17ms/step - loss: 0.5531 - f1: 0.9079 - auc: 0.9654 - accuracy: 0.9084 - val_loss: 0.6533 - val_f1: 0.5036 - val_auc: 0.8654 - val_accuracy: 0.8343 - _timestamp: 1656352448.0000 - _runtime: 843.0000\n",
            "Epoch 95/100\n",
            "380/380 [==============================] - 7s 17ms/step - loss: 0.5518 - f1: 0.9047 - auc: 0.9660 - accuracy: 0.9053 - val_loss: 0.6533 - val_f1: 0.5068 - val_auc: 0.8656 - val_accuracy: 0.8348 - _timestamp: 1656352454.0000 - _runtime: 849.0000\n",
            "Epoch 96/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.5514 - f1: 0.9052 - auc: 0.9658 - accuracy: 0.9068 - val_loss: 0.6517 - val_f1: 0.5049 - val_auc: 0.8654 - val_accuracy: 0.8354 - _timestamp: 1656352461.0000 - _runtime: 856.0000\n",
            "Epoch 97/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 0.5545 - f1: 0.9030 - auc: 0.9648 - accuracy: 0.9038 - val_loss: 0.6507 - val_f1: 0.5057 - val_auc: 0.8653 - val_accuracy: 0.8370 - _timestamp: 1656352470.0000 - _runtime: 865.0000\n",
            "Epoch 98/100\n",
            "380/380 [==============================] - 6s 17ms/step - loss: 0.5505 - f1: 0.9024 - auc: 0.9663 - accuracy: 0.9042 - val_loss: 0.6510 - val_f1: 0.5052 - val_auc: 0.8655 - val_accuracy: 0.8365 - _timestamp: 1656352481.0000 - _runtime: 876.0000\n",
            "Epoch 99/100\n",
            "380/380 [==============================] - 6s 17ms/step - loss: 0.5465 - f1: 0.9062 - auc: 0.9675 - accuracy: 0.9075 - val_loss: 0.6516 - val_f1: 0.5028 - val_auc: 0.8656 - val_accuracy: 0.8348 - _timestamp: 1656352488.0000 - _runtime: 883.0000\n",
            "Epoch 100/100\n",
            "380/380 [==============================] - 9s 23ms/step - loss: 0.5505 - f1: 0.9056 - auc: 0.9660 - accuracy: 0.9064 - val_loss: 0.6506 - val_f1: 0.5060 - val_auc: 0.8654 - val_accuracy: 0.8370 - _timestamp: 1656352494.0000 - _runtime: 889.0000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b814ca6c413a42eca069224122360bcd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='1001.788 MB of 1001.788 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████████</td></tr><tr><td>auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1</td><td>▁▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██████████████</td></tr><tr><td>loss</td><td>█▆▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████████████████</td></tr><tr><td>val_auc</td><td>▁▇██▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▅▆▆▆▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>val_f1</td><td>▁▅▆▇▇▇████▇▇▇▇█▇▇████████████▇▇▇▆▆▆▆▆▆▆▆</td></tr><tr><td>val_loss</td><td>█▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.90639</td></tr><tr><td>auc</td><td>0.96596</td></tr><tr><td>best_epoch</td><td>99</td></tr><tr><td>best_val_loss</td><td>0.65056</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>f1</td><td>0.90559</td></tr><tr><td>loss</td><td>0.55052</td></tr><tr><td>val_accuracy</td><td>0.83704</td></tr><tr><td>val_auc</td><td>0.86544</td></tr><tr><td>val_f1</td><td>0.50599</td></tr><tr><td>val_loss</td><td>0.65056</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">efficient-sweep-2</strong>: <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/f9lsv4ai\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/runs/f9lsv4ai</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220627_174005-f9lsv4ai/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lt08804y with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: prelu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_value: 0.06385109826725666\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.30000000000000004\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons: 4500\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptomizer: adagrad\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_factor: 0.0005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_type: l1_l2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.19"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220627_175530-lt08804y</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/lt08804y\" target=\"_blank\">morning-sweep-3</a></strong> to <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 25008)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4500)              112540500 \n",
            "                                                                 \n",
            " p_re_lu (PReLU)             (None, 4500)              4500      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4500)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4500)              20254500  \n",
            "                                                                 \n",
            " p_re_lu_1 (PReLU)           (None, 4500)              4500      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4500)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4500)              20254500  \n",
            "                                                                 \n",
            " p_re_lu_2 (PReLU)           (None, 4500)              4500      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 4500)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 4501      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 153,067,501\n",
            "Trainable params: 153,067,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "380/380 [==============================] - 19s 45ms/step - loss: 669.2231 - f1: 0.6678 - auc: 0.6705 - accuracy: 0.5591 - val_loss: 666.8511 - val_f1: 0.3768 - val_auc: 0.8532 - val_accuracy: 0.4872 - _timestamp: 1656352549.0000 - _runtime: 19.0000\n",
            "Epoch 2/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 664.4623 - f1: 0.7313 - auc: 0.7671 - accuracy: 0.6839 - val_loss: 662.1067 - val_f1: 0.4203 - val_auc: 0.8674 - val_accuracy: 0.5912 - _timestamp: 1656352566.0000 - _runtime: 36.0000\n",
            "Epoch 3/100\n",
            "380/380 [==============================] - 16s 42ms/step - loss: 659.7241 - f1: 0.7816 - auc: 0.8391 - accuracy: 0.7538 - val_loss: 657.3866 - val_f1: 0.4460 - val_auc: 0.8712 - val_accuracy: 0.6352 - _timestamp: 1656352580.0000 - _runtime: 50.0000\n",
            "Epoch 4/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 655.0098 - f1: 0.8032 - auc: 0.8662 - accuracy: 0.7812 - val_loss: 652.6867 - val_f1: 0.4620 - val_auc: 0.8723 - val_accuracy: 0.6630 - _timestamp: 1656352596.0000 - _runtime: 66.0000\n",
            "Epoch 5/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 650.3124 - f1: 0.8225 - auc: 0.8888 - accuracy: 0.8071 - val_loss: 648.0113 - val_f1: 0.4666 - val_auc: 0.8727 - val_accuracy: 0.6691 - _timestamp: 1656352610.0000 - _runtime: 80.0000\n",
            "Epoch 6/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 645.6365 - f1: 0.8352 - auc: 0.9003 - accuracy: 0.8236 - val_loss: 643.3619 - val_f1: 0.4641 - val_auc: 0.8735 - val_accuracy: 0.6646 - _timestamp: 1656352624.0000 - _runtime: 94.0000\n",
            "Epoch 7/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 640.9819 - f1: 0.8363 - auc: 0.9052 - accuracy: 0.8245 - val_loss: 638.7225 - val_f1: 0.4752 - val_auc: 0.8737 - val_accuracy: 0.6802 - _timestamp: 1656352640.0000 - _runtime: 110.0000\n",
            "Epoch 8/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 636.3466 - f1: 0.8427 - auc: 0.9124 - accuracy: 0.8317 - val_loss: 634.1088 - val_f1: 0.4803 - val_auc: 0.8734 - val_accuracy: 0.6869 - _timestamp: 1656352654.0000 - _runtime: 124.0000\n",
            "Epoch 9/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 631.7344 - f1: 0.8498 - auc: 0.9154 - accuracy: 0.8404 - val_loss: 629.5156 - val_f1: 0.4847 - val_auc: 0.8740 - val_accuracy: 0.6924 - _timestamp: 1656352670.0000 - _runtime: 140.0000\n",
            "Epoch 10/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 627.1420 - f1: 0.8477 - auc: 0.9192 - accuracy: 0.8395 - val_loss: 624.9420 - val_f1: 0.4862 - val_auc: 0.8745 - val_accuracy: 0.7008 - _timestamp: 1656352684.0000 - _runtime: 154.0000\n",
            "Epoch 11/100\n",
            "380/380 [==============================] - 15s 41ms/step - loss: 622.5698 - f1: 0.8530 - auc: 0.9234 - accuracy: 0.8460 - val_loss: 620.3926 - val_f1: 0.4907 - val_auc: 0.8745 - val_accuracy: 0.7069 - _timestamp: 1656352700.0000 - _runtime: 170.0000\n",
            "Epoch 12/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 618.0209 - f1: 0.8540 - auc: 0.9258 - accuracy: 0.8479 - val_loss: 615.8627 - val_f1: 0.4963 - val_auc: 0.8747 - val_accuracy: 0.7152 - _timestamp: 1656352716.0000 - _runtime: 186.0000\n",
            "Epoch 13/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 613.4940 - f1: 0.8562 - auc: 0.9265 - accuracy: 0.8495 - val_loss: 611.3456 - val_f1: 0.5051 - val_auc: 0.8746 - val_accuracy: 0.7280 - _timestamp: 1656352730.0000 - _runtime: 200.0000\n",
            "Epoch 14/100\n",
            "380/380 [==============================] - 16s 42ms/step - loss: 608.9896 - f1: 0.8607 - auc: 0.9294 - accuracy: 0.8554 - val_loss: 606.8618 - val_f1: 0.5073 - val_auc: 0.8750 - val_accuracy: 0.7314 - _timestamp: 1656352744.0000 - _runtime: 214.0000\n",
            "Epoch 15/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 604.5057 - f1: 0.8611 - auc: 0.9309 - accuracy: 0.8572 - val_loss: 602.3938 - val_f1: 0.5064 - val_auc: 0.8753 - val_accuracy: 0.7341 - _timestamp: 1656352760.0000 - _runtime: 230.0000\n",
            "Epoch 16/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 600.0453 - f1: 0.8603 - auc: 0.9329 - accuracy: 0.8557 - val_loss: 597.9490 - val_f1: 0.5084 - val_auc: 0.8754 - val_accuracy: 0.7386 - _timestamp: 1656352774.0000 - _runtime: 244.0000\n",
            "Epoch 17/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 595.6050 - f1: 0.8664 - auc: 0.9341 - accuracy: 0.8627 - val_loss: 593.5229 - val_f1: 0.5129 - val_auc: 0.8756 - val_accuracy: 0.7442 - _timestamp: 1656352790.0000 - _runtime: 260.0000\n",
            "Epoch 18/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 591.1855 - f1: 0.8662 - auc: 0.9367 - accuracy: 0.8608 - val_loss: 589.1156 - val_f1: 0.5161 - val_auc: 0.8757 - val_accuracy: 0.7497 - _timestamp: 1656352804.0000 - _runtime: 274.0000\n",
            "Epoch 19/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 586.7891 - f1: 0.8664 - auc: 0.9378 - accuracy: 0.8644 - val_loss: 584.7351 - val_f1: 0.5196 - val_auc: 0.8757 - val_accuracy: 0.7536 - _timestamp: 1656352820.0000 - _runtime: 290.0000\n",
            "Epoch 20/100\n",
            "380/380 [==============================] - 16s 42ms/step - loss: 582.4116 - f1: 0.8724 - auc: 0.9396 - accuracy: 0.8698 - val_loss: 580.3705 - val_f1: 0.5211 - val_auc: 0.8759 - val_accuracy: 0.7558 - _timestamp: 1656352834.0000 - _runtime: 304.0000\n",
            "Epoch 21/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 578.0554 - f1: 0.8708 - auc: 0.9418 - accuracy: 0.8685 - val_loss: 576.0271 - val_f1: 0.5204 - val_auc: 0.8761 - val_accuracy: 0.7592 - _timestamp: 1656352850.0000 - _runtime: 320.0000\n",
            "Epoch 22/100\n",
            "380/380 [==============================] - 17s 44ms/step - loss: 573.7213 - f1: 0.8709 - auc: 0.9427 - accuracy: 0.8684 - val_loss: 571.7068 - val_f1: 0.5218 - val_auc: 0.8763 - val_accuracy: 0.7620 - _timestamp: 1656352864.0000 - _runtime: 334.0000\n",
            "Epoch 23/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 569.4070 - f1: 0.8755 - auc: 0.9439 - accuracy: 0.8736 - val_loss: 567.4050 - val_f1: 0.5229 - val_auc: 0.8764 - val_accuracy: 0.7631 - _timestamp: 1656352881.0000 - _runtime: 351.0000\n",
            "Epoch 24/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 565.1105 - f1: 0.8763 - auc: 0.9465 - accuracy: 0.8751 - val_loss: 563.1270 - val_f1: 0.5227 - val_auc: 0.8767 - val_accuracy: 0.7631 - _timestamp: 1656352898.0000 - _runtime: 368.0000\n",
            "Epoch 25/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 560.8363 - f1: 0.8762 - auc: 0.9471 - accuracy: 0.8753 - val_loss: 558.8543 - val_f1: 0.5254 - val_auc: 0.8766 - val_accuracy: 0.7681 - _timestamp: 1656352912.0000 - _runtime: 382.0000\n",
            "Epoch 26/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 556.5845 - f1: 0.8783 - auc: 0.9479 - accuracy: 0.8772 - val_loss: 554.6202 - val_f1: 0.5265 - val_auc: 0.8771 - val_accuracy: 0.7686 - _timestamp: 1656352927.0000 - _runtime: 397.0000\n",
            "Epoch 27/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 552.3492 - f1: 0.8793 - auc: 0.9502 - accuracy: 0.8791 - val_loss: 550.3953 - val_f1: 0.5226 - val_auc: 0.8772 - val_accuracy: 0.7697 - _timestamp: 1656352941.0000 - _runtime: 411.0000\n",
            "Epoch 28/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 548.1366 - f1: 0.8801 - auc: 0.9507 - accuracy: 0.8800 - val_loss: 546.1940 - val_f1: 0.5217 - val_auc: 0.8773 - val_accuracy: 0.7709 - _timestamp: 1656352955.0000 - _runtime: 425.0000\n",
            "Epoch 29/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 543.9431 - f1: 0.8823 - auc: 0.9527 - accuracy: 0.8826 - val_loss: 542.0074 - val_f1: 0.5242 - val_auc: 0.8773 - val_accuracy: 0.7731 - _timestamp: 1656352970.0000 - _runtime: 440.0000\n",
            "Epoch 30/100\n",
            "380/380 [==============================] - 16s 42ms/step - loss: 539.7719 - f1: 0.8853 - auc: 0.9529 - accuracy: 0.8848 - val_loss: 537.8533 - val_f1: 0.5242 - val_auc: 0.8778 - val_accuracy: 0.7731 - _timestamp: 1656352984.0000 - _runtime: 454.0000\n",
            "Epoch 31/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 535.6172 - f1: 0.8848 - auc: 0.9547 - accuracy: 0.8850 - val_loss: 533.7097 - val_f1: 0.5257 - val_auc: 0.8777 - val_accuracy: 0.7742 - _timestamp: 1656353000.0000 - _runtime: 470.0000\n",
            "Epoch 32/100\n",
            "380/380 [==============================] - 16s 42ms/step - loss: 531.4860 - f1: 0.8870 - auc: 0.9549 - accuracy: 0.8865 - val_loss: 529.5800 - val_f1: 0.5240 - val_auc: 0.8776 - val_accuracy: 0.7764 - _timestamp: 1656353014.0000 - _runtime: 484.0000\n",
            "Epoch 33/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 527.3707 - f1: 0.8878 - auc: 0.9574 - accuracy: 0.8874 - val_loss: 525.4791 - val_f1: 0.5257 - val_auc: 0.8780 - val_accuracy: 0.7775 - _timestamp: 1656353030.0000 - _runtime: 500.0000\n",
            "Epoch 34/100\n",
            "380/380 [==============================] - 15s 41ms/step - loss: 523.2770 - f1: 0.8895 - auc: 0.9577 - accuracy: 0.8897 - val_loss: 521.3943 - val_f1: 0.5263 - val_auc: 0.8779 - val_accuracy: 0.7798 - _timestamp: 1656353044.0000 - _runtime: 514.0000\n",
            "Epoch 35/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 519.2066 - f1: 0.8911 - auc: 0.9572 - accuracy: 0.8903 - val_loss: 517.3328 - val_f1: 0.5284 - val_auc: 0.8782 - val_accuracy: 0.7814 - _timestamp: 1656353060.0000 - _runtime: 530.0000\n",
            "Epoch 36/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 515.1539 - f1: 0.8886 - auc: 0.9576 - accuracy: 0.8882 - val_loss: 513.2867 - val_f1: 0.5302 - val_auc: 0.8785 - val_accuracy: 0.7848 - _timestamp: 1656353074.0000 - _runtime: 544.0000\n",
            "Epoch 37/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 511.1191 - f1: 0.8918 - auc: 0.9584 - accuracy: 0.8923 - val_loss: 509.2676 - val_f1: 0.5327 - val_auc: 0.8786 - val_accuracy: 0.7853 - _timestamp: 1656353090.0000 - _runtime: 560.0000\n",
            "Epoch 38/100\n",
            "380/380 [==============================] - 14s 38ms/step - loss: 507.1048 - f1: 0.8937 - auc: 0.9591 - accuracy: 0.8935 - val_loss: 505.2575 - val_f1: 0.5365 - val_auc: 0.8785 - val_accuracy: 0.7903 - _timestamp: 1656353105.0000 - _runtime: 575.0000\n",
            "Epoch 39/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 503.1095 - f1: 0.8945 - auc: 0.9604 - accuracy: 0.8950 - val_loss: 501.2800 - val_f1: 0.5355 - val_auc: 0.8791 - val_accuracy: 0.7881 - _timestamp: 1656353119.0000 - _runtime: 589.0000\n",
            "Epoch 40/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 499.1337 - f1: 0.8959 - auc: 0.9619 - accuracy: 0.8959 - val_loss: 497.3118 - val_f1: 0.5369 - val_auc: 0.8790 - val_accuracy: 0.7898 - _timestamp: 1656353133.0000 - _runtime: 603.0000\n",
            "Epoch 41/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 495.1793 - f1: 0.8954 - auc: 0.9618 - accuracy: 0.8959 - val_loss: 493.3635 - val_f1: 0.5416 - val_auc: 0.8788 - val_accuracy: 0.7942 - _timestamp: 1656353147.0000 - _runtime: 617.0000\n",
            "Epoch 42/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 491.2447 - f1: 0.8932 - auc: 0.9621 - accuracy: 0.8953 - val_loss: 489.4431 - val_f1: 0.5382 - val_auc: 0.8795 - val_accuracy: 0.7914 - _timestamp: 1656353161.0000 - _runtime: 631.0000\n",
            "Epoch 43/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 487.3285 - f1: 0.8977 - auc: 0.9627 - accuracy: 0.8979 - val_loss: 485.5335 - val_f1: 0.5409 - val_auc: 0.8792 - val_accuracy: 0.7937 - _timestamp: 1656353175.0000 - _runtime: 645.0000\n",
            "Epoch 44/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 483.4310 - f1: 0.8952 - auc: 0.9635 - accuracy: 0.8960 - val_loss: 481.6450 - val_f1: 0.5395 - val_auc: 0.8794 - val_accuracy: 0.7942 - _timestamp: 1656353189.0000 - _runtime: 659.0000\n",
            "Epoch 45/100\n",
            "380/380 [==============================] - 19s 49ms/step - loss: 479.5534 - f1: 0.8987 - auc: 0.9639 - accuracy: 0.8992 - val_loss: 477.7755 - val_f1: 0.5391 - val_auc: 0.8793 - val_accuracy: 0.7964 - _timestamp: 1656353203.0000 - _runtime: 673.0000\n",
            "Epoch 46/100\n",
            "380/380 [==============================] - 14s 38ms/step - loss: 475.6925 - f1: 0.9010 - auc: 0.9654 - accuracy: 0.9018 - val_loss: 473.9345 - val_f1: 0.5372 - val_auc: 0.8800 - val_accuracy: 0.7937 - _timestamp: 1656353222.0000 - _runtime: 692.0000\n",
            "Epoch 47/100\n",
            "380/380 [==============================] - 15s 40ms/step - loss: 471.8545 - f1: 0.9020 - auc: 0.9654 - accuracy: 0.9029 - val_loss: 470.0999 - val_f1: 0.5402 - val_auc: 0.8798 - val_accuracy: 0.7976 - _timestamp: 1656353236.0000 - _runtime: 706.0000\n",
            "Epoch 48/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 468.0360 - f1: 0.9056 - auc: 0.9653 - accuracy: 0.9067 - val_loss: 466.2882 - val_f1: 0.5428 - val_auc: 0.8799 - val_accuracy: 0.8003 - _timestamp: 1656353252.0000 - _runtime: 722.0000\n",
            "Epoch 49/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 464.2355 - f1: 0.9040 - auc: 0.9659 - accuracy: 0.9046 - val_loss: 462.4971 - val_f1: 0.5457 - val_auc: 0.8800 - val_accuracy: 0.8026 - _timestamp: 1656353266.0000 - _runtime: 736.0000\n",
            "Epoch 50/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 460.4560 - f1: 0.9018 - auc: 0.9659 - accuracy: 0.9034 - val_loss: 458.7333 - val_f1: 0.5425 - val_auc: 0.8807 - val_accuracy: 0.7992 - _timestamp: 1656353280.0000 - _runtime: 750.0000\n",
            "Epoch 51/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 456.6920 - f1: 0.9036 - auc: 0.9674 - accuracy: 0.9049 - val_loss: 454.9726 - val_f1: 0.5488 - val_auc: 0.8805 - val_accuracy: 0.8059 - _timestamp: 1656353294.0000 - _runtime: 764.0000\n",
            "Epoch 52/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 452.9525 - f1: 0.9050 - auc: 0.9668 - accuracy: 0.9057 - val_loss: 451.2428 - val_f1: 0.5488 - val_auc: 0.8808 - val_accuracy: 0.8059 - _timestamp: 1656353308.0000 - _runtime: 778.0000\n",
            "Epoch 53/100\n",
            "380/380 [==============================] - 14s 36ms/step - loss: 449.2307 - f1: 0.9007 - auc: 0.9665 - accuracy: 0.9020 - val_loss: 447.5287 - val_f1: 0.5502 - val_auc: 0.8808 - val_accuracy: 0.8076 - _timestamp: 1656353322.0000 - _runtime: 792.0000\n",
            "Epoch 54/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 445.5267 - f1: 0.9033 - auc: 0.9668 - accuracy: 0.9037 - val_loss: 443.8289 - val_f1: 0.5481 - val_auc: 0.8804 - val_accuracy: 0.8098 - _timestamp: 1656353336.0000 - _runtime: 806.0000\n",
            "Epoch 55/100\n",
            "380/380 [==============================] - 14s 36ms/step - loss: 441.8383 - f1: 0.9067 - auc: 0.9685 - accuracy: 0.9084 - val_loss: 440.1607 - val_f1: 0.5485 - val_auc: 0.8809 - val_accuracy: 0.8065 - _timestamp: 1656353350.0000 - _runtime: 820.0000\n",
            "Epoch 56/100\n",
            "380/380 [==============================] - 14s 36ms/step - loss: 438.1764 - f1: 0.9071 - auc: 0.9674 - accuracy: 0.9083 - val_loss: 436.5091 - val_f1: 0.5460 - val_auc: 0.8814 - val_accuracy: 0.8042 - _timestamp: 1656353364.0000 - _runtime: 834.0000\n",
            "Epoch 57/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 434.5268 - f1: 0.9053 - auc: 0.9687 - accuracy: 0.9067 - val_loss: 432.8611 - val_f1: 0.5520 - val_auc: 0.8808 - val_accuracy: 0.8142 - _timestamp: 1656353378.0000 - _runtime: 848.0000\n",
            "Epoch 58/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 430.9008 - f1: 0.9065 - auc: 0.9683 - accuracy: 0.9078 - val_loss: 429.2426 - val_f1: 0.5529 - val_auc: 0.8812 - val_accuracy: 0.8148 - _timestamp: 1656353393.0000 - _runtime: 863.0000\n",
            "Epoch 59/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 427.2932 - f1: 0.9047 - auc: 0.9679 - accuracy: 0.9073 - val_loss: 425.6451 - val_f1: 0.5520 - val_auc: 0.8812 - val_accuracy: 0.8137 - _timestamp: 1656353409.0000 - _runtime: 879.0000\n",
            "Epoch 60/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 423.7005 - f1: 0.9063 - auc: 0.9693 - accuracy: 0.9085 - val_loss: 422.0619 - val_f1: 0.5528 - val_auc: 0.8812 - val_accuracy: 0.8154 - _timestamp: 1656353423.0000 - _runtime: 893.0000\n",
            "Epoch 61/100\n",
            "380/380 [==============================] - 17s 44ms/step - loss: 420.1312 - f1: 0.9059 - auc: 0.9687 - accuracy: 0.9072 - val_loss: 418.5013 - val_f1: 0.5528 - val_auc: 0.8813 - val_accuracy: 0.8154 - _timestamp: 1656353439.0000 - _runtime: 909.0000\n",
            "Epoch 62/100\n",
            "380/380 [==============================] - 15s 40ms/step - loss: 416.5786 - f1: 0.9079 - auc: 0.9693 - accuracy: 0.9097 - val_loss: 414.9575 - val_f1: 0.5513 - val_auc: 0.8819 - val_accuracy: 0.8148 - _timestamp: 1656353456.0000 - _runtime: 926.0000\n",
            "Epoch 63/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 413.0443 - f1: 0.9091 - auc: 0.9697 - accuracy: 0.9108 - val_loss: 411.4326 - val_f1: 0.5519 - val_auc: 0.8819 - val_accuracy: 0.8154 - _timestamp: 1656353471.0000 - _runtime: 941.0000\n",
            "Epoch 64/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 409.5284 - f1: 0.9132 - auc: 0.9705 - accuracy: 0.9136 - val_loss: 407.9282 - val_f1: 0.5519 - val_auc: 0.8820 - val_accuracy: 0.8154 - _timestamp: 1656353485.0000 - _runtime: 955.0000\n",
            "Epoch 65/100\n",
            "380/380 [==============================] - 14s 36ms/step - loss: 406.0342 - f1: 0.9098 - auc: 0.9698 - accuracy: 0.9110 - val_loss: 404.4377 - val_f1: 0.5500 - val_auc: 0.8819 - val_accuracy: 0.8159 - _timestamp: 1656353499.0000 - _runtime: 969.0000\n",
            "Epoch 66/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 402.5552 - f1: 0.9105 - auc: 0.9712 - accuracy: 0.9115 - val_loss: 400.9677 - val_f1: 0.5479 - val_auc: 0.8821 - val_accuracy: 0.8181 - _timestamp: 1656353513.0000 - _runtime: 983.0000\n",
            "Epoch 67/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 399.1005 - f1: 0.9102 - auc: 0.9700 - accuracy: 0.9116 - val_loss: 397.5219 - val_f1: 0.5484 - val_auc: 0.8824 - val_accuracy: 0.8165 - _timestamp: 1656353530.0000 - _runtime: 1000.0000\n",
            "Epoch 68/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 395.6589 - f1: 0.9102 - auc: 0.9707 - accuracy: 0.9126 - val_loss: 394.0951 - val_f1: 0.5516 - val_auc: 0.8828 - val_accuracy: 0.8159 - _timestamp: 1656353547.0000 - _runtime: 1017.0000\n",
            "Epoch 69/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 392.2383 - f1: 0.9100 - auc: 0.9710 - accuracy: 0.9121 - val_loss: 390.6815 - val_f1: 0.5490 - val_auc: 0.8828 - val_accuracy: 0.8170 - _timestamp: 1656353561.0000 - _runtime: 1031.0000\n",
            "Epoch 70/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 388.8364 - f1: 0.9128 - auc: 0.9709 - accuracy: 0.9139 - val_loss: 387.2837 - val_f1: 0.5452 - val_auc: 0.8820 - val_accuracy: 0.8204 - _timestamp: 1656353575.0000 - _runtime: 1045.0000\n",
            "Epoch 71/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 385.4523 - f1: 0.9134 - auc: 0.9712 - accuracy: 0.9151 - val_loss: 383.9089 - val_f1: 0.5447 - val_auc: 0.8821 - val_accuracy: 0.8204 - _timestamp: 1656353590.0000 - _runtime: 1060.0000\n",
            "Epoch 72/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 382.0902 - f1: 0.9085 - auc: 0.9705 - accuracy: 0.9105 - val_loss: 380.5552 - val_f1: 0.5433 - val_auc: 0.8824 - val_accuracy: 0.8192 - _timestamp: 1656353604.0000 - _runtime: 1074.0000\n",
            "Epoch 73/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 378.7395 - f1: 0.9130 - auc: 0.9719 - accuracy: 0.9133 - val_loss: 377.2181 - val_f1: 0.5468 - val_auc: 0.8828 - val_accuracy: 0.8204 - _timestamp: 1656353618.0000 - _runtime: 1088.0000\n",
            "Epoch 74/100\n",
            "380/380 [==============================] - 14s 38ms/step - loss: 375.4125 - f1: 0.9122 - auc: 0.9716 - accuracy: 0.9128 - val_loss: 373.8949 - val_f1: 0.5483 - val_auc: 0.8824 - val_accuracy: 0.8237 - _timestamp: 1656353632.0000 - _runtime: 1102.0000\n",
            "Epoch 75/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 372.1007 - f1: 0.9128 - auc: 0.9719 - accuracy: 0.9140 - val_loss: 370.5952 - val_f1: 0.5483 - val_auc: 0.8824 - val_accuracy: 0.8237 - _timestamp: 1656353646.0000 - _runtime: 1116.0000\n",
            "Epoch 76/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 368.8088 - f1: 0.9132 - auc: 0.9722 - accuracy: 0.9150 - val_loss: 367.3136 - val_f1: 0.5483 - val_auc: 0.8827 - val_accuracy: 0.8237 - _timestamp: 1656353661.0000 - _runtime: 1131.0000\n",
            "Epoch 77/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 365.5362 - f1: 0.9137 - auc: 0.9720 - accuracy: 0.9158 - val_loss: 364.0513 - val_f1: 0.5477 - val_auc: 0.8829 - val_accuracy: 0.8231 - _timestamp: 1656353676.0000 - _runtime: 1146.0000\n",
            "Epoch 78/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 362.2823 - f1: 0.9138 - auc: 0.9719 - accuracy: 0.9155 - val_loss: 360.8035 - val_f1: 0.5476 - val_auc: 0.8828 - val_accuracy: 0.8237 - _timestamp: 1656353690.0000 - _runtime: 1160.0000\n",
            "Epoch 79/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 359.0464 - f1: 0.9135 - auc: 0.9721 - accuracy: 0.9152 - val_loss: 357.5748 - val_f1: 0.5489 - val_auc: 0.8827 - val_accuracy: 0.8248 - _timestamp: 1656353705.0000 - _runtime: 1175.0000\n",
            "Epoch 80/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 355.8299 - f1: 0.9123 - auc: 0.9715 - accuracy: 0.9140 - val_loss: 354.3680 - val_f1: 0.5476 - val_auc: 0.8831 - val_accuracy: 0.8237 - _timestamp: 1656353719.0000 - _runtime: 1189.0000\n",
            "Epoch 81/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 352.6294 - f1: 0.9162 - auc: 0.9719 - accuracy: 0.9173 - val_loss: 351.1740 - val_f1: 0.5497 - val_auc: 0.8830 - val_accuracy: 0.8259 - _timestamp: 1656353733.0000 - _runtime: 1203.0000\n",
            "Epoch 82/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 349.4469 - f1: 0.9144 - auc: 0.9724 - accuracy: 0.9153 - val_loss: 347.9984 - val_f1: 0.5507 - val_auc: 0.8831 - val_accuracy: 0.8270 - _timestamp: 1656353751.0000 - _runtime: 1221.0000\n",
            "Epoch 83/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 346.2830 - f1: 0.9164 - auc: 0.9727 - accuracy: 0.9183 - val_loss: 344.8494 - val_f1: 0.5495 - val_auc: 0.8836 - val_accuracy: 0.8254 - _timestamp: 1656353765.0000 - _runtime: 1235.0000\n",
            "Epoch 84/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 343.1396 - f1: 0.9129 - auc: 0.9723 - accuracy: 0.9141 - val_loss: 341.7073 - val_f1: 0.5530 - val_auc: 0.8832 - val_accuracy: 0.8281 - _timestamp: 1656353779.0000 - _runtime: 1249.0000\n",
            "Epoch 85/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 340.0114 - f1: 0.9143 - auc: 0.9727 - accuracy: 0.9158 - val_loss: 338.5919 - val_f1: 0.5505 - val_auc: 0.8836 - val_accuracy: 0.8265 - _timestamp: 1656353793.0000 - _runtime: 1263.0000\n",
            "Epoch 86/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 336.9013 - f1: 0.9146 - auc: 0.9733 - accuracy: 0.9156 - val_loss: 335.4858 - val_f1: 0.5562 - val_auc: 0.8830 - val_accuracy: 0.8315 - _timestamp: 1656353811.0000 - _runtime: 1281.0000\n",
            "Epoch 87/100\n",
            "380/380 [==============================] - 14s 38ms/step - loss: 333.8067 - f1: 0.9149 - auc: 0.9747 - accuracy: 0.9167 - val_loss: 332.4092 - val_f1: 0.5513 - val_auc: 0.8837 - val_accuracy: 0.8270 - _timestamp: 1656353825.0000 - _runtime: 1295.0000\n",
            "Epoch 88/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 330.7342 - f1: 0.9168 - auc: 0.9743 - accuracy: 0.9185 - val_loss: 329.3405 - val_f1: 0.5562 - val_auc: 0.8832 - val_accuracy: 0.8315 - _timestamp: 1656353839.0000 - _runtime: 1309.0000\n",
            "Epoch 89/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 327.6824 - f1: 0.9158 - auc: 0.9733 - accuracy: 0.9175 - val_loss: 326.2968 - val_f1: 0.5533 - val_auc: 0.8836 - val_accuracy: 0.8293 - _timestamp: 1656353857.0000 - _runtime: 1327.0000\n",
            "Epoch 90/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 324.6479 - f1: 0.9157 - auc: 0.9727 - accuracy: 0.9172 - val_loss: 323.2701 - val_f1: 0.5520 - val_auc: 0.8838 - val_accuracy: 0.8281 - _timestamp: 1656353874.0000 - _runtime: 1344.0000\n",
            "Epoch 91/100\n",
            "380/380 [==============================] - 15s 40ms/step - loss: 321.6275 - f1: 0.9159 - auc: 0.9730 - accuracy: 0.9178 - val_loss: 320.2669 - val_f1: 0.5515 - val_auc: 0.8844 - val_accuracy: 0.8254 - _timestamp: 1656353888.0000 - _runtime: 1358.0000\n",
            "Epoch 92/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 318.6269 - f1: 0.9165 - auc: 0.9734 - accuracy: 0.9178 - val_loss: 317.2641 - val_f1: 0.5575 - val_auc: 0.8836 - val_accuracy: 0.8326 - _timestamp: 1656353903.0000 - _runtime: 1373.0000\n",
            "Epoch 93/100\n",
            "380/380 [==============================] - 15s 41ms/step - loss: 315.6418 - f1: 0.9164 - auc: 0.9740 - accuracy: 0.9177 - val_loss: 314.2902 - val_f1: 0.5575 - val_auc: 0.8833 - val_accuracy: 0.8326 - _timestamp: 1656353917.0000 - _runtime: 1387.0000\n",
            "Epoch 94/100\n",
            "380/380 [==============================] - 15s 41ms/step - loss: 312.6769 - f1: 0.9152 - auc: 0.9739 - accuracy: 0.9168 - val_loss: 311.3369 - val_f1: 0.5553 - val_auc: 0.8840 - val_accuracy: 0.8304 - _timestamp: 1656353933.0000 - _runtime: 1403.0000\n",
            "Epoch 95/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 309.7299 - f1: 0.9185 - auc: 0.9741 - accuracy: 0.9196 - val_loss: 308.3941 - val_f1: 0.5578 - val_auc: 0.8836 - val_accuracy: 0.8337 - _timestamp: 1656353948.0000 - _runtime: 1418.0000\n",
            "Epoch 96/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 306.8016 - f1: 0.9166 - auc: 0.9734 - accuracy: 0.9182 - val_loss: 305.4740 - val_f1: 0.5580 - val_auc: 0.8841 - val_accuracy: 0.8331 - _timestamp: 1656353962.0000 - _runtime: 1432.0000\n",
            "Epoch 97/100\n",
            "380/380 [==============================] - 16s 42ms/step - loss: 303.8868 - f1: 0.9180 - auc: 0.9744 - accuracy: 0.9193 - val_loss: 302.5717 - val_f1: 0.5574 - val_auc: 0.8842 - val_accuracy: 0.8320 - _timestamp: 1656353977.0000 - _runtime: 1447.0000\n",
            "Epoch 98/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 300.9936 - f1: 0.9179 - auc: 0.9741 - accuracy: 0.9194 - val_loss: 299.6851 - val_f1: 0.5593 - val_auc: 0.8843 - val_accuracy: 0.8343 - _timestamp: 1656353993.0000 - _runtime: 1463.0000\n",
            "Epoch 99/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 298.1171 - f1: 0.9179 - auc: 0.9742 - accuracy: 0.9191 - val_loss: 296.8175 - val_f1: 0.5593 - val_auc: 0.8843 - val_accuracy: 0.8343 - _timestamp: 1656354007.0000 - _runtime: 1477.0000\n",
            "Epoch 100/100\n",
            "380/380 [==============================] - 14s 38ms/step - loss: 295.2596 - f1: 0.9171 - auc: 0.9740 - accuracy: 0.9183 - val_loss: 293.9702 - val_f1: 0.5567 - val_auc: 0.8847 - val_accuracy: 0.8315 - _timestamp: 1656354023.0000 - _runtime: 1493.0000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f9295dab18e4f4681f85824b79f8e95",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='1167.873 MB of 1167.873 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>auc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1</td><td>▁▄▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████████████████</td></tr><tr><td>loss</td><td>███▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█████████████████</td></tr><tr><td>val_auc</td><td>▁▅▆▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██████████</td></tr><tr><td>val_f1</td><td>▁▄▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████▇███████████</td></tr><tr><td>val_loss</td><td>███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.91833</td></tr><tr><td>auc</td><td>0.97399</td></tr><tr><td>best_epoch</td><td>99</td></tr><tr><td>best_val_loss</td><td>293.97018</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>f1</td><td>0.91709</td></tr><tr><td>loss</td><td>295.25955</td></tr><tr><td>val_accuracy</td><td>0.83148</td></tr><tr><td>val_auc</td><td>0.88472</td></tr><tr><td>val_f1</td><td>0.5567</td></tr><tr><td>val_loss</td><td>293.97018</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">morning-sweep-3</strong>: <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/lt08804y\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/runs/lt08804y</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220627_175530-lt08804y/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: id26bzh5 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: swish\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_value: 0.015533506815625098\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-07\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons: 2500\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptomizer: adagrad\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_factor: 1e-08\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_type: l1_l2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.19"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220627_182059-id26bzh5</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/id26bzh5\" target=\"_blank\">vivid-sweep-4</a></strong> to <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 25008)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2500)              62522500  \n",
            "                                                                 \n",
            " activation (Activation)     (None, 2500)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 2500)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2500)              6252500   \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 2500)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2500)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2500)              6252500   \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 2500)              0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 2500)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 2501      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 75,030,001\n",
            "Trainable params: 75,030,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "380/380 [==============================] - 10s 22ms/step - loss: 0.6980 - f1: 0.6595 - auc: 0.6511 - accuracy: 0.5450 - val_loss: 0.7085 - val_f1: 0.2756 - val_auc: 0.5284 - val_accuracy: 0.2319 - _timestamp: 1656354073.0000 - _runtime: 14.0000\n",
            "Epoch 2/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6977 - f1: 0.6637 - auc: 0.6018 - accuracy: 0.5514 - val_loss: 0.7085 - val_f1: 0.2756 - val_auc: 0.5308 - val_accuracy: 0.2319 - _timestamp: 1656354081.0000 - _runtime: 22.0000\n",
            "Epoch 3/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6979 - f1: 0.6625 - auc: 0.5980 - accuracy: 0.5487 - val_loss: 0.7085 - val_f1: 0.2756 - val_auc: 0.5338 - val_accuracy: 0.2319 - _timestamp: 1656354088.0000 - _runtime: 29.0000\n",
            "Epoch 4/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6979 - f1: 0.6616 - auc: 0.5985 - accuracy: 0.5473 - val_loss: 0.7085 - val_f1: 0.2756 - val_auc: 0.5371 - val_accuracy: 0.2325 - _timestamp: 1656354095.0000 - _runtime: 36.0000\n",
            "Epoch 5/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6978 - f1: 0.6608 - auc: 0.5996 - accuracy: 0.5453 - val_loss: 0.7085 - val_f1: 0.2753 - val_auc: 0.5374 - val_accuracy: 0.2314 - _timestamp: 1656354101.0000 - _runtime: 42.0000\n",
            "Epoch 6/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6978 - f1: 0.6614 - auc: 0.6033 - accuracy: 0.5478 - val_loss: 0.7085 - val_f1: 0.2753 - val_auc: 0.5369 - val_accuracy: 0.2314 - _timestamp: 1656354108.0000 - _runtime: 49.0000\n",
            "Epoch 7/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6979 - f1: 0.6625 - auc: 0.5931 - accuracy: 0.5477 - val_loss: 0.7085 - val_f1: 0.2753 - val_auc: 0.5370 - val_accuracy: 0.2314 - _timestamp: 1656354115.0000 - _runtime: 56.0000\n",
            "Epoch 8/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6980 - f1: 0.6604 - auc: 0.5952 - accuracy: 0.5443 - val_loss: 0.7085 - val_f1: 0.2753 - val_auc: 0.5391 - val_accuracy: 0.2314 - _timestamp: 1656354122.0000 - _runtime: 63.0000\n",
            "Epoch 9/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6978 - f1: 0.6619 - auc: 0.6042 - accuracy: 0.5468 - val_loss: 0.7085 - val_f1: 0.2762 - val_auc: 0.5416 - val_accuracy: 0.2319 - _timestamp: 1656354128.0000 - _runtime: 69.0000\n",
            "Epoch 10/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6978 - f1: 0.6640 - auc: 0.6056 - accuracy: 0.5503 - val_loss: 0.7085 - val_f1: 0.2773 - val_auc: 0.5466 - val_accuracy: 0.2330 - _timestamp: 1656354135.0000 - _runtime: 76.0000\n",
            "Epoch 11/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6978 - f1: 0.6655 - auc: 0.5996 - accuracy: 0.5519 - val_loss: 0.7085 - val_f1: 0.2771 - val_auc: 0.5460 - val_accuracy: 0.2319 - _timestamp: 1656354142.0000 - _runtime: 83.0000\n",
            "Epoch 12/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6977 - f1: 0.6626 - auc: 0.6039 - accuracy: 0.5478 - val_loss: 0.7085 - val_f1: 0.2771 - val_auc: 0.5484 - val_accuracy: 0.2319 - _timestamp: 1656354148.0000 - _runtime: 89.0000\n",
            "Epoch 13/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6976 - f1: 0.6677 - auc: 0.6072 - accuracy: 0.5533 - val_loss: 0.7085 - val_f1: 0.2771 - val_auc: 0.5476 - val_accuracy: 0.2319 - _timestamp: 1656354155.0000 - _runtime: 96.0000\n",
            "Epoch 14/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6978 - f1: 0.6649 - auc: 0.6036 - accuracy: 0.5496 - val_loss: 0.7085 - val_f1: 0.2778 - val_auc: 0.5500 - val_accuracy: 0.2319 - _timestamp: 1656354162.0000 - _runtime: 103.0000\n",
            "Epoch 15/100\n",
            "380/380 [==============================] - 7s 17ms/step - loss: 0.6976 - f1: 0.6684 - auc: 0.6106 - accuracy: 0.5521 - val_loss: 0.7086 - val_f1: 0.2783 - val_auc: 0.5495 - val_accuracy: 0.2314 - _timestamp: 1656354169.0000 - _runtime: 110.0000\n",
            "Epoch 16/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6976 - f1: 0.6640 - auc: 0.6087 - accuracy: 0.5474 - val_loss: 0.7086 - val_f1: 0.2783 - val_auc: 0.5509 - val_accuracy: 0.2314 - _timestamp: 1656354175.0000 - _runtime: 116.0000\n",
            "Epoch 17/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6976 - f1: 0.6653 - auc: 0.6081 - accuracy: 0.5487 - val_loss: 0.7086 - val_f1: 0.2783 - val_auc: 0.5524 - val_accuracy: 0.2314 - _timestamp: 1656354182.0000 - _runtime: 123.0000\n",
            "Epoch 18/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6976 - f1: 0.6654 - auc: 0.6093 - accuracy: 0.5491 - val_loss: 0.7086 - val_f1: 0.2790 - val_auc: 0.5532 - val_accuracy: 0.2319 - _timestamp: 1656354189.0000 - _runtime: 130.0000\n",
            "Epoch 19/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6975 - f1: 0.6669 - auc: 0.6126 - accuracy: 0.5494 - val_loss: 0.7086 - val_f1: 0.2788 - val_auc: 0.5542 - val_accuracy: 0.2314 - _timestamp: 1656354195.0000 - _runtime: 136.0000\n",
            "Epoch 20/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6975 - f1: 0.6709 - auc: 0.6119 - accuracy: 0.5553 - val_loss: 0.7086 - val_f1: 0.2787 - val_auc: 0.5561 - val_accuracy: 0.2308 - _timestamp: 1656354202.0000 - _runtime: 143.0000\n",
            "Epoch 21/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6976 - f1: 0.6647 - auc: 0.6086 - accuracy: 0.5478 - val_loss: 0.7086 - val_f1: 0.2785 - val_auc: 0.5572 - val_accuracy: 0.2303 - _timestamp: 1656354209.0000 - _runtime: 150.0000\n",
            "Epoch 22/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6974 - f1: 0.6688 - auc: 0.6171 - accuracy: 0.5542 - val_loss: 0.7086 - val_f1: 0.2783 - val_auc: 0.5571 - val_accuracy: 0.2297 - _timestamp: 1656354216.0000 - _runtime: 157.0000\n",
            "Epoch 23/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6974 - f1: 0.6706 - auc: 0.6156 - accuracy: 0.5554 - val_loss: 0.7086 - val_f1: 0.2783 - val_auc: 0.5596 - val_accuracy: 0.2297 - _timestamp: 1656354222.0000 - _runtime: 163.0000\n",
            "Epoch 24/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6975 - f1: 0.6694 - auc: 0.6131 - accuracy: 0.5520 - val_loss: 0.7086 - val_f1: 0.2783 - val_auc: 0.5604 - val_accuracy: 0.2297 - _timestamp: 1656354229.0000 - _runtime: 170.0000\n",
            "Epoch 25/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6973 - f1: 0.6711 - auc: 0.6186 - accuracy: 0.5561 - val_loss: 0.7086 - val_f1: 0.2783 - val_auc: 0.5619 - val_accuracy: 0.2297 - _timestamp: 1656354236.0000 - _runtime: 177.0000\n",
            "Epoch 26/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6974 - f1: 0.6662 - auc: 0.6181 - accuracy: 0.5508 - val_loss: 0.7086 - val_f1: 0.2782 - val_auc: 0.5619 - val_accuracy: 0.2291 - _timestamp: 1656354242.0000 - _runtime: 183.0000\n",
            "Epoch 27/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6973 - f1: 0.6691 - auc: 0.6183 - accuracy: 0.5531 - val_loss: 0.7086 - val_f1: 0.2788 - val_auc: 0.5619 - val_accuracy: 0.2291 - _timestamp: 1656354249.0000 - _runtime: 190.0000\n",
            "Epoch 28/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6973 - f1: 0.6710 - auc: 0.6167 - accuracy: 0.5561 - val_loss: 0.7086 - val_f1: 0.2788 - val_auc: 0.5629 - val_accuracy: 0.2291 - _timestamp: 1656354256.0000 - _runtime: 197.0000\n",
            "Epoch 29/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6973 - f1: 0.6695 - auc: 0.6203 - accuracy: 0.5543 - val_loss: 0.7086 - val_f1: 0.2789 - val_auc: 0.5662 - val_accuracy: 0.2291 - _timestamp: 1656354263.0000 - _runtime: 204.0000\n",
            "Epoch 30/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6971 - f1: 0.6705 - auc: 0.6303 - accuracy: 0.5547 - val_loss: 0.7086 - val_f1: 0.2787 - val_auc: 0.5657 - val_accuracy: 0.2286 - _timestamp: 1656354269.0000 - _runtime: 210.0000\n",
            "Epoch 31/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6972 - f1: 0.6696 - auc: 0.6285 - accuracy: 0.5519 - val_loss: 0.7086 - val_f1: 0.2787 - val_auc: 0.5705 - val_accuracy: 0.2286 - _timestamp: 1656354276.0000 - _runtime: 217.0000\n",
            "Epoch 32/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6972 - f1: 0.6724 - auc: 0.6259 - accuracy: 0.5580 - val_loss: 0.7086 - val_f1: 0.2785 - val_auc: 0.5716 - val_accuracy: 0.2280 - _timestamp: 1656354283.0000 - _runtime: 224.0000\n",
            "Epoch 33/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6972 - f1: 0.6710 - auc: 0.6241 - accuracy: 0.5560 - val_loss: 0.7086 - val_f1: 0.2785 - val_auc: 0.5717 - val_accuracy: 0.2280 - _timestamp: 1656354290.0000 - _runtime: 231.0000\n",
            "Epoch 34/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6970 - f1: 0.6733 - auc: 0.6335 - accuracy: 0.5570 - val_loss: 0.7086 - val_f1: 0.2785 - val_auc: 0.5740 - val_accuracy: 0.2280 - _timestamp: 1656354296.0000 - _runtime: 237.0000\n",
            "Epoch 35/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6972 - f1: 0.6717 - auc: 0.6240 - accuracy: 0.5560 - val_loss: 0.7087 - val_f1: 0.2784 - val_auc: 0.5747 - val_accuracy: 0.2275 - _timestamp: 1656354303.0000 - _runtime: 244.0000\n",
            "Epoch 36/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6968 - f1: 0.6753 - auc: 0.6321 - accuracy: 0.5623 - val_loss: 0.7087 - val_f1: 0.2795 - val_auc: 0.5751 - val_accuracy: 0.2286 - _timestamp: 1656354310.0000 - _runtime: 251.0000\n",
            "Epoch 37/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6970 - f1: 0.6721 - auc: 0.6317 - accuracy: 0.5551 - val_loss: 0.7087 - val_f1: 0.2795 - val_auc: 0.5771 - val_accuracy: 0.2286 - _timestamp: 1656354317.0000 - _runtime: 258.0000\n",
            "Epoch 38/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6970 - f1: 0.6716 - auc: 0.6326 - accuracy: 0.5543 - val_loss: 0.7087 - val_f1: 0.2795 - val_auc: 0.5781 - val_accuracy: 0.2286 - _timestamp: 1656354323.0000 - _runtime: 264.0000\n",
            "Epoch 39/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6971 - f1: 0.6725 - auc: 0.6304 - accuracy: 0.5562 - val_loss: 0.7087 - val_f1: 0.2793 - val_auc: 0.5770 - val_accuracy: 0.2280 - _timestamp: 1656354330.0000 - _runtime: 271.0000\n",
            "Epoch 40/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6968 - f1: 0.6767 - auc: 0.6370 - accuracy: 0.5612 - val_loss: 0.7087 - val_f1: 0.2795 - val_auc: 0.5772 - val_accuracy: 0.2291 - _timestamp: 1656354337.0000 - _runtime: 278.0000\n",
            "Epoch 41/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6968 - f1: 0.6722 - auc: 0.6400 - accuracy: 0.5567 - val_loss: 0.7087 - val_f1: 0.2794 - val_auc: 0.5780 - val_accuracy: 0.2286 - _timestamp: 1656354344.0000 - _runtime: 285.0000\n",
            "Epoch 42/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6970 - f1: 0.6747 - auc: 0.6348 - accuracy: 0.5581 - val_loss: 0.7087 - val_f1: 0.2804 - val_auc: 0.5769 - val_accuracy: 0.2297 - _timestamp: 1656354350.0000 - _runtime: 291.0000\n",
            "Epoch 43/100\n",
            "380/380 [==============================] - 7s 17ms/step - loss: 0.6969 - f1: 0.6763 - auc: 0.6374 - accuracy: 0.5603 - val_loss: 0.7087 - val_f1: 0.2804 - val_auc: 0.5801 - val_accuracy: 0.2297 - _timestamp: 1656354357.0000 - _runtime: 298.0000\n",
            "Epoch 44/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6968 - f1: 0.6739 - auc: 0.6391 - accuracy: 0.5574 - val_loss: 0.7087 - val_f1: 0.2801 - val_auc: 0.5816 - val_accuracy: 0.2286 - _timestamp: 1656354364.0000 - _runtime: 305.0000\n",
            "Epoch 45/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6968 - f1: 0.6768 - auc: 0.6408 - accuracy: 0.5589 - val_loss: 0.7087 - val_f1: 0.2799 - val_auc: 0.5823 - val_accuracy: 0.2275 - _timestamp: 1656354370.0000 - _runtime: 311.0000\n",
            "Epoch 46/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6967 - f1: 0.6767 - auc: 0.6425 - accuracy: 0.5616 - val_loss: 0.7087 - val_f1: 0.2808 - val_auc: 0.5839 - val_accuracy: 0.2280 - _timestamp: 1656354377.0000 - _runtime: 318.0000\n",
            "Epoch 47/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6967 - f1: 0.6769 - auc: 0.6418 - accuracy: 0.5609 - val_loss: 0.7087 - val_f1: 0.2808 - val_auc: 0.5858 - val_accuracy: 0.2280 - _timestamp: 1656354384.0000 - _runtime: 325.0000\n",
            "Epoch 48/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6967 - f1: 0.6784 - auc: 0.6450 - accuracy: 0.5608 - val_loss: 0.7087 - val_f1: 0.2808 - val_auc: 0.5883 - val_accuracy: 0.2280 - _timestamp: 1656354391.0000 - _runtime: 332.0000\n",
            "Epoch 49/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6969 - f1: 0.6728 - auc: 0.6377 - accuracy: 0.5562 - val_loss: 0.7087 - val_f1: 0.2807 - val_auc: 0.5906 - val_accuracy: 0.2275 - _timestamp: 1656354397.0000 - _runtime: 338.0000\n",
            "Epoch 50/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6966 - f1: 0.6782 - auc: 0.6499 - accuracy: 0.5610 - val_loss: 0.7087 - val_f1: 0.2807 - val_auc: 0.5928 - val_accuracy: 0.2275 - _timestamp: 1656354404.0000 - _runtime: 345.0000\n",
            "Epoch 51/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6965 - f1: 0.6773 - auc: 0.6499 - accuracy: 0.5630 - val_loss: 0.7087 - val_f1: 0.2806 - val_auc: 0.5930 - val_accuracy: 0.2269 - _timestamp: 1656354411.0000 - _runtime: 352.0000\n",
            "Epoch 52/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6966 - f1: 0.6777 - auc: 0.6486 - accuracy: 0.5613 - val_loss: 0.7087 - val_f1: 0.2806 - val_auc: 0.5921 - val_accuracy: 0.2269 - _timestamp: 1656354418.0000 - _runtime: 359.0000\n",
            "Epoch 53/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6966 - f1: 0.6774 - auc: 0.6487 - accuracy: 0.5598 - val_loss: 0.7087 - val_f1: 0.2806 - val_auc: 0.5948 - val_accuracy: 0.2269 - _timestamp: 1656354424.0000 - _runtime: 365.0000\n",
            "Epoch 54/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6966 - f1: 0.6780 - auc: 0.6464 - accuracy: 0.5620 - val_loss: 0.7087 - val_f1: 0.2804 - val_auc: 0.5978 - val_accuracy: 0.2264 - _timestamp: 1656354431.0000 - _runtime: 372.0000\n",
            "Epoch 55/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6964 - f1: 0.6773 - auc: 0.6528 - accuracy: 0.5599 - val_loss: 0.7087 - val_f1: 0.2804 - val_auc: 0.5969 - val_accuracy: 0.2264 - _timestamp: 1656354438.0000 - _runtime: 379.0000\n",
            "Epoch 56/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6964 - f1: 0.6817 - auc: 0.6544 - accuracy: 0.5652 - val_loss: 0.7087 - val_f1: 0.2804 - val_auc: 0.5969 - val_accuracy: 0.2264 - _timestamp: 1656354445.0000 - _runtime: 386.0000\n",
            "Epoch 57/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6965 - f1: 0.6769 - auc: 0.6495 - accuracy: 0.5592 - val_loss: 0.7087 - val_f1: 0.2804 - val_auc: 0.5976 - val_accuracy: 0.2264 - _timestamp: 1656354451.0000 - _runtime: 392.0000\n",
            "Epoch 58/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6966 - f1: 0.6793 - auc: 0.6488 - accuracy: 0.5622 - val_loss: 0.7088 - val_f1: 0.2805 - val_auc: 0.5992 - val_accuracy: 0.2269 - _timestamp: 1656354458.0000 - _runtime: 399.0000\n",
            "Epoch 59/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6965 - f1: 0.6802 - auc: 0.6509 - accuracy: 0.5617 - val_loss: 0.7088 - val_f1: 0.2812 - val_auc: 0.6034 - val_accuracy: 0.2275 - _timestamp: 1656354465.0000 - _runtime: 406.0000\n",
            "Epoch 60/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6965 - f1: 0.6782 - auc: 0.6526 - accuracy: 0.5611 - val_loss: 0.7088 - val_f1: 0.2813 - val_auc: 0.6057 - val_accuracy: 0.2275 - _timestamp: 1656354472.0000 - _runtime: 413.0000\n",
            "Epoch 61/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6963 - f1: 0.6783 - auc: 0.6585 - accuracy: 0.5615 - val_loss: 0.7088 - val_f1: 0.2821 - val_auc: 0.6074 - val_accuracy: 0.2280 - _timestamp: 1656354478.0000 - _runtime: 419.0000\n",
            "Epoch 62/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6963 - f1: 0.6814 - auc: 0.6597 - accuracy: 0.5656 - val_loss: 0.7088 - val_f1: 0.2821 - val_auc: 0.6090 - val_accuracy: 0.2280 - _timestamp: 1656354485.0000 - _runtime: 426.0000\n",
            "Epoch 63/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6964 - f1: 0.6813 - auc: 0.6554 - accuracy: 0.5639 - val_loss: 0.7088 - val_f1: 0.2821 - val_auc: 0.6109 - val_accuracy: 0.2280 - _timestamp: 1656354492.0000 - _runtime: 433.0000\n",
            "Epoch 64/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6962 - f1: 0.6801 - auc: 0.6599 - accuracy: 0.5636 - val_loss: 0.7088 - val_f1: 0.2821 - val_auc: 0.6127 - val_accuracy: 0.2280 - _timestamp: 1656354498.0000 - _runtime: 439.0000\n",
            "Epoch 65/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6961 - f1: 0.6803 - auc: 0.6655 - accuracy: 0.5637 - val_loss: 0.7088 - val_f1: 0.2830 - val_auc: 0.6138 - val_accuracy: 0.2286 - _timestamp: 1656354505.0000 - _runtime: 446.0000\n",
            "Epoch 66/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6961 - f1: 0.6839 - auc: 0.6645 - accuracy: 0.5682 - val_loss: 0.7088 - val_f1: 0.2830 - val_auc: 0.6156 - val_accuracy: 0.2286 - _timestamp: 1656354512.0000 - _runtime: 453.0000\n",
            "Epoch 67/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6963 - f1: 0.6832 - auc: 0.6589 - accuracy: 0.5649 - val_loss: 0.7088 - val_f1: 0.2832 - val_auc: 0.6167 - val_accuracy: 0.2291 - _timestamp: 1656354519.0000 - _runtime: 460.0000\n",
            "Epoch 68/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6962 - f1: 0.6828 - auc: 0.6632 - accuracy: 0.5663 - val_loss: 0.7088 - val_f1: 0.2832 - val_auc: 0.6142 - val_accuracy: 0.2291 - _timestamp: 1656354525.0000 - _runtime: 466.0000\n",
            "Epoch 69/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6963 - f1: 0.6816 - auc: 0.6584 - accuracy: 0.5646 - val_loss: 0.7088 - val_f1: 0.2832 - val_auc: 0.6147 - val_accuracy: 0.2291 - _timestamp: 1656354532.0000 - _runtime: 473.0000\n",
            "Epoch 70/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6961 - f1: 0.6801 - auc: 0.6613 - accuracy: 0.5637 - val_loss: 0.7088 - val_f1: 0.2832 - val_auc: 0.6175 - val_accuracy: 0.2291 - _timestamp: 1656354539.0000 - _runtime: 480.0000\n",
            "Epoch 71/100\n",
            "380/380 [==============================] - 7s 17ms/step - loss: 0.6961 - f1: 0.6825 - auc: 0.6613 - accuracy: 0.5663 - val_loss: 0.7088 - val_f1: 0.2832 - val_auc: 0.6189 - val_accuracy: 0.2291 - _timestamp: 1656354545.0000 - _runtime: 486.0000\n",
            "Epoch 72/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6959 - f1: 0.6852 - auc: 0.6709 - accuracy: 0.5698 - val_loss: 0.7088 - val_f1: 0.2831 - val_auc: 0.6192 - val_accuracy: 0.2286 - _timestamp: 1656354552.0000 - _runtime: 493.0000\n",
            "Epoch 73/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6960 - f1: 0.6824 - auc: 0.6695 - accuracy: 0.5647 - val_loss: 0.7088 - val_f1: 0.2832 - val_auc: 0.6198 - val_accuracy: 0.2291 - _timestamp: 1656354559.0000 - _runtime: 500.0000\n",
            "Epoch 74/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6959 - f1: 0.6823 - auc: 0.6712 - accuracy: 0.5657 - val_loss: 0.7088 - val_f1: 0.2832 - val_auc: 0.6204 - val_accuracy: 0.2291 - _timestamp: 1656354566.0000 - _runtime: 507.0000\n",
            "Epoch 75/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6960 - f1: 0.6817 - auc: 0.6658 - accuracy: 0.5655 - val_loss: 0.7088 - val_f1: 0.2832 - val_auc: 0.6211 - val_accuracy: 0.2291 - _timestamp: 1656354572.0000 - _runtime: 513.0000\n",
            "Epoch 76/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6960 - f1: 0.6833 - auc: 0.6684 - accuracy: 0.5669 - val_loss: 0.7088 - val_f1: 0.2832 - val_auc: 0.6217 - val_accuracy: 0.2291 - _timestamp: 1656354579.0000 - _runtime: 520.0000\n",
            "Epoch 77/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6958 - f1: 0.6861 - auc: 0.6767 - accuracy: 0.5686 - val_loss: 0.7088 - val_f1: 0.2832 - val_auc: 0.6223 - val_accuracy: 0.2291 - _timestamp: 1656354586.0000 - _runtime: 527.0000\n",
            "Epoch 78/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6960 - f1: 0.6841 - auc: 0.6684 - accuracy: 0.5675 - val_loss: 0.7088 - val_f1: 0.2833 - val_auc: 0.6230 - val_accuracy: 0.2297 - _timestamp: 1656354593.0000 - _runtime: 534.0000\n",
            "Epoch 79/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6960 - f1: 0.6814 - auc: 0.6661 - accuracy: 0.5618 - val_loss: 0.7088 - val_f1: 0.2833 - val_auc: 0.6235 - val_accuracy: 0.2297 - _timestamp: 1656354599.0000 - _runtime: 540.0000\n",
            "Epoch 80/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6958 - f1: 0.6822 - auc: 0.6758 - accuracy: 0.5649 - val_loss: 0.7088 - val_f1: 0.2833 - val_auc: 0.6231 - val_accuracy: 0.2297 - _timestamp: 1656354606.0000 - _runtime: 547.0000\n",
            "Epoch 81/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6957 - f1: 0.6835 - auc: 0.6792 - accuracy: 0.5668 - val_loss: 0.7088 - val_f1: 0.2842 - val_auc: 0.6252 - val_accuracy: 0.2303 - _timestamp: 1656354613.0000 - _runtime: 554.0000\n",
            "Epoch 82/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6958 - f1: 0.6868 - auc: 0.6731 - accuracy: 0.5711 - val_loss: 0.7088 - val_f1: 0.2842 - val_auc: 0.6251 - val_accuracy: 0.2303 - _timestamp: 1656354620.0000 - _runtime: 561.0000\n",
            "Epoch 83/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6957 - f1: 0.6859 - auc: 0.6787 - accuracy: 0.5690 - val_loss: 0.7088 - val_f1: 0.2842 - val_auc: 0.6290 - val_accuracy: 0.2303 - _timestamp: 1656354626.0000 - _runtime: 567.0000\n",
            "Epoch 84/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6958 - f1: 0.6848 - auc: 0.6730 - accuracy: 0.5688 - val_loss: 0.7089 - val_f1: 0.2843 - val_auc: 0.6319 - val_accuracy: 0.2303 - _timestamp: 1656354633.0000 - _runtime: 574.0000\n",
            "Epoch 85/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6958 - f1: 0.6873 - auc: 0.6767 - accuracy: 0.5711 - val_loss: 0.7089 - val_f1: 0.2843 - val_auc: 0.6332 - val_accuracy: 0.2303 - _timestamp: 1656354640.0000 - _runtime: 581.0000\n",
            "Epoch 86/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6957 - f1: 0.6838 - auc: 0.6759 - accuracy: 0.5677 - val_loss: 0.7089 - val_f1: 0.2844 - val_auc: 0.6339 - val_accuracy: 0.2308 - _timestamp: 1656354647.0000 - _runtime: 588.0000\n",
            "Epoch 87/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6957 - f1: 0.6845 - auc: 0.6783 - accuracy: 0.5671 - val_loss: 0.7089 - val_f1: 0.2844 - val_auc: 0.6338 - val_accuracy: 0.2308 - _timestamp: 1656354653.0000 - _runtime: 594.0000\n",
            "Epoch 88/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6957 - f1: 0.6870 - auc: 0.6784 - accuracy: 0.5697 - val_loss: 0.7089 - val_f1: 0.2843 - val_auc: 0.6332 - val_accuracy: 0.2308 - _timestamp: 1656354660.0000 - _runtime: 601.0000\n",
            "Epoch 89/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6956 - f1: 0.6853 - auc: 0.6830 - accuracy: 0.5697 - val_loss: 0.7089 - val_f1: 0.2844 - val_auc: 0.6341 - val_accuracy: 0.2314 - _timestamp: 1656354667.0000 - _runtime: 608.0000\n",
            "Epoch 90/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6956 - f1: 0.6854 - auc: 0.6822 - accuracy: 0.5671 - val_loss: 0.7089 - val_f1: 0.2843 - val_auc: 0.6341 - val_accuracy: 0.2308 - _timestamp: 1656354674.0000 - _runtime: 615.0000\n",
            "Epoch 91/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6956 - f1: 0.6869 - auc: 0.6781 - accuracy: 0.5687 - val_loss: 0.7089 - val_f1: 0.2843 - val_auc: 0.6340 - val_accuracy: 0.2314 - _timestamp: 1656354680.0000 - _runtime: 621.0000\n",
            "Epoch 92/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6955 - f1: 0.6877 - auc: 0.6844 - accuracy: 0.5720 - val_loss: 0.7089 - val_f1: 0.2843 - val_auc: 0.6352 - val_accuracy: 0.2314 - _timestamp: 1656354687.0000 - _runtime: 628.0000\n",
            "Epoch 93/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6955 - f1: 0.6864 - auc: 0.6848 - accuracy: 0.5695 - val_loss: 0.7089 - val_f1: 0.2843 - val_auc: 0.6361 - val_accuracy: 0.2314 - _timestamp: 1656354694.0000 - _runtime: 635.0000\n",
            "Epoch 94/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6955 - f1: 0.6872 - auc: 0.6812 - accuracy: 0.5706 - val_loss: 0.7089 - val_f1: 0.2852 - val_auc: 0.6363 - val_accuracy: 0.2319 - _timestamp: 1656354701.0000 - _runtime: 642.0000\n",
            "Epoch 95/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6954 - f1: 0.6881 - auc: 0.6877 - accuracy: 0.5721 - val_loss: 0.7089 - val_f1: 0.2852 - val_auc: 0.6377 - val_accuracy: 0.2319 - _timestamp: 1656354707.0000 - _runtime: 648.0000\n",
            "Epoch 96/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6955 - f1: 0.6866 - auc: 0.6823 - accuracy: 0.5694 - val_loss: 0.7089 - val_f1: 0.2852 - val_auc: 0.6382 - val_accuracy: 0.2319 - _timestamp: 1656354714.0000 - _runtime: 655.0000\n",
            "Epoch 97/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6954 - f1: 0.6866 - auc: 0.6889 - accuracy: 0.5673 - val_loss: 0.7089 - val_f1: 0.2852 - val_auc: 0.6414 - val_accuracy: 0.2319 - _timestamp: 1656354721.0000 - _runtime: 662.0000\n",
            "Epoch 98/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6954 - f1: 0.6884 - auc: 0.6867 - accuracy: 0.5726 - val_loss: 0.7089 - val_f1: 0.2853 - val_auc: 0.6405 - val_accuracy: 0.2325 - _timestamp: 1656354727.0000 - _runtime: 668.0000\n",
            "Epoch 99/100\n",
            "380/380 [==============================] - 7s 17ms/step - loss: 0.6952 - f1: 0.6873 - auc: 0.6944 - accuracy: 0.5711 - val_loss: 0.7089 - val_f1: 0.2854 - val_auc: 0.6402 - val_accuracy: 0.2330 - _timestamp: 1656354734.0000 - _runtime: 675.0000\n",
            "Epoch 100/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.6953 - f1: 0.6865 - auc: 0.6920 - accuracy: 0.5692 - val_loss: 0.7089 - val_f1: 0.2854 - val_auc: 0.6390 - val_accuracy: 0.2330 - _timestamp: 1656354741.0000 - _runtime: 682.0000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "656423f5b93549a9b3ff088eac96d1a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='572.483 MB of 572.483 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▂▂▁▃▃▂▂▂▄▃▄▃▄▆▄▄▄▅▄▆▅▆▅▅▆▆▆▇▆▇▅█▇▇▇██▇▇</td></tr><tr><td>auc</td><td>▅▁▂▁▁▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇██</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1</td><td>▁▂▁▁▃▃▂▂▂▄▃▄▄▄▅▄▄▅▅▄▅▆▇▆▆▆▇▇▇▇█▆█▇▇▇████</td></tr><tr><td>loss</td><td>██▇█▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▃▄▄▃▃▂▃▂▂▂▂▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▇▇▆▆▇▇▆▇▅▅▄▄▃▃▃▃▃▃▃▂▂▁▁▂▃▃▄▄▃▄▄▅▅▅▆▆▆▇▇█</td></tr><tr><td>val_auc</td><td>▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██████</td></tr><tr><td>val_f1</td><td>▁▁▁▁▂▂▃▄▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_loss</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.56916</td></tr><tr><td>auc</td><td>0.69197</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.70848</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>f1</td><td>0.68649</td></tr><tr><td>loss</td><td>0.69531</td></tr><tr><td>val_accuracy</td><td>0.23304</td></tr><tr><td>val_auc</td><td>0.63896</td></tr><tr><td>val_f1</td><td>0.28543</td></tr><tr><td>val_loss</td><td>0.7089</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">vivid-sweep-4</strong>: <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/id26bzh5\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/runs/id26bzh5</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220627_182059-id26bzh5/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dhugb9w7 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: swish\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_value: 0.17063798287560922\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons: 5000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptomizer: adadelta\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_factor: 5e-06\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_type: l1_l2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.19"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220627_183242-dhugb9w7</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/dhugb9w7\" target=\"_blank\">worldly-sweep-5</a></strong> to <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 25008)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5000)              125045000 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 5000)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5000)              25005000  \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 5000)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5000)              25005000  \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 5000)              0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5000)              25005000  \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 5000)              0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 5000)              25005000  \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 5000)              0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 5001      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 225,070,001\n",
            "Trainable params: 225,070,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "380/380 [==============================] - 36s 89ms/step - loss: 11.3794 - f1: 0.4870 - auc: 0.4400 - accuracy: 0.4866 - val_loss: 11.3795 - val_f1: 0.2494 - val_auc: 0.4977 - val_accuracy: 0.4505 - _timestamp: 1656354787.0000 - _runtime: 25.0000\n",
            "Epoch 2/100\n",
            "380/380 [==============================] - 27s 72ms/step - loss: 11.3791 - f1: 0.5139 - auc: 0.5009 - accuracy: 0.5053 - val_loss: 11.3794 - val_f1: 0.2656 - val_auc: 0.5053 - val_accuracy: 0.4427 - _timestamp: 1656354820.0000 - _runtime: 58.0000\n",
            "Epoch 3/100\n",
            "380/380 [==============================] - 27s 72ms/step - loss: 11.3789 - f1: 0.5200 - auc: 0.5055 - accuracy: 0.5049 - val_loss: 11.3794 - val_f1: 0.2792 - val_auc: 0.5158 - val_accuracy: 0.4394 - _timestamp: 1656354848.0000 - _runtime: 86.0000\n",
            "Epoch 4/100\n",
            "380/380 [==============================] - 29s 75ms/step - loss: 11.3788 - f1: 0.5419 - auc: 0.5146 - accuracy: 0.5156 - val_loss: 11.3793 - val_f1: 0.2932 - val_auc: 0.5209 - val_accuracy: 0.4327 - _timestamp: 1656354875.0000 - _runtime: 113.0000\n",
            "Epoch 5/100\n",
            "380/380 [==============================] - 27s 71ms/step - loss: 11.3785 - f1: 0.5622 - auc: 0.5297 - accuracy: 0.5311 - val_loss: 11.3793 - val_f1: 0.2999 - val_auc: 0.5320 - val_accuracy: 0.4271 - _timestamp: 1656354904.0000 - _runtime: 142.0000\n",
            "Epoch 6/100\n",
            "380/380 [==============================] - 27s 71ms/step - loss: 11.3782 - f1: 0.5723 - auc: 0.5383 - accuracy: 0.5378 - val_loss: 11.3792 - val_f1: 0.3105 - val_auc: 0.5341 - val_accuracy: 0.4277 - _timestamp: 1656354930.0000 - _runtime: 168.0000\n",
            "Epoch 7/100\n",
            "380/380 [==============================] - 28s 73ms/step - loss: 11.3780 - f1: 0.5907 - auc: 0.5517 - accuracy: 0.5494 - val_loss: 11.3791 - val_f1: 0.3125 - val_auc: 0.5489 - val_accuracy: 0.4221 - _timestamp: 1656354957.0000 - _runtime: 195.0000\n",
            "Epoch 8/100\n",
            "380/380 [==============================] - 27s 71ms/step - loss: 11.3778 - f1: 0.6009 - auc: 0.5594 - accuracy: 0.5586 - val_loss: 11.3791 - val_f1: 0.3134 - val_auc: 0.5657 - val_accuracy: 0.4182 - _timestamp: 1656354985.0000 - _runtime: 223.0000\n",
            "Epoch 9/100\n",
            "380/380 [==============================] - 28s 74ms/step - loss: 11.3776 - f1: 0.6179 - auc: 0.5697 - accuracy: 0.5682 - val_loss: 11.3790 - val_f1: 0.3182 - val_auc: 0.5752 - val_accuracy: 0.4149 - _timestamp: 1656355012.0000 - _runtime: 250.0000\n",
            "Epoch 10/100\n",
            "380/380 [==============================] - 27s 72ms/step - loss: 11.3774 - f1: 0.6234 - auc: 0.5770 - accuracy: 0.5715 - val_loss: 11.3790 - val_f1: 0.3230 - val_auc: 0.6013 - val_accuracy: 0.4149 - _timestamp: 1656355040.0000 - _runtime: 278.0000\n",
            "Epoch 11/100\n",
            "380/380 [==============================] - 27s 71ms/step - loss: 11.3772 - f1: 0.6364 - auc: 0.5854 - accuracy: 0.5813 - val_loss: 11.3789 - val_f1: 0.3330 - val_auc: 0.6191 - val_accuracy: 0.4171 - _timestamp: 1656355067.0000 - _runtime: 305.0000\n",
            "Epoch 12/100\n",
            "380/380 [==============================] - 27s 71ms/step - loss: 11.3770 - f1: 0.6480 - auc: 0.5955 - accuracy: 0.5879 - val_loss: 11.3788 - val_f1: 0.3365 - val_auc: 0.6405 - val_accuracy: 0.4143 - _timestamp: 1656355094.0000 - _runtime: 332.0000\n",
            "Epoch 13/100\n",
            "380/380 [==============================] - 28s 73ms/step - loss: 11.3766 - f1: 0.6599 - auc: 0.6142 - accuracy: 0.6025 - val_loss: 11.3788 - val_f1: 0.3399 - val_auc: 0.6610 - val_accuracy: 0.4138 - _timestamp: 1656355121.0000 - _runtime: 359.0000\n",
            "Epoch 14/100\n",
            "380/380 [==============================] - 27s 70ms/step - loss: 11.3765 - f1: 0.6644 - auc: 0.6135 - accuracy: 0.6012 - val_loss: 11.3787 - val_f1: 0.3394 - val_auc: 0.6704 - val_accuracy: 0.4105 - _timestamp: 1656355149.0000 - _runtime: 387.0000\n",
            "Epoch 15/100\n",
            "380/380 [==============================] - 27s 70ms/step - loss: 11.3763 - f1: 0.6754 - auc: 0.6248 - accuracy: 0.6120 - val_loss: 11.3786 - val_f1: 0.3419 - val_auc: 0.6972 - val_accuracy: 0.4105 - _timestamp: 1656355175.0000 - _runtime: 413.0000\n",
            "Epoch 16/100\n",
            "380/380 [==============================] - 28s 73ms/step - loss: 11.3761 - f1: 0.6767 - auc: 0.6317 - accuracy: 0.6102 - val_loss: 11.3786 - val_f1: 0.3424 - val_auc: 0.7094 - val_accuracy: 0.4088 - _timestamp: 1656355202.0000 - _runtime: 440.0000\n",
            "Epoch 17/100\n",
            "380/380 [==============================] - 27s 70ms/step - loss: 11.3759 - f1: 0.6851 - auc: 0.6443 - accuracy: 0.6186 - val_loss: 11.3785 - val_f1: 0.3424 - val_auc: 0.7114 - val_accuracy: 0.4088 - _timestamp: 1656355230.0000 - _runtime: 468.0000\n",
            "Epoch 18/100\n",
            "380/380 [==============================] - 28s 73ms/step - loss: 11.3756 - f1: 0.6939 - auc: 0.6519 - accuracy: 0.6265 - val_loss: 11.3784 - val_f1: 0.3430 - val_auc: 0.7140 - val_accuracy: 0.4077 - _timestamp: 1656355256.0000 - _runtime: 494.0000\n",
            "Epoch 19/100\n",
            "380/380 [==============================] - 27s 72ms/step - loss: 11.3755 - f1: 0.6940 - auc: 0.6590 - accuracy: 0.6230 - val_loss: 11.3784 - val_f1: 0.3427 - val_auc: 0.7312 - val_accuracy: 0.4066 - _timestamp: 1656355284.0000 - _runtime: 522.0000\n",
            "Epoch 20/100\n",
            "380/380 [==============================] - 28s 73ms/step - loss: 11.3752 - f1: 0.7022 - auc: 0.6696 - accuracy: 0.6312 - val_loss: 11.3783 - val_f1: 0.3437 - val_auc: 0.7400 - val_accuracy: 0.4066 - _timestamp: 1656355312.0000 - _runtime: 550.0000\n",
            "Epoch 21/100\n",
            "380/380 [==============================] - 27s 72ms/step - loss: 11.3749 - f1: 0.7066 - auc: 0.6804 - accuracy: 0.6383 - val_loss: 11.3782 - val_f1: 0.3431 - val_auc: 0.7422 - val_accuracy: 0.4049 - _timestamp: 1656355339.0000 - _runtime: 577.0000\n",
            "Epoch 22/100\n",
            "380/380 [==============================] - 28s 73ms/step - loss: 11.3747 - f1: 0.7087 - auc: 0.6881 - accuracy: 0.6394 - val_loss: 11.3782 - val_f1: 0.3448 - val_auc: 0.7498 - val_accuracy: 0.4049 - _timestamp: 1656355367.0000 - _runtime: 605.0000\n",
            "Epoch 23/100\n",
            "380/380 [==============================] - 38s 99ms/step - loss: 11.3745 - f1: 0.7119 - auc: 0.6905 - accuracy: 0.6390 - val_loss: 11.3781 - val_f1: 0.3448 - val_auc: 0.7518 - val_accuracy: 0.4055 - _timestamp: 1656355394.0000 - _runtime: 632.0000\n",
            "Epoch 24/100\n",
            "380/380 [==============================] - 26s 70ms/step - loss: 11.3743 - f1: 0.7181 - auc: 0.7016 - accuracy: 0.6440 - val_loss: 11.3780 - val_f1: 0.3447 - val_auc: 0.7618 - val_accuracy: 0.4055 - _timestamp: 1656355432.0000 - _runtime: 670.0000\n",
            "Epoch 25/100\n",
            "380/380 [==============================] - 27s 70ms/step - loss: 11.3740 - f1: 0.7193 - auc: 0.7105 - accuracy: 0.6461 - val_loss: 11.3780 - val_f1: 0.3432 - val_auc: 0.7712 - val_accuracy: 0.4032 - _timestamp: 1656355458.0000 - _runtime: 696.0000\n",
            "Epoch 26/100\n",
            "380/380 [==============================] - 27s 72ms/step - loss: 11.3738 - f1: 0.7226 - auc: 0.7145 - accuracy: 0.6479 - val_loss: 11.3779 - val_f1: 0.3446 - val_auc: 0.7736 - val_accuracy: 0.4043 - _timestamp: 1656355485.0000 - _runtime: 723.0000\n",
            "Epoch 27/100\n",
            "380/380 [==============================] - 27s 72ms/step - loss: 11.3735 - f1: 0.7257 - auc: 0.7275 - accuracy: 0.6521 - val_loss: 11.3778 - val_f1: 0.3445 - val_auc: 0.7742 - val_accuracy: 0.4038 - _timestamp: 1656355512.0000 - _runtime: 750.0000\n",
            "Epoch 28/100\n",
            "380/380 [==============================] - 27s 72ms/step - loss: 11.3733 - f1: 0.7273 - auc: 0.7292 - accuracy: 0.6549 - val_loss: 11.3778 - val_f1: 0.3441 - val_auc: 0.7708 - val_accuracy: 0.4027 - _timestamp: 1656355540.0000 - _runtime: 778.0000\n",
            "Epoch 29/100\n",
            "380/380 [==============================] - 27s 70ms/step - loss: 11.3731 - f1: 0.7307 - auc: 0.7362 - accuracy: 0.6558 - val_loss: 11.3777 - val_f1: 0.3439 - val_auc: 0.7722 - val_accuracy: 0.4021 - _timestamp: 1656355567.0000 - _runtime: 805.0000\n",
            "Epoch 30/100\n",
            "380/380 [==============================] - 29s 76ms/step - loss: 11.3729 - f1: 0.7312 - auc: 0.7424 - accuracy: 0.6582 - val_loss: 11.3776 - val_f1: 0.3440 - val_auc: 0.7768 - val_accuracy: 0.4021 - _timestamp: 1656355594.0000 - _runtime: 832.0000\n",
            "Epoch 31/100\n",
            "380/380 [==============================] - 28s 74ms/step - loss: 11.3727 - f1: 0.7318 - auc: 0.7458 - accuracy: 0.6573 - val_loss: 11.3775 - val_f1: 0.3439 - val_auc: 0.7839 - val_accuracy: 0.4016 - _timestamp: 1656355622.0000 - _runtime: 860.0000\n",
            "Epoch 32/100\n",
            "380/380 [==============================] - 29s 76ms/step - loss: 11.3725 - f1: 0.7300 - auc: 0.7467 - accuracy: 0.6551 - val_loss: 11.3775 - val_f1: 0.3444 - val_auc: 0.7877 - val_accuracy: 0.4032 - _timestamp: 1656355650.0000 - _runtime: 888.0000\n",
            "Epoch 33/100\n",
            "380/380 [==============================] - 27s 71ms/step - loss: 11.3722 - f1: 0.7355 - auc: 0.7571 - accuracy: 0.6620 - val_loss: 11.3774 - val_f1: 0.3436 - val_auc: 0.7939 - val_accuracy: 0.4021 - _timestamp: 1656355679.0000 - _runtime: 917.0000\n",
            "Epoch 34/100\n",
            "380/380 [==============================] - 26s 70ms/step - loss: 11.3720 - f1: 0.7340 - auc: 0.7594 - accuracy: 0.6577 - val_loss: 11.3773 - val_f1: 0.3441 - val_auc: 0.7917 - val_accuracy: 0.4032 - _timestamp: 1656355706.0000 - _runtime: 944.0000\n",
            "Epoch 35/100\n",
            "380/380 [==============================] - 28s 73ms/step - loss: 11.3717 - f1: 0.7380 - auc: 0.7696 - accuracy: 0.6657 - val_loss: 11.3772 - val_f1: 0.3439 - val_auc: 0.7925 - val_accuracy: 0.4032 - _timestamp: 1656355733.0000 - _runtime: 971.0000\n",
            "Epoch 36/100\n",
            "380/380 [==============================] - 27s 70ms/step - loss: 11.3716 - f1: 0.7360 - auc: 0.7680 - accuracy: 0.6588 - val_loss: 11.3772 - val_f1: 0.3443 - val_auc: 0.7962 - val_accuracy: 0.4043 - _timestamp: 1656355760.0000 - _runtime: 998.0000\n",
            "Epoch 37/100\n",
            "380/380 [==============================] - 28s 74ms/step - loss: 11.3715 - f1: 0.7371 - auc: 0.7678 - accuracy: 0.6614 - val_loss: 11.3771 - val_f1: 0.3446 - val_auc: 0.7984 - val_accuracy: 0.4049 - _timestamp: 1656355787.0000 - _runtime: 1025.0000\n",
            "Epoch 38/100\n",
            "380/380 [==============================] - 28s 74ms/step - loss: 11.3711 - f1: 0.7343 - auc: 0.7776 - accuracy: 0.6585 - val_loss: 11.3770 - val_f1: 0.3451 - val_auc: 0.8114 - val_accuracy: 0.4066 - _timestamp: 1656355815.0000 - _runtime: 1053.0000\n",
            "Epoch 39/100\n",
            "380/380 [==============================] - 28s 74ms/step - loss: 11.3709 - f1: 0.7402 - auc: 0.7832 - accuracy: 0.6662 - val_loss: 11.3769 - val_f1: 0.3454 - val_auc: 0.8126 - val_accuracy: 0.4077 - _timestamp: 1656355843.0000 - _runtime: 1081.0000\n",
            "Epoch 40/100\n",
            "380/380 [==============================] - 28s 73ms/step - loss: 11.3706 - f1: 0.7373 - auc: 0.7867 - accuracy: 0.6618 - val_loss: 11.3768 - val_f1: 0.3457 - val_auc: 0.8110 - val_accuracy: 0.4088 - _timestamp: 1656355872.0000 - _runtime: 1110.0000\n",
            "Epoch 41/100\n",
            "380/380 [==============================] - 28s 75ms/step - loss: 11.3704 - f1: 0.7411 - auc: 0.7853 - accuracy: 0.6654 - val_loss: 11.3768 - val_f1: 0.3464 - val_auc: 0.8138 - val_accuracy: 0.4105 - _timestamp: 1656355899.0000 - _runtime: 1137.0000\n",
            "Epoch 42/100\n",
            "380/380 [==============================] - 29s 75ms/step - loss: 11.3703 - f1: 0.7412 - auc: 0.7883 - accuracy: 0.6661 - val_loss: 11.3767 - val_f1: 0.3466 - val_auc: 0.8153 - val_accuracy: 0.4110 - _timestamp: 1656355928.0000 - _runtime: 1166.0000\n",
            "Epoch 43/100\n",
            "380/380 [==============================] - 26s 70ms/step - loss: 11.3701 - f1: 0.7389 - auc: 0.7900 - accuracy: 0.6627 - val_loss: 11.3766 - val_f1: 0.3468 - val_auc: 0.8178 - val_accuracy: 0.4121 - _timestamp: 1656355956.0000 - _runtime: 1194.0000\n",
            "Epoch 44/100\n",
            "380/380 [==============================] - 28s 73ms/step - loss: 11.3698 - f1: 0.7402 - auc: 0.7986 - accuracy: 0.6642 - val_loss: 11.3765 - val_f1: 0.3467 - val_auc: 0.8206 - val_accuracy: 0.4116 - _timestamp: 1656355983.0000 - _runtime: 1221.0000\n",
            "Epoch 45/100\n",
            "380/380 [==============================] - 29s 76ms/step - loss: 11.3695 - f1: 0.7408 - auc: 0.7997 - accuracy: 0.6660 - val_loss: 11.3764 - val_f1: 0.3469 - val_auc: 0.8212 - val_accuracy: 0.4127 - _timestamp: 1656356011.0000 - _runtime: 1249.0000\n",
            "Epoch 46/100\n",
            "380/380 [==============================] - 28s 74ms/step - loss: 11.3693 - f1: 0.7423 - auc: 0.8042 - accuracy: 0.6655 - val_loss: 11.3764 - val_f1: 0.3472 - val_auc: 0.8197 - val_accuracy: 0.4138 - _timestamp: 1656356039.0000 - _runtime: 1277.0000\n",
            "Epoch 47/100\n",
            "380/380 [==============================] - 29s 77ms/step - loss: 11.3690 - f1: 0.7422 - auc: 0.8069 - accuracy: 0.6685 - val_loss: 11.3763 - val_f1: 0.3482 - val_auc: 0.8228 - val_accuracy: 0.4160 - _timestamp: 1656356068.0000 - _runtime: 1306.0000\n",
            "Epoch 48/100\n",
            "380/380 [==============================] - 26s 70ms/step - loss: 11.3689 - f1: 0.7451 - auc: 0.8080 - accuracy: 0.6699 - val_loss: 11.3762 - val_f1: 0.3483 - val_auc: 0.8277 - val_accuracy: 0.4166 - _timestamp: 1656356097.0000 - _runtime: 1335.0000\n",
            "Epoch 49/100\n",
            "380/380 [==============================] - 27s 72ms/step - loss: 11.3687 - f1: 0.7439 - auc: 0.8091 - accuracy: 0.6689 - val_loss: 11.3761 - val_f1: 0.3486 - val_auc: 0.8299 - val_accuracy: 0.4171 - _timestamp: 1656356123.0000 - _runtime: 1361.0000\n",
            "Epoch 50/100\n",
            "380/380 [==============================] - 27s 70ms/step - loss: 11.3683 - f1: 0.7442 - auc: 0.8143 - accuracy: 0.6699 - val_loss: 11.3760 - val_f1: 0.3488 - val_auc: 0.8294 - val_accuracy: 0.4177 - _timestamp: 1656356151.0000 - _runtime: 1389.0000\n",
            "Epoch 51/100\n",
            "380/380 [==============================] - 27s 72ms/step - loss: 11.3682 - f1: 0.7419 - auc: 0.8146 - accuracy: 0.6652 - val_loss: 11.3759 - val_f1: 0.3491 - val_auc: 0.8296 - val_accuracy: 0.4182 - _timestamp: 1656356177.0000 - _runtime: 1415.0000\n",
            "Epoch 52/100\n",
            "380/380 [==============================] - 27s 70ms/step - loss: 11.3680 - f1: 0.7427 - auc: 0.8143 - accuracy: 0.6683 - val_loss: 11.3759 - val_f1: 0.3493 - val_auc: 0.8322 - val_accuracy: 0.4188 - _timestamp: 1656356205.0000 - _runtime: 1443.0000\n",
            "Epoch 53/100\n",
            "380/380 [==============================] - 28s 74ms/step - loss: 11.3676 - f1: 0.7428 - auc: 0.8249 - accuracy: 0.6666 - val_loss: 11.3758 - val_f1: 0.3493 - val_auc: 0.8325 - val_accuracy: 0.4188 - _timestamp: 1656356231.0000 - _runtime: 1469.0000\n",
            "Epoch 54/100\n",
            "380/380 [==============================] - 29s 76ms/step - loss: 11.3675 - f1: 0.7458 - auc: 0.8194 - accuracy: 0.6711 - val_loss: 11.3757 - val_f1: 0.3494 - val_auc: 0.8376 - val_accuracy: 0.4188 - _timestamp: 1656356259.0000 - _runtime: 1497.0000\n",
            "Epoch 55/100\n",
            "380/380 [==============================] - 27s 71ms/step - loss: 11.3673 - f1: 0.7445 - auc: 0.8226 - accuracy: 0.6703 - val_loss: 11.3756 - val_f1: 0.3500 - val_auc: 0.8381 - val_accuracy: 0.4199 - _timestamp: 1656356288.0000 - _runtime: 1526.0000\n",
            "Epoch 56/100\n",
            "380/380 [==============================] - 29s 75ms/step - loss: 11.3671 - f1: 0.7424 - auc: 0.8237 - accuracy: 0.6675 - val_loss: 11.3755 - val_f1: 0.3502 - val_auc: 0.8373 - val_accuracy: 0.4205 - _timestamp: 1656356315.0000 - _runtime: 1553.0000\n",
            "Epoch 57/100\n",
            "380/380 [==============================] - 27s 71ms/step - loss: 11.3668 - f1: 0.7436 - auc: 0.8247 - accuracy: 0.6715 - val_loss: 11.3754 - val_f1: 0.3502 - val_auc: 0.8399 - val_accuracy: 0.4205 - _timestamp: 1656356344.0000 - _runtime: 1582.0000\n",
            "Epoch 58/100\n",
            "380/380 [==============================] - 29s 77ms/step - loss: 11.3665 - f1: 0.7427 - auc: 0.8330 - accuracy: 0.6687 - val_loss: 11.3753 - val_f1: 0.3504 - val_auc: 0.8418 - val_accuracy: 0.4210 - _timestamp: 1656356371.0000 - _runtime: 1609.0000\n",
            "Epoch 59/100\n",
            "380/380 [==============================] - 28s 73ms/step - loss: 11.3665 - f1: 0.7424 - auc: 0.8298 - accuracy: 0.6669 - val_loss: 11.3753 - val_f1: 0.3505 - val_auc: 0.8458 - val_accuracy: 0.4216 - _timestamp: 1656356400.0000 - _runtime: 1638.0000\n",
            "Epoch 60/100\n",
            "380/380 [==============================] - 27s 70ms/step - loss: 11.3661 - f1: 0.7450 - auc: 0.8332 - accuracy: 0.6708 - val_loss: 11.3752 - val_f1: 0.3512 - val_auc: 0.8445 - val_accuracy: 0.4232 - _timestamp: 1656356428.0000 - _runtime: 1666.0000\n",
            "Epoch 61/100\n",
            "380/380 [==============================] - 27s 71ms/step - loss: 11.3660 - f1: 0.7439 - auc: 0.8324 - accuracy: 0.6694 - val_loss: 11.3751 - val_f1: 0.3511 - val_auc: 0.8477 - val_accuracy: 0.4232 - _timestamp: 1656356454.0000 - _runtime: 1692.0000\n",
            "Epoch 62/100\n",
            "380/380 [==============================] - 28s 75ms/step - loss: 11.3657 - f1: 0.7440 - auc: 0.8387 - accuracy: 0.6698 - val_loss: 11.3750 - val_f1: 0.3508 - val_auc: 0.8474 - val_accuracy: 0.4227 - _timestamp: 1656356481.0000 - _runtime: 1719.0000\n",
            "Epoch 63/100\n",
            "380/380 [==============================] - 28s 75ms/step - loss: 11.3655 - f1: 0.7447 - auc: 0.8351 - accuracy: 0.6699 - val_loss: 11.3749 - val_f1: 0.3511 - val_auc: 0.8465 - val_accuracy: 0.4238 - _timestamp: 1656356509.0000 - _runtime: 1747.0000\n",
            "Epoch 64/100\n",
            "380/380 [==============================] - 28s 75ms/step - loss: 11.3653 - f1: 0.7458 - auc: 0.8368 - accuracy: 0.6719 - val_loss: 11.3748 - val_f1: 0.3523 - val_auc: 0.8486 - val_accuracy: 0.4260 - _timestamp: 1656356538.0000 - _runtime: 1776.0000\n",
            "Epoch 65/100\n",
            "380/380 [==============================] - 28s 73ms/step - loss: 11.3650 - f1: 0.7454 - auc: 0.8404 - accuracy: 0.6717 - val_loss: 11.3747 - val_f1: 0.3528 - val_auc: 0.8478 - val_accuracy: 0.4271 - _timestamp: 1656356566.0000 - _runtime: 1804.0000\n",
            "Epoch 66/100\n",
            "380/380 [==============================] - 33s 86ms/step - loss: 11.3648 - f1: 0.7471 - auc: 0.8394 - accuracy: 0.6736 - val_loss: 11.3746 - val_f1: 0.3528 - val_auc: 0.8508 - val_accuracy: 0.4271 - _timestamp: 1656356594.0000 - _runtime: 1832.0000\n",
            "Epoch 67/100\n",
            "380/380 [==============================] - 28s 73ms/step - loss: 11.3644 - f1: 0.7487 - auc: 0.8456 - accuracy: 0.6764 - val_loss: 11.3745 - val_f1: 0.3531 - val_auc: 0.8517 - val_accuracy: 0.4277 - _timestamp: 1656356627.0000 - _runtime: 1865.0000\n",
            "Epoch 68/100\n",
            "380/380 [==============================] - 27s 72ms/step - loss: 11.3643 - f1: 0.7449 - auc: 0.8436 - accuracy: 0.6705 - val_loss: 11.3744 - val_f1: 0.3532 - val_auc: 0.8513 - val_accuracy: 0.4283 - _timestamp: 1656356654.0000 - _runtime: 1892.0000\n",
            "Epoch 69/100\n",
            "380/380 [==============================] - 29s 76ms/step - loss: 11.3641 - f1: 0.7465 - auc: 0.8428 - accuracy: 0.6744 - val_loss: 11.3744 - val_f1: 0.3532 - val_auc: 0.8497 - val_accuracy: 0.4283 - _timestamp: 1656356682.0000 - _runtime: 1920.0000\n",
            "Epoch 70/100\n",
            "380/380 [==============================] - 27s 72ms/step - loss: 11.3639 - f1: 0.7459 - auc: 0.8450 - accuracy: 0.6718 - val_loss: 11.3743 - val_f1: 0.3532 - val_auc: 0.8511 - val_accuracy: 0.4283 - _timestamp: 1656356710.0000 - _runtime: 1948.0000\n",
            "Epoch 71/100\n",
            "380/380 [==============================] - 29s 75ms/step - loss: 11.3637 - f1: 0.7475 - auc: 0.8433 - accuracy: 0.6755 - val_loss: 11.3742 - val_f1: 0.3534 - val_auc: 0.8516 - val_accuracy: 0.4294 - _timestamp: 1656356738.0000 - _runtime: 1976.0000\n",
            "Epoch 72/100\n",
            "380/380 [==============================] - 28s 74ms/step - loss: 11.3634 - f1: 0.7479 - auc: 0.8488 - accuracy: 0.6768 - val_loss: 11.3741 - val_f1: 0.3540 - val_auc: 0.8515 - val_accuracy: 0.4310 - _timestamp: 1656356766.0000 - _runtime: 2004.0000\n",
            "Epoch 73/100\n",
            "380/380 [==============================] - 27s 70ms/step - loss: 11.3631 - f1: 0.7488 - auc: 0.8511 - accuracy: 0.6773 - val_loss: 11.3740 - val_f1: 0.3540 - val_auc: 0.8526 - val_accuracy: 0.4310 - _timestamp: 1656356794.0000 - _runtime: 2032.0000\n",
            "Epoch 74/100\n",
            "380/380 [==============================] - 29s 76ms/step - loss: 11.3630 - f1: 0.7488 - auc: 0.8471 - accuracy: 0.6778 - val_loss: 11.3739 - val_f1: 0.3543 - val_auc: 0.8528 - val_accuracy: 0.4321 - _timestamp: 1656356821.0000 - _runtime: 2059.0000\n",
            "Epoch 75/100\n",
            "380/380 [==============================] - 29s 77ms/step - loss: 11.3626 - f1: 0.7487 - auc: 0.8516 - accuracy: 0.6769 - val_loss: 11.3738 - val_f1: 0.3543 - val_auc: 0.8535 - val_accuracy: 0.4321 - _timestamp: 1656356850.0000 - _runtime: 2088.0000\n",
            "Epoch 76/100\n",
            "380/380 [==============================] - 30s 78ms/step - loss: 11.3625 - f1: 0.7476 - auc: 0.8512 - accuracy: 0.6759 - val_loss: 11.3737 - val_f1: 0.3549 - val_auc: 0.8534 - val_accuracy: 0.4338 - _timestamp: 1656356879.0000 - _runtime: 2117.0000\n",
            "Epoch 77/100\n",
            "380/380 [==============================] - 27s 70ms/step - loss: 11.3622 - f1: 0.7473 - auc: 0.8520 - accuracy: 0.6739 - val_loss: 11.3736 - val_f1: 0.3550 - val_auc: 0.8541 - val_accuracy: 0.4344 - _timestamp: 1656356909.0000 - _runtime: 2147.0000\n",
            "Epoch 78/100\n",
            "380/380 [==============================] - 27s 71ms/step - loss: 11.3619 - f1: 0.7487 - auc: 0.8522 - accuracy: 0.6781 - val_loss: 11.3735 - val_f1: 0.3552 - val_auc: 0.8537 - val_accuracy: 0.4349 - _timestamp: 1656356936.0000 - _runtime: 2174.0000\n",
            "Epoch 79/100\n",
            "380/380 [==============================] - 27s 70ms/step - loss: 11.3617 - f1: 0.7477 - auc: 0.8568 - accuracy: 0.6766 - val_loss: 11.3734 - val_f1: 0.3553 - val_auc: 0.8547 - val_accuracy: 0.4355 - _timestamp: 1656356962.0000 - _runtime: 2200.0000\n",
            "Epoch 80/100\n",
            "380/380 [==============================] - 27s 72ms/step - loss: 11.3616 - f1: 0.7476 - auc: 0.8538 - accuracy: 0.6771 - val_loss: 11.3733 - val_f1: 0.3553 - val_auc: 0.8535 - val_accuracy: 0.4355 - _timestamp: 1656356989.0000 - _runtime: 2227.0000\n",
            "Epoch 81/100\n",
            "380/380 [==============================] - 29s 76ms/step - loss: 11.3612 - f1: 0.7513 - auc: 0.8574 - accuracy: 0.6805 - val_loss: 11.3732 - val_f1: 0.3558 - val_auc: 0.8539 - val_accuracy: 0.4366 - _timestamp: 1656357016.0000 - _runtime: 2254.0000\n",
            "Epoch 82/100\n",
            "380/380 [==============================] - 28s 75ms/step - loss: 11.3610 - f1: 0.7495 - auc: 0.8575 - accuracy: 0.6790 - val_loss: 11.3731 - val_f1: 0.3564 - val_auc: 0.8541 - val_accuracy: 0.4377 - _timestamp: 1656357045.0000 - _runtime: 2283.0000\n",
            "Epoch 83/100\n",
            "380/380 [==============================] - 27s 71ms/step - loss: 11.3608 - f1: 0.7497 - auc: 0.8560 - accuracy: 0.6801 - val_loss: 11.3730 - val_f1: 0.3566 - val_auc: 0.8561 - val_accuracy: 0.4383 - _timestamp: 1656357073.0000 - _runtime: 2311.0000\n",
            "Epoch 84/100\n",
            "380/380 [==============================] - 27s 72ms/step - loss: 11.3605 - f1: 0.7508 - auc: 0.8586 - accuracy: 0.6812 - val_loss: 11.3729 - val_f1: 0.3567 - val_auc: 0.8556 - val_accuracy: 0.4388 - _timestamp: 1656357100.0000 - _runtime: 2338.0000\n",
            "Epoch 85/100\n",
            "380/380 [==============================] - 28s 74ms/step - loss: 11.3602 - f1: 0.7513 - auc: 0.8596 - accuracy: 0.6824 - val_loss: 11.3728 - val_f1: 0.3567 - val_auc: 0.8560 - val_accuracy: 0.4388 - _timestamp: 1656357128.0000 - _runtime: 2366.0000\n",
            "Epoch 86/100\n",
            "380/380 [==============================] - 28s 73ms/step - loss: 11.3601 - f1: 0.7514 - auc: 0.8579 - accuracy: 0.6811 - val_loss: 11.3727 - val_f1: 0.3574 - val_auc: 0.8549 - val_accuracy: 0.4405 - _timestamp: 1656357156.0000 - _runtime: 2394.0000\n",
            "Epoch 87/100\n",
            "380/380 [==============================] - 27s 71ms/step - loss: 11.3597 - f1: 0.7495 - auc: 0.8632 - accuracy: 0.6796 - val_loss: 11.3726 - val_f1: 0.3574 - val_auc: 0.8547 - val_accuracy: 0.4405 - _timestamp: 1656357183.0000 - _runtime: 2421.0000\n",
            "Epoch 88/100\n",
            "380/380 [==============================] - 29s 77ms/step - loss: 11.3595 - f1: 0.7511 - auc: 0.8632 - accuracy: 0.6823 - val_loss: 11.3725 - val_f1: 0.3576 - val_auc: 0.8559 - val_accuracy: 0.4410 - _timestamp: 1656357210.0000 - _runtime: 2448.0000\n",
            "Epoch 89/100\n",
            "380/380 [==============================] - 28s 74ms/step - loss: 11.3593 - f1: 0.7502 - auc: 0.8621 - accuracy: 0.6795 - val_loss: 11.3724 - val_f1: 0.3580 - val_auc: 0.8571 - val_accuracy: 0.4422 - _timestamp: 1656357240.0000 - _runtime: 2478.0000\n",
            "Epoch 90/100\n",
            "380/380 [==============================] - 29s 75ms/step - loss: 11.3590 - f1: 0.7495 - auc: 0.8624 - accuracy: 0.6808 - val_loss: 11.3723 - val_f1: 0.3571 - val_auc: 0.8560 - val_accuracy: 0.4433 - _timestamp: 1656357268.0000 - _runtime: 2506.0000\n",
            "Epoch 91/100\n",
            "380/380 [==============================] - 27s 70ms/step - loss: 11.3588 - f1: 0.7503 - auc: 0.8635 - accuracy: 0.6813 - val_loss: 11.3722 - val_f1: 0.3573 - val_auc: 0.8582 - val_accuracy: 0.4438 - _timestamp: 1656357296.0000 - _runtime: 2534.0000\n",
            "Epoch 92/100\n",
            "380/380 [==============================] - 28s 73ms/step - loss: 11.3587 - f1: 0.7503 - auc: 0.8608 - accuracy: 0.6791 - val_loss: 11.3721 - val_f1: 0.3573 - val_auc: 0.8594 - val_accuracy: 0.4438 - _timestamp: 1656357323.0000 - _runtime: 2561.0000\n",
            "Epoch 93/100\n",
            "380/380 [==============================] - 27s 71ms/step - loss: 11.3583 - f1: 0.7520 - auc: 0.8647 - accuracy: 0.6842 - val_loss: 11.3720 - val_f1: 0.3575 - val_auc: 0.8602 - val_accuracy: 0.4444 - _timestamp: 1656357351.0000 - _runtime: 2589.0000\n",
            "Epoch 94/100\n",
            "380/380 [==============================] - 27s 71ms/step - loss: 11.3581 - f1: 0.7524 - auc: 0.8668 - accuracy: 0.6832 - val_loss: 11.3719 - val_f1: 0.3580 - val_auc: 0.8600 - val_accuracy: 0.4455 - _timestamp: 1656357378.0000 - _runtime: 2616.0000\n",
            "Epoch 95/100\n",
            "380/380 [==============================] - 27s 72ms/step - loss: 11.3579 - f1: 0.7514 - auc: 0.8652 - accuracy: 0.6843 - val_loss: 11.3718 - val_f1: 0.3582 - val_auc: 0.8613 - val_accuracy: 0.4461 - _timestamp: 1656357405.0000 - _runtime: 2643.0000\n",
            "Epoch 96/100\n",
            "380/380 [==============================] - 27s 72ms/step - loss: 11.3576 - f1: 0.7513 - auc: 0.8681 - accuracy: 0.6829 - val_loss: 11.3717 - val_f1: 0.3590 - val_auc: 0.8620 - val_accuracy: 0.4477 - _timestamp: 1656357432.0000 - _runtime: 2670.0000\n",
            "Epoch 97/100\n",
            "380/380 [==============================] - 27s 70ms/step - loss: 11.3575 - f1: 0.7513 - auc: 0.8635 - accuracy: 0.6818 - val_loss: 11.3715 - val_f1: 0.3588 - val_auc: 0.8628 - val_accuracy: 0.4477 - _timestamp: 1656357459.0000 - _runtime: 2697.0000\n",
            "Epoch 98/100\n",
            "380/380 [==============================] - 26s 70ms/step - loss: 11.3571 - f1: 0.7532 - auc: 0.8676 - accuracy: 0.6839 - val_loss: 11.3714 - val_f1: 0.3589 - val_auc: 0.8615 - val_accuracy: 0.4483 - _timestamp: 1656357486.0000 - _runtime: 2724.0000\n",
            "Epoch 99/100\n",
            "380/380 [==============================] - 28s 73ms/step - loss: 11.3568 - f1: 0.7510 - auc: 0.8672 - accuracy: 0.6829 - val_loss: 11.3713 - val_f1: 0.3592 - val_auc: 0.8617 - val_accuracy: 0.4488 - _timestamp: 1656357512.0000 - _runtime: 2750.0000\n",
            "Epoch 100/100\n",
            "380/380 [==============================] - 27s 70ms/step - loss: 11.3566 - f1: 0.7520 - auc: 0.8676 - accuracy: 0.6837 - val_loss: 11.3712 - val_f1: 0.3594 - val_auc: 0.8622 - val_accuracy: 0.4494 - _timestamp: 1656357540.0000 - _runtime: 2778.0000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d78ed3cdf26c4919ab928b79936a8d26",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='2575.797 MB of 2575.797 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▂▃▄▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇███████████████</td></tr><tr><td>auc</td><td>▁▂▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1</td><td>▁▂▃▄▅▆▆▆▇▇▇▇▇███████████████████████████</td></tr><tr><td>loss</td><td>████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>█▆▅▃▃▃▂▂▁▂▁▁▁▁▁▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>val_auc</td><td>▁▁▂▂▃▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇███████████████████</td></tr><tr><td>val_f1</td><td>▁▃▅▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>val_loss</td><td>█████▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.68368</td></tr><tr><td>auc</td><td>0.86761</td></tr><tr><td>best_epoch</td><td>99</td></tr><tr><td>best_val_loss</td><td>11.37123</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>f1</td><td>0.75197</td></tr><tr><td>loss</td><td>11.35655</td></tr><tr><td>val_accuracy</td><td>0.44939</td></tr><tr><td>val_auc</td><td>0.86221</td></tr><tr><td>val_f1</td><td>0.35944</td></tr><tr><td>val_loss</td><td>11.37123</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">worldly-sweep-5</strong>: <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/dhugb9w7\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/runs/dhugb9w7</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220627_183242-dhugb9w7/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: suff6jdk with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: leaky_relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_value: 0.3439682510311136\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons: 3000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptomizer: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_factor: 5e-08\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_type: l1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.19"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220627_192031-suff6jdk</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/suff6jdk\" target=\"_blank\">olive-sweep-6</a></strong> to <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 25008)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3000)              75027000  \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 3000)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 3000)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3000)              9003000   \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 3000)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 3000)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3000)              9003000   \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 3000)              0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 3000)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3000)              9003000   \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 3000)              0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 3000)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 3001      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 102,039,001\n",
            "Trainable params: 102,039,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "380/380 [==============================] - 14s 34ms/step - loss: 0.3302 - f1: 0.8879 - auc: 0.9392 - accuracy: 0.8884 - val_loss: 0.4701 - val_f1: 0.5464 - val_auc: 0.8871 - val_accuracy: 0.7964 - _timestamp: 1656357645.0000 - _runtime: 14.0000\n",
            "Epoch 2/100\n",
            "380/380 [==============================] - 10s 25ms/step - loss: 0.2306 - f1: 0.9256 - auc: 0.9778 - accuracy: 0.9272 - val_loss: 0.4049 - val_f1: 0.5720 - val_auc: 0.8858 - val_accuracy: 0.8370 - _timestamp: 1656357657.0000 - _runtime: 26.0000\n",
            "Epoch 3/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.1882 - f1: 0.9395 - auc: 0.9860 - accuracy: 0.9411 - val_loss: 0.3451 - val_f1: 0.5629 - val_auc: 0.8890 - val_accuracy: 0.8726 - _timestamp: 1656357667.0000 - _runtime: 36.0000\n",
            "Epoch 4/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.1615 - f1: 0.9495 - auc: 0.9905 - accuracy: 0.9508 - val_loss: 0.4209 - val_f1: 0.5813 - val_auc: 0.8943 - val_accuracy: 0.8476 - _timestamp: 1656357679.0000 - _runtime: 48.0000\n",
            "Epoch 5/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.1515 - f1: 0.9522 - auc: 0.9917 - accuracy: 0.9536 - val_loss: 0.3535 - val_f1: 0.5871 - val_auc: 0.8941 - val_accuracy: 0.8754 - _timestamp: 1656357686.0000 - _runtime: 55.0000\n",
            "Epoch 6/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.1361 - f1: 0.9595 - auc: 0.9937 - accuracy: 0.9606 - val_loss: 0.4235 - val_f1: 0.5632 - val_auc: 0.8799 - val_accuracy: 0.8665 - _timestamp: 1656357693.0000 - _runtime: 62.0000\n",
            "Epoch 7/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.1316 - f1: 0.9616 - auc: 0.9943 - accuracy: 0.9625 - val_loss: 0.3978 - val_f1: 0.5528 - val_auc: 0.8728 - val_accuracy: 0.8715 - _timestamp: 1656357700.0000 - _runtime: 69.0000\n",
            "Epoch 8/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.1163 - f1: 0.9690 - auc: 0.9960 - accuracy: 0.9696 - val_loss: 0.4315 - val_f1: 0.5998 - val_auc: 0.8857 - val_accuracy: 0.8671 - _timestamp: 1656357707.0000 - _runtime: 76.0000\n",
            "Epoch 9/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.1092 - f1: 0.9697 - auc: 0.9964 - accuracy: 0.9709 - val_loss: 0.4603 - val_f1: 0.5676 - val_auc: 0.8642 - val_accuracy: 0.8749 - _timestamp: 1656357713.0000 - _runtime: 82.0000\n",
            "Epoch 10/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.1060 - f1: 0.9737 - auc: 0.9966 - accuracy: 0.9744 - val_loss: 0.4742 - val_f1: 0.5983 - val_auc: 0.8760 - val_accuracy: 0.8654 - _timestamp: 1656357720.0000 - _runtime: 89.0000\n",
            "Epoch 11/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.1033 - f1: 0.9748 - auc: 0.9968 - accuracy: 0.9754 - val_loss: 0.5557 - val_f1: 0.5816 - val_auc: 0.8814 - val_accuracy: 0.8320 - _timestamp: 1656357727.0000 - _runtime: 96.0000\n",
            "Epoch 12/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0969 - f1: 0.9754 - auc: 0.9976 - accuracy: 0.9765 - val_loss: 0.5026 - val_f1: 0.5965 - val_auc: 0.8738 - val_accuracy: 0.8548 - _timestamp: 1656357734.0000 - _runtime: 103.0000\n",
            "Epoch 13/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0947 - f1: 0.9779 - auc: 0.9977 - accuracy: 0.9786 - val_loss: 0.5635 - val_f1: 0.5821 - val_auc: 0.8596 - val_accuracy: 0.8710 - _timestamp: 1656357741.0000 - _runtime: 110.0000\n",
            "Epoch 14/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0978 - f1: 0.9763 - auc: 0.9970 - accuracy: 0.9769 - val_loss: 0.5968 - val_f1: 0.5675 - val_auc: 0.8400 - val_accuracy: 0.8715 - _timestamp: 1656357748.0000 - _runtime: 117.0000\n",
            "Epoch 15/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0910 - f1: 0.9791 - auc: 0.9976 - accuracy: 0.9798 - val_loss: 0.6726 - val_f1: 0.5557 - val_auc: 0.8453 - val_accuracy: 0.8543 - _timestamp: 1656357754.0000 - _runtime: 123.0000\n",
            "Epoch 16/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0878 - f1: 0.9815 - auc: 0.9979 - accuracy: 0.9822 - val_loss: 0.5549 - val_f1: 0.5932 - val_auc: 0.8562 - val_accuracy: 0.8799 - _timestamp: 1656357761.0000 - _runtime: 130.0000\n",
            "Epoch 17/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0812 - f1: 0.9821 - auc: 0.9984 - accuracy: 0.9829 - val_loss: 0.6149 - val_f1: 0.5883 - val_auc: 0.8616 - val_accuracy: 0.8587 - _timestamp: 1656357768.0000 - _runtime: 137.0000\n",
            "Epoch 18/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0869 - f1: 0.9798 - auc: 0.9981 - accuracy: 0.9803 - val_loss: 0.5134 - val_f1: 0.5683 - val_auc: 0.8658 - val_accuracy: 0.8687 - _timestamp: 1656357775.0000 - _runtime: 144.0000\n",
            "Epoch 19/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0789 - f1: 0.9830 - auc: 0.9985 - accuracy: 0.9835 - val_loss: 0.6452 - val_f1: 0.5762 - val_auc: 0.8557 - val_accuracy: 0.8565 - _timestamp: 1656357782.0000 - _runtime: 151.0000\n",
            "Epoch 20/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0777 - f1: 0.9830 - auc: 0.9987 - accuracy: 0.9836 - val_loss: 0.6141 - val_f1: 0.6055 - val_auc: 0.8544 - val_accuracy: 0.8687 - _timestamp: 1656357789.0000 - _runtime: 158.0000\n",
            "Epoch 21/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0772 - f1: 0.9845 - auc: 0.9986 - accuracy: 0.9853 - val_loss: 0.6098 - val_f1: 0.5711 - val_auc: 0.8439 - val_accuracy: 0.8726 - _timestamp: 1656357795.0000 - _runtime: 164.0000\n",
            "Epoch 22/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0781 - f1: 0.9835 - auc: 0.9986 - accuracy: 0.9844 - val_loss: 0.6196 - val_f1: 0.5758 - val_auc: 0.8479 - val_accuracy: 0.8732 - _timestamp: 1656357802.0000 - _runtime: 171.0000\n",
            "Epoch 23/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0716 - f1: 0.9853 - auc: 0.9988 - accuracy: 0.9862 - val_loss: 0.7281 - val_f1: 0.5998 - val_auc: 0.8602 - val_accuracy: 0.8598 - _timestamp: 1656357809.0000 - _runtime: 178.0000\n",
            "Epoch 24/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0696 - f1: 0.9867 - auc: 0.9987 - accuracy: 0.9872 - val_loss: 0.5592 - val_f1: 0.5264 - val_auc: 0.8515 - val_accuracy: 0.8710 - _timestamp: 1656357816.0000 - _runtime: 185.0000\n",
            "Epoch 25/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0743 - f1: 0.9852 - auc: 0.9985 - accuracy: 0.9858 - val_loss: 0.7094 - val_f1: 0.5571 - val_auc: 0.8459 - val_accuracy: 0.8593 - _timestamp: 1656357823.0000 - _runtime: 192.0000\n",
            "Epoch 26/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0718 - f1: 0.9872 - auc: 0.9987 - accuracy: 0.9877 - val_loss: 0.6224 - val_f1: 0.5268 - val_auc: 0.8371 - val_accuracy: 0.8576 - _timestamp: 1656357829.0000 - _runtime: 198.0000\n",
            "Epoch 27/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0682 - f1: 0.9872 - auc: 0.9990 - accuracy: 0.9877 - val_loss: 0.6342 - val_f1: 0.5533 - val_auc: 0.8500 - val_accuracy: 0.8737 - _timestamp: 1656357836.0000 - _runtime: 205.0000\n",
            "Epoch 28/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0716 - f1: 0.9872 - auc: 0.9984 - accuracy: 0.9872 - val_loss: 0.6395 - val_f1: 0.5676 - val_auc: 0.8464 - val_accuracy: 0.8660 - _timestamp: 1656357843.0000 - _runtime: 212.0000\n",
            "Epoch 29/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0648 - f1: 0.9885 - auc: 0.9989 - accuracy: 0.9890 - val_loss: 0.7112 - val_f1: 0.5601 - val_auc: 0.8447 - val_accuracy: 0.8654 - _timestamp: 1656357850.0000 - _runtime: 219.0000\n",
            "Epoch 30/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0678 - f1: 0.9869 - auc: 0.9988 - accuracy: 0.9876 - val_loss: 0.6793 - val_f1: 0.5814 - val_auc: 0.8439 - val_accuracy: 0.8704 - _timestamp: 1656357857.0000 - _runtime: 226.0000\n",
            "Epoch 31/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0692 - f1: 0.9872 - auc: 0.9988 - accuracy: 0.9877 - val_loss: 0.6827 - val_f1: 0.5302 - val_auc: 0.8227 - val_accuracy: 0.8676 - _timestamp: 1656357864.0000 - _runtime: 233.0000\n",
            "Epoch 32/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0655 - f1: 0.9888 - auc: 0.9989 - accuracy: 0.9890 - val_loss: 0.6845 - val_f1: 0.5843 - val_auc: 0.8508 - val_accuracy: 0.8598 - _timestamp: 1656357870.0000 - _runtime: 239.0000\n",
            "Epoch 33/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0694 - f1: 0.9868 - auc: 0.9987 - accuracy: 0.9873 - val_loss: 0.7610 - val_f1: 0.5278 - val_auc: 0.8166 - val_accuracy: 0.8710 - _timestamp: 1656357877.0000 - _runtime: 246.0000\n",
            "Epoch 34/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0640 - f1: 0.9895 - auc: 0.9989 - accuracy: 0.9896 - val_loss: 0.8004 - val_f1: 0.5060 - val_auc: 0.8115 - val_accuracy: 0.8665 - _timestamp: 1656357884.0000 - _runtime: 253.0000\n",
            "Epoch 35/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0656 - f1: 0.9878 - auc: 0.9987 - accuracy: 0.9881 - val_loss: 0.7073 - val_f1: 0.5770 - val_auc: 0.8624 - val_accuracy: 0.8426 - _timestamp: 1656357891.0000 - _runtime: 260.0000\n",
            "Epoch 36/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0697 - f1: 0.9880 - auc: 0.9984 - accuracy: 0.9884 - val_loss: 0.6110 - val_f1: 0.5962 - val_auc: 0.8744 - val_accuracy: 0.8571 - _timestamp: 1656357898.0000 - _runtime: 267.0000\n",
            "Epoch 37/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0583 - f1: 0.9912 - auc: 0.9991 - accuracy: 0.9914 - val_loss: 0.6696 - val_f1: 0.5706 - val_auc: 0.8520 - val_accuracy: 0.8671 - _timestamp: 1656357904.0000 - _runtime: 273.0000\n",
            "Epoch 38/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0622 - f1: 0.9893 - auc: 0.9989 - accuracy: 0.9893 - val_loss: 0.6682 - val_f1: 0.5804 - val_auc: 0.8524 - val_accuracy: 0.8632 - _timestamp: 1656357911.0000 - _runtime: 280.0000\n",
            "Epoch 39/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0640 - f1: 0.9881 - auc: 0.9990 - accuracy: 0.9886 - val_loss: 0.7502 - val_f1: 0.5578 - val_auc: 0.8447 - val_accuracy: 0.8732 - _timestamp: 1656357918.0000 - _runtime: 287.0000\n",
            "Epoch 40/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0601 - f1: 0.9902 - auc: 0.9992 - accuracy: 0.9904 - val_loss: 0.7368 - val_f1: 0.5752 - val_auc: 0.8393 - val_accuracy: 0.8593 - _timestamp: 1656357925.0000 - _runtime: 294.0000\n",
            "Epoch 41/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0569 - f1: 0.9914 - auc: 0.9992 - accuracy: 0.9918 - val_loss: 0.8513 - val_f1: 0.5796 - val_auc: 0.8457 - val_accuracy: 0.8471 - _timestamp: 1656357932.0000 - _runtime: 301.0000\n",
            "Epoch 42/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0587 - f1: 0.9897 - auc: 0.9992 - accuracy: 0.9900 - val_loss: 0.8467 - val_f1: 0.5449 - val_auc: 0.8152 - val_accuracy: 0.8710 - _timestamp: 1656357938.0000 - _runtime: 307.0000\n",
            "Epoch 43/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0611 - f1: 0.9893 - auc: 0.9989 - accuracy: 0.9896 - val_loss: 0.7031 - val_f1: 0.6040 - val_auc: 0.8570 - val_accuracy: 0.8687 - _timestamp: 1656357945.0000 - _runtime: 314.0000\n",
            "Epoch 44/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0635 - f1: 0.9900 - auc: 0.9984 - accuracy: 0.9902 - val_loss: 0.8219 - val_f1: 0.5490 - val_auc: 0.8608 - val_accuracy: 0.8204 - _timestamp: 1656357952.0000 - _runtime: 321.0000\n",
            "Epoch 45/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0594 - f1: 0.9906 - auc: 0.9993 - accuracy: 0.9906 - val_loss: 0.8161 - val_f1: 0.5473 - val_auc: 0.8425 - val_accuracy: 0.8760 - _timestamp: 1656357959.0000 - _runtime: 328.0000\n",
            "Epoch 46/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0582 - f1: 0.9911 - auc: 0.9991 - accuracy: 0.9916 - val_loss: 0.8384 - val_f1: 0.5796 - val_auc: 0.8410 - val_accuracy: 0.8710 - _timestamp: 1656357965.0000 - _runtime: 334.0000\n",
            "Epoch 47/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0590 - f1: 0.9896 - auc: 0.9992 - accuracy: 0.9900 - val_loss: 0.6911 - val_f1: 0.5917 - val_auc: 0.8509 - val_accuracy: 0.8593 - _timestamp: 1656357972.0000 - _runtime: 341.0000\n",
            "Epoch 48/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0567 - f1: 0.9906 - auc: 0.9991 - accuracy: 0.9909 - val_loss: 0.7923 - val_f1: 0.5810 - val_auc: 0.8358 - val_accuracy: 0.8693 - _timestamp: 1656357979.0000 - _runtime: 348.0000\n",
            "Epoch 49/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0601 - f1: 0.9914 - auc: 0.9987 - accuracy: 0.9918 - val_loss: 0.7764 - val_f1: 0.5881 - val_auc: 0.8595 - val_accuracy: 0.8543 - _timestamp: 1656357986.0000 - _runtime: 355.0000\n",
            "Epoch 50/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0524 - f1: 0.9919 - auc: 0.9996 - accuracy: 0.9925 - val_loss: 0.9178 - val_f1: 0.5852 - val_auc: 0.8413 - val_accuracy: 0.8721 - _timestamp: 1656357993.0000 - _runtime: 362.0000\n",
            "Epoch 51/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0593 - f1: 0.9901 - auc: 0.9988 - accuracy: 0.9904 - val_loss: 0.7578 - val_f1: 0.5830 - val_auc: 0.8555 - val_accuracy: 0.8732 - _timestamp: 1656357999.0000 - _runtime: 368.0000\n",
            "Epoch 52/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0546 - f1: 0.9911 - auc: 0.9994 - accuracy: 0.9912 - val_loss: 0.8301 - val_f1: 0.6013 - val_auc: 0.8540 - val_accuracy: 0.8643 - _timestamp: 1656358006.0000 - _runtime: 375.0000\n",
            "Epoch 53/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0576 - f1: 0.9911 - auc: 0.9989 - accuracy: 0.9914 - val_loss: 0.7303 - val_f1: 0.5430 - val_auc: 0.8360 - val_accuracy: 0.8760 - _timestamp: 1656358013.0000 - _runtime: 382.0000\n",
            "Epoch 54/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0533 - f1: 0.9926 - auc: 0.9991 - accuracy: 0.9929 - val_loss: 0.7962 - val_f1: 0.5674 - val_auc: 0.8346 - val_accuracy: 0.8743 - _timestamp: 1656358020.0000 - _runtime: 389.0000\n",
            "Epoch 55/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0518 - f1: 0.9926 - auc: 0.9994 - accuracy: 0.9931 - val_loss: 0.8325 - val_f1: 0.6152 - val_auc: 0.8527 - val_accuracy: 0.8793 - _timestamp: 1656358026.0000 - _runtime: 395.0000\n",
            "Epoch 56/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0505 - f1: 0.9932 - auc: 0.9993 - accuracy: 0.9935 - val_loss: 0.7026 - val_f1: 0.5693 - val_auc: 0.8605 - val_accuracy: 0.8576 - _timestamp: 1656358033.0000 - _runtime: 402.0000\n",
            "Epoch 57/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0570 - f1: 0.9923 - auc: 0.9988 - accuracy: 0.9924 - val_loss: 0.8883 - val_f1: 0.5309 - val_auc: 0.8252 - val_accuracy: 0.8743 - _timestamp: 1656358040.0000 - _runtime: 409.0000\n",
            "Epoch 58/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0537 - f1: 0.9921 - auc: 0.9994 - accuracy: 0.9924 - val_loss: 0.8093 - val_f1: 0.5855 - val_auc: 0.8345 - val_accuracy: 0.8793 - _timestamp: 1656358047.0000 - _runtime: 416.0000\n",
            "Epoch 59/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0511 - f1: 0.9929 - auc: 0.9995 - accuracy: 0.9929 - val_loss: 0.7723 - val_f1: 0.5328 - val_auc: 0.8234 - val_accuracy: 0.8782 - _timestamp: 1656358054.0000 - _runtime: 423.0000\n",
            "Epoch 60/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0552 - f1: 0.9917 - auc: 0.9990 - accuracy: 0.9920 - val_loss: 0.7290 - val_f1: 0.5380 - val_auc: 0.8286 - val_accuracy: 0.8699 - _timestamp: 1656358060.0000 - _runtime: 429.0000\n",
            "Epoch 61/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0549 - f1: 0.9905 - auc: 0.9992 - accuracy: 0.9909 - val_loss: 0.7726 - val_f1: 0.5633 - val_auc: 0.8373 - val_accuracy: 0.8660 - _timestamp: 1656358067.0000 - _runtime: 436.0000\n",
            "Epoch 62/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0532 - f1: 0.9927 - auc: 0.9994 - accuracy: 0.9929 - val_loss: 0.7534 - val_f1: 0.5861 - val_auc: 0.8510 - val_accuracy: 0.8671 - _timestamp: 1656358074.0000 - _runtime: 443.0000\n",
            "Epoch 63/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0565 - f1: 0.9916 - auc: 0.9990 - accuracy: 0.9918 - val_loss: 0.6799 - val_f1: 0.6022 - val_auc: 0.8539 - val_accuracy: 0.8721 - _timestamp: 1656358081.0000 - _runtime: 450.0000\n",
            "Epoch 64/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0501 - f1: 0.9920 - auc: 0.9996 - accuracy: 0.9926 - val_loss: 0.8492 - val_f1: 0.5822 - val_auc: 0.8508 - val_accuracy: 0.8610 - _timestamp: 1656358088.0000 - _runtime: 457.0000\n",
            "Epoch 65/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0531 - f1: 0.9919 - auc: 0.9994 - accuracy: 0.9922 - val_loss: 0.6840 - val_f1: 0.5513 - val_auc: 0.8376 - val_accuracy: 0.8654 - _timestamp: 1656358094.0000 - _runtime: 463.0000\n",
            "Epoch 66/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0529 - f1: 0.9924 - auc: 0.9990 - accuracy: 0.9927 - val_loss: 0.7220 - val_f1: 0.5790 - val_auc: 0.8430 - val_accuracy: 0.8726 - _timestamp: 1656358101.0000 - _runtime: 470.0000\n",
            "Epoch 67/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0493 - f1: 0.9927 - auc: 0.9995 - accuracy: 0.9931 - val_loss: 0.9234 - val_f1: 0.5258 - val_auc: 0.8141 - val_accuracy: 0.8749 - _timestamp: 1656358108.0000 - _runtime: 477.0000\n",
            "Epoch 68/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0517 - f1: 0.9919 - auc: 0.9995 - accuracy: 0.9921 - val_loss: 0.7734 - val_f1: 0.5409 - val_auc: 0.8404 - val_accuracy: 0.8660 - _timestamp: 1656358115.0000 - _runtime: 484.0000\n",
            "Epoch 69/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0512 - f1: 0.9925 - auc: 0.9995 - accuracy: 0.9924 - val_loss: 0.7944 - val_f1: 0.5483 - val_auc: 0.8276 - val_accuracy: 0.8715 - _timestamp: 1656358122.0000 - _runtime: 491.0000\n",
            "Epoch 70/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0576 - f1: 0.9907 - auc: 0.9988 - accuracy: 0.9910 - val_loss: 0.6289 - val_f1: 0.5201 - val_auc: 0.8352 - val_accuracy: 0.8754 - _timestamp: 1656358128.0000 - _runtime: 497.0000\n",
            "Epoch 71/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0509 - f1: 0.9922 - auc: 0.9995 - accuracy: 0.9924 - val_loss: 0.8887 - val_f1: 0.5762 - val_auc: 0.8447 - val_accuracy: 0.8532 - _timestamp: 1656358135.0000 - _runtime: 504.0000\n",
            "Epoch 72/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0497 - f1: 0.9930 - auc: 0.9993 - accuracy: 0.9933 - val_loss: 0.7599 - val_f1: 0.5623 - val_auc: 0.8467 - val_accuracy: 0.8604 - _timestamp: 1656358142.0000 - _runtime: 511.0000\n",
            "Epoch 73/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0514 - f1: 0.9915 - auc: 0.9994 - accuracy: 0.9915 - val_loss: 0.7514 - val_f1: 0.5620 - val_auc: 0.8459 - val_accuracy: 0.8637 - _timestamp: 1656358149.0000 - _runtime: 518.0000\n",
            "Epoch 74/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0481 - f1: 0.9934 - auc: 0.9996 - accuracy: 0.9937 - val_loss: 0.7648 - val_f1: 0.5648 - val_auc: 0.8437 - val_accuracy: 0.8776 - _timestamp: 1656358156.0000 - _runtime: 525.0000\n",
            "Epoch 75/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0478 - f1: 0.9934 - auc: 0.9993 - accuracy: 0.9937 - val_loss: 0.7856 - val_f1: 0.5365 - val_auc: 0.8141 - val_accuracy: 0.8704 - _timestamp: 1656358162.0000 - _runtime: 531.0000\n",
            "Epoch 76/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0509 - f1: 0.9919 - auc: 0.9994 - accuracy: 0.9923 - val_loss: 0.7361 - val_f1: 0.5507 - val_auc: 0.8454 - val_accuracy: 0.8710 - _timestamp: 1656358169.0000 - _runtime: 538.0000\n",
            "Epoch 77/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0520 - f1: 0.9915 - auc: 0.9994 - accuracy: 0.9915 - val_loss: 0.8973 - val_f1: 0.5293 - val_auc: 0.8288 - val_accuracy: 0.8582 - _timestamp: 1656358176.0000 - _runtime: 545.0000\n",
            "Epoch 78/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0460 - f1: 0.9941 - auc: 0.9994 - accuracy: 0.9944 - val_loss: 0.7903 - val_f1: 0.5578 - val_auc: 0.8406 - val_accuracy: 0.8626 - _timestamp: 1656358182.0000 - _runtime: 551.0000\n",
            "Epoch 79/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0463 - f1: 0.9934 - auc: 0.9996 - accuracy: 0.9937 - val_loss: 0.8940 - val_f1: 0.5884 - val_auc: 0.8422 - val_accuracy: 0.8699 - _timestamp: 1656358189.0000 - _runtime: 558.0000\n",
            "Epoch 80/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0520 - f1: 0.9926 - auc: 0.9991 - accuracy: 0.9927 - val_loss: 0.7340 - val_f1: 0.5592 - val_auc: 0.8482 - val_accuracy: 0.8587 - _timestamp: 1656358196.0000 - _runtime: 565.0000\n",
            "Epoch 81/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0446 - f1: 0.9948 - auc: 0.9995 - accuracy: 0.9950 - val_loss: 0.8796 - val_f1: 0.5525 - val_auc: 0.8338 - val_accuracy: 0.8665 - _timestamp: 1656358203.0000 - _runtime: 572.0000\n",
            "Epoch 82/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0477 - f1: 0.9945 - auc: 0.9993 - accuracy: 0.9947 - val_loss: 0.8070 - val_f1: 0.5624 - val_auc: 0.8375 - val_accuracy: 0.8671 - _timestamp: 1656358210.0000 - _runtime: 579.0000\n",
            "Epoch 83/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0517 - f1: 0.9920 - auc: 0.9991 - accuracy: 0.9921 - val_loss: 0.7974 - val_f1: 0.5556 - val_auc: 0.8374 - val_accuracy: 0.8637 - _timestamp: 1656358216.0000 - _runtime: 585.0000\n",
            "Epoch 84/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0474 - f1: 0.9934 - auc: 0.9995 - accuracy: 0.9937 - val_loss: 0.8724 - val_f1: 0.5685 - val_auc: 0.8328 - val_accuracy: 0.8671 - _timestamp: 1656358223.0000 - _runtime: 592.0000\n",
            "Epoch 85/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0446 - f1: 0.9947 - auc: 0.9996 - accuracy: 0.9948 - val_loss: 0.9493 - val_f1: 0.5509 - val_auc: 0.8319 - val_accuracy: 0.8648 - _timestamp: 1656358230.0000 - _runtime: 599.0000\n",
            "Epoch 86/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0450 - f1: 0.9944 - auc: 0.9993 - accuracy: 0.9947 - val_loss: 0.8913 - val_f1: 0.5628 - val_auc: 0.8226 - val_accuracy: 0.8682 - _timestamp: 1656358237.0000 - _runtime: 606.0000\n",
            "Epoch 87/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0437 - f1: 0.9942 - auc: 0.9995 - accuracy: 0.9946 - val_loss: 0.8952 - val_f1: 0.5685 - val_auc: 0.8413 - val_accuracy: 0.8593 - _timestamp: 1656358243.0000 - _runtime: 612.0000\n",
            "Epoch 88/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0484 - f1: 0.9937 - auc: 0.9989 - accuracy: 0.9941 - val_loss: 0.8240 - val_f1: 0.5665 - val_auc: 0.8472 - val_accuracy: 0.8521 - _timestamp: 1656358250.0000 - _runtime: 619.0000\n",
            "Epoch 89/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0452 - f1: 0.9941 - auc: 0.9993 - accuracy: 0.9943 - val_loss: 0.7812 - val_f1: 0.5395 - val_auc: 0.8306 - val_accuracy: 0.8598 - _timestamp: 1656358257.0000 - _runtime: 626.0000\n",
            "Epoch 90/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0459 - f1: 0.9940 - auc: 0.9993 - accuracy: 0.9942 - val_loss: 0.8394 - val_f1: 0.5466 - val_auc: 0.8199 - val_accuracy: 0.8693 - _timestamp: 1656358264.0000 - _runtime: 633.0000\n",
            "Epoch 91/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0459 - f1: 0.9937 - auc: 0.9994 - accuracy: 0.9938 - val_loss: 0.7870 - val_f1: 0.5625 - val_auc: 0.8370 - val_accuracy: 0.8643 - _timestamp: 1656358270.0000 - _runtime: 639.0000\n",
            "Epoch 92/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0478 - f1: 0.9926 - auc: 0.9994 - accuracy: 0.9927 - val_loss: 0.8557 - val_f1: 0.5838 - val_auc: 0.8430 - val_accuracy: 0.8621 - _timestamp: 1656358277.0000 - _runtime: 646.0000\n",
            "Epoch 93/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0467 - f1: 0.9936 - auc: 0.9993 - accuracy: 0.9942 - val_loss: 0.8537 - val_f1: 0.5413 - val_auc: 0.8259 - val_accuracy: 0.8632 - _timestamp: 1656358284.0000 - _runtime: 653.0000\n",
            "Epoch 94/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0445 - f1: 0.9945 - auc: 0.9996 - accuracy: 0.9947 - val_loss: 0.8076 - val_f1: 0.5146 - val_auc: 0.8211 - val_accuracy: 0.8737 - _timestamp: 1656358291.0000 - _runtime: 660.0000\n",
            "Epoch 95/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0418 - f1: 0.9949 - auc: 0.9996 - accuracy: 0.9951 - val_loss: 0.8762 - val_f1: 0.5332 - val_auc: 0.8289 - val_accuracy: 0.8682 - _timestamp: 1656358297.0000 - _runtime: 666.0000\n",
            "Epoch 96/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0426 - f1: 0.9944 - auc: 0.9995 - accuracy: 0.9949 - val_loss: 0.9459 - val_f1: 0.5570 - val_auc: 0.8371 - val_accuracy: 0.8482 - _timestamp: 1656358304.0000 - _runtime: 673.0000\n",
            "Epoch 97/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0440 - f1: 0.9945 - auc: 0.9994 - accuracy: 0.9947 - val_loss: 0.8973 - val_f1: 0.5400 - val_auc: 0.8194 - val_accuracy: 0.8693 - _timestamp: 1656358311.0000 - _runtime: 680.0000\n",
            "Epoch 98/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0461 - f1: 0.9946 - auc: 0.9993 - accuracy: 0.9946 - val_loss: 0.7849 - val_f1: 0.5595 - val_auc: 0.8342 - val_accuracy: 0.8721 - _timestamp: 1656358318.0000 - _runtime: 687.0000\n",
            "Epoch 99/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0446 - f1: 0.9937 - auc: 0.9997 - accuracy: 0.9940 - val_loss: 0.7924 - val_f1: 0.5255 - val_auc: 0.8147 - val_accuracy: 0.8699 - _timestamp: 1656358324.0000 - _runtime: 693.0000\n",
            "Epoch 100/100\n",
            "380/380 [==============================] - 7s 18ms/step - loss: 0.0436 - f1: 0.9942 - auc: 0.9995 - accuracy: 0.9943 - val_loss: 0.9232 - val_f1: 0.5796 - val_auc: 0.8529 - val_accuracy: 0.8498 - _timestamp: 1656358331.0000 - _runtime: 700.0000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa5ef451cf1b41ee89fe659d6eaf2ca9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='1167.806 MB of 1167.806 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▄▆▆▇▇▇▇▇▇██████████████████████████████</td></tr><tr><td>auc</td><td>▁▆▇█████████████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1</td><td>▁▄▆▆▇▇▇▇▇▇██████████████████████████████</td></tr><tr><td>loss</td><td>█▅▃▃▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▇▇▇▄▇█▇▇▆▆▇▇▇▆▇▅▃▇▆▇█▆█▇▆█▇▆█▆▇▇▇▆▆▇▇▇▅</td></tr><tr><td>val_auc</td><td>██▇█▇▅▅▆▄▅▃▄▂▁▇▄▄▅▄▅▅▃▅▂▃▅▁▂▄▄▃▄▃▃▄▃▄▂▂▅</td></tr><tr><td>val_f1</td><td>▄▅▅█▇▇█▆▆█▃▆▃▁█▅▆▄▆▇▇▆▆▃▅▇▂▄▅▅▃▇▅▆▆▃▇▂▄▆</td></tr><tr><td>val_loss</td><td>▃▁▂▂▄▄▄▃▄▆▄▅▅▇▄▆▇▇▇▆▆▆▅▆▆▇█▆▆▆██▇▇█▆▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.99432</td></tr><tr><td>auc</td><td>0.99953</td></tr><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_val_loss</td><td>0.34511</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>f1</td><td>0.99417</td></tr><tr><td>loss</td><td>0.04357</td></tr><tr><td>val_accuracy</td><td>0.84983</td></tr><tr><td>val_auc</td><td>0.85285</td></tr><tr><td>val_f1</td><td>0.57957</td></tr><tr><td>val_loss</td><td>0.92318</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">olive-sweep-6</strong>: <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/suff6jdk\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/runs/suff6jdk</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220627_192031-suff6jdk/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nvwn427w with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: prelu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_value: 0.43985373925668886\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.30000000000000004\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons: 4500\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptomizer: adadelta\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_factor: 5e-07\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_type: l1_l2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.19"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220627_193250-nvwn427w</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/nvwn427w\" target=\"_blank\">efficient-sweep-7</a></strong> to <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 25008)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4500)              112540500 \n",
            "                                                                 \n",
            " p_re_lu (PReLU)             (None, 4500)              4500      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4500)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4500)              20254500  \n",
            "                                                                 \n",
            " p_re_lu_1 (PReLU)           (None, 4500)              4500      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4500)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4500)              20254500  \n",
            "                                                                 \n",
            " p_re_lu_2 (PReLU)           (None, 4500)              4500      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 4500)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 4501      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 153,067,501\n",
            "Trainable params: 153,067,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "380/380 [==============================] - 26s 64ms/step - loss: 1.3558 - f1: 0.6477 - auc: 0.6640 - accuracy: 0.5661 - val_loss: 1.3605 - val_f1: 0.3844 - val_auc: 0.8117 - val_accuracy: 0.5200 - _timestamp: 1656358390.0000 - _runtime: 20.0000\n",
            "Epoch 2/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 1.3315 - f1: 0.7392 - auc: 0.7781 - accuracy: 0.6993 - val_loss: 1.3427 - val_f1: 0.4311 - val_auc: 0.8512 - val_accuracy: 0.6190 - _timestamp: 1656358414.0000 - _runtime: 44.0000\n",
            "Epoch 3/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 1.3076 - f1: 0.7877 - auc: 0.8517 - accuracy: 0.7638 - val_loss: 1.3250 - val_f1: 0.4552 - val_auc: 0.8595 - val_accuracy: 0.6618 - _timestamp: 1656358432.0000 - _runtime: 62.0000\n",
            "Epoch 4/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 1.2837 - f1: 0.8161 - auc: 0.8820 - accuracy: 0.7977 - val_loss: 1.3066 - val_f1: 0.4703 - val_auc: 0.8626 - val_accuracy: 0.6835 - _timestamp: 1656358450.0000 - _runtime: 80.0000\n",
            "Epoch 5/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 1.2573 - f1: 0.8294 - auc: 0.9008 - accuracy: 0.8152 - val_loss: 1.2887 - val_f1: 0.4817 - val_auc: 0.8639 - val_accuracy: 0.6963 - _timestamp: 1656358470.0000 - _runtime: 100.0000\n",
            "Epoch 6/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 1.2295 - f1: 0.8383 - auc: 0.9109 - accuracy: 0.8271 - val_loss: 1.2741 - val_f1: 0.4822 - val_auc: 0.8657 - val_accuracy: 0.6974 - _timestamp: 1656358488.0000 - _runtime: 118.0000\n",
            "Epoch 7/100\n",
            "380/380 [==============================] - 19s 50ms/step - loss: 1.2007 - f1: 0.8474 - auc: 0.9178 - accuracy: 0.8369 - val_loss: 1.2579 - val_f1: 0.4874 - val_auc: 0.8663 - val_accuracy: 0.7041 - _timestamp: 1656358507.0000 - _runtime: 137.0000\n",
            "Epoch 8/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 1.1731 - f1: 0.8462 - auc: 0.9207 - accuracy: 0.8390 - val_loss: 1.2377 - val_f1: 0.4915 - val_auc: 0.8667 - val_accuracy: 0.7147 - _timestamp: 1656358526.0000 - _runtime: 156.0000\n",
            "Epoch 9/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 1.1457 - f1: 0.8546 - auc: 0.9239 - accuracy: 0.8502 - val_loss: 1.2272 - val_f1: 0.4961 - val_auc: 0.8676 - val_accuracy: 0.7186 - _timestamp: 1656358544.0000 - _runtime: 174.0000\n",
            "Epoch 10/100\n",
            "380/380 [==============================] - 21s 55ms/step - loss: 1.1188 - f1: 0.8578 - auc: 0.9282 - accuracy: 0.8515 - val_loss: 1.2111 - val_f1: 0.5013 - val_auc: 0.8673 - val_accuracy: 0.7291 - _timestamp: 1656358562.0000 - _runtime: 192.0000\n",
            "Epoch 11/100\n",
            "380/380 [==============================] - 21s 55ms/step - loss: 1.0975 - f1: 0.8607 - auc: 0.9306 - accuracy: 0.8572 - val_loss: 1.1996 - val_f1: 0.5088 - val_auc: 0.8675 - val_accuracy: 0.7397 - _timestamp: 1656358583.0000 - _runtime: 213.0000\n",
            "Epoch 12/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 1.0756 - f1: 0.8622 - auc: 0.9330 - accuracy: 0.8581 - val_loss: 1.1872 - val_f1: 0.5065 - val_auc: 0.8676 - val_accuracy: 0.7436 - _timestamp: 1656358604.0000 - _runtime: 234.0000\n",
            "Epoch 13/100\n",
            "380/380 [==============================] - 21s 54ms/step - loss: 1.0604 - f1: 0.8642 - auc: 0.9339 - accuracy: 0.8604 - val_loss: 1.1832 - val_f1: 0.5041 - val_auc: 0.8680 - val_accuracy: 0.7447 - _timestamp: 1656358622.0000 - _runtime: 252.0000\n",
            "Epoch 14/100\n",
            "380/380 [==============================] - 20s 53ms/step - loss: 1.0432 - f1: 0.8661 - auc: 0.9372 - accuracy: 0.8637 - val_loss: 1.1764 - val_f1: 0.5062 - val_auc: 0.8682 - val_accuracy: 0.7486 - _timestamp: 1656358643.0000 - _runtime: 273.0000\n",
            "Epoch 15/100\n",
            "380/380 [==============================] - 21s 55ms/step - loss: 1.0306 - f1: 0.8681 - auc: 0.9386 - accuracy: 0.8652 - val_loss: 1.1689 - val_f1: 0.5110 - val_auc: 0.8682 - val_accuracy: 0.7542 - _timestamp: 1656358663.0000 - _runtime: 293.0000\n",
            "Epoch 16/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 1.0197 - f1: 0.8687 - auc: 0.9404 - accuracy: 0.8672 - val_loss: 1.1700 - val_f1: 0.5117 - val_auc: 0.8685 - val_accuracy: 0.7564 - _timestamp: 1656358684.0000 - _runtime: 314.0000\n",
            "Epoch 17/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 1.0089 - f1: 0.8721 - auc: 0.9426 - accuracy: 0.8713 - val_loss: 1.1670 - val_f1: 0.5154 - val_auc: 0.8686 - val_accuracy: 0.7603 - _timestamp: 1656358697.0000 - _runtime: 327.0000\n",
            "Epoch 18/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 1.0001 - f1: 0.8751 - auc: 0.9443 - accuracy: 0.8737 - val_loss: 1.1646 - val_f1: 0.5160 - val_auc: 0.8688 - val_accuracy: 0.7614 - _timestamp: 1656358715.0000 - _runtime: 345.0000\n",
            "Epoch 19/100\n",
            "380/380 [==============================] - 20s 53ms/step - loss: 0.9942 - f1: 0.8762 - auc: 0.9449 - accuracy: 0.8743 - val_loss: 1.1638 - val_f1: 0.5167 - val_auc: 0.8690 - val_accuracy: 0.7620 - _timestamp: 1656358736.0000 - _runtime: 366.0000\n",
            "Epoch 20/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 0.9847 - f1: 0.8777 - auc: 0.9475 - accuracy: 0.8777 - val_loss: 1.1599 - val_f1: 0.5178 - val_auc: 0.8692 - val_accuracy: 0.7647 - _timestamp: 1656358756.0000 - _runtime: 386.0000\n",
            "Epoch 21/100\n",
            "380/380 [==============================] - 21s 54ms/step - loss: 0.9793 - f1: 0.8806 - auc: 0.9485 - accuracy: 0.8805 - val_loss: 1.1594 - val_f1: 0.5171 - val_auc: 0.8692 - val_accuracy: 0.7653 - _timestamp: 1656358774.0000 - _runtime: 404.0000\n",
            "Epoch 22/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 0.9732 - f1: 0.8798 - auc: 0.9503 - accuracy: 0.8798 - val_loss: 1.1532 - val_f1: 0.5152 - val_auc: 0.8692 - val_accuracy: 0.7664 - _timestamp: 1656358795.0000 - _runtime: 425.0000\n",
            "Epoch 23/100\n",
            "380/380 [==============================] - 21s 55ms/step - loss: 0.9660 - f1: 0.8820 - auc: 0.9523 - accuracy: 0.8828 - val_loss: 1.1516 - val_f1: 0.5157 - val_auc: 0.8693 - val_accuracy: 0.7681 - _timestamp: 1656358813.0000 - _runtime: 443.0000\n",
            "Epoch 24/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.9610 - f1: 0.8856 - auc: 0.9534 - accuracy: 0.8856 - val_loss: 1.1594 - val_f1: 0.5154 - val_auc: 0.8699 - val_accuracy: 0.7670 - _timestamp: 1656358834.0000 - _runtime: 464.0000\n",
            "Epoch 25/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.9580 - f1: 0.8834 - auc: 0.9538 - accuracy: 0.8840 - val_loss: 1.1528 - val_f1: 0.5187 - val_auc: 0.8701 - val_accuracy: 0.7697 - _timestamp: 1656358847.0000 - _runtime: 477.0000\n",
            "Epoch 26/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.9544 - f1: 0.8859 - auc: 0.9549 - accuracy: 0.8868 - val_loss: 1.1571 - val_f1: 0.5166 - val_auc: 0.8707 - val_accuracy: 0.7686 - _timestamp: 1656358860.0000 - _runtime: 490.0000\n",
            "Epoch 27/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 0.9507 - f1: 0.8878 - auc: 0.9558 - accuracy: 0.8876 - val_loss: 1.1509 - val_f1: 0.5177 - val_auc: 0.8709 - val_accuracy: 0.7731 - _timestamp: 1656358873.0000 - _runtime: 503.0000\n",
            "Epoch 28/100\n",
            "380/380 [==============================] - 20s 53ms/step - loss: 0.9427 - f1: 0.8926 - auc: 0.9583 - accuracy: 0.8924 - val_loss: 1.1497 - val_f1: 0.5180 - val_auc: 0.8707 - val_accuracy: 0.7747 - _timestamp: 1656358892.0000 - _runtime: 522.0000\n",
            "Epoch 29/100\n",
            "380/380 [==============================] - 20s 53ms/step - loss: 0.9409 - f1: 0.8912 - auc: 0.9587 - accuracy: 0.8918 - val_loss: 1.1483 - val_f1: 0.5213 - val_auc: 0.8711 - val_accuracy: 0.7775 - _timestamp: 1656358912.0000 - _runtime: 542.0000\n",
            "Epoch 30/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.9367 - f1: 0.8930 - auc: 0.9599 - accuracy: 0.8949 - val_loss: 1.1538 - val_f1: 0.5195 - val_auc: 0.8719 - val_accuracy: 0.7759 - _timestamp: 1656358932.0000 - _runtime: 562.0000\n",
            "Epoch 31/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.9329 - f1: 0.8941 - auc: 0.9609 - accuracy: 0.8956 - val_loss: 1.1492 - val_f1: 0.5200 - val_auc: 0.8718 - val_accuracy: 0.7770 - _timestamp: 1656358945.0000 - _runtime: 575.0000\n",
            "Epoch 32/100\n",
            "380/380 [==============================] - 21s 55ms/step - loss: 0.9332 - f1: 0.8944 - auc: 0.9603 - accuracy: 0.8955 - val_loss: 1.1396 - val_f1: 0.5234 - val_auc: 0.8719 - val_accuracy: 0.7814 - _timestamp: 1656358959.0000 - _runtime: 589.0000\n",
            "Epoch 33/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.9293 - f1: 0.8931 - auc: 0.9615 - accuracy: 0.8959 - val_loss: 1.1464 - val_f1: 0.5236 - val_auc: 0.8724 - val_accuracy: 0.7798 - _timestamp: 1656358979.0000 - _runtime: 609.0000\n",
            "Epoch 34/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.9276 - f1: 0.8957 - auc: 0.9619 - accuracy: 0.8970 - val_loss: 1.1479 - val_f1: 0.5236 - val_auc: 0.8729 - val_accuracy: 0.7792 - _timestamp: 1656358993.0000 - _runtime: 623.0000\n",
            "Epoch 35/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.9232 - f1: 0.8957 - auc: 0.9631 - accuracy: 0.8973 - val_loss: 1.1461 - val_f1: 0.5283 - val_auc: 0.8731 - val_accuracy: 0.7831 - _timestamp: 1656359006.0000 - _runtime: 636.0000\n",
            "Epoch 36/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.9208 - f1: 0.8994 - auc: 0.9638 - accuracy: 0.9000 - val_loss: 1.1460 - val_f1: 0.5284 - val_auc: 0.8735 - val_accuracy: 0.7831 - _timestamp: 1656359019.0000 - _runtime: 649.0000\n",
            "Epoch 37/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.9176 - f1: 0.9028 - auc: 0.9645 - accuracy: 0.9036 - val_loss: 1.1455 - val_f1: 0.5282 - val_auc: 0.8740 - val_accuracy: 0.7836 - _timestamp: 1656359032.0000 - _runtime: 662.0000\n",
            "Epoch 38/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 0.9136 - f1: 0.9024 - auc: 0.9658 - accuracy: 0.9040 - val_loss: 1.1363 - val_f1: 0.5330 - val_auc: 0.8739 - val_accuracy: 0.7903 - _timestamp: 1656359045.0000 - _runtime: 675.0000\n",
            "Epoch 39/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 0.9114 - f1: 0.9035 - auc: 0.9662 - accuracy: 0.9049 - val_loss: 1.1305 - val_f1: 0.5361 - val_auc: 0.8734 - val_accuracy: 0.7942 - _timestamp: 1656359068.0000 - _runtime: 698.0000\n",
            "Epoch 40/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.9111 - f1: 0.9034 - auc: 0.9662 - accuracy: 0.9058 - val_loss: 1.1368 - val_f1: 0.5356 - val_auc: 0.8739 - val_accuracy: 0.7914 - _timestamp: 1656359086.0000 - _runtime: 716.0000\n",
            "Epoch 41/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.9110 - f1: 0.9041 - auc: 0.9660 - accuracy: 0.9059 - val_loss: 1.1324 - val_f1: 0.5346 - val_auc: 0.8742 - val_accuracy: 0.7925 - _timestamp: 1656359099.0000 - _runtime: 729.0000\n",
            "Epoch 42/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.9079 - f1: 0.9044 - auc: 0.9670 - accuracy: 0.9055 - val_loss: 1.1323 - val_f1: 0.5364 - val_auc: 0.8747 - val_accuracy: 0.7931 - _timestamp: 1656359112.0000 - _runtime: 742.0000\n",
            "Epoch 43/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 0.9067 - f1: 0.9040 - auc: 0.9671 - accuracy: 0.9077 - val_loss: 1.1298 - val_f1: 0.5405 - val_auc: 0.8750 - val_accuracy: 0.7964 - _timestamp: 1656359126.0000 - _runtime: 756.0000\n",
            "Epoch 44/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.9027 - f1: 0.9073 - auc: 0.9683 - accuracy: 0.9099 - val_loss: 1.1325 - val_f1: 0.5419 - val_auc: 0.8754 - val_accuracy: 0.7970 - _timestamp: 1656359144.0000 - _runtime: 774.0000\n",
            "Epoch 45/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.9037 - f1: 0.9073 - auc: 0.9675 - accuracy: 0.9093 - val_loss: 1.1397 - val_f1: 0.5382 - val_auc: 0.8761 - val_accuracy: 0.7931 - _timestamp: 1656359157.0000 - _runtime: 787.0000\n",
            "Epoch 46/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 0.9010 - f1: 0.9077 - auc: 0.9683 - accuracy: 0.9100 - val_loss: 1.1263 - val_f1: 0.5417 - val_auc: 0.8751 - val_accuracy: 0.7981 - _timestamp: 1656359170.0000 - _runtime: 800.0000\n",
            "Epoch 47/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8998 - f1: 0.9065 - auc: 0.9689 - accuracy: 0.9084 - val_loss: 1.1352 - val_f1: 0.5426 - val_auc: 0.8762 - val_accuracy: 0.7970 - _timestamp: 1656359189.0000 - _runtime: 819.0000\n",
            "Epoch 48/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.8979 - f1: 0.9078 - auc: 0.9694 - accuracy: 0.9094 - val_loss: 1.1267 - val_f1: 0.5418 - val_auc: 0.8757 - val_accuracy: 0.7992 - _timestamp: 1656359202.0000 - _runtime: 832.0000\n",
            "Epoch 49/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.8939 - f1: 0.9098 - auc: 0.9704 - accuracy: 0.9122 - val_loss: 1.1316 - val_f1: 0.5411 - val_auc: 0.8762 - val_accuracy: 0.7981 - _timestamp: 1656359215.0000 - _runtime: 845.0000\n",
            "Epoch 50/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8959 - f1: 0.9078 - auc: 0.9694 - accuracy: 0.9107 - val_loss: 1.1313 - val_f1: 0.5430 - val_auc: 0.8763 - val_accuracy: 0.7998 - _timestamp: 1656359228.0000 - _runtime: 858.0000\n",
            "Epoch 51/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 0.8913 - f1: 0.9112 - auc: 0.9710 - accuracy: 0.9142 - val_loss: 1.1246 - val_f1: 0.5400 - val_auc: 0.8765 - val_accuracy: 0.8009 - _timestamp: 1656359241.0000 - _runtime: 871.0000\n",
            "Epoch 52/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 0.8905 - f1: 0.9112 - auc: 0.9711 - accuracy: 0.9137 - val_loss: 1.1145 - val_f1: 0.5388 - val_auc: 0.8766 - val_accuracy: 0.8042 - _timestamp: 1656359259.0000 - _runtime: 889.0000\n",
            "Epoch 53/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8924 - f1: 0.9098 - auc: 0.9701 - accuracy: 0.9123 - val_loss: 1.1187 - val_f1: 0.5423 - val_auc: 0.8772 - val_accuracy: 0.8048 - _timestamp: 1656359277.0000 - _runtime: 907.0000\n",
            "Epoch 54/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8921 - f1: 0.9125 - auc: 0.9703 - accuracy: 0.9136 - val_loss: 1.1347 - val_f1: 0.5348 - val_auc: 0.8777 - val_accuracy: 0.7970 - _timestamp: 1656359291.0000 - _runtime: 921.0000\n",
            "Epoch 55/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8858 - f1: 0.9137 - auc: 0.9723 - accuracy: 0.9158 - val_loss: 1.1235 - val_f1: 0.5441 - val_auc: 0.8780 - val_accuracy: 0.8053 - _timestamp: 1656359304.0000 - _runtime: 934.0000\n",
            "Epoch 56/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8885 - f1: 0.9122 - auc: 0.9714 - accuracy: 0.9145 - val_loss: 1.1241 - val_f1: 0.5433 - val_auc: 0.8783 - val_accuracy: 0.8053 - _timestamp: 1656359317.0000 - _runtime: 947.0000\n",
            "Epoch 57/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8860 - f1: 0.9156 - auc: 0.9720 - accuracy: 0.9185 - val_loss: 1.1250 - val_f1: 0.5409 - val_auc: 0.8786 - val_accuracy: 0.8048 - _timestamp: 1656359330.0000 - _runtime: 960.0000\n",
            "Epoch 58/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8851 - f1: 0.9154 - auc: 0.9722 - accuracy: 0.9178 - val_loss: 1.1213 - val_f1: 0.5428 - val_auc: 0.8786 - val_accuracy: 0.8065 - _timestamp: 1656359343.0000 - _runtime: 973.0000\n",
            "Epoch 59/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8826 - f1: 0.9140 - auc: 0.9729 - accuracy: 0.9168 - val_loss: 1.1181 - val_f1: 0.5432 - val_auc: 0.8786 - val_accuracy: 0.8076 - _timestamp: 1656359356.0000 - _runtime: 986.0000\n",
            "Epoch 60/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8813 - f1: 0.9181 - auc: 0.9731 - accuracy: 0.9198 - val_loss: 1.1230 - val_f1: 0.5449 - val_auc: 0.8793 - val_accuracy: 0.8076 - _timestamp: 1656359370.0000 - _runtime: 1000.0000\n",
            "Epoch 61/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8797 - f1: 0.9176 - auc: 0.9735 - accuracy: 0.9196 - val_loss: 1.1229 - val_f1: 0.5444 - val_auc: 0.8794 - val_accuracy: 0.8070 - _timestamp: 1656359383.0000 - _runtime: 1013.0000\n",
            "Epoch 62/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8818 - f1: 0.9151 - auc: 0.9729 - accuracy: 0.9173 - val_loss: 1.1178 - val_f1: 0.5450 - val_auc: 0.8796 - val_accuracy: 0.8092 - _timestamp: 1656359396.0000 - _runtime: 1026.0000\n",
            "Epoch 63/100\n",
            "380/380 [==============================] - 21s 55ms/step - loss: 0.8770 - f1: 0.9183 - auc: 0.9742 - accuracy: 0.9203 - val_loss: 1.1133 - val_f1: 0.5461 - val_auc: 0.8791 - val_accuracy: 0.8103 - _timestamp: 1656359409.0000 - _runtime: 1039.0000\n",
            "Epoch 64/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8763 - f1: 0.9162 - auc: 0.9746 - accuracy: 0.9190 - val_loss: 1.1216 - val_f1: 0.5460 - val_auc: 0.8801 - val_accuracy: 0.8081 - _timestamp: 1656359430.0000 - _runtime: 1060.0000\n",
            "Epoch 65/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8752 - f1: 0.9171 - auc: 0.9748 - accuracy: 0.9192 - val_loss: 1.1226 - val_f1: 0.5467 - val_auc: 0.8800 - val_accuracy: 0.8081 - _timestamp: 1656359443.0000 - _runtime: 1073.0000\n",
            "Epoch 66/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8800 - f1: 0.9174 - auc: 0.9732 - accuracy: 0.9195 - val_loss: 1.1203 - val_f1: 0.5490 - val_auc: 0.8800 - val_accuracy: 0.8092 - _timestamp: 1656359456.0000 - _runtime: 1086.0000\n",
            "Epoch 67/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8753 - f1: 0.9169 - auc: 0.9746 - accuracy: 0.9199 - val_loss: 1.1171 - val_f1: 0.5456 - val_auc: 0.8804 - val_accuracy: 0.8087 - _timestamp: 1656359470.0000 - _runtime: 1100.0000\n",
            "Epoch 68/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8741 - f1: 0.9172 - auc: 0.9747 - accuracy: 0.9197 - val_loss: 1.1217 - val_f1: 0.5474 - val_auc: 0.8809 - val_accuracy: 0.8081 - _timestamp: 1656359483.0000 - _runtime: 1113.0000\n",
            "Epoch 69/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 0.8726 - f1: 0.9206 - auc: 0.9752 - accuracy: 0.9218 - val_loss: 1.1120 - val_f1: 0.5501 - val_auc: 0.8809 - val_accuracy: 0.8126 - _timestamp: 1656359496.0000 - _runtime: 1126.0000\n",
            "Epoch 70/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8746 - f1: 0.9184 - auc: 0.9745 - accuracy: 0.9205 - val_loss: 1.1221 - val_f1: 0.5496 - val_auc: 0.8815 - val_accuracy: 0.8092 - _timestamp: 1656359514.0000 - _runtime: 1144.0000\n",
            "Epoch 71/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8696 - f1: 0.9192 - auc: 0.9761 - accuracy: 0.9213 - val_loss: 1.1175 - val_f1: 0.5510 - val_auc: 0.8816 - val_accuracy: 0.8109 - _timestamp: 1656359527.0000 - _runtime: 1157.0000\n",
            "Epoch 72/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8727 - f1: 0.9208 - auc: 0.9751 - accuracy: 0.9229 - val_loss: 1.1251 - val_f1: 0.5539 - val_auc: 0.8820 - val_accuracy: 0.8103 - _timestamp: 1656359540.0000 - _runtime: 1170.0000\n",
            "Epoch 73/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8714 - f1: 0.9181 - auc: 0.9754 - accuracy: 0.9205 - val_loss: 1.1200 - val_f1: 0.5519 - val_auc: 0.8820 - val_accuracy: 0.8103 - _timestamp: 1656359554.0000 - _runtime: 1184.0000\n",
            "Epoch 74/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8689 - f1: 0.9226 - auc: 0.9759 - accuracy: 0.9242 - val_loss: 1.1192 - val_f1: 0.5519 - val_auc: 0.8825 - val_accuracy: 0.8103 - _timestamp: 1656359567.0000 - _runtime: 1197.0000\n",
            "Epoch 75/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 0.8715 - f1: 0.9221 - auc: 0.9751 - accuracy: 0.9242 - val_loss: 1.1103 - val_f1: 0.5501 - val_auc: 0.8820 - val_accuracy: 0.8131 - _timestamp: 1656359580.0000 - _runtime: 1210.0000\n",
            "Epoch 76/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8700 - f1: 0.9209 - auc: 0.9755 - accuracy: 0.9232 - val_loss: 1.1169 - val_f1: 0.5583 - val_auc: 0.8830 - val_accuracy: 0.8131 - _timestamp: 1656359598.0000 - _runtime: 1228.0000\n",
            "Epoch 77/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8692 - f1: 0.9208 - auc: 0.9757 - accuracy: 0.9224 - val_loss: 1.1221 - val_f1: 0.5573 - val_auc: 0.8834 - val_accuracy: 0.8115 - _timestamp: 1656359611.0000 - _runtime: 1241.0000\n",
            "Epoch 78/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8660 - f1: 0.9226 - auc: 0.9765 - accuracy: 0.9247 - val_loss: 1.1136 - val_f1: 0.5555 - val_auc: 0.8830 - val_accuracy: 0.8142 - _timestamp: 1656359624.0000 - _runtime: 1254.0000\n",
            "Epoch 79/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8675 - f1: 0.9221 - auc: 0.9761 - accuracy: 0.9246 - val_loss: 1.1123 - val_f1: 0.5555 - val_auc: 0.8830 - val_accuracy: 0.8142 - _timestamp: 1656359638.0000 - _runtime: 1268.0000\n",
            "Epoch 80/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8657 - f1: 0.9240 - auc: 0.9767 - accuracy: 0.9259 - val_loss: 1.1105 - val_f1: 0.5538 - val_auc: 0.8829 - val_accuracy: 0.8142 - _timestamp: 1656359651.0000 - _runtime: 1281.0000\n",
            "Epoch 81/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8666 - f1: 0.9179 - auc: 0.9766 - accuracy: 0.9200 - val_loss: 1.1139 - val_f1: 0.5550 - val_auc: 0.8836 - val_accuracy: 0.8142 - _timestamp: 1656359664.0000 - _runtime: 1294.0000\n",
            "Epoch 82/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8642 - f1: 0.9252 - auc: 0.9771 - accuracy: 0.9264 - val_loss: 1.1139 - val_f1: 0.5534 - val_auc: 0.8838 - val_accuracy: 0.8131 - _timestamp: 1656359677.0000 - _runtime: 1307.0000\n",
            "Epoch 83/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 0.8651 - f1: 0.9212 - auc: 0.9767 - accuracy: 0.9229 - val_loss: 1.1083 - val_f1: 0.5593 - val_auc: 0.8832 - val_accuracy: 0.8176 - _timestamp: 1656359690.0000 - _runtime: 1320.0000\n",
            "Epoch 84/100\n",
            "380/380 [==============================] - 21s 55ms/step - loss: 0.8621 - f1: 0.9253 - auc: 0.9775 - accuracy: 0.9271 - val_loss: 1.1058 - val_f1: 0.5583 - val_auc: 0.8833 - val_accuracy: 0.8176 - _timestamp: 1656359709.0000 - _runtime: 1339.0000\n",
            "Epoch 85/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8681 - f1: 0.9205 - auc: 0.9759 - accuracy: 0.9223 - val_loss: 1.1115 - val_f1: 0.5573 - val_auc: 0.8838 - val_accuracy: 0.8159 - _timestamp: 1656359730.0000 - _runtime: 1360.0000\n",
            "Epoch 86/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8641 - f1: 0.9235 - auc: 0.9770 - accuracy: 0.9257 - val_loss: 1.1125 - val_f1: 0.5578 - val_auc: 0.8838 - val_accuracy: 0.8159 - _timestamp: 1656359743.0000 - _runtime: 1373.0000\n",
            "Epoch 87/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8624 - f1: 0.9252 - auc: 0.9771 - accuracy: 0.9270 - val_loss: 1.1198 - val_f1: 0.5530 - val_auc: 0.8852 - val_accuracy: 0.8115 - _timestamp: 1656359756.0000 - _runtime: 1386.0000\n",
            "Epoch 88/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8587 - f1: 0.9238 - auc: 0.9785 - accuracy: 0.9265 - val_loss: 1.1167 - val_f1: 0.5563 - val_auc: 0.8851 - val_accuracy: 0.8142 - _timestamp: 1656359769.0000 - _runtime: 1399.0000\n",
            "Epoch 89/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8590 - f1: 0.9232 - auc: 0.9784 - accuracy: 0.9247 - val_loss: 1.1133 - val_f1: 0.5571 - val_auc: 0.8851 - val_accuracy: 0.8148 - _timestamp: 1656359782.0000 - _runtime: 1412.0000\n",
            "Epoch 90/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8622 - f1: 0.9235 - auc: 0.9775 - accuracy: 0.9255 - val_loss: 1.1093 - val_f1: 0.5601 - val_auc: 0.8847 - val_accuracy: 0.8176 - _timestamp: 1656359795.0000 - _runtime: 1425.0000\n",
            "Epoch 91/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8593 - f1: 0.9247 - auc: 0.9782 - accuracy: 0.9271 - val_loss: 1.1199 - val_f1: 0.5614 - val_auc: 0.8859 - val_accuracy: 0.8142 - _timestamp: 1656359809.0000 - _runtime: 1439.0000\n",
            "Epoch 92/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8594 - f1: 0.9234 - auc: 0.9783 - accuracy: 0.9252 - val_loss: 1.1193 - val_f1: 0.5593 - val_auc: 0.8857 - val_accuracy: 0.8142 - _timestamp: 1656359822.0000 - _runtime: 1452.0000\n",
            "Epoch 93/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8568 - f1: 0.9249 - auc: 0.9787 - accuracy: 0.9266 - val_loss: 1.1147 - val_f1: 0.5579 - val_auc: 0.8857 - val_accuracy: 0.8154 - _timestamp: 1656359835.0000 - _runtime: 1465.0000\n",
            "Epoch 94/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8581 - f1: 0.9273 - auc: 0.9784 - accuracy: 0.9287 - val_loss: 1.1134 - val_f1: 0.5588 - val_auc: 0.8853 - val_accuracy: 0.8159 - _timestamp: 1656359848.0000 - _runtime: 1478.0000\n",
            "Epoch 95/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8550 - f1: 0.9270 - auc: 0.9793 - accuracy: 0.9288 - val_loss: 1.1135 - val_f1: 0.5615 - val_auc: 0.8854 - val_accuracy: 0.8165 - _timestamp: 1656359861.0000 - _runtime: 1491.0000\n",
            "Epoch 96/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8601 - f1: 0.9255 - auc: 0.9778 - accuracy: 0.9267 - val_loss: 1.1123 - val_f1: 0.5627 - val_auc: 0.8855 - val_accuracy: 0.8170 - _timestamp: 1656359875.0000 - _runtime: 1505.0000\n",
            "Epoch 97/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8529 - f1: 0.9284 - auc: 0.9796 - accuracy: 0.9294 - val_loss: 1.1119 - val_f1: 0.5627 - val_auc: 0.8857 - val_accuracy: 0.8170 - _timestamp: 1656359888.0000 - _runtime: 1518.0000\n",
            "Epoch 98/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8572 - f1: 0.9235 - auc: 0.9785 - accuracy: 0.9260 - val_loss: 1.1127 - val_f1: 0.5627 - val_auc: 0.8859 - val_accuracy: 0.8170 - _timestamp: 1656359901.0000 - _runtime: 1531.0000\n",
            "Epoch 99/100\n",
            "380/380 [==============================] - 20s 53ms/step - loss: 0.8538 - f1: 0.9257 - auc: 0.9793 - accuracy: 0.9286 - val_loss: 1.1037 - val_f1: 0.5605 - val_auc: 0.8857 - val_accuracy: 0.8187 - _timestamp: 1656359914.0000 - _runtime: 1544.0000\n",
            "Epoch 100/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.8480 - f1: 0.9286 - auc: 0.9808 - accuracy: 0.9304 - val_loss: 1.1186 - val_f1: 0.5605 - val_auc: 0.8868 - val_accuracy: 0.8148 - _timestamp: 1656359934.0000 - _runtime: 1564.0000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "886b94f6e0f040d19a097498370fb909",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='1751.782 MB of 1751.782 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>auc</td><td>▁▅▆▇▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1</td><td>▁▄▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>loss</td><td>█▇▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████████████████</td></tr><tr><td>val_auc</td><td>▁▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>val_f1</td><td>▁▄▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>val_loss</td><td>█▇▆▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.93043</td></tr><tr><td>auc</td><td>0.98079</td></tr><tr><td>best_epoch</td><td>98</td></tr><tr><td>best_val_loss</td><td>1.10374</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>f1</td><td>0.92862</td></tr><tr><td>loss</td><td>0.84798</td></tr><tr><td>val_accuracy</td><td>0.81479</td></tr><tr><td>val_auc</td><td>0.88681</td></tr><tr><td>val_f1</td><td>0.5605</td></tr><tr><td>val_loss</td><td>1.11859</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">efficient-sweep-7</strong>: <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/nvwn427w\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/runs/nvwn427w</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220627_193250-nvwn427w/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bg5mpyb0 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: leaky_relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_value: 0.2970392980098799\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons: 2500\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptomizer: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_factor: 1e-07\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_type: l2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.19"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220627_195953-bg5mpyb0</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/bg5mpyb0\" target=\"_blank\">atomic-sweep-8</a></strong> to <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 25008)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2500)              62522500  \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 2500)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 2500)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2500)              6252500   \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 2500)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2500)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2500)              6252500   \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 2500)              0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 2500)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2500)              6252500   \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 2500)              0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 2500)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2500)              6252500   \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 2500)              0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 2500)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 2501      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87,535,001\n",
            "Trainable params: 87,535,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "380/380 [==============================] - 10s 24ms/step - loss: 0.2989 - f1: 0.8756 - auc: 0.9404 - accuracy: 0.8815 - val_loss: 0.3386 - val_f1: 0.5353 - val_auc: 0.8712 - val_accuracy: 0.8498 - _timestamp: 1656360007.0000 - _runtime: 14.0000\n",
            "Epoch 2/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.1906 - f1: 0.9261 - auc: 0.9776 - accuracy: 0.9276 - val_loss: 0.4129 - val_f1: 0.5541 - val_auc: 0.8897 - val_accuracy: 0.8042 - _timestamp: 1656360016.0000 - _runtime: 23.0000\n",
            "Epoch 3/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.1489 - f1: 0.9406 - auc: 0.9862 - accuracy: 0.9420 - val_loss: 0.3378 - val_f1: 0.5445 - val_auc: 0.8866 - val_accuracy: 0.8587 - _timestamp: 1656360022.0000 - _runtime: 29.0000\n",
            "Epoch 4/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.1269 - f1: 0.9466 - auc: 0.9902 - accuracy: 0.9489 - val_loss: 0.3733 - val_f1: 0.6091 - val_auc: 0.8929 - val_accuracy: 0.8637 - _timestamp: 1656360030.0000 - _runtime: 37.0000\n",
            "Epoch 5/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.1147 - f1: 0.9537 - auc: 0.9918 - accuracy: 0.9558 - val_loss: 0.3225 - val_f1: 0.5928 - val_auc: 0.8966 - val_accuracy: 0.8576 - _timestamp: 1656360036.0000 - _runtime: 43.0000\n",
            "Epoch 6/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.1027 - f1: 0.9578 - auc: 0.9934 - accuracy: 0.9593 - val_loss: 0.3907 - val_f1: 0.5924 - val_auc: 0.8874 - val_accuracy: 0.8454 - _timestamp: 1656360044.0000 - _runtime: 51.0000\n",
            "Epoch 7/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0847 - f1: 0.9671 - auc: 0.9953 - accuracy: 0.9685 - val_loss: 0.4109 - val_f1: 0.5804 - val_auc: 0.8865 - val_accuracy: 0.8682 - _timestamp: 1656360050.0000 - _runtime: 57.0000\n",
            "Epoch 8/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0769 - f1: 0.9696 - auc: 0.9961 - accuracy: 0.9709 - val_loss: 0.4105 - val_f1: 0.5814 - val_auc: 0.8605 - val_accuracy: 0.8804 - _timestamp: 1656360056.0000 - _runtime: 63.0000\n",
            "Epoch 9/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0772 - f1: 0.9704 - auc: 0.9960 - accuracy: 0.9717 - val_loss: 0.4390 - val_f1: 0.6076 - val_auc: 0.8894 - val_accuracy: 0.8565 - _timestamp: 1656360063.0000 - _runtime: 70.0000\n",
            "Epoch 10/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0635 - f1: 0.9744 - auc: 0.9973 - accuracy: 0.9755 - val_loss: 0.5165 - val_f1: 0.5616 - val_auc: 0.8457 - val_accuracy: 0.8765 - _timestamp: 1656360069.0000 - _runtime: 76.0000\n",
            "Epoch 11/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0667 - f1: 0.9741 - auc: 0.9971 - accuracy: 0.9746 - val_loss: 0.4523 - val_f1: 0.5974 - val_auc: 0.8756 - val_accuracy: 0.8604 - _timestamp: 1656360075.0000 - _runtime: 82.0000\n",
            "Epoch 12/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0621 - f1: 0.9762 - auc: 0.9974 - accuracy: 0.9770 - val_loss: 0.4874 - val_f1: 0.5874 - val_auc: 0.8649 - val_accuracy: 0.8571 - _timestamp: 1656360081.0000 - _runtime: 88.0000\n",
            "Epoch 13/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0589 - f1: 0.9781 - auc: 0.9974 - accuracy: 0.9788 - val_loss: 0.4756 - val_f1: 0.5806 - val_auc: 0.8658 - val_accuracy: 0.8648 - _timestamp: 1656360087.0000 - _runtime: 94.0000\n",
            "Epoch 14/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0479 - f1: 0.9808 - auc: 0.9983 - accuracy: 0.9816 - val_loss: 0.7501 - val_f1: 0.5177 - val_auc: 0.8141 - val_accuracy: 0.8760 - _timestamp: 1656360093.0000 - _runtime: 100.0000\n",
            "Epoch 15/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0558 - f1: 0.9809 - auc: 0.9978 - accuracy: 0.9813 - val_loss: 0.5283 - val_f1: 0.5799 - val_auc: 0.8639 - val_accuracy: 0.8593 - _timestamp: 1656360100.0000 - _runtime: 107.0000\n",
            "Epoch 16/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0503 - f1: 0.9816 - auc: 0.9981 - accuracy: 0.9824 - val_loss: 0.5857 - val_f1: 0.5541 - val_auc: 0.8406 - val_accuracy: 0.8726 - _timestamp: 1656360106.0000 - _runtime: 113.0000\n",
            "Epoch 17/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0430 - f1: 0.9846 - auc: 0.9984 - accuracy: 0.9849 - val_loss: 0.6190 - val_f1: 0.5494 - val_auc: 0.8349 - val_accuracy: 0.8665 - _timestamp: 1656360112.0000 - _runtime: 119.0000\n",
            "Epoch 18/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0509 - f1: 0.9821 - auc: 0.9977 - accuracy: 0.9829 - val_loss: 0.6308 - val_f1: 0.5044 - val_auc: 0.8339 - val_accuracy: 0.8587 - _timestamp: 1656360118.0000 - _runtime: 125.0000\n",
            "Epoch 19/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0423 - f1: 0.9830 - auc: 0.9986 - accuracy: 0.9834 - val_loss: 0.7228 - val_f1: 0.5366 - val_auc: 0.8329 - val_accuracy: 0.8565 - _timestamp: 1656360124.0000 - _runtime: 131.0000\n",
            "Epoch 20/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0428 - f1: 0.9857 - auc: 0.9986 - accuracy: 0.9860 - val_loss: 0.5902 - val_f1: 0.5114 - val_auc: 0.8367 - val_accuracy: 0.8660 - _timestamp: 1656360130.0000 - _runtime: 137.0000\n",
            "Epoch 21/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0383 - f1: 0.9857 - auc: 0.9989 - accuracy: 0.9861 - val_loss: 0.6033 - val_f1: 0.5892 - val_auc: 0.8601 - val_accuracy: 0.8543 - _timestamp: 1656360136.0000 - _runtime: 143.0000\n",
            "Epoch 22/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0417 - f1: 0.9847 - auc: 0.9986 - accuracy: 0.9857 - val_loss: 0.7765 - val_f1: 0.5542 - val_auc: 0.8342 - val_accuracy: 0.8715 - _timestamp: 1656360142.0000 - _runtime: 149.0000\n",
            "Epoch 23/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0348 - f1: 0.9888 - auc: 0.9989 - accuracy: 0.9890 - val_loss: 0.7611 - val_f1: 0.5240 - val_auc: 0.8233 - val_accuracy: 0.8643 - _timestamp: 1656360149.0000 - _runtime: 156.0000\n",
            "Epoch 24/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0406 - f1: 0.9849 - auc: 0.9987 - accuracy: 0.9857 - val_loss: 0.7560 - val_f1: 0.5495 - val_auc: 0.8366 - val_accuracy: 0.8582 - _timestamp: 1656360155.0000 - _runtime: 162.0000\n",
            "Epoch 25/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0389 - f1: 0.9872 - auc: 0.9986 - accuracy: 0.9876 - val_loss: 0.6641 - val_f1: 0.5853 - val_auc: 0.8570 - val_accuracy: 0.8587 - _timestamp: 1656360161.0000 - _runtime: 168.0000\n",
            "Epoch 26/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0375 - f1: 0.9880 - auc: 0.9989 - accuracy: 0.9879 - val_loss: 0.7849 - val_f1: 0.5211 - val_auc: 0.8244 - val_accuracy: 0.8604 - _timestamp: 1656360167.0000 - _runtime: 174.0000\n",
            "Epoch 27/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0324 - f1: 0.9891 - auc: 0.9990 - accuracy: 0.9893 - val_loss: 0.6795 - val_f1: 0.5542 - val_auc: 0.8400 - val_accuracy: 0.8509 - _timestamp: 1656360173.0000 - _runtime: 180.0000\n",
            "Epoch 28/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0329 - f1: 0.9882 - auc: 0.9991 - accuracy: 0.9884 - val_loss: 0.6130 - val_f1: 0.5328 - val_auc: 0.8371 - val_accuracy: 0.8726 - _timestamp: 1656360179.0000 - _runtime: 186.0000\n",
            "Epoch 29/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0280 - f1: 0.9914 - auc: 0.9993 - accuracy: 0.9918 - val_loss: 0.7776 - val_f1: 0.5634 - val_auc: 0.8310 - val_accuracy: 0.8598 - _timestamp: 1656360186.0000 - _runtime: 193.0000\n",
            "Epoch 30/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0311 - f1: 0.9900 - auc: 0.9990 - accuracy: 0.9901 - val_loss: 0.7234 - val_f1: 0.5608 - val_auc: 0.8380 - val_accuracy: 0.8654 - _timestamp: 1656360192.0000 - _runtime: 199.0000\n",
            "Epoch 31/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0292 - f1: 0.9892 - auc: 0.9992 - accuracy: 0.9895 - val_loss: 0.7087 - val_f1: 0.5219 - val_auc: 0.8237 - val_accuracy: 0.8660 - _timestamp: 1656360198.0000 - _runtime: 205.0000\n",
            "Epoch 32/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0323 - f1: 0.9891 - auc: 0.9989 - accuracy: 0.9891 - val_loss: 0.5790 - val_f1: 0.5501 - val_auc: 0.8532 - val_accuracy: 0.8571 - _timestamp: 1656360204.0000 - _runtime: 211.0000\n",
            "Epoch 33/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0267 - f1: 0.9915 - auc: 0.9992 - accuracy: 0.9917 - val_loss: 0.7114 - val_f1: 0.5846 - val_auc: 0.8442 - val_accuracy: 0.8732 - _timestamp: 1656360210.0000 - _runtime: 217.0000\n",
            "Epoch 34/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0271 - f1: 0.9915 - auc: 0.9992 - accuracy: 0.9916 - val_loss: 0.8023 - val_f1: 0.5329 - val_auc: 0.8248 - val_accuracy: 0.8676 - _timestamp: 1656360216.0000 - _runtime: 223.0000\n",
            "Epoch 35/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0299 - f1: 0.9889 - auc: 0.9991 - accuracy: 0.9892 - val_loss: 0.9059 - val_f1: 0.5433 - val_auc: 0.8243 - val_accuracy: 0.8643 - _timestamp: 1656360222.0000 - _runtime: 229.0000\n",
            "Epoch 36/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0294 - f1: 0.9901 - auc: 0.9990 - accuracy: 0.9904 - val_loss: 0.8795 - val_f1: 0.5626 - val_auc: 0.8214 - val_accuracy: 0.8804 - _timestamp: 1656360229.0000 - _runtime: 236.0000\n",
            "Epoch 37/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0288 - f1: 0.9896 - auc: 0.9993 - accuracy: 0.9900 - val_loss: 0.7491 - val_f1: 0.5815 - val_auc: 0.8455 - val_accuracy: 0.8665 - _timestamp: 1656360235.0000 - _runtime: 242.0000\n",
            "Epoch 38/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0282 - f1: 0.9906 - auc: 0.9990 - accuracy: 0.9909 - val_loss: 0.7148 - val_f1: 0.5782 - val_auc: 0.8451 - val_accuracy: 0.8637 - _timestamp: 1656360241.0000 - _runtime: 248.0000\n",
            "Epoch 39/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0267 - f1: 0.9905 - auc: 0.9993 - accuracy: 0.9908 - val_loss: 0.9891 - val_f1: 0.5673 - val_auc: 0.8346 - val_accuracy: 0.8498 - _timestamp: 1656360247.0000 - _runtime: 254.0000\n",
            "Epoch 40/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0263 - f1: 0.9902 - auc: 0.9994 - accuracy: 0.9906 - val_loss: 0.7815 - val_f1: 0.5726 - val_auc: 0.8423 - val_accuracy: 0.8571 - _timestamp: 1656360253.0000 - _runtime: 260.0000\n",
            "Epoch 41/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0238 - f1: 0.9923 - auc: 0.9992 - accuracy: 0.9925 - val_loss: 0.6734 - val_f1: 0.5458 - val_auc: 0.8315 - val_accuracy: 0.8665 - _timestamp: 1656360259.0000 - _runtime: 266.0000\n",
            "Epoch 42/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0207 - f1: 0.9929 - auc: 0.9996 - accuracy: 0.9932 - val_loss: 0.7732 - val_f1: 0.5267 - val_auc: 0.8289 - val_accuracy: 0.8604 - _timestamp: 1656360266.0000 - _runtime: 273.0000\n",
            "Epoch 43/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0286 - f1: 0.9916 - auc: 0.9990 - accuracy: 0.9918 - val_loss: 0.7869 - val_f1: 0.5074 - val_auc: 0.8252 - val_accuracy: 0.8687 - _timestamp: 1656360272.0000 - _runtime: 279.0000\n",
            "Epoch 44/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0219 - f1: 0.9932 - auc: 0.9993 - accuracy: 0.9933 - val_loss: 0.7503 - val_f1: 0.5105 - val_auc: 0.8219 - val_accuracy: 0.8665 - _timestamp: 1656360278.0000 - _runtime: 285.0000\n",
            "Epoch 45/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0231 - f1: 0.9916 - auc: 0.9993 - accuracy: 0.9915 - val_loss: 1.0687 - val_f1: 0.5764 - val_auc: 0.8317 - val_accuracy: 0.8582 - _timestamp: 1656360284.0000 - _runtime: 291.0000\n",
            "Epoch 46/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0228 - f1: 0.9924 - auc: 0.9993 - accuracy: 0.9927 - val_loss: 0.9651 - val_f1: 0.5802 - val_auc: 0.8343 - val_accuracy: 0.8493 - _timestamp: 1656360290.0000 - _runtime: 297.0000\n",
            "Epoch 47/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0221 - f1: 0.9930 - auc: 0.9994 - accuracy: 0.9932 - val_loss: 0.8444 - val_f1: 0.5649 - val_auc: 0.8338 - val_accuracy: 0.8554 - _timestamp: 1656360296.0000 - _runtime: 303.0000\n",
            "Epoch 48/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0192 - f1: 0.9939 - auc: 0.9994 - accuracy: 0.9942 - val_loss: 1.1862 - val_f1: 0.5732 - val_auc: 0.8263 - val_accuracy: 0.8554 - _timestamp: 1656360302.0000 - _runtime: 309.0000\n",
            "Epoch 49/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0263 - f1: 0.9911 - auc: 0.9991 - accuracy: 0.9914 - val_loss: 0.8239 - val_f1: 0.5589 - val_auc: 0.8372 - val_accuracy: 0.8604 - _timestamp: 1656360309.0000 - _runtime: 316.0000\n",
            "Epoch 50/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0204 - f1: 0.9932 - auc: 0.9995 - accuracy: 0.9933 - val_loss: 0.7987 - val_f1: 0.5083 - val_auc: 0.8063 - val_accuracy: 0.8665 - _timestamp: 1656360315.0000 - _runtime: 322.0000\n",
            "Epoch 51/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0217 - f1: 0.9925 - auc: 0.9994 - accuracy: 0.9927 - val_loss: 0.7328 - val_f1: 0.5463 - val_auc: 0.8206 - val_accuracy: 0.8687 - _timestamp: 1656360321.0000 - _runtime: 328.0000\n",
            "Epoch 52/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0187 - f1: 0.9934 - auc: 0.9994 - accuracy: 0.9937 - val_loss: 1.0137 - val_f1: 0.5181 - val_auc: 0.7912 - val_accuracy: 0.8665 - _timestamp: 1656360327.0000 - _runtime: 334.0000\n",
            "Epoch 53/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0204 - f1: 0.9937 - auc: 0.9992 - accuracy: 0.9939 - val_loss: 0.7566 - val_f1: 0.5466 - val_auc: 0.8395 - val_accuracy: 0.8543 - _timestamp: 1656360333.0000 - _runtime: 340.0000\n",
            "Epoch 54/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0201 - f1: 0.9935 - auc: 0.9994 - accuracy: 0.9937 - val_loss: 0.9483 - val_f1: 0.5692 - val_auc: 0.8225 - val_accuracy: 0.8726 - _timestamp: 1656360339.0000 - _runtime: 346.0000\n",
            "Epoch 55/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0165 - f1: 0.9944 - auc: 0.9998 - accuracy: 0.9947 - val_loss: 0.9139 - val_f1: 0.5930 - val_auc: 0.8275 - val_accuracy: 0.8760 - _timestamp: 1656360345.0000 - _runtime: 352.0000\n",
            "Epoch 56/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0220 - f1: 0.9929 - auc: 0.9990 - accuracy: 0.9932 - val_loss: 0.7602 - val_f1: 0.5321 - val_auc: 0.8266 - val_accuracy: 0.8654 - _timestamp: 1656360352.0000 - _runtime: 359.0000\n",
            "Epoch 57/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0200 - f1: 0.9935 - auc: 0.9993 - accuracy: 0.9936 - val_loss: 0.9865 - val_f1: 0.5394 - val_auc: 0.8224 - val_accuracy: 0.8615 - _timestamp: 1656360358.0000 - _runtime: 365.0000\n",
            "Epoch 58/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0256 - f1: 0.9924 - auc: 0.9991 - accuracy: 0.9925 - val_loss: 0.7488 - val_f1: 0.5891 - val_auc: 0.8512 - val_accuracy: 0.8715 - _timestamp: 1656360364.0000 - _runtime: 371.0000\n",
            "Epoch 59/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0170 - f1: 0.9942 - auc: 0.9995 - accuracy: 0.9943 - val_loss: 0.8751 - val_f1: 0.5506 - val_auc: 0.8280 - val_accuracy: 0.8760 - _timestamp: 1656360370.0000 - _runtime: 377.0000\n",
            "Epoch 60/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0184 - f1: 0.9943 - auc: 0.9994 - accuracy: 0.9946 - val_loss: 0.8833 - val_f1: 0.5610 - val_auc: 0.8427 - val_accuracy: 0.8482 - _timestamp: 1656360376.0000 - _runtime: 383.0000\n",
            "Epoch 61/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0147 - f1: 0.9949 - auc: 0.9997 - accuracy: 0.9950 - val_loss: 1.3033 - val_f1: 0.5403 - val_auc: 0.7866 - val_accuracy: 0.8749 - _timestamp: 1656360382.0000 - _runtime: 389.0000\n",
            "Epoch 62/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0153 - f1: 0.9949 - auc: 0.9998 - accuracy: 0.9951 - val_loss: 1.2683 - val_f1: 0.5310 - val_auc: 0.8044 - val_accuracy: 0.8626 - _timestamp: 1656360388.0000 - _runtime: 395.0000\n",
            "Epoch 63/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0213 - f1: 0.9933 - auc: 0.9993 - accuracy: 0.9935 - val_loss: 1.0627 - val_f1: 0.5243 - val_auc: 0.8103 - val_accuracy: 0.8643 - _timestamp: 1656360395.0000 - _runtime: 402.0000\n",
            "Epoch 64/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0166 - f1: 0.9953 - auc: 0.9992 - accuracy: 0.9953 - val_loss: 0.8526 - val_f1: 0.5676 - val_auc: 0.8506 - val_accuracy: 0.8482 - _timestamp: 1656360401.0000 - _runtime: 408.0000\n",
            "Epoch 65/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0188 - f1: 0.9942 - auc: 0.9992 - accuracy: 0.9943 - val_loss: 1.0085 - val_f1: 0.5590 - val_auc: 0.8233 - val_accuracy: 0.8693 - _timestamp: 1656360407.0000 - _runtime: 414.0000\n",
            "Epoch 66/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0191 - f1: 0.9937 - auc: 0.9994 - accuracy: 0.9941 - val_loss: 1.0414 - val_f1: 0.5276 - val_auc: 0.8084 - val_accuracy: 0.8737 - _timestamp: 1656360413.0000 - _runtime: 420.0000\n",
            "Epoch 67/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0159 - f1: 0.9948 - auc: 0.9996 - accuracy: 0.9952 - val_loss: 0.9258 - val_f1: 0.5611 - val_auc: 0.8085 - val_accuracy: 0.8732 - _timestamp: 1656360419.0000 - _runtime: 426.0000\n",
            "Epoch 68/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0175 - f1: 0.9944 - auc: 0.9994 - accuracy: 0.9946 - val_loss: 0.8831 - val_f1: 0.5333 - val_auc: 0.8201 - val_accuracy: 0.8760 - _timestamp: 1656360425.0000 - _runtime: 432.0000\n",
            "Epoch 69/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0209 - f1: 0.9941 - auc: 0.9993 - accuracy: 0.9943 - val_loss: 0.9417 - val_f1: 0.5202 - val_auc: 0.8114 - val_accuracy: 0.8621 - _timestamp: 1656360431.0000 - _runtime: 438.0000\n",
            "Epoch 70/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0174 - f1: 0.9943 - auc: 0.9995 - accuracy: 0.9946 - val_loss: 0.9318 - val_f1: 0.5459 - val_auc: 0.8184 - val_accuracy: 0.8693 - _timestamp: 1656360438.0000 - _runtime: 445.0000\n",
            "Epoch 71/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0168 - f1: 0.9950 - auc: 0.9996 - accuracy: 0.9950 - val_loss: 0.8657 - val_f1: 0.5554 - val_auc: 0.8362 - val_accuracy: 0.8604 - _timestamp: 1656360444.0000 - _runtime: 451.0000\n",
            "Epoch 72/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0136 - f1: 0.9959 - auc: 0.9996 - accuracy: 0.9960 - val_loss: 1.2063 - val_f1: 0.5128 - val_auc: 0.7884 - val_accuracy: 0.8721 - _timestamp: 1656360450.0000 - _runtime: 457.0000\n",
            "Epoch 73/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0182 - f1: 0.9946 - auc: 0.9992 - accuracy: 0.9946 - val_loss: 0.8651 - val_f1: 0.5745 - val_auc: 0.8553 - val_accuracy: 0.8537 - _timestamp: 1656360456.0000 - _runtime: 463.0000\n",
            "Epoch 74/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0170 - f1: 0.9950 - auc: 0.9995 - accuracy: 0.9952 - val_loss: 0.8103 - val_f1: 0.5653 - val_auc: 0.8340 - val_accuracy: 0.8693 - _timestamp: 1656360462.0000 - _runtime: 469.0000\n",
            "Epoch 75/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0171 - f1: 0.9939 - auc: 0.9997 - accuracy: 0.9937 - val_loss: 1.1693 - val_f1: 0.5626 - val_auc: 0.8287 - val_accuracy: 0.8615 - _timestamp: 1656360468.0000 - _runtime: 475.0000\n",
            "Epoch 76/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0173 - f1: 0.9955 - auc: 0.9995 - accuracy: 0.9956 - val_loss: 1.1463 - val_f1: 0.5562 - val_auc: 0.8283 - val_accuracy: 0.8593 - _timestamp: 1656360474.0000 - _runtime: 481.0000\n",
            "Epoch 77/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0168 - f1: 0.9951 - auc: 0.9997 - accuracy: 0.9950 - val_loss: 1.0000 - val_f1: 0.5676 - val_auc: 0.8295 - val_accuracy: 0.8632 - _timestamp: 1656360481.0000 - _runtime: 488.0000\n",
            "Epoch 78/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0167 - f1: 0.9945 - auc: 0.9998 - accuracy: 0.9947 - val_loss: 0.9433 - val_f1: 0.5305 - val_auc: 0.8137 - val_accuracy: 0.8610 - _timestamp: 1656360487.0000 - _runtime: 494.0000\n",
            "Epoch 79/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0148 - f1: 0.9957 - auc: 0.9997 - accuracy: 0.9958 - val_loss: 1.0585 - val_f1: 0.5367 - val_auc: 0.8039 - val_accuracy: 0.8643 - _timestamp: 1656360493.0000 - _runtime: 500.0000\n",
            "Epoch 80/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0159 - f1: 0.9952 - auc: 0.9995 - accuracy: 0.9956 - val_loss: 1.1461 - val_f1: 0.5167 - val_auc: 0.8025 - val_accuracy: 0.8610 - _timestamp: 1656360499.0000 - _runtime: 506.0000\n",
            "Epoch 81/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0125 - f1: 0.9965 - auc: 0.9996 - accuracy: 0.9965 - val_loss: 1.2188 - val_f1: 0.5447 - val_auc: 0.8169 - val_accuracy: 0.8626 - _timestamp: 1656360505.0000 - _runtime: 512.0000\n",
            "Epoch 82/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0177 - f1: 0.9949 - auc: 0.9992 - accuracy: 0.9951 - val_loss: 0.8471 - val_f1: 0.5566 - val_auc: 0.8313 - val_accuracy: 0.8554 - _timestamp: 1656360511.0000 - _runtime: 518.0000\n",
            "Epoch 83/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0172 - f1: 0.9953 - auc: 0.9994 - accuracy: 0.9953 - val_loss: 0.7424 - val_f1: 0.5489 - val_auc: 0.8330 - val_accuracy: 0.8543 - _timestamp: 1656360517.0000 - _runtime: 524.0000\n",
            "Epoch 84/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0153 - f1: 0.9955 - auc: 0.9996 - accuracy: 0.9956 - val_loss: 0.8432 - val_f1: 0.5416 - val_auc: 0.8208 - val_accuracy: 0.8654 - _timestamp: 1656360523.0000 - _runtime: 530.0000\n",
            "Epoch 85/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0139 - f1: 0.9967 - auc: 0.9994 - accuracy: 0.9966 - val_loss: 0.9597 - val_f1: 0.5294 - val_auc: 0.8190 - val_accuracy: 0.8682 - _timestamp: 1656360530.0000 - _runtime: 537.0000\n",
            "Epoch 86/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0179 - f1: 0.9952 - auc: 0.9996 - accuracy: 0.9955 - val_loss: 0.9144 - val_f1: 0.5467 - val_auc: 0.8270 - val_accuracy: 0.8699 - _timestamp: 1656360536.0000 - _runtime: 543.0000\n",
            "Epoch 87/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0166 - f1: 0.9951 - auc: 0.9996 - accuracy: 0.9952 - val_loss: 0.9930 - val_f1: 0.5435 - val_auc: 0.8198 - val_accuracy: 0.8621 - _timestamp: 1656360542.0000 - _runtime: 549.0000\n",
            "Epoch 88/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0115 - f1: 0.9972 - auc: 0.9996 - accuracy: 0.9974 - val_loss: 1.3195 - val_f1: 0.4903 - val_auc: 0.7825 - val_accuracy: 0.8648 - _timestamp: 1656360548.0000 - _runtime: 555.0000\n",
            "Epoch 89/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0128 - f1: 0.9968 - auc: 0.9997 - accuracy: 0.9969 - val_loss: 1.2226 - val_f1: 0.4985 - val_auc: 0.7861 - val_accuracy: 0.8626 - _timestamp: 1656360554.0000 - _runtime: 561.0000\n",
            "Epoch 90/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0176 - f1: 0.9943 - auc: 0.9993 - accuracy: 0.9946 - val_loss: 1.0106 - val_f1: 0.4914 - val_auc: 0.7934 - val_accuracy: 0.8660 - _timestamp: 1656360560.0000 - _runtime: 567.0000\n",
            "Epoch 91/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0155 - f1: 0.9952 - auc: 0.9997 - accuracy: 0.9953 - val_loss: 1.2266 - val_f1: 0.5494 - val_auc: 0.8222 - val_accuracy: 0.8610 - _timestamp: 1656360567.0000 - _runtime: 574.0000\n",
            "Epoch 92/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0139 - f1: 0.9959 - auc: 0.9997 - accuracy: 0.9960 - val_loss: 0.9973 - val_f1: 0.5476 - val_auc: 0.8282 - val_accuracy: 0.8560 - _timestamp: 1656360573.0000 - _runtime: 580.0000\n",
            "Epoch 93/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0135 - f1: 0.9961 - auc: 0.9995 - accuracy: 0.9960 - val_loss: 1.0223 - val_f1: 0.5581 - val_auc: 0.8194 - val_accuracy: 0.8699 - _timestamp: 1656360579.0000 - _runtime: 586.0000\n",
            "Epoch 94/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0174 - f1: 0.9949 - auc: 0.9995 - accuracy: 0.9953 - val_loss: 0.9169 - val_f1: 0.5504 - val_auc: 0.8408 - val_accuracy: 0.8610 - _timestamp: 1656360585.0000 - _runtime: 592.0000\n",
            "Epoch 95/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0157 - f1: 0.9944 - auc: 0.9996 - accuracy: 0.9946 - val_loss: 0.8425 - val_f1: 0.5328 - val_auc: 0.8363 - val_accuracy: 0.8699 - _timestamp: 1656360591.0000 - _runtime: 598.0000\n",
            "Epoch 96/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0147 - f1: 0.9959 - auc: 0.9996 - accuracy: 0.9959 - val_loss: 0.9580 - val_f1: 0.5018 - val_auc: 0.8206 - val_accuracy: 0.8676 - _timestamp: 1656360597.0000 - _runtime: 604.0000\n",
            "Epoch 97/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0108 - f1: 0.9965 - auc: 0.9998 - accuracy: 0.9968 - val_loss: 1.0932 - val_f1: 0.5598 - val_auc: 0.8200 - val_accuracy: 0.8699 - _timestamp: 1656360603.0000 - _runtime: 610.0000\n",
            "Epoch 98/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0114 - f1: 0.9962 - auc: 0.9997 - accuracy: 0.9962 - val_loss: 1.1115 - val_f1: 0.5701 - val_auc: 0.8277 - val_accuracy: 0.8637 - _timestamp: 1656360610.0000 - _runtime: 617.0000\n",
            "Epoch 99/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0130 - f1: 0.9963 - auc: 0.9998 - accuracy: 0.9964 - val_loss: 0.9236 - val_f1: 0.5298 - val_auc: 0.8255 - val_accuracy: 0.8604 - _timestamp: 1656360616.0000 - _runtime: 623.0000\n",
            "Epoch 100/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.0128 - f1: 0.9961 - auc: 0.9996 - accuracy: 0.9961 - val_loss: 1.0363 - val_f1: 0.5619 - val_auc: 0.8298 - val_accuracy: 0.8560 - _timestamp: 1656360622.0000 - _runtime: 629.0000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50e11e8588b54904853d446c2b47f0f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='333.950 MB of 333.950 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▆▆▇▇▇▇▇█▇▇████████████████████████████</td></tr><tr><td>auc</td><td>▁▆▇█████████████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1</td><td>▁▅▆▆▇▇▇▇▇█▇█████████████████████████████</td></tr><tr><td>loss</td><td>█▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▂▄▁█▄▅▆▄▃▅▄▆▅▅█▂▅▅▂▄▆▆▅▇▇▂▇▄▆▆▅▅▃▅▄▄▃▄▆▃</td></tr><tr><td>val_auc</td><td>▇██▆▇▇▅▄▆▄▄▅▄▄▃▄▄▃▄▅▃▄▄▄▁▅▃▃▁▄▄▂▄▃▃▁▄▅▃▄</td></tr><tr><td>val_f1</td><td>▄▄█▇█▇▅▁▇▃▃▃▃▃▆▆▄▂▇▅▄▆▃▅▄▆▅▃▂▆▆▄▅▄▄▁▄▅▅▅</td></tr><tr><td>val_loss</td><td>▁▁▁▂▂▂▃▃▃▄▄▃▄▄▅▆▃▄▆▅▄▅▄▅█▅▅▅▇▄▆▆▅▅▆▇▆▅▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.99613</td></tr><tr><td>auc</td><td>0.99962</td></tr><tr><td>best_epoch</td><td>4</td></tr><tr><td>best_val_loss</td><td>0.3225</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>f1</td><td>0.99609</td></tr><tr><td>loss</td><td>0.01277</td></tr><tr><td>val_accuracy</td><td>0.85595</td></tr><tr><td>val_auc</td><td>0.82976</td></tr><tr><td>val_f1</td><td>0.56186</td></tr><tr><td>val_loss</td><td>1.03626</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">atomic-sweep-8</strong>: <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/bg5mpyb0\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/runs/bg5mpyb0</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220627_195953-bg5mpyb0/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tvx4pdz9 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: elu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_value: 0.3333675390626839\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-06\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons: 3500\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptomizer: nadam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_factor: 1e-07\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_type: l2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.19"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220627_201100-tvx4pdz9</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/tvx4pdz9\" target=\"_blank\">proud-sweep-9</a></strong> to <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 25008)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3500)              87531500  \n",
            "                                                                 \n",
            " activation (Activation)     (None, 3500)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 3500)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3500)              12253500  \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 3500)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 3500)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3500)              12253500  \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 3500)              0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 3500)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3500)              12253500  \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 3500)              0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 3500)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 3500)              12253500  \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 3500)              0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 3500)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 3501      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 136,549,001\n",
            "Trainable params: 136,549,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "  5/380 [..............................] - ETA: 16s - loss: 0.7238 - f1: 0.5326 - auc: 0.8347 - accuracy: 0.5188WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0159s vs `on_train_batch_end` time: 0.0274s). Check your callbacks.\n",
            "380/380 [==============================] - 26s 62ms/step - loss: 0.5637 - f1: 0.7434 - auc: 0.8187 - accuracy: 0.7304 - val_loss: 0.5026 - val_f1: 0.4939 - val_auc: 0.8675 - val_accuracy: 0.7414 - _timestamp: 1656360685.0000 - _runtime: 25.0000\n",
            "Epoch 2/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 0.4063 - f1: 0.8457 - auc: 0.9093 - accuracy: 0.8428 - val_loss: 0.4158 - val_f1: 0.5177 - val_auc: 0.8615 - val_accuracy: 0.7914 - _timestamp: 1656360708.0000 - _runtime: 48.0000\n",
            "Epoch 3/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 0.3342 - f1: 0.8644 - auc: 0.9355 - accuracy: 0.8638 - val_loss: 0.4093 - val_f1: 0.5168 - val_auc: 0.8594 - val_accuracy: 0.7992 - _timestamp: 1656360732.0000 - _runtime: 72.0000\n",
            "Epoch 4/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 0.2967 - f1: 0.8800 - auc: 0.9484 - accuracy: 0.8807 - val_loss: 0.3796 - val_f1: 0.5236 - val_auc: 0.8552 - val_accuracy: 0.8259 - _timestamp: 1656360754.0000 - _runtime: 94.0000\n",
            "Epoch 5/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.2693 - f1: 0.8920 - auc: 0.9569 - accuracy: 0.8938 - val_loss: 0.3821 - val_f1: 0.5278 - val_auc: 0.8594 - val_accuracy: 0.8298 - _timestamp: 1656360776.0000 - _runtime: 116.0000\n",
            "Epoch 6/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 0.2509 - f1: 0.8972 - auc: 0.9624 - accuracy: 0.8990 - val_loss: 0.3771 - val_f1: 0.5268 - val_auc: 0.8594 - val_accuracy: 0.8326 - _timestamp: 1656360793.0000 - _runtime: 133.0000\n",
            "Epoch 7/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 0.2412 - f1: 0.9049 - auc: 0.9648 - accuracy: 0.9069 - val_loss: 0.3729 - val_f1: 0.5195 - val_auc: 0.8628 - val_accuracy: 0.8348 - _timestamp: 1656360817.0000 - _runtime: 157.0000\n",
            "Epoch 8/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.2369 - f1: 0.9043 - auc: 0.9663 - accuracy: 0.9057 - val_loss: 0.3737 - val_f1: 0.5319 - val_auc: 0.8644 - val_accuracy: 0.8393 - _timestamp: 1656360839.0000 - _runtime: 179.0000\n",
            "Epoch 9/100\n",
            "380/380 [==============================] - 24s 63ms/step - loss: 0.2236 - f1: 0.9096 - auc: 0.9697 - accuracy: 0.9113 - val_loss: 0.3704 - val_f1: 0.5131 - val_auc: 0.8609 - val_accuracy: 0.8432 - _timestamp: 1656360857.0000 - _runtime: 197.0000\n",
            "Epoch 10/100\n",
            "380/380 [==============================] - 24s 62ms/step - loss: 0.2163 - f1: 0.9149 - auc: 0.9716 - accuracy: 0.9167 - val_loss: 0.3640 - val_f1: 0.5349 - val_auc: 0.8636 - val_accuracy: 0.8526 - _timestamp: 1656360881.0000 - _runtime: 221.0000\n",
            "Epoch 11/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.2153 - f1: 0.9128 - auc: 0.9718 - accuracy: 0.9154 - val_loss: 0.3707 - val_f1: 0.5306 - val_auc: 0.8633 - val_accuracy: 0.8504 - _timestamp: 1656360904.0000 - _runtime: 244.0000\n",
            "Epoch 12/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.2067 - f1: 0.9194 - auc: 0.9740 - accuracy: 0.9210 - val_loss: 0.3645 - val_f1: 0.5417 - val_auc: 0.8632 - val_accuracy: 0.8582 - _timestamp: 1656360922.0000 - _runtime: 262.0000\n",
            "Epoch 13/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.2036 - f1: 0.9156 - auc: 0.9749 - accuracy: 0.9176 - val_loss: 0.3660 - val_f1: 0.5420 - val_auc: 0.8643 - val_accuracy: 0.8604 - _timestamp: 1656360939.0000 - _runtime: 279.0000\n",
            "Epoch 14/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1950 - f1: 0.9221 - auc: 0.9769 - accuracy: 0.9244 - val_loss: 0.3725 - val_f1: 0.5549 - val_auc: 0.8677 - val_accuracy: 0.8560 - _timestamp: 1656360956.0000 - _runtime: 296.0000\n",
            "Epoch 15/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1988 - f1: 0.9193 - auc: 0.9759 - accuracy: 0.9215 - val_loss: 0.3662 - val_f1: 0.5411 - val_auc: 0.8638 - val_accuracy: 0.8621 - _timestamp: 1656360973.0000 - _runtime: 313.0000\n",
            "Epoch 16/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1895 - f1: 0.9233 - auc: 0.9781 - accuracy: 0.9251 - val_loss: 0.3691 - val_f1: 0.5445 - val_auc: 0.8655 - val_accuracy: 0.8626 - _timestamp: 1656360991.0000 - _runtime: 331.0000\n",
            "Epoch 17/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 0.1920 - f1: 0.9241 - auc: 0.9775 - accuracy: 0.9255 - val_loss: 0.3705 - val_f1: 0.5410 - val_auc: 0.8647 - val_accuracy: 0.8621 - _timestamp: 1656361008.0000 - _runtime: 348.0000\n",
            "Epoch 18/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1792 - f1: 0.9295 - auc: 0.9806 - accuracy: 0.9315 - val_loss: 0.3720 - val_f1: 0.5465 - val_auc: 0.8648 - val_accuracy: 0.8632 - _timestamp: 1656361025.0000 - _runtime: 365.0000\n",
            "Epoch 19/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1758 - f1: 0.9288 - auc: 0.9814 - accuracy: 0.9308 - val_loss: 0.3705 - val_f1: 0.5403 - val_auc: 0.8645 - val_accuracy: 0.8637 - _timestamp: 1656361043.0000 - _runtime: 383.0000\n",
            "Epoch 20/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 0.1809 - f1: 0.9265 - auc: 0.9802 - accuracy: 0.9283 - val_loss: 0.3754 - val_f1: 0.5442 - val_auc: 0.8645 - val_accuracy: 0.8621 - _timestamp: 1656361060.0000 - _runtime: 400.0000\n",
            "Epoch 21/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 0.1758 - f1: 0.9312 - auc: 0.9810 - accuracy: 0.9336 - val_loss: 0.3744 - val_f1: 0.5494 - val_auc: 0.8647 - val_accuracy: 0.8654 - _timestamp: 1656361077.0000 - _runtime: 417.0000\n",
            "Epoch 22/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1691 - f1: 0.9315 - auc: 0.9825 - accuracy: 0.9335 - val_loss: 0.3784 - val_f1: 0.5646 - val_auc: 0.8686 - val_accuracy: 0.8604 - _timestamp: 1656361095.0000 - _runtime: 435.0000\n",
            "Epoch 23/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1708 - f1: 0.9306 - auc: 0.9824 - accuracy: 0.9331 - val_loss: 0.3798 - val_f1: 0.5461 - val_auc: 0.8634 - val_accuracy: 0.8654 - _timestamp: 1656361112.0000 - _runtime: 452.0000\n",
            "Epoch 24/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1638 - f1: 0.9337 - auc: 0.9837 - accuracy: 0.9353 - val_loss: 0.3794 - val_f1: 0.5542 - val_auc: 0.8639 - val_accuracy: 0.8671 - _timestamp: 1656361129.0000 - _runtime: 469.0000\n",
            "Epoch 25/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1636 - f1: 0.9349 - auc: 0.9838 - accuracy: 0.9371 - val_loss: 0.3846 - val_f1: 0.5645 - val_auc: 0.8658 - val_accuracy: 0.8637 - _timestamp: 1656361146.0000 - _runtime: 486.0000\n",
            "Epoch 26/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1628 - f1: 0.9386 - auc: 0.9837 - accuracy: 0.9401 - val_loss: 0.3840 - val_f1: 0.5628 - val_auc: 0.8636 - val_accuracy: 0.8687 - _timestamp: 1656361164.0000 - _runtime: 504.0000\n",
            "Epoch 27/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1604 - f1: 0.9363 - auc: 0.9840 - accuracy: 0.9383 - val_loss: 0.3845 - val_f1: 0.5677 - val_auc: 0.8629 - val_accuracy: 0.8704 - _timestamp: 1656361181.0000 - _runtime: 521.0000\n",
            "Epoch 28/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1578 - f1: 0.9376 - auc: 0.9848 - accuracy: 0.9393 - val_loss: 0.3879 - val_f1: 0.5517 - val_auc: 0.8611 - val_accuracy: 0.8699 - _timestamp: 1656361198.0000 - _runtime: 538.0000\n",
            "Epoch 29/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1539 - f1: 0.9388 - auc: 0.9856 - accuracy: 0.9401 - val_loss: 0.3922 - val_f1: 0.5674 - val_auc: 0.8626 - val_accuracy: 0.8660 - _timestamp: 1656361216.0000 - _runtime: 556.0000\n",
            "Epoch 30/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1551 - f1: 0.9396 - auc: 0.9852 - accuracy: 0.9419 - val_loss: 0.3910 - val_f1: 0.5666 - val_auc: 0.8612 - val_accuracy: 0.8704 - _timestamp: 1656361233.0000 - _runtime: 573.0000\n",
            "Epoch 31/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1500 - f1: 0.9406 - auc: 0.9862 - accuracy: 0.9415 - val_loss: 0.3956 - val_f1: 0.5702 - val_auc: 0.8613 - val_accuracy: 0.8699 - _timestamp: 1656361250.0000 - _runtime: 590.0000\n",
            "Epoch 32/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 0.1476 - f1: 0.9415 - auc: 0.9866 - accuracy: 0.9436 - val_loss: 0.4012 - val_f1: 0.5668 - val_auc: 0.8621 - val_accuracy: 0.8676 - _timestamp: 1656361268.0000 - _runtime: 608.0000\n",
            "Epoch 33/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1483 - f1: 0.9430 - auc: 0.9865 - accuracy: 0.9443 - val_loss: 0.4005 - val_f1: 0.5661 - val_auc: 0.8621 - val_accuracy: 0.8665 - _timestamp: 1656361285.0000 - _runtime: 625.0000\n",
            "Epoch 34/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1427 - f1: 0.9444 - auc: 0.9874 - accuracy: 0.9462 - val_loss: 0.3992 - val_f1: 0.5674 - val_auc: 0.8620 - val_accuracy: 0.8721 - _timestamp: 1656361302.0000 - _runtime: 642.0000\n",
            "Epoch 35/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1427 - f1: 0.9429 - auc: 0.9875 - accuracy: 0.9449 - val_loss: 0.4016 - val_f1: 0.5690 - val_auc: 0.8651 - val_accuracy: 0.8654 - _timestamp: 1656361320.0000 - _runtime: 660.0000\n",
            "Epoch 36/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1408 - f1: 0.9441 - auc: 0.9877 - accuracy: 0.9462 - val_loss: 0.4098 - val_f1: 0.5680 - val_auc: 0.8631 - val_accuracy: 0.8648 - _timestamp: 1656361337.0000 - _runtime: 677.0000\n",
            "Epoch 37/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1382 - f1: 0.9463 - auc: 0.9883 - accuracy: 0.9481 - val_loss: 0.4111 - val_f1: 0.5722 - val_auc: 0.8590 - val_accuracy: 0.8715 - _timestamp: 1656361354.0000 - _runtime: 694.0000\n",
            "Epoch 38/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1347 - f1: 0.9464 - auc: 0.9888 - accuracy: 0.9483 - val_loss: 0.4143 - val_f1: 0.5701 - val_auc: 0.8637 - val_accuracy: 0.8665 - _timestamp: 1656361372.0000 - _runtime: 712.0000\n",
            "Epoch 39/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1330 - f1: 0.9486 - auc: 0.9890 - accuracy: 0.9502 - val_loss: 0.4157 - val_f1: 0.5696 - val_auc: 0.8592 - val_accuracy: 0.8704 - _timestamp: 1656361389.0000 - _runtime: 729.0000\n",
            "Epoch 40/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1323 - f1: 0.9493 - auc: 0.9891 - accuracy: 0.9499 - val_loss: 0.4225 - val_f1: 0.5614 - val_auc: 0.8514 - val_accuracy: 0.8743 - _timestamp: 1656361407.0000 - _runtime: 747.0000\n",
            "Epoch 41/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1267 - f1: 0.9531 - auc: 0.9899 - accuracy: 0.9542 - val_loss: 0.4247 - val_f1: 0.5760 - val_auc: 0.8554 - val_accuracy: 0.8749 - _timestamp: 1656361424.0000 - _runtime: 764.0000\n",
            "Epoch 42/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 0.1312 - f1: 0.9496 - auc: 0.9891 - accuracy: 0.9509 - val_loss: 0.4247 - val_f1: 0.5735 - val_auc: 0.8568 - val_accuracy: 0.8726 - _timestamp: 1656361441.0000 - _runtime: 781.0000\n",
            "Epoch 43/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1260 - f1: 0.9514 - auc: 0.9900 - accuracy: 0.9527 - val_loss: 0.4320 - val_f1: 0.5756 - val_auc: 0.8588 - val_accuracy: 0.8687 - _timestamp: 1656361459.0000 - _runtime: 799.0000\n",
            "Epoch 44/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1215 - f1: 0.9527 - auc: 0.9908 - accuracy: 0.9536 - val_loss: 0.4357 - val_f1: 0.5691 - val_auc: 0.8533 - val_accuracy: 0.8693 - _timestamp: 1656361476.0000 - _runtime: 816.0000\n",
            "Epoch 45/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1284 - f1: 0.9492 - auc: 0.9896 - accuracy: 0.9499 - val_loss: 0.4351 - val_f1: 0.5783 - val_auc: 0.8509 - val_accuracy: 0.8737 - _timestamp: 1656361493.0000 - _runtime: 833.0000\n",
            "Epoch 46/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1309 - f1: 0.9495 - auc: 0.9893 - accuracy: 0.9512 - val_loss: 0.4365 - val_f1: 0.5761 - val_auc: 0.8511 - val_accuracy: 0.8732 - _timestamp: 1656361511.0000 - _runtime: 851.0000\n",
            "Epoch 47/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1234 - f1: 0.9529 - auc: 0.9904 - accuracy: 0.9540 - val_loss: 0.4361 - val_f1: 0.5842 - val_auc: 0.8515 - val_accuracy: 0.8793 - _timestamp: 1656361528.0000 - _runtime: 868.0000\n",
            "Epoch 48/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1231 - f1: 0.9508 - auc: 0.9905 - accuracy: 0.9526 - val_loss: 0.4394 - val_f1: 0.5771 - val_auc: 0.8521 - val_accuracy: 0.8704 - _timestamp: 1656361545.0000 - _runtime: 885.0000\n",
            "Epoch 49/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1190 - f1: 0.9538 - auc: 0.9911 - accuracy: 0.9553 - val_loss: 0.4450 - val_f1: 0.5765 - val_auc: 0.8502 - val_accuracy: 0.8737 - _timestamp: 1656361563.0000 - _runtime: 903.0000\n",
            "Epoch 50/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1246 - f1: 0.9522 - auc: 0.9903 - accuracy: 0.9531 - val_loss: 0.4426 - val_f1: 0.5783 - val_auc: 0.8493 - val_accuracy: 0.8771 - _timestamp: 1656361580.0000 - _runtime: 920.0000\n",
            "Epoch 51/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1156 - f1: 0.9562 - auc: 0.9917 - accuracy: 0.9573 - val_loss: 0.4509 - val_f1: 0.5848 - val_auc: 0.8513 - val_accuracy: 0.8715 - _timestamp: 1656361597.0000 - _runtime: 937.0000\n",
            "Epoch 52/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1140 - f1: 0.9563 - auc: 0.9916 - accuracy: 0.9575 - val_loss: 0.4488 - val_f1: 0.5823 - val_auc: 0.8522 - val_accuracy: 0.8732 - _timestamp: 1656361614.0000 - _runtime: 954.0000\n",
            "Epoch 53/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1177 - f1: 0.9536 - auc: 0.9913 - accuracy: 0.9546 - val_loss: 0.4535 - val_f1: 0.5735 - val_auc: 0.8540 - val_accuracy: 0.8682 - _timestamp: 1656361632.0000 - _runtime: 972.0000\n",
            "Epoch 54/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1103 - f1: 0.9573 - auc: 0.9923 - accuracy: 0.9583 - val_loss: 0.4580 - val_f1: 0.5777 - val_auc: 0.8514 - val_accuracy: 0.8699 - _timestamp: 1656361649.0000 - _runtime: 989.0000\n",
            "Epoch 55/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1139 - f1: 0.9569 - auc: 0.9918 - accuracy: 0.9573 - val_loss: 0.4629 - val_f1: 0.5777 - val_auc: 0.8455 - val_accuracy: 0.8799 - _timestamp: 1656361666.0000 - _runtime: 1006.0000\n",
            "Epoch 56/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1077 - f1: 0.9580 - auc: 0.9927 - accuracy: 0.9587 - val_loss: 0.4659 - val_f1: 0.5775 - val_auc: 0.8477 - val_accuracy: 0.8682 - _timestamp: 1656361684.0000 - _runtime: 1024.0000\n",
            "Epoch 57/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1101 - f1: 0.9590 - auc: 0.9924 - accuracy: 0.9597 - val_loss: 0.4722 - val_f1: 0.5768 - val_auc: 0.8505 - val_accuracy: 0.8626 - _timestamp: 1656361701.0000 - _runtime: 1041.0000\n",
            "Epoch 58/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1080 - f1: 0.9593 - auc: 0.9925 - accuracy: 0.9600 - val_loss: 0.4735 - val_f1: 0.5890 - val_auc: 0.8475 - val_accuracy: 0.8721 - _timestamp: 1656361718.0000 - _runtime: 1058.0000\n",
            "Epoch 59/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1085 - f1: 0.9584 - auc: 0.9925 - accuracy: 0.9595 - val_loss: 0.4738 - val_f1: 0.5921 - val_auc: 0.8457 - val_accuracy: 0.8804 - _timestamp: 1656361736.0000 - _runtime: 1076.0000\n",
            "Epoch 60/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1072 - f1: 0.9602 - auc: 0.9928 - accuracy: 0.9611 - val_loss: 0.4743 - val_f1: 0.5811 - val_auc: 0.8458 - val_accuracy: 0.8793 - _timestamp: 1656361753.0000 - _runtime: 1093.0000\n",
            "Epoch 61/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1076 - f1: 0.9581 - auc: 0.9925 - accuracy: 0.9597 - val_loss: 0.4761 - val_f1: 0.5742 - val_auc: 0.8492 - val_accuracy: 0.8715 - _timestamp: 1656361770.0000 - _runtime: 1110.0000\n",
            "Epoch 62/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1018 - f1: 0.9605 - auc: 0.9935 - accuracy: 0.9620 - val_loss: 0.4868 - val_f1: 0.5789 - val_auc: 0.8449 - val_accuracy: 0.8726 - _timestamp: 1656361788.0000 - _runtime: 1128.0000\n",
            "Epoch 63/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1030 - f1: 0.9611 - auc: 0.9930 - accuracy: 0.9617 - val_loss: 0.4875 - val_f1: 0.5776 - val_auc: 0.8463 - val_accuracy: 0.8676 - _timestamp: 1656361805.0000 - _runtime: 1145.0000\n",
            "Epoch 64/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1018 - f1: 0.9610 - auc: 0.9933 - accuracy: 0.9622 - val_loss: 0.4915 - val_f1: 0.5758 - val_auc: 0.8474 - val_accuracy: 0.8687 - _timestamp: 1656361822.0000 - _runtime: 1162.0000\n",
            "Epoch 65/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1006 - f1: 0.9614 - auc: 0.9935 - accuracy: 0.9627 - val_loss: 0.4986 - val_f1: 0.5777 - val_auc: 0.8363 - val_accuracy: 0.8776 - _timestamp: 1656361840.0000 - _runtime: 1180.0000\n",
            "Epoch 66/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1000 - f1: 0.9634 - auc: 0.9933 - accuracy: 0.9640 - val_loss: 0.4985 - val_f1: 0.5769 - val_auc: 0.8443 - val_accuracy: 0.8732 - _timestamp: 1656361857.0000 - _runtime: 1197.0000\n",
            "Epoch 67/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0947 - f1: 0.9644 - auc: 0.9941 - accuracy: 0.9655 - val_loss: 0.5033 - val_f1: 0.5820 - val_auc: 0.8437 - val_accuracy: 0.8715 - _timestamp: 1656361874.0000 - _runtime: 1214.0000\n",
            "Epoch 68/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0946 - f1: 0.9647 - auc: 0.9943 - accuracy: 0.9651 - val_loss: 0.5046 - val_f1: 0.5838 - val_auc: 0.8450 - val_accuracy: 0.8704 - _timestamp: 1656361892.0000 - _runtime: 1232.0000\n",
            "Epoch 69/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0973 - f1: 0.9622 - auc: 0.9942 - accuracy: 0.9634 - val_loss: 0.5056 - val_f1: 0.5842 - val_auc: 0.8371 - val_accuracy: 0.8771 - _timestamp: 1656361909.0000 - _runtime: 1249.0000\n",
            "Epoch 70/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0925 - f1: 0.9649 - auc: 0.9945 - accuracy: 0.9660 - val_loss: 0.5206 - val_f1: 0.5708 - val_auc: 0.8340 - val_accuracy: 0.8776 - _timestamp: 1656361926.0000 - _runtime: 1266.0000\n",
            "Epoch 71/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.1009 - f1: 0.9599 - auc: 0.9934 - accuracy: 0.9613 - val_loss: 0.5159 - val_f1: 0.5671 - val_auc: 0.8428 - val_accuracy: 0.8665 - _timestamp: 1656361944.0000 - _runtime: 1284.0000\n",
            "Epoch 72/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0914 - f1: 0.9642 - auc: 0.9948 - accuracy: 0.9653 - val_loss: 0.5243 - val_f1: 0.5786 - val_auc: 0.8366 - val_accuracy: 0.8721 - _timestamp: 1656361961.0000 - _runtime: 1301.0000\n",
            "Epoch 73/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0932 - f1: 0.9635 - auc: 0.9944 - accuracy: 0.9651 - val_loss: 0.5228 - val_f1: 0.5689 - val_auc: 0.8360 - val_accuracy: 0.8693 - _timestamp: 1656361978.0000 - _runtime: 1318.0000\n",
            "Epoch 74/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0969 - f1: 0.9620 - auc: 0.9938 - accuracy: 0.9637 - val_loss: 0.5252 - val_f1: 0.5636 - val_auc: 0.8362 - val_accuracy: 0.8699 - _timestamp: 1656361996.0000 - _runtime: 1336.0000\n",
            "Epoch 75/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0961 - f1: 0.9619 - auc: 0.9942 - accuracy: 0.9631 - val_loss: 0.5332 - val_f1: 0.5593 - val_auc: 0.8346 - val_accuracy: 0.8682 - _timestamp: 1656362013.0000 - _runtime: 1353.0000\n",
            "Epoch 76/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0900 - f1: 0.9638 - auc: 0.9951 - accuracy: 0.9653 - val_loss: 0.5380 - val_f1: 0.5707 - val_auc: 0.8346 - val_accuracy: 0.8687 - _timestamp: 1656362030.0000 - _runtime: 1370.0000\n",
            "Epoch 77/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0904 - f1: 0.9656 - auc: 0.9947 - accuracy: 0.9668 - val_loss: 0.5414 - val_f1: 0.5720 - val_auc: 0.8349 - val_accuracy: 0.8737 - _timestamp: 1656362048.0000 - _runtime: 1388.0000\n",
            "Epoch 78/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0898 - f1: 0.9657 - auc: 0.9948 - accuracy: 0.9664 - val_loss: 0.5445 - val_f1: 0.5773 - val_auc: 0.8348 - val_accuracy: 0.8687 - _timestamp: 1656362065.0000 - _runtime: 1405.0000\n",
            "Epoch 79/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0887 - f1: 0.9654 - auc: 0.9947 - accuracy: 0.9661 - val_loss: 0.5425 - val_f1: 0.5683 - val_auc: 0.8339 - val_accuracy: 0.8682 - _timestamp: 1656362082.0000 - _runtime: 1422.0000\n",
            "Epoch 80/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0932 - f1: 0.9634 - auc: 0.9946 - accuracy: 0.9650 - val_loss: 0.5448 - val_f1: 0.5595 - val_auc: 0.8336 - val_accuracy: 0.8710 - _timestamp: 1656362100.0000 - _runtime: 1440.0000\n",
            "Epoch 81/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0908 - f1: 0.9674 - auc: 0.9945 - accuracy: 0.9685 - val_loss: 0.5447 - val_f1: 0.5699 - val_auc: 0.8348 - val_accuracy: 0.8682 - _timestamp: 1656362117.0000 - _runtime: 1457.0000\n",
            "Epoch 82/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0884 - f1: 0.9662 - auc: 0.9948 - accuracy: 0.9672 - val_loss: 0.5487 - val_f1: 0.5742 - val_auc: 0.8406 - val_accuracy: 0.8654 - _timestamp: 1656362134.0000 - _runtime: 1474.0000\n",
            "Epoch 83/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0851 - f1: 0.9677 - auc: 0.9952 - accuracy: 0.9690 - val_loss: 0.5590 - val_f1: 0.5550 - val_auc: 0.8281 - val_accuracy: 0.8710 - _timestamp: 1656362152.0000 - _runtime: 1492.0000\n",
            "Epoch 84/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0872 - f1: 0.9664 - auc: 0.9952 - accuracy: 0.9671 - val_loss: 0.5510 - val_f1: 0.5814 - val_auc: 0.8377 - val_accuracy: 0.8715 - _timestamp: 1656362169.0000 - _runtime: 1509.0000\n",
            "Epoch 85/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0865 - f1: 0.9667 - auc: 0.9952 - accuracy: 0.9677 - val_loss: 0.5536 - val_f1: 0.5774 - val_auc: 0.8351 - val_accuracy: 0.8704 - _timestamp: 1656362186.0000 - _runtime: 1526.0000\n",
            "Epoch 86/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0822 - f1: 0.9694 - auc: 0.9956 - accuracy: 0.9703 - val_loss: 0.5556 - val_f1: 0.5753 - val_auc: 0.8323 - val_accuracy: 0.8710 - _timestamp: 1656362204.0000 - _runtime: 1544.0000\n",
            "Epoch 87/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0872 - f1: 0.9650 - auc: 0.9949 - accuracy: 0.9665 - val_loss: 0.5548 - val_f1: 0.5778 - val_auc: 0.8340 - val_accuracy: 0.8699 - _timestamp: 1656362221.0000 - _runtime: 1561.0000\n",
            "Epoch 88/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0841 - f1: 0.9688 - auc: 0.9953 - accuracy: 0.9696 - val_loss: 0.5570 - val_f1: 0.5829 - val_auc: 0.8334 - val_accuracy: 0.8704 - _timestamp: 1656362238.0000 - _runtime: 1578.0000\n",
            "Epoch 89/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0810 - f1: 0.9694 - auc: 0.9958 - accuracy: 0.9702 - val_loss: 0.5672 - val_f1: 0.5675 - val_auc: 0.8306 - val_accuracy: 0.8715 - _timestamp: 1656362256.0000 - _runtime: 1596.0000\n",
            "Epoch 90/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0866 - f1: 0.9681 - auc: 0.9952 - accuracy: 0.9685 - val_loss: 0.5653 - val_f1: 0.5778 - val_auc: 0.8319 - val_accuracy: 0.8693 - _timestamp: 1656362273.0000 - _runtime: 1613.0000\n",
            "Epoch 91/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0854 - f1: 0.9672 - auc: 0.9951 - accuracy: 0.9682 - val_loss: 0.5727 - val_f1: 0.5448 - val_auc: 0.8277 - val_accuracy: 0.8687 - _timestamp: 1656362290.0000 - _runtime: 1630.0000\n",
            "Epoch 92/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0818 - f1: 0.9699 - auc: 0.9954 - accuracy: 0.9706 - val_loss: 0.5682 - val_f1: 0.5656 - val_auc: 0.8307 - val_accuracy: 0.8693 - _timestamp: 1656362308.0000 - _runtime: 1648.0000\n",
            "Epoch 93/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0799 - f1: 0.9682 - auc: 0.9959 - accuracy: 0.9695 - val_loss: 0.5677 - val_f1: 0.5899 - val_auc: 0.8365 - val_accuracy: 0.8726 - _timestamp: 1656362325.0000 - _runtime: 1665.0000\n",
            "Epoch 94/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0817 - f1: 0.9694 - auc: 0.9957 - accuracy: 0.9703 - val_loss: 0.5832 - val_f1: 0.5327 - val_auc: 0.8296 - val_accuracy: 0.8682 - _timestamp: 1656362342.0000 - _runtime: 1682.0000\n",
            "Epoch 95/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0839 - f1: 0.9675 - auc: 0.9954 - accuracy: 0.9686 - val_loss: 0.5838 - val_f1: 0.5575 - val_auc: 0.8293 - val_accuracy: 0.8660 - _timestamp: 1656362359.0000 - _runtime: 1699.0000\n",
            "Epoch 96/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0851 - f1: 0.9662 - auc: 0.9953 - accuracy: 0.9674 - val_loss: 0.5782 - val_f1: 0.5713 - val_auc: 0.8291 - val_accuracy: 0.8682 - _timestamp: 1656362377.0000 - _runtime: 1717.0000\n",
            "Epoch 97/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0780 - f1: 0.9701 - auc: 0.9962 - accuracy: 0.9713 - val_loss: 0.5960 - val_f1: 0.5494 - val_auc: 0.8252 - val_accuracy: 0.8671 - _timestamp: 1656362394.0000 - _runtime: 1734.0000\n",
            "Epoch 98/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0772 - f1: 0.9700 - auc: 0.9960 - accuracy: 0.9709 - val_loss: 0.5918 - val_f1: 0.5555 - val_auc: 0.8298 - val_accuracy: 0.8660 - _timestamp: 1656362411.0000 - _runtime: 1751.0000\n",
            "Epoch 99/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 0.0790 - f1: 0.9704 - auc: 0.9960 - accuracy: 0.9714 - val_loss: 0.5972 - val_f1: 0.5746 - val_auc: 0.8285 - val_accuracy: 0.8671 - _timestamp: 1656362429.0000 - _runtime: 1769.0000\n",
            "Epoch 100/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.0815 - f1: 0.9688 - auc: 0.9958 - accuracy: 0.9698 - val_loss: 0.6065 - val_f1: 0.5322 - val_auc: 0.8259 - val_accuracy: 0.8654 - _timestamp: 1656362446.0000 - _runtime: 1786.0000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef42712a0646452abf974574a0b857a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='520.928 MB of 520.928 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇█████████████████████</td></tr><tr><td>auc</td><td>▁▆▇▇▇▇▇▇▇▇██████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>loss</td><td>█▅▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▆▆▇▇▇▇▇▇▇▇█▇▇█▇███▇▇██▇███▇█▇▇█▇█▇▇▇▇</td></tr><tr><td>val_auc</td><td>█▇▇▇▇▇███▇▇▇▇▇▇▇▆▆▅▅▅▅▅▄▅▅▄▃▃▃▃▂▄▃▂▂▂▂▁▁</td></tr><tr><td>val_f1</td><td>▁▃▃▄▄▄▅▅▅▅▆▅▆▆▆▆▇▆▇▇▇▇▇█▇▇▇▇▇▆▇▆▇▇▇▆▆▄▅▄</td></tr><tr><td>val_loss</td><td>▅▂▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.96978</td></tr><tr><td>auc</td><td>0.99582</td></tr><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.36401</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>f1</td><td>0.96877</td></tr><tr><td>loss</td><td>0.0815</td></tr><tr><td>val_accuracy</td><td>0.86541</td></tr><tr><td>val_auc</td><td>0.82586</td></tr><tr><td>val_f1</td><td>0.53217</td></tr><tr><td>val_loss</td><td>0.60655</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">proud-sweep-9</strong>: <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/tvx4pdz9\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/runs/tvx4pdz9</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220627_201100-tvx4pdz9/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 430j9dma with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: elu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_value: 0.2093795011208321\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons: 4500\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptomizer: adagrad\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_factor: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_type: l1_l2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.19"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220627_204147-430j9dma</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/430j9dma\" target=\"_blank\">misunderstood-sweep-10</a></strong> to <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 25008)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4500)              112540500 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 4500)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4500)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4500)              20254500  \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 4500)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4500)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4500)              20254500  \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 4500)              0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 4500)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 4501      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 153,054,001\n",
            "Trainable params: 153,054,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "380/380 [==============================] - 16s 38ms/step - loss: 489.8981 - f1: 0.8462 - auc: 0.9151 - accuracy: 0.8490 - val_loss: 151.9925 - val_f1: 0.5628 - val_auc: 0.8919 - val_accuracy: 0.8354 - _timestamp: 1656362525.0000 - _runtime: 18.0000\n",
            "Epoch 2/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 69.2993 - f1: 0.8453 - auc: 0.9136 - accuracy: 0.8441 - val_loss: 19.5260 - val_f1: 0.5373 - val_auc: 0.8928 - val_accuracy: 0.7725 - _timestamp: 1656362539.0000 - _runtime: 32.0000\n",
            "Epoch 3/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 6.8257 - f1: 0.8476 - auc: 0.9190 - accuracy: 0.8489 - val_loss: 2.9986 - val_f1: 0.5343 - val_auc: 0.8804 - val_accuracy: 0.8326 - _timestamp: 1656362553.0000 - _runtime: 46.0000\n",
            "Epoch 4/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.9471 - f1: 0.8686 - auc: 0.9357 - accuracy: 0.8721 - val_loss: 3.0087 - val_f1: 0.5538 - val_auc: 0.8850 - val_accuracy: 0.8142 - _timestamp: 1656362568.0000 - _runtime: 61.0000\n",
            "Epoch 5/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 2.8931 - f1: 0.8813 - auc: 0.9458 - accuracy: 0.8860 - val_loss: 2.9236 - val_f1: 0.5303 - val_auc: 0.8802 - val_accuracy: 0.8359 - _timestamp: 1656362580.0000 - _runtime: 73.0000\n",
            "Epoch 6/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 2.8700 - f1: 0.8884 - auc: 0.9496 - accuracy: 0.8913 - val_loss: 2.8965 - val_f1: 0.5297 - val_auc: 0.8806 - val_accuracy: 0.8493 - _timestamp: 1656362597.0000 - _runtime: 90.0000\n",
            "Epoch 7/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 2.8483 - f1: 0.8908 - auc: 0.9529 - accuracy: 0.8951 - val_loss: 2.8909 - val_f1: 0.5297 - val_auc: 0.8846 - val_accuracy: 0.8515 - _timestamp: 1656362611.0000 - _runtime: 104.0000\n",
            "Epoch 8/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.8425 - f1: 0.8936 - auc: 0.9524 - accuracy: 0.8968 - val_loss: 2.8960 - val_f1: 0.5371 - val_auc: 0.8840 - val_accuracy: 0.8393 - _timestamp: 1656362625.0000 - _runtime: 118.0000\n",
            "Epoch 9/100\n",
            "380/380 [==============================] - 12s 30ms/step - loss: 2.8369 - f1: 0.8949 - auc: 0.9517 - accuracy: 0.8973 - val_loss: 2.8918 - val_f1: 0.5362 - val_auc: 0.8769 - val_accuracy: 0.8443 - _timestamp: 1656362637.0000 - _runtime: 130.0000\n",
            "Epoch 10/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 2.8208 - f1: 0.8988 - auc: 0.9543 - accuracy: 0.9014 - val_loss: 2.8713 - val_f1: 0.5151 - val_auc: 0.8794 - val_accuracy: 0.8515 - _timestamp: 1656362649.0000 - _runtime: 142.0000\n",
            "Epoch 11/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 2.8118 - f1: 0.8970 - auc: 0.9563 - accuracy: 0.9013 - val_loss: 2.8635 - val_f1: 0.4726 - val_auc: 0.8605 - val_accuracy: 0.8621 - _timestamp: 1656362663.0000 - _runtime: 156.0000\n",
            "Epoch 12/100\n",
            "380/380 [==============================] - 17s 44ms/step - loss: 2.8039 - f1: 0.9012 - auc: 0.9577 - accuracy: 0.9045 - val_loss: 2.8583 - val_f1: 0.4748 - val_auc: 0.8595 - val_accuracy: 0.8598 - _timestamp: 1656362678.0000 - _runtime: 171.0000\n",
            "Epoch 13/100\n",
            "380/380 [==============================] - 20s 51ms/step - loss: 2.7925 - f1: 0.9044 - auc: 0.9587 - accuracy: 0.9070 - val_loss: 2.8575 - val_f1: 0.5190 - val_auc: 0.8740 - val_accuracy: 0.8532 - _timestamp: 1656362695.0000 - _runtime: 188.0000\n",
            "Epoch 14/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 2.7914 - f1: 0.9015 - auc: 0.9570 - accuracy: 0.9052 - val_loss: 2.8537 - val_f1: 0.5076 - val_auc: 0.8665 - val_accuracy: 0.8587 - _timestamp: 1656362715.0000 - _runtime: 208.0000\n",
            "Epoch 15/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.7822 - f1: 0.9023 - auc: 0.9587 - accuracy: 0.9058 - val_loss: 2.8739 - val_f1: 0.5340 - val_auc: 0.8740 - val_accuracy: 0.8432 - _timestamp: 1656362729.0000 - _runtime: 222.0000\n",
            "Epoch 16/100\n",
            "380/380 [==============================] - 15s 40ms/step - loss: 2.7825 - f1: 0.9042 - auc: 0.9566 - accuracy: 0.9069 - val_loss: 2.8313 - val_f1: 0.4995 - val_auc: 0.8682 - val_accuracy: 0.8643 - _timestamp: 1656362740.0000 - _runtime: 233.0000\n",
            "Epoch 17/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 2.7799 - f1: 0.9015 - auc: 0.9560 - accuracy: 0.9049 - val_loss: 2.8283 - val_f1: 0.4761 - val_auc: 0.8594 - val_accuracy: 0.8648 - _timestamp: 1656362755.0000 - _runtime: 248.0000\n",
            "Epoch 18/100\n",
            "380/380 [==============================] - 14s 38ms/step - loss: 2.7640 - f1: 0.9016 - auc: 0.9587 - accuracy: 0.9049 - val_loss: 2.8168 - val_f1: 0.5038 - val_auc: 0.8711 - val_accuracy: 0.8648 - _timestamp: 1656362769.0000 - _runtime: 262.0000\n",
            "Epoch 19/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 2.7558 - f1: 0.9053 - auc: 0.9608 - accuracy: 0.9080 - val_loss: 2.8100 - val_f1: 0.4962 - val_auc: 0.8745 - val_accuracy: 0.8660 - _timestamp: 1656362784.0000 - _runtime: 277.0000\n",
            "Epoch 20/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.7509 - f1: 0.9060 - auc: 0.9597 - accuracy: 0.9085 - val_loss: 2.8229 - val_f1: 0.5292 - val_auc: 0.8754 - val_accuracy: 0.8593 - _timestamp: 1656362798.0000 - _runtime: 291.0000\n",
            "Epoch 21/100\n",
            "380/380 [==============================] - 12s 30ms/step - loss: 2.7515 - f1: 0.9055 - auc: 0.9592 - accuracy: 0.9082 - val_loss: 2.8166 - val_f1: 0.4841 - val_auc: 0.8554 - val_accuracy: 0.8604 - _timestamp: 1656362809.0000 - _runtime: 302.0000\n",
            "Epoch 22/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.7396 - f1: 0.9061 - auc: 0.9605 - accuracy: 0.9098 - val_loss: 2.8399 - val_f1: 0.5565 - val_auc: 0.8804 - val_accuracy: 0.8459 - _timestamp: 1656362821.0000 - _runtime: 314.0000\n",
            "Epoch 23/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 2.7351 - f1: 0.9083 - auc: 0.9609 - accuracy: 0.9114 - val_loss: 2.8026 - val_f1: 0.5025 - val_auc: 0.8585 - val_accuracy: 0.8671 - _timestamp: 1656362833.0000 - _runtime: 326.0000\n",
            "Epoch 24/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 2.7334 - f1: 0.9050 - auc: 0.9599 - accuracy: 0.9079 - val_loss: 2.7940 - val_f1: 0.5045 - val_auc: 0.8729 - val_accuracy: 0.8610 - _timestamp: 1656362847.0000 - _runtime: 340.0000\n",
            "Epoch 25/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.7291 - f1: 0.9073 - auc: 0.9598 - accuracy: 0.9109 - val_loss: 2.8337 - val_f1: 0.5712 - val_auc: 0.8869 - val_accuracy: 0.8432 - _timestamp: 1656362863.0000 - _runtime: 356.0000\n",
            "Epoch 26/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.7266 - f1: 0.9079 - auc: 0.9591 - accuracy: 0.9102 - val_loss: 2.7972 - val_f1: 0.5456 - val_auc: 0.8775 - val_accuracy: 0.8537 - _timestamp: 1656362875.0000 - _runtime: 368.0000\n",
            "Epoch 27/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 2.7152 - f1: 0.9114 - auc: 0.9611 - accuracy: 0.9133 - val_loss: 2.7805 - val_f1: 0.5104 - val_auc: 0.8707 - val_accuracy: 0.8610 - _timestamp: 1656362886.0000 - _runtime: 379.0000\n",
            "Epoch 28/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.7111 - f1: 0.9114 - auc: 0.9610 - accuracy: 0.9132 - val_loss: 2.7881 - val_f1: 0.5270 - val_auc: 0.8735 - val_accuracy: 0.8521 - _timestamp: 1656362902.0000 - _runtime: 395.0000\n",
            "Epoch 29/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.7108 - f1: 0.9073 - auc: 0.9595 - accuracy: 0.9098 - val_loss: 2.7956 - val_f1: 0.5232 - val_auc: 0.8702 - val_accuracy: 0.8432 - _timestamp: 1656362914.0000 - _runtime: 407.0000\n",
            "Epoch 30/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 2.7004 - f1: 0.9123 - auc: 0.9615 - accuracy: 0.9149 - val_loss: 2.7766 - val_f1: 0.5190 - val_auc: 0.8763 - val_accuracy: 0.8509 - _timestamp: 1656362926.0000 - _runtime: 419.0000\n",
            "Epoch 31/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 2.6924 - f1: 0.9122 - auc: 0.9628 - accuracy: 0.9145 - val_loss: 2.7740 - val_f1: 0.5191 - val_auc: 0.8728 - val_accuracy: 0.8560 - _timestamp: 1656362940.0000 - _runtime: 433.0000\n",
            "Epoch 32/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.6955 - f1: 0.9085 - auc: 0.9613 - accuracy: 0.9114 - val_loss: 2.7792 - val_f1: 0.5328 - val_auc: 0.8735 - val_accuracy: 0.8515 - _timestamp: 1656362954.0000 - _runtime: 447.0000\n",
            "Epoch 33/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 2.6949 - f1: 0.9068 - auc: 0.9603 - accuracy: 0.9097 - val_loss: 2.7603 - val_f1: 0.5220 - val_auc: 0.8703 - val_accuracy: 0.8615 - _timestamp: 1656362965.0000 - _runtime: 458.0000\n",
            "Epoch 34/100\n",
            "380/380 [==============================] - 15s 41ms/step - loss: 2.6874 - f1: 0.9091 - auc: 0.9615 - accuracy: 0.9126 - val_loss: 2.7501 - val_f1: 0.5119 - val_auc: 0.8751 - val_accuracy: 0.8637 - _timestamp: 1656362979.0000 - _runtime: 472.0000\n",
            "Epoch 35/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.6819 - f1: 0.9135 - auc: 0.9624 - accuracy: 0.9161 - val_loss: 2.7579 - val_f1: 0.4987 - val_auc: 0.8743 - val_accuracy: 0.8548 - _timestamp: 1656362995.0000 - _runtime: 488.0000\n",
            "Epoch 36/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.6728 - f1: 0.9147 - auc: 0.9632 - accuracy: 0.9166 - val_loss: 2.7505 - val_f1: 0.5347 - val_auc: 0.8747 - val_accuracy: 0.8632 - _timestamp: 1656363006.0000 - _runtime: 499.0000\n",
            "Epoch 37/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.6676 - f1: 0.9096 - auc: 0.9638 - accuracy: 0.9121 - val_loss: 2.7727 - val_f1: 0.5410 - val_auc: 0.8746 - val_accuracy: 0.8448 - _timestamp: 1656363018.0000 - _runtime: 511.0000\n",
            "Epoch 38/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.6704 - f1: 0.9099 - auc: 0.9616 - accuracy: 0.9131 - val_loss: 2.7528 - val_f1: 0.5239 - val_auc: 0.8702 - val_accuracy: 0.8554 - _timestamp: 1656363030.0000 - _runtime: 523.0000\n",
            "Epoch 39/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 2.6558 - f1: 0.9128 - auc: 0.9646 - accuracy: 0.9150 - val_loss: 2.7369 - val_f1: 0.5261 - val_auc: 0.8731 - val_accuracy: 0.8621 - _timestamp: 1656363041.0000 - _runtime: 534.0000\n",
            "Epoch 40/100\n",
            "380/380 [==============================] - 16s 42ms/step - loss: 2.6569 - f1: 0.9101 - auc: 0.9631 - accuracy: 0.9130 - val_loss: 2.7236 - val_f1: 0.5063 - val_auc: 0.8678 - val_accuracy: 0.8671 - _timestamp: 1656363055.0000 - _runtime: 548.0000\n",
            "Epoch 41/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.6517 - f1: 0.9099 - auc: 0.9628 - accuracy: 0.9131 - val_loss: 2.7254 - val_f1: 0.5295 - val_auc: 0.8726 - val_accuracy: 0.8654 - _timestamp: 1656363071.0000 - _runtime: 564.0000\n",
            "Epoch 42/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 2.6449 - f1: 0.9119 - auc: 0.9636 - accuracy: 0.9142 - val_loss: 2.7221 - val_f1: 0.5501 - val_auc: 0.8762 - val_accuracy: 0.8654 - _timestamp: 1656363083.0000 - _runtime: 576.0000\n",
            "Epoch 43/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 2.6375 - f1: 0.9144 - auc: 0.9649 - accuracy: 0.9167 - val_loss: 2.7157 - val_f1: 0.5303 - val_auc: 0.8713 - val_accuracy: 0.8648 - _timestamp: 1656363097.0000 - _runtime: 590.0000\n",
            "Epoch 44/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 2.6388 - f1: 0.9124 - auc: 0.9645 - accuracy: 0.9149 - val_loss: 2.7150 - val_f1: 0.5574 - val_auc: 0.8807 - val_accuracy: 0.8643 - _timestamp: 1656363111.0000 - _runtime: 604.0000\n",
            "Epoch 45/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 2.6346 - f1: 0.9139 - auc: 0.9642 - accuracy: 0.9164 - val_loss: 2.7100 - val_f1: 0.5140 - val_auc: 0.8696 - val_accuracy: 0.8665 - _timestamp: 1656363125.0000 - _runtime: 618.0000\n",
            "Epoch 46/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.6280 - f1: 0.9136 - auc: 0.9646 - accuracy: 0.9161 - val_loss: 2.7201 - val_f1: 0.5176 - val_auc: 0.8623 - val_accuracy: 0.8604 - _timestamp: 1656363139.0000 - _runtime: 632.0000\n",
            "Epoch 47/100\n",
            "380/380 [==============================] - 19s 50ms/step - loss: 2.6251 - f1: 0.9140 - auc: 0.9644 - accuracy: 0.9175 - val_loss: 2.7071 - val_f1: 0.5059 - val_auc: 0.8641 - val_accuracy: 0.8632 - _timestamp: 1656363150.0000 - _runtime: 643.0000\n",
            "Epoch 48/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 2.6225 - f1: 0.9109 - auc: 0.9643 - accuracy: 0.9140 - val_loss: 2.7040 - val_f1: 0.5232 - val_auc: 0.8699 - val_accuracy: 0.8604 - _timestamp: 1656363169.0000 - _runtime: 662.0000\n",
            "Epoch 49/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 2.6159 - f1: 0.9138 - auc: 0.9639 - accuracy: 0.9157 - val_loss: 2.7009 - val_f1: 0.4971 - val_auc: 0.8508 - val_accuracy: 0.8671 - _timestamp: 1656363186.0000 - _runtime: 679.0000\n",
            "Epoch 50/100\n",
            "380/380 [==============================] - 14s 36ms/step - loss: 2.6113 - f1: 0.9160 - auc: 0.9648 - accuracy: 0.9182 - val_loss: 2.6944 - val_f1: 0.5225 - val_auc: 0.8736 - val_accuracy: 0.8582 - _timestamp: 1656363203.0000 - _runtime: 696.0000\n",
            "Epoch 51/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.6121 - f1: 0.9148 - auc: 0.9643 - accuracy: 0.9179 - val_loss: 2.6989 - val_f1: 0.5220 - val_auc: 0.8655 - val_accuracy: 0.8598 - _timestamp: 1656363217.0000 - _runtime: 710.0000\n",
            "Epoch 52/100\n",
            "380/380 [==============================] - 14s 36ms/step - loss: 2.6002 - f1: 0.9162 - auc: 0.9652 - accuracy: 0.9179 - val_loss: 2.6892 - val_f1: 0.5317 - val_auc: 0.8672 - val_accuracy: 0.8626 - _timestamp: 1656363228.0000 - _runtime: 721.0000\n",
            "Epoch 53/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 2.5957 - f1: 0.9135 - auc: 0.9663 - accuracy: 0.9167 - val_loss: 2.6806 - val_f1: 0.5532 - val_auc: 0.8774 - val_accuracy: 0.8626 - _timestamp: 1656363242.0000 - _runtime: 735.0000\n",
            "Epoch 54/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.5961 - f1: 0.9154 - auc: 0.9657 - accuracy: 0.9182 - val_loss: 2.6860 - val_f1: 0.5223 - val_auc: 0.8706 - val_accuracy: 0.8626 - _timestamp: 1656363256.0000 - _runtime: 749.0000\n",
            "Epoch 55/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 2.5934 - f1: 0.9170 - auc: 0.9651 - accuracy: 0.9187 - val_loss: 2.6699 - val_f1: 0.5200 - val_auc: 0.8692 - val_accuracy: 0.8660 - _timestamp: 1656363267.0000 - _runtime: 760.0000\n",
            "Epoch 56/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 2.5883 - f1: 0.9157 - auc: 0.9657 - accuracy: 0.9186 - val_loss: 2.6686 - val_f1: 0.5178 - val_auc: 0.8674 - val_accuracy: 0.8704 - _timestamp: 1656363284.0000 - _runtime: 777.0000\n",
            "Epoch 57/100\n",
            "380/380 [==============================] - 14s 36ms/step - loss: 2.5913 - f1: 0.9155 - auc: 0.9641 - accuracy: 0.9174 - val_loss: 2.6672 - val_f1: 0.5366 - val_auc: 0.8702 - val_accuracy: 0.8682 - _timestamp: 1656363300.0000 - _runtime: 793.0000\n",
            "Epoch 58/100\n",
            "380/380 [==============================] - 15s 40ms/step - loss: 2.5819 - f1: 0.9138 - auc: 0.9649 - accuracy: 0.9160 - val_loss: 2.6608 - val_f1: 0.5397 - val_auc: 0.8761 - val_accuracy: 0.8704 - _timestamp: 1656363314.0000 - _runtime: 807.0000\n",
            "Epoch 59/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.5720 - f1: 0.9165 - auc: 0.9666 - accuracy: 0.9198 - val_loss: 2.6661 - val_f1: 0.5520 - val_auc: 0.8774 - val_accuracy: 0.8632 - _timestamp: 1656363329.0000 - _runtime: 822.0000\n",
            "Epoch 60/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 2.5667 - f1: 0.9168 - auc: 0.9671 - accuracy: 0.9192 - val_loss: 2.6499 - val_f1: 0.5240 - val_auc: 0.8751 - val_accuracy: 0.8699 - _timestamp: 1656363341.0000 - _runtime: 834.0000\n",
            "Epoch 61/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.5672 - f1: 0.9176 - auc: 0.9663 - accuracy: 0.9206 - val_loss: 2.6501 - val_f1: 0.5171 - val_auc: 0.8643 - val_accuracy: 0.8721 - _timestamp: 1656363355.0000 - _runtime: 848.0000\n",
            "Epoch 62/100\n",
            "380/380 [==============================] - 14s 36ms/step - loss: 2.5634 - f1: 0.9182 - auc: 0.9663 - accuracy: 0.9200 - val_loss: 2.6478 - val_f1: 0.5180 - val_auc: 0.8704 - val_accuracy: 0.8682 - _timestamp: 1656363366.0000 - _runtime: 859.0000\n",
            "Epoch 63/100\n",
            "380/380 [==============================] - 12s 30ms/step - loss: 2.5657 - f1: 0.9155 - auc: 0.9652 - accuracy: 0.9187 - val_loss: 2.6567 - val_f1: 0.5369 - val_auc: 0.8675 - val_accuracy: 0.8671 - _timestamp: 1656363380.0000 - _runtime: 873.0000\n",
            "Epoch 64/100\n",
            "380/380 [==============================] - 16s 42ms/step - loss: 2.5609 - f1: 0.9173 - auc: 0.9653 - accuracy: 0.9195 - val_loss: 2.6393 - val_f1: 0.4721 - val_auc: 0.8600 - val_accuracy: 0.8710 - _timestamp: 1656363392.0000 - _runtime: 885.0000\n",
            "Epoch 65/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.5504 - f1: 0.9170 - auc: 0.9664 - accuracy: 0.9186 - val_loss: 2.6473 - val_f1: 0.5243 - val_auc: 0.8688 - val_accuracy: 0.8582 - _timestamp: 1656363408.0000 - _runtime: 901.0000\n",
            "Epoch 66/100\n",
            "380/380 [==============================] - 12s 30ms/step - loss: 2.5595 - f1: 0.9128 - auc: 0.9636 - accuracy: 0.9150 - val_loss: 2.6412 - val_f1: 0.5304 - val_auc: 0.8640 - val_accuracy: 0.8648 - _timestamp: 1656363419.0000 - _runtime: 912.0000\n",
            "Epoch 67/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 2.5529 - f1: 0.9130 - auc: 0.9648 - accuracy: 0.9164 - val_loss: 2.6319 - val_f1: 0.5209 - val_auc: 0.8686 - val_accuracy: 0.8637 - _timestamp: 1656363431.0000 - _runtime: 924.0000\n",
            "Epoch 68/100\n",
            "380/380 [==============================] - 12s 30ms/step - loss: 2.5436 - f1: 0.9173 - auc: 0.9649 - accuracy: 0.9200 - val_loss: 2.6322 - val_f1: 0.5177 - val_auc: 0.8742 - val_accuracy: 0.8582 - _timestamp: 1656363445.0000 - _runtime: 938.0000\n",
            "Epoch 69/100\n",
            "380/380 [==============================] - 15s 40ms/step - loss: 2.5317 - f1: 0.9161 - auc: 0.9677 - accuracy: 0.9184 - val_loss: 2.6218 - val_f1: 0.5263 - val_auc: 0.8706 - val_accuracy: 0.8687 - _timestamp: 1656363457.0000 - _runtime: 950.0000\n",
            "Epoch 70/100\n",
            "380/380 [==============================] - 17s 44ms/step - loss: 2.5320 - f1: 0.9179 - auc: 0.9670 - accuracy: 0.9199 - val_loss: 2.6173 - val_f1: 0.5171 - val_auc: 0.8659 - val_accuracy: 0.8693 - _timestamp: 1656363472.0000 - _runtime: 965.0000\n",
            "Epoch 71/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.5335 - f1: 0.9183 - auc: 0.9655 - accuracy: 0.9194 - val_loss: 2.6178 - val_f1: 0.4759 - val_auc: 0.8619 - val_accuracy: 0.8682 - _timestamp: 1656363489.0000 - _runtime: 982.0000\n",
            "Epoch 72/100\n",
            "380/380 [==============================] - 15s 40ms/step - loss: 2.5245 - f1: 0.9155 - auc: 0.9672 - accuracy: 0.9181 - val_loss: 2.6162 - val_f1: 0.5236 - val_auc: 0.8630 - val_accuracy: 0.8699 - _timestamp: 1656363500.0000 - _runtime: 993.0000\n",
            "Epoch 73/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.5282 - f1: 0.9167 - auc: 0.9656 - accuracy: 0.9182 - val_loss: 2.6203 - val_f1: 0.5299 - val_auc: 0.8642 - val_accuracy: 0.8615 - _timestamp: 1656363516.0000 - _runtime: 1009.0000\n",
            "Epoch 74/100\n",
            "380/380 [==============================] - 12s 30ms/step - loss: 2.5129 - f1: 0.9203 - auc: 0.9688 - accuracy: 0.9224 - val_loss: 2.6242 - val_f1: 0.5043 - val_auc: 0.8514 - val_accuracy: 0.8637 - _timestamp: 1656363527.0000 - _runtime: 1020.0000\n",
            "Epoch 75/100\n",
            "380/380 [==============================] - 14s 36ms/step - loss: 2.5201 - f1: 0.9202 - auc: 0.9662 - accuracy: 0.9221 - val_loss: 2.6154 - val_f1: 0.5082 - val_auc: 0.8559 - val_accuracy: 0.8682 - _timestamp: 1656363539.0000 - _runtime: 1032.0000\n",
            "Epoch 76/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 2.5211 - f1: 0.9178 - auc: 0.9651 - accuracy: 0.9204 - val_loss: 2.6073 - val_f1: 0.5149 - val_auc: 0.8716 - val_accuracy: 0.8604 - _timestamp: 1656363553.0000 - _runtime: 1046.0000\n",
            "Epoch 77/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.5041 - f1: 0.9199 - auc: 0.9686 - accuracy: 0.9226 - val_loss: 2.6101 - val_f1: 0.5250 - val_auc: 0.8637 - val_accuracy: 0.8604 - _timestamp: 1656363567.0000 - _runtime: 1060.0000\n",
            "Epoch 78/100\n",
            "380/380 [==============================] - 16s 42ms/step - loss: 2.5115 - f1: 0.9167 - auc: 0.9660 - accuracy: 0.9182 - val_loss: 2.6036 - val_f1: 0.5320 - val_auc: 0.8671 - val_accuracy: 0.8648 - _timestamp: 1656363578.0000 - _runtime: 1071.0000\n",
            "Epoch 79/100\n",
            "380/380 [==============================] - 12s 30ms/step - loss: 2.4981 - f1: 0.9219 - auc: 0.9688 - accuracy: 0.9233 - val_loss: 2.6059 - val_f1: 0.5341 - val_auc: 0.8565 - val_accuracy: 0.8660 - _timestamp: 1656363594.0000 - _runtime: 1087.0000\n",
            "Epoch 80/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 2.4947 - f1: 0.9215 - auc: 0.9684 - accuracy: 0.9233 - val_loss: 2.5950 - val_f1: 0.5148 - val_auc: 0.8612 - val_accuracy: 0.8737 - _timestamp: 1656363606.0000 - _runtime: 1099.0000\n",
            "Epoch 81/100\n",
            "380/380 [==============================] - 12s 30ms/step - loss: 2.5003 - f1: 0.9168 - auc: 0.9668 - accuracy: 0.9193 - val_loss: 2.5964 - val_f1: 0.5308 - val_auc: 0.8670 - val_accuracy: 0.8665 - _timestamp: 1656363623.0000 - _runtime: 1116.0000\n",
            "Epoch 82/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.5017 - f1: 0.9161 - auc: 0.9654 - accuracy: 0.9182 - val_loss: 2.5969 - val_f1: 0.5517 - val_auc: 0.8744 - val_accuracy: 0.8571 - _timestamp: 1656363635.0000 - _runtime: 1128.0000\n",
            "Epoch 83/100\n",
            "380/380 [==============================] - 15s 40ms/step - loss: 2.4844 - f1: 0.9230 - auc: 0.9691 - accuracy: 0.9252 - val_loss: 2.5895 - val_f1: 0.4966 - val_auc: 0.8527 - val_accuracy: 0.8699 - _timestamp: 1656363646.0000 - _runtime: 1139.0000\n",
            "Epoch 84/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 2.4935 - f1: 0.9146 - auc: 0.9661 - accuracy: 0.9168 - val_loss: 2.5770 - val_f1: 0.5069 - val_auc: 0.8640 - val_accuracy: 0.8710 - _timestamp: 1656363662.0000 - _runtime: 1155.0000\n",
            "Epoch 85/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.4840 - f1: 0.9174 - auc: 0.9671 - accuracy: 0.9198 - val_loss: 2.5877 - val_f1: 0.5147 - val_auc: 0.8530 - val_accuracy: 0.8715 - _timestamp: 1656363676.0000 - _runtime: 1169.0000\n",
            "Epoch 86/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.4846 - f1: 0.9185 - auc: 0.9663 - accuracy: 0.9201 - val_loss: 2.5884 - val_f1: 0.5346 - val_auc: 0.8691 - val_accuracy: 0.8543 - _timestamp: 1656363687.0000 - _runtime: 1180.0000\n",
            "Epoch 87/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 2.4807 - f1: 0.9180 - auc: 0.9666 - accuracy: 0.9202 - val_loss: 2.5670 - val_f1: 0.5185 - val_auc: 0.8711 - val_accuracy: 0.8682 - _timestamp: 1656363699.0000 - _runtime: 1192.0000\n",
            "Epoch 88/100\n",
            "380/380 [==============================] - 12s 30ms/step - loss: 2.4759 - f1: 0.9171 - auc: 0.9667 - accuracy: 0.9199 - val_loss: 2.5714 - val_f1: 0.5113 - val_auc: 0.8644 - val_accuracy: 0.8643 - _timestamp: 1656363713.0000 - _runtime: 1206.0000\n",
            "Epoch 89/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 2.4726 - f1: 0.9191 - auc: 0.9669 - accuracy: 0.9215 - val_loss: 2.5631 - val_f1: 0.5117 - val_auc: 0.8673 - val_accuracy: 0.8710 - _timestamp: 1656363724.0000 - _runtime: 1217.0000\n",
            "Epoch 90/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.4677 - f1: 0.9191 - auc: 0.9674 - accuracy: 0.9219 - val_loss: 2.5760 - val_f1: 0.5490 - val_auc: 0.8751 - val_accuracy: 0.8554 - _timestamp: 1656363740.0000 - _runtime: 1233.0000\n",
            "Epoch 91/100\n",
            "380/380 [==============================] - 12s 30ms/step - loss: 2.4689 - f1: 0.9204 - auc: 0.9658 - accuracy: 0.9213 - val_loss: 2.5641 - val_f1: 0.4792 - val_auc: 0.8634 - val_accuracy: 0.8654 - _timestamp: 1656363752.0000 - _runtime: 1245.0000\n",
            "Epoch 92/100\n",
            "380/380 [==============================] - 19s 49ms/step - loss: 2.4613 - f1: 0.9197 - auc: 0.9678 - accuracy: 0.9221 - val_loss: 2.5591 - val_f1: 0.5152 - val_auc: 0.8702 - val_accuracy: 0.8548 - _timestamp: 1656363763.0000 - _runtime: 1256.0000\n",
            "Epoch 93/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 2.4519 - f1: 0.9207 - auc: 0.9687 - accuracy: 0.9229 - val_loss: 2.5503 - val_f1: 0.5163 - val_auc: 0.8698 - val_accuracy: 0.8632 - _timestamp: 1656363782.0000 - _runtime: 1275.0000\n",
            "Epoch 94/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.4479 - f1: 0.9233 - auc: 0.9693 - accuracy: 0.9251 - val_loss: 2.5586 - val_f1: 0.5162 - val_auc: 0.8616 - val_accuracy: 0.8621 - _timestamp: 1656363796.0000 - _runtime: 1289.0000\n",
            "Epoch 95/100\n",
            "380/380 [==============================] - 12s 30ms/step - loss: 2.4560 - f1: 0.9184 - auc: 0.9662 - accuracy: 0.9200 - val_loss: 2.5632 - val_f1: 0.5615 - val_auc: 0.8722 - val_accuracy: 0.8576 - _timestamp: 1656363808.0000 - _runtime: 1301.0000\n",
            "Epoch 96/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.4418 - f1: 0.9191 - auc: 0.9693 - accuracy: 0.9210 - val_loss: 2.5710 - val_f1: 0.5736 - val_auc: 0.8780 - val_accuracy: 0.8560 - _timestamp: 1656363819.0000 - _runtime: 1312.0000\n",
            "Epoch 97/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 2.4502 - f1: 0.9203 - auc: 0.9670 - accuracy: 0.9222 - val_loss: 2.5427 - val_f1: 0.5221 - val_auc: 0.8666 - val_accuracy: 0.8671 - _timestamp: 1656363831.0000 - _runtime: 1324.0000\n",
            "Epoch 98/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 2.4328 - f1: 0.9231 - auc: 0.9706 - accuracy: 0.9256 - val_loss: 2.5414 - val_f1: 0.5223 - val_auc: 0.8688 - val_accuracy: 0.8654 - _timestamp: 1656363845.0000 - _runtime: 1338.0000\n",
            "Epoch 99/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.4381 - f1: 0.9206 - auc: 0.9683 - accuracy: 0.9231 - val_loss: 2.5456 - val_f1: 0.5595 - val_auc: 0.8711 - val_accuracy: 0.8615 - _timestamp: 1656363862.0000 - _runtime: 1355.0000\n",
            "Epoch 100/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.4326 - f1: 0.9191 - auc: 0.9691 - accuracy: 0.9212 - val_loss: 2.5484 - val_f1: 0.5467 - val_auc: 0.8712 - val_accuracy: 0.8548 - _timestamp: 1656363874.0000 - _runtime: 1367.0000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01a9c1ddd0c84be2b03fbb9cdf63d5e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='1167.759 MB of 1167.759 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▁▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇███▇▇██████</td></tr><tr><td>auc</td><td>▁▁▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇▇█████▇███████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1</td><td>▁▁▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇▇██████</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▄▂▆▅▇▇▆▇▅▄▅▇▆▆▇▇▆▇▆▆█▆██▇▇█▇▆▇▅█▇█▅▆▇▅</td></tr><tr><td>val_auc</td><td>█▆▆▇▃▅▄▄▂▂▆▅▅▅▅▅▅▆▃▁▄▄▄▆▃▃▄▄▃▁▃▂▅▃▄▄▄▃▄▄</td></tr><tr><td>val_f1</td><td>█▆▅▆▁▅▃▃▂▃▇▅▅▄▆▅▅█▅▃▅▅▅▇▄▁▅▅▅▃▅▆▇▄▅▄▄▄▅▇</td></tr><tr><td>val_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.92121</td></tr><tr><td>auc</td><td>0.96908</td></tr><tr><td>best_epoch</td><td>97</td></tr><tr><td>best_val_loss</td><td>2.54141</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>f1</td><td>0.91908</td></tr><tr><td>loss</td><td>2.4326</td></tr><tr><td>val_accuracy</td><td>0.85484</td></tr><tr><td>val_auc</td><td>0.8712</td></tr><tr><td>val_f1</td><td>0.54672</td></tr><tr><td>val_loss</td><td>2.54841</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">misunderstood-sweep-10</strong>: <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/430j9dma\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/runs/430j9dma</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220627_204147-430j9dma/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 94ycasap with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_value: 0.3378178772822781\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.30000000000000004\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons: 4000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptomizer: adamax\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_factor: 5e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_type: l1_l2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.19"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220627_210517-94ycasap</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/94ycasap\" target=\"_blank\">dark-sweep-11</a></strong> to <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 25008)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4000)              100036000 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 4000)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4000)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4000)              16004000  \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 4000)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4000)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4000)              16004000  \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 4000)              0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 4000)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 4001      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 132,048,001\n",
            "Trainable params: 132,048,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "380/380 [==============================] - 22s 53ms/step - loss: 52.3549 - f1: 0.8337 - auc: 0.8943 - accuracy: 0.8218 - val_loss: 47.0903 - val_f1: 0.5143 - val_auc: 0.8703 - val_accuracy: 0.7536 - _timestamp: 1656363935.0000 - _runtime: 18.0000\n",
            "Epoch 2/100\n",
            "380/380 [==============================] - 18s 47ms/step - loss: 43.2744 - f1: 0.8835 - auc: 0.9489 - accuracy: 0.8820 - val_loss: 40.3398 - val_f1: 0.5133 - val_auc: 0.8712 - val_accuracy: 0.7692 - _timestamp: 1656363954.0000 - _runtime: 37.0000\n",
            "Epoch 3/100\n",
            "380/380 [==============================] - 15s 41ms/step - loss: 37.8596 - f1: 0.8939 - auc: 0.9608 - accuracy: 0.8956 - val_loss: 36.1431 - val_f1: 0.5349 - val_auc: 0.8741 - val_accuracy: 0.7903 - _timestamp: 1656363972.0000 - _runtime: 55.0000\n",
            "Epoch 4/100\n",
            "380/380 [==============================] - 18s 46ms/step - loss: 34.6355 - f1: 0.9062 - auc: 0.9680 - accuracy: 0.9084 - val_loss: 33.8298 - val_f1: 0.5385 - val_auc: 0.8770 - val_accuracy: 0.7964 - _timestamp: 1656363988.0000 - _runtime: 71.0000\n",
            "Epoch 5/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 32.7699 - f1: 0.9119 - auc: 0.9707 - accuracy: 0.9140 - val_loss: 32.2144 - val_f1: 0.5475 - val_auc: 0.8812 - val_accuracy: 0.7998 - _timestamp: 1656364005.0000 - _runtime: 88.0000\n",
            "Epoch 6/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 31.2472 - f1: 0.9155 - auc: 0.9723 - accuracy: 0.9173 - val_loss: 30.7963 - val_f1: 0.5514 - val_auc: 0.8846 - val_accuracy: 0.8026 - _timestamp: 1656364023.0000 - _runtime: 106.0000\n",
            "Epoch 7/100\n",
            "380/380 [==============================] - 18s 47ms/step - loss: 29.8918 - f1: 0.9210 - auc: 0.9757 - accuracy: 0.9229 - val_loss: 29.5810 - val_f1: 0.5534 - val_auc: 0.8879 - val_accuracy: 0.7931 - _timestamp: 1656364039.0000 - _runtime: 122.0000\n",
            "Epoch 8/100\n",
            "380/380 [==============================] - 18s 47ms/step - loss: 28.7079 - f1: 0.9233 - auc: 0.9768 - accuracy: 0.9253 - val_loss: 28.4479 - val_f1: 0.5616 - val_auc: 0.8903 - val_accuracy: 0.8048 - _timestamp: 1656364056.0000 - _runtime: 139.0000\n",
            "Epoch 9/100\n",
            "380/380 [==============================] - 15s 41ms/step - loss: 27.6589 - f1: 0.9228 - auc: 0.9790 - accuracy: 0.9257 - val_loss: 27.4557 - val_f1: 0.5668 - val_auc: 0.8916 - val_accuracy: 0.8098 - _timestamp: 1656364074.0000 - _runtime: 157.0000\n",
            "Epoch 10/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 26.7107 - f1: 0.9274 - auc: 0.9803 - accuracy: 0.9293 - val_loss: 26.5572 - val_f1: 0.5654 - val_auc: 0.8922 - val_accuracy: 0.8076 - _timestamp: 1656364089.0000 - _runtime: 172.0000\n",
            "Epoch 11/100\n",
            "380/380 [==============================] - 18s 47ms/step - loss: 25.8373 - f1: 0.9302 - auc: 0.9812 - accuracy: 0.9328 - val_loss: 25.6919 - val_f1: 0.5668 - val_auc: 0.8926 - val_accuracy: 0.8131 - _timestamp: 1656364107.0000 - _runtime: 190.0000\n",
            "Epoch 12/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 25.0232 - f1: 0.9294 - auc: 0.9817 - accuracy: 0.9320 - val_loss: 24.9480 - val_f1: 0.5593 - val_auc: 0.8932 - val_accuracy: 0.8014 - _timestamp: 1656364125.0000 - _runtime: 208.0000\n",
            "Epoch 13/100\n",
            "380/380 [==============================] - 18s 46ms/step - loss: 24.2572 - f1: 0.9317 - auc: 0.9822 - accuracy: 0.9336 - val_loss: 24.2826 - val_f1: 0.5418 - val_auc: 0.8951 - val_accuracy: 0.7781 - _timestamp: 1656364140.0000 - _runtime: 223.0000\n",
            "Epoch 14/100\n",
            "380/380 [==============================] - 15s 41ms/step - loss: 23.5257 - f1: 0.9331 - auc: 0.9831 - accuracy: 0.9351 - val_loss: 23.4743 - val_f1: 0.5684 - val_auc: 0.8935 - val_accuracy: 0.8098 - _timestamp: 1656364158.0000 - _runtime: 241.0000\n",
            "Epoch 15/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 22.8257 - f1: 0.9347 - auc: 0.9832 - accuracy: 0.9369 - val_loss: 22.8099 - val_f1: 0.5557 - val_auc: 0.8942 - val_accuracy: 0.7992 - _timestamp: 1656364173.0000 - _runtime: 256.0000\n",
            "Epoch 16/100\n",
            "380/380 [==============================] - 18s 47ms/step - loss: 22.1593 - f1: 0.9343 - auc: 0.9841 - accuracy: 0.9361 - val_loss: 22.1899 - val_f1: 0.5514 - val_auc: 0.8944 - val_accuracy: 0.7942 - _timestamp: 1656364191.0000 - _runtime: 274.0000\n",
            "Epoch 17/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 21.5195 - f1: 0.9360 - auc: 0.9845 - accuracy: 0.9383 - val_loss: 21.5184 - val_f1: 0.5713 - val_auc: 0.8941 - val_accuracy: 0.8131 - _timestamp: 1656364208.0000 - _runtime: 291.0000\n",
            "Epoch 18/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 20.9038 - f1: 0.9347 - auc: 0.9856 - accuracy: 0.9378 - val_loss: 20.9012 - val_f1: 0.5765 - val_auc: 0.8934 - val_accuracy: 0.8181 - _timestamp: 1656364227.0000 - _runtime: 310.0000\n",
            "Epoch 19/100\n",
            "380/380 [==============================] - 15s 41ms/step - loss: 20.3048 - f1: 0.9391 - auc: 0.9866 - accuracy: 0.9416 - val_loss: 20.3427 - val_f1: 0.5629 - val_auc: 0.8956 - val_accuracy: 0.8087 - _timestamp: 1656364241.0000 - _runtime: 324.0000\n",
            "Epoch 20/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 19.7302 - f1: 0.9414 - auc: 0.9866 - accuracy: 0.9432 - val_loss: 19.7905 - val_f1: 0.5628 - val_auc: 0.8954 - val_accuracy: 0.8059 - _timestamp: 1656364257.0000 - _runtime: 340.0000\n",
            "Epoch 21/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 19.1770 - f1: 0.9407 - auc: 0.9872 - accuracy: 0.9436 - val_loss: 19.2283 - val_f1: 0.5738 - val_auc: 0.8947 - val_accuracy: 0.8176 - _timestamp: 1656364272.0000 - _runtime: 355.0000\n",
            "Epoch 22/100\n",
            "380/380 [==============================] - 18s 47ms/step - loss: 18.6496 - f1: 0.9449 - auc: 0.9881 - accuracy: 0.9467 - val_loss: 18.7623 - val_f1: 0.5598 - val_auc: 0.8957 - val_accuracy: 0.8009 - _timestamp: 1656364289.0000 - _runtime: 372.0000\n",
            "Epoch 23/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 18.1405 - f1: 0.9423 - auc: 0.9888 - accuracy: 0.9454 - val_loss: 18.2218 - val_f1: 0.5737 - val_auc: 0.8962 - val_accuracy: 0.8176 - _timestamp: 1656364307.0000 - _runtime: 390.0000\n",
            "Epoch 24/100\n",
            "380/380 [==============================] - 18s 46ms/step - loss: 17.6459 - f1: 0.9446 - auc: 0.9881 - accuracy: 0.9460 - val_loss: 17.7527 - val_f1: 0.5560 - val_auc: 0.8965 - val_accuracy: 0.8042 - _timestamp: 1656364323.0000 - _runtime: 406.0000\n",
            "Epoch 25/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 17.1604 - f1: 0.9472 - auc: 0.9895 - accuracy: 0.9484 - val_loss: 17.2973 - val_f1: 0.5571 - val_auc: 0.8966 - val_accuracy: 0.8026 - _timestamp: 1656364340.0000 - _runtime: 423.0000\n",
            "Epoch 26/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 16.6972 - f1: 0.9465 - auc: 0.9888 - accuracy: 0.9482 - val_loss: 16.8105 - val_f1: 0.5653 - val_auc: 0.8950 - val_accuracy: 0.8115 - _timestamp: 1656364358.0000 - _runtime: 441.0000\n",
            "Epoch 27/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 16.2520 - f1: 0.9447 - auc: 0.9886 - accuracy: 0.9468 - val_loss: 16.3508 - val_f1: 0.5674 - val_auc: 0.8946 - val_accuracy: 0.8209 - _timestamp: 1656364376.0000 - _runtime: 459.0000\n",
            "Epoch 28/100\n",
            "380/380 [==============================] - 18s 46ms/step - loss: 15.8178 - f1: 0.9515 - auc: 0.9903 - accuracy: 0.9526 - val_loss: 15.9602 - val_f1: 0.5638 - val_auc: 0.8959 - val_accuracy: 0.8120 - _timestamp: 1656364390.0000 - _runtime: 473.0000\n",
            "Epoch 29/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 15.4054 - f1: 0.9481 - auc: 0.9897 - accuracy: 0.9492 - val_loss: 15.5720 - val_f1: 0.5583 - val_auc: 0.8960 - val_accuracy: 0.8053 - _timestamp: 1656364408.0000 - _runtime: 491.0000\n",
            "Epoch 30/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 15.0011 - f1: 0.9486 - auc: 0.9908 - accuracy: 0.9503 - val_loss: 15.1276 - val_f1: 0.5725 - val_auc: 0.8943 - val_accuracy: 0.8226 - _timestamp: 1656364426.0000 - _runtime: 509.0000\n",
            "Epoch 31/100\n",
            "380/380 [==============================] - 18s 46ms/step - loss: 14.6146 - f1: 0.9486 - auc: 0.9904 - accuracy: 0.9503 - val_loss: 14.7030 - val_f1: 0.5884 - val_auc: 0.8944 - val_accuracy: 0.8398 - _timestamp: 1656364443.0000 - _runtime: 526.0000\n",
            "Epoch 32/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 14.2311 - f1: 0.9497 - auc: 0.9911 - accuracy: 0.9512 - val_loss: 14.3835 - val_f1: 0.5707 - val_auc: 0.8954 - val_accuracy: 0.8181 - _timestamp: 1656364460.0000 - _runtime: 543.0000\n",
            "Epoch 33/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 13.8644 - f1: 0.9503 - auc: 0.9910 - accuracy: 0.9516 - val_loss: 14.0890 - val_f1: 0.5480 - val_auc: 0.8958 - val_accuracy: 0.7953 - _timestamp: 1656364477.0000 - _runtime: 560.0000\n",
            "Epoch 34/100\n",
            "380/380 [==============================] - 18s 47ms/step - loss: 13.5003 - f1: 0.9521 - auc: 0.9921 - accuracy: 0.9543 - val_loss: 13.6986 - val_f1: 0.5672 - val_auc: 0.8964 - val_accuracy: 0.8120 - _timestamp: 1656364493.0000 - _runtime: 576.0000\n",
            "Epoch 35/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 13.1521 - f1: 0.9550 - auc: 0.9920 - accuracy: 0.9560 - val_loss: 13.3316 - val_f1: 0.5733 - val_auc: 0.8959 - val_accuracy: 0.8204 - _timestamp: 1656364511.0000 - _runtime: 594.0000\n",
            "Epoch 36/100\n",
            "380/380 [==============================] - 16s 42ms/step - loss: 12.8181 - f1: 0.9537 - auc: 0.9922 - accuracy: 0.9555 - val_loss: 13.0213 - val_f1: 0.5660 - val_auc: 0.8953 - val_accuracy: 0.8142 - _timestamp: 1656364528.0000 - _runtime: 611.0000\n",
            "Epoch 37/100\n",
            "380/380 [==============================] - 21s 55ms/step - loss: 12.4935 - f1: 0.9567 - auc: 0.9920 - accuracy: 0.9576 - val_loss: 12.6556 - val_f1: 0.5822 - val_auc: 0.8939 - val_accuracy: 0.8304 - _timestamp: 1656364544.0000 - _runtime: 627.0000\n",
            "Epoch 38/100\n",
            "380/380 [==============================] - 18s 47ms/step - loss: 12.1726 - f1: 0.9579 - auc: 0.9930 - accuracy: 0.9595 - val_loss: 12.4107 - val_f1: 0.5646 - val_auc: 0.8954 - val_accuracy: 0.8087 - _timestamp: 1656364565.0000 - _runtime: 648.0000\n",
            "Epoch 39/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 11.8698 - f1: 0.9555 - auc: 0.9928 - accuracy: 0.9574 - val_loss: 12.0539 - val_f1: 0.5795 - val_auc: 0.8953 - val_accuracy: 0.8287 - _timestamp: 1656364583.0000 - _runtime: 666.0000\n",
            "Epoch 40/100\n",
            "380/380 [==============================] - 15s 40ms/step - loss: 11.5760 - f1: 0.9561 - auc: 0.9927 - accuracy: 0.9570 - val_loss: 11.7768 - val_f1: 0.5745 - val_auc: 0.8938 - val_accuracy: 0.8231 - _timestamp: 1656364598.0000 - _runtime: 681.0000\n",
            "Epoch 41/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 11.2879 - f1: 0.9587 - auc: 0.9935 - accuracy: 0.9601 - val_loss: 11.5507 - val_f1: 0.5596 - val_auc: 0.8962 - val_accuracy: 0.8053 - _timestamp: 1656364613.0000 - _runtime: 696.0000\n",
            "Epoch 42/100\n",
            "380/380 [==============================] - 18s 46ms/step - loss: 11.0179 - f1: 0.9569 - auc: 0.9929 - accuracy: 0.9586 - val_loss: 11.2546 - val_f1: 0.5683 - val_auc: 0.8964 - val_accuracy: 0.8154 - _timestamp: 1656364632.0000 - _runtime: 715.0000\n",
            "Epoch 43/100\n",
            "380/380 [==============================] - 18s 46ms/step - loss: 10.7438 - f1: 0.9584 - auc: 0.9937 - accuracy: 0.9606 - val_loss: 10.9332 - val_f1: 0.5858 - val_auc: 0.8942 - val_accuracy: 0.8348 - _timestamp: 1656364649.0000 - _runtime: 732.0000\n",
            "Epoch 44/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 10.4887 - f1: 0.9596 - auc: 0.9935 - accuracy: 0.9606 - val_loss: 10.7223 - val_f1: 0.5699 - val_auc: 0.8977 - val_accuracy: 0.8204 - _timestamp: 1656364667.0000 - _runtime: 750.0000\n",
            "Epoch 45/100\n",
            "380/380 [==============================] - 15s 40ms/step - loss: 10.2372 - f1: 0.9606 - auc: 0.9937 - accuracy: 0.9619 - val_loss: 10.4366 - val_f1: 0.5825 - val_auc: 0.8930 - val_accuracy: 0.8343 - _timestamp: 1656364684.0000 - _runtime: 767.0000\n",
            "Epoch 46/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 9.9927 - f1: 0.9615 - auc: 0.9941 - accuracy: 0.9619 - val_loss: 10.1933 - val_f1: 0.5894 - val_auc: 0.8925 - val_accuracy: 0.8393 - _timestamp: 1656364699.0000 - _runtime: 782.0000\n",
            "Epoch 47/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 9.7555 - f1: 0.9621 - auc: 0.9944 - accuracy: 0.9634 - val_loss: 10.0206 - val_f1: 0.5677 - val_auc: 0.8940 - val_accuracy: 0.8176 - _timestamp: 1656364717.0000 - _runtime: 800.0000\n",
            "Epoch 48/100\n",
            "380/380 [==============================] - 18s 47ms/step - loss: 9.5297 - f1: 0.9604 - auc: 0.9941 - accuracy: 0.9614 - val_loss: 9.7482 - val_f1: 0.5855 - val_auc: 0.8931 - val_accuracy: 0.8365 - _timestamp: 1656364734.0000 - _runtime: 817.0000\n",
            "Epoch 49/100\n",
            "380/380 [==============================] - 18s 47ms/step - loss: 9.3102 - f1: 0.9617 - auc: 0.9944 - accuracy: 0.9625 - val_loss: 9.5658 - val_f1: 0.5732 - val_auc: 0.8931 - val_accuracy: 0.8220 - _timestamp: 1656364752.0000 - _runtime: 835.0000\n",
            "Epoch 50/100\n",
            "380/380 [==============================] - 18s 46ms/step - loss: 9.0980 - f1: 0.9644 - auc: 0.9946 - accuracy: 0.9651 - val_loss: 9.3259 - val_f1: 0.5892 - val_auc: 0.8943 - val_accuracy: 0.8354 - _timestamp: 1656364770.0000 - _runtime: 853.0000\n",
            "Epoch 51/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 8.8935 - f1: 0.9637 - auc: 0.9945 - accuracy: 0.9650 - val_loss: 9.0998 - val_f1: 0.5934 - val_auc: 0.8912 - val_accuracy: 0.8454 - _timestamp: 1656364787.0000 - _runtime: 870.0000\n",
            "Epoch 52/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 8.6923 - f1: 0.9632 - auc: 0.9947 - accuracy: 0.9646 - val_loss: 8.9229 - val_f1: 0.5877 - val_auc: 0.8956 - val_accuracy: 0.8365 - _timestamp: 1656364805.0000 - _runtime: 888.0000\n",
            "Epoch 53/100\n",
            "380/380 [==============================] - 15s 41ms/step - loss: 8.4924 - f1: 0.9633 - auc: 0.9953 - accuracy: 0.9644 - val_loss: 8.7011 - val_f1: 0.5970 - val_auc: 0.8937 - val_accuracy: 0.8504 - _timestamp: 1656364819.0000 - _runtime: 902.0000\n",
            "Epoch 54/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 8.3048 - f1: 0.9660 - auc: 0.9952 - accuracy: 0.9674 - val_loss: 8.5245 - val_f1: 0.6019 - val_auc: 0.8938 - val_accuracy: 0.8487 - _timestamp: 1656364835.0000 - _runtime: 918.0000\n",
            "Epoch 55/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 8.1201 - f1: 0.9650 - auc: 0.9955 - accuracy: 0.9662 - val_loss: 8.3491 - val_f1: 0.5977 - val_auc: 0.8932 - val_accuracy: 0.8459 - _timestamp: 1656364849.0000 - _runtime: 932.0000\n",
            "Epoch 56/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 7.9450 - f1: 0.9657 - auc: 0.9951 - accuracy: 0.9666 - val_loss: 8.2313 - val_f1: 0.5731 - val_auc: 0.8951 - val_accuracy: 0.8220 - _timestamp: 1656364867.0000 - _runtime: 950.0000\n",
            "Epoch 57/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 7.7717 - f1: 0.9642 - auc: 0.9953 - accuracy: 0.9659 - val_loss: 8.0353 - val_f1: 0.5850 - val_auc: 0.8929 - val_accuracy: 0.8337 - _timestamp: 1656364883.0000 - _runtime: 966.0000\n",
            "Epoch 58/100\n",
            "380/380 [==============================] - 15s 41ms/step - loss: 7.6071 - f1: 0.9667 - auc: 0.9955 - accuracy: 0.9677 - val_loss: 7.8710 - val_f1: 0.5795 - val_auc: 0.8920 - val_accuracy: 0.8320 - _timestamp: 1656364899.0000 - _runtime: 982.0000\n",
            "Epoch 59/100\n",
            "380/380 [==============================] - 15s 41ms/step - loss: 7.4487 - f1: 0.9653 - auc: 0.9953 - accuracy: 0.9663 - val_loss: 7.6788 - val_f1: 0.5903 - val_auc: 0.8902 - val_accuracy: 0.8465 - _timestamp: 1656364914.0000 - _runtime: 997.0000\n",
            "Epoch 60/100\n",
            "380/380 [==============================] - 18s 47ms/step - loss: 7.2879 - f1: 0.9675 - auc: 0.9959 - accuracy: 0.9687 - val_loss: 7.5408 - val_f1: 0.5897 - val_auc: 0.8935 - val_accuracy: 0.8420 - _timestamp: 1656364930.0000 - _runtime: 1013.0000\n",
            "Epoch 61/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 7.1350 - f1: 0.9674 - auc: 0.9959 - accuracy: 0.9683 - val_loss: 7.3967 - val_f1: 0.5908 - val_auc: 0.8946 - val_accuracy: 0.8404 - _timestamp: 1656364947.0000 - _runtime: 1030.0000\n",
            "Epoch 62/100\n",
            "380/380 [==============================] - 18s 47ms/step - loss: 6.9899 - f1: 0.9664 - auc: 0.9956 - accuracy: 0.9675 - val_loss: 7.2418 - val_f1: 0.5956 - val_auc: 0.8945 - val_accuracy: 0.8443 - _timestamp: 1656364962.0000 - _runtime: 1045.0000\n",
            "Epoch 63/100\n",
            "380/380 [==============================] - 18s 47ms/step - loss: 6.8446 - f1: 0.9688 - auc: 0.9959 - accuracy: 0.9699 - val_loss: 7.1314 - val_f1: 0.5796 - val_auc: 0.8965 - val_accuracy: 0.8326 - _timestamp: 1656364980.0000 - _runtime: 1063.0000\n",
            "Epoch 64/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 6.7059 - f1: 0.9689 - auc: 0.9962 - accuracy: 0.9700 - val_loss: 6.9672 - val_f1: 0.5943 - val_auc: 0.8944 - val_accuracy: 0.8432 - _timestamp: 1656364998.0000 - _runtime: 1081.0000\n",
            "Epoch 65/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 6.5680 - f1: 0.9704 - auc: 0.9967 - accuracy: 0.9707 - val_loss: 6.8050 - val_f1: 0.5964 - val_auc: 0.8907 - val_accuracy: 0.8532 - _timestamp: 1656365016.0000 - _runtime: 1099.0000\n",
            "Epoch 66/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 6.4399 - f1: 0.9703 - auc: 0.9963 - accuracy: 0.9713 - val_loss: 6.7225 - val_f1: 0.5880 - val_auc: 0.8949 - val_accuracy: 0.8382 - _timestamp: 1656365033.0000 - _runtime: 1116.0000\n",
            "Epoch 67/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 6.3155 - f1: 0.9684 - auc: 0.9963 - accuracy: 0.9699 - val_loss: 6.5661 - val_f1: 0.5919 - val_auc: 0.8928 - val_accuracy: 0.8498 - _timestamp: 1656365049.0000 - _runtime: 1132.0000\n",
            "Epoch 68/100\n",
            "380/380 [==============================] - 16s 42ms/step - loss: 6.1904 - f1: 0.9694 - auc: 0.9964 - accuracy: 0.9703 - val_loss: 6.4691 - val_f1: 0.5895 - val_auc: 0.8946 - val_accuracy: 0.8409 - _timestamp: 1656365066.0000 - _runtime: 1149.0000\n",
            "Epoch 69/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 6.0733 - f1: 0.9684 - auc: 0.9961 - accuracy: 0.9690 - val_loss: 6.3477 - val_f1: 0.5895 - val_auc: 0.8930 - val_accuracy: 0.8398 - _timestamp: 1656365082.0000 - _runtime: 1165.0000\n",
            "Epoch 70/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 5.9551 - f1: 0.9694 - auc: 0.9963 - accuracy: 0.9704 - val_loss: 6.2350 - val_f1: 0.5916 - val_auc: 0.8928 - val_accuracy: 0.8420 - _timestamp: 1656365099.0000 - _runtime: 1182.0000\n",
            "Epoch 71/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 5.8387 - f1: 0.9710 - auc: 0.9967 - accuracy: 0.9723 - val_loss: 6.1011 - val_f1: 0.5871 - val_auc: 0.8921 - val_accuracy: 0.8448 - _timestamp: 1656365117.0000 - _runtime: 1200.0000\n",
            "Epoch 72/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 5.7256 - f1: 0.9726 - auc: 0.9970 - accuracy: 0.9733 - val_loss: 6.0006 - val_f1: 0.5845 - val_auc: 0.8908 - val_accuracy: 0.8409 - _timestamp: 1656365135.0000 - _runtime: 1218.0000\n",
            "Epoch 73/100\n",
            "380/380 [==============================] - 17s 44ms/step - loss: 5.6182 - f1: 0.9716 - auc: 0.9967 - accuracy: 0.9723 - val_loss: 5.8703 - val_f1: 0.5938 - val_auc: 0.8935 - val_accuracy: 0.8504 - _timestamp: 1656365153.0000 - _runtime: 1236.0000\n",
            "Epoch 74/100\n",
            "380/380 [==============================] - 15s 40ms/step - loss: 5.5129 - f1: 0.9704 - auc: 0.9967 - accuracy: 0.9715 - val_loss: 5.7916 - val_f1: 0.5859 - val_auc: 0.8941 - val_accuracy: 0.8415 - _timestamp: 1656365169.0000 - _runtime: 1252.0000\n",
            "Epoch 75/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 5.4100 - f1: 0.9712 - auc: 0.9968 - accuracy: 0.9721 - val_loss: 5.6787 - val_f1: 0.5928 - val_auc: 0.8928 - val_accuracy: 0.8476 - _timestamp: 1656365185.0000 - _runtime: 1268.0000\n",
            "Epoch 76/100\n",
            "380/380 [==============================] - 15s 40ms/step - loss: 5.3088 - f1: 0.9719 - auc: 0.9971 - accuracy: 0.9727 - val_loss: 5.6059 - val_f1: 0.5880 - val_auc: 0.8957 - val_accuracy: 0.8376 - _timestamp: 1656365201.0000 - _runtime: 1284.0000\n",
            "Epoch 77/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 5.2090 - f1: 0.9721 - auc: 0.9972 - accuracy: 0.9729 - val_loss: 5.4807 - val_f1: 0.5945 - val_auc: 0.8941 - val_accuracy: 0.8482 - _timestamp: 1656365217.0000 - _runtime: 1300.0000\n",
            "Epoch 78/100\n",
            "380/380 [==============================] - 15s 40ms/step - loss: 5.1163 - f1: 0.9718 - auc: 0.9969 - accuracy: 0.9723 - val_loss: 5.4087 - val_f1: 0.5925 - val_auc: 0.8962 - val_accuracy: 0.8432 - _timestamp: 1656365234.0000 - _runtime: 1317.0000\n",
            "Epoch 79/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 5.0215 - f1: 0.9735 - auc: 0.9972 - accuracy: 0.9741 - val_loss: 5.3028 - val_f1: 0.5973 - val_auc: 0.8960 - val_accuracy: 0.8471 - _timestamp: 1656365249.0000 - _runtime: 1332.0000\n",
            "Epoch 80/100\n",
            "380/380 [==============================] - 16s 42ms/step - loss: 4.9346 - f1: 0.9712 - auc: 0.9968 - accuracy: 0.9717 - val_loss: 5.1990 - val_f1: 0.5953 - val_auc: 0.8939 - val_accuracy: 0.8493 - _timestamp: 1656365266.0000 - _runtime: 1349.0000\n",
            "Epoch 81/100\n",
            "380/380 [==============================] - 18s 46ms/step - loss: 4.8444 - f1: 0.9726 - auc: 0.9973 - accuracy: 0.9733 - val_loss: 5.1060 - val_f1: 0.5957 - val_auc: 0.8931 - val_accuracy: 0.8532 - _timestamp: 1656365282.0000 - _runtime: 1365.0000\n",
            "Epoch 82/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 4.7587 - f1: 0.9723 - auc: 0.9974 - accuracy: 0.9732 - val_loss: 5.0350 - val_f1: 0.5966 - val_auc: 0.8944 - val_accuracy: 0.8493 - _timestamp: 1656365299.0000 - _runtime: 1382.0000\n",
            "Epoch 83/100\n",
            "380/380 [==============================] - 16s 42ms/step - loss: 4.6766 - f1: 0.9715 - auc: 0.9972 - accuracy: 0.9725 - val_loss: 4.9515 - val_f1: 0.5943 - val_auc: 0.8947 - val_accuracy: 0.8493 - _timestamp: 1656365317.0000 - _runtime: 1400.0000\n",
            "Epoch 84/100\n",
            "380/380 [==============================] - 15s 41ms/step - loss: 4.5971 - f1: 0.9725 - auc: 0.9972 - accuracy: 0.9737 - val_loss: 4.8729 - val_f1: 0.5961 - val_auc: 0.8945 - val_accuracy: 0.8493 - _timestamp: 1656365333.0000 - _runtime: 1416.0000\n",
            "Epoch 85/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 4.5189 - f1: 0.9725 - auc: 0.9971 - accuracy: 0.9739 - val_loss: 4.7766 - val_f1: 0.5939 - val_auc: 0.8952 - val_accuracy: 0.8560 - _timestamp: 1656365348.0000 - _runtime: 1431.0000\n",
            "Epoch 86/100\n",
            "380/380 [==============================] - 15s 41ms/step - loss: 4.4426 - f1: 0.9726 - auc: 0.9972 - accuracy: 0.9731 - val_loss: 4.7497 - val_f1: 0.5851 - val_auc: 0.8963 - val_accuracy: 0.8359 - _timestamp: 1656365364.0000 - _runtime: 1447.0000\n",
            "Epoch 87/100\n",
            "380/380 [==============================] - 21s 55ms/step - loss: 4.3642 - f1: 0.9736 - auc: 0.9976 - accuracy: 0.9742 - val_loss: 4.6416 - val_f1: 0.5888 - val_auc: 0.8923 - val_accuracy: 0.8471 - _timestamp: 1656365379.0000 - _runtime: 1462.0000\n",
            "Epoch 88/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 4.2900 - f1: 0.9743 - auc: 0.9975 - accuracy: 0.9755 - val_loss: 4.5565 - val_f1: 0.5997 - val_auc: 0.8917 - val_accuracy: 0.8554 - _timestamp: 1656365400.0000 - _runtime: 1483.0000\n",
            "Epoch 89/100\n",
            "380/380 [==============================] - 15s 40ms/step - loss: 4.2195 - f1: 0.9704 - auc: 0.9972 - accuracy: 0.9712 - val_loss: 4.4754 - val_f1: 0.5985 - val_auc: 0.8943 - val_accuracy: 0.8565 - _timestamp: 1656365416.0000 - _runtime: 1499.0000\n",
            "Epoch 90/100\n",
            "380/380 [==============================] - 18s 47ms/step - loss: 4.1451 - f1: 0.9740 - auc: 0.9975 - accuracy: 0.9749 - val_loss: 4.4206 - val_f1: 0.5951 - val_auc: 0.8926 - val_accuracy: 0.8509 - _timestamp: 1656365431.0000 - _runtime: 1514.0000\n",
            "Epoch 91/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 4.0766 - f1: 0.9749 - auc: 0.9975 - accuracy: 0.9752 - val_loss: 4.3253 - val_f1: 0.6038 - val_auc: 0.8902 - val_accuracy: 0.8648 - _timestamp: 1656365449.0000 - _runtime: 1532.0000\n",
            "Epoch 92/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 4.0080 - f1: 0.9750 - auc: 0.9976 - accuracy: 0.9756 - val_loss: 4.3004 - val_f1: 0.5936 - val_auc: 0.8942 - val_accuracy: 0.8454 - _timestamp: 1656365466.0000 - _runtime: 1549.0000\n",
            "Epoch 93/100\n",
            "380/380 [==============================] - 16s 42ms/step - loss: 3.9404 - f1: 0.9757 - auc: 0.9977 - accuracy: 0.9764 - val_loss: 4.2160 - val_f1: 0.6003 - val_auc: 0.8940 - val_accuracy: 0.8526 - _timestamp: 1656365484.0000 - _runtime: 1567.0000\n",
            "Epoch 94/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 3.8756 - f1: 0.9765 - auc: 0.9976 - accuracy: 0.9774 - val_loss: 4.1423 - val_f1: 0.6011 - val_auc: 0.8948 - val_accuracy: 0.8554 - _timestamp: 1656365500.0000 - _runtime: 1583.0000\n",
            "Epoch 95/100\n",
            "380/380 [==============================] - 15s 41ms/step - loss: 3.8142 - f1: 0.9735 - auc: 0.9971 - accuracy: 0.9743 - val_loss: 4.0770 - val_f1: 0.6013 - val_auc: 0.8945 - val_accuracy: 0.8565 - _timestamp: 1656365515.0000 - _runtime: 1598.0000\n",
            "Epoch 96/100\n",
            "380/380 [==============================] - 18s 46ms/step - loss: 3.7501 - f1: 0.9757 - auc: 0.9977 - accuracy: 0.9768 - val_loss: 4.0475 - val_f1: 0.5881 - val_auc: 0.8957 - val_accuracy: 0.8437 - _timestamp: 1656365531.0000 - _runtime: 1614.0000\n",
            "Epoch 97/100\n",
            "380/380 [==============================] - 18s 46ms/step - loss: 3.6932 - f1: 0.9747 - auc: 0.9973 - accuracy: 0.9751 - val_loss: 3.9523 - val_f1: 0.6061 - val_auc: 0.8919 - val_accuracy: 0.8598 - _timestamp: 1656365548.0000 - _runtime: 1631.0000\n",
            "Epoch 98/100\n",
            "380/380 [==============================] - 17s 43ms/step - loss: 3.6335 - f1: 0.9765 - auc: 0.9975 - accuracy: 0.9770 - val_loss: 3.9201 - val_f1: 0.5891 - val_auc: 0.8946 - val_accuracy: 0.8465 - _timestamp: 1656365566.0000 - _runtime: 1649.0000\n",
            "Epoch 99/100\n",
            "380/380 [==============================] - 18s 47ms/step - loss: 3.5732 - f1: 0.9779 - auc: 0.9977 - accuracy: 0.9782 - val_loss: 3.8383 - val_f1: 0.6028 - val_auc: 0.8948 - val_accuracy: 0.8576 - _timestamp: 1656365582.0000 - _runtime: 1665.0000\n",
            "Epoch 100/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 3.5195 - f1: 0.9763 - auc: 0.9976 - accuracy: 0.9765 - val_loss: 3.8079 - val_f1: 0.5926 - val_auc: 0.8959 - val_accuracy: 0.8454 - _timestamp: 1656365600.0000 - _runtime: 1683.0000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e46da6294a249679a80abc9a88bb57f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='1511.221 MB of 1511.221 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████████████</td></tr><tr><td>auc</td><td>▁▆▆▇▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1</td><td>▁▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>loss</td><td>█▆▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▄▄▅▃▄▅▅▅▅▅▇▅▅▆▄▅▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇</td></tr><tr><td>val_auc</td><td>▁▂▅▆▇▇▇▇▇█▇█▇█▇▇██▇▇▆▇▇▆▇▇▇▇▆▇▇█▇▇▇▇▇▇▇█</td></tr><tr><td>val_f1</td><td>▁▃▄▅▅▃▄▆▆▆▅▅▇▅▅▆▄▅▇▅▇█▅▇▇▇▇▇▆▆▇▇▇▇▇▇▇██▇</td></tr><tr><td>val_loss</td><td>█▆▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.97654</td></tr><tr><td>auc</td><td>0.99756</td></tr><tr><td>best_epoch</td><td>99</td></tr><tr><td>best_val_loss</td><td>3.80787</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>f1</td><td>0.9763</td></tr><tr><td>loss</td><td>3.51947</td></tr><tr><td>val_accuracy</td><td>0.84538</td></tr><tr><td>val_auc</td><td>0.89593</td></tr><tr><td>val_f1</td><td>0.59259</td></tr><tr><td>val_loss</td><td>3.80787</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">dark-sweep-11</strong>: <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/94ycasap\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/runs/94ycasap</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220627_210517-94ycasap/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: g8sz18zb with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_value: 0.40204661040702727\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons: 3000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptomizer: nadam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_factor: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_type: l1_l2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.19"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220627_213417-g8sz18zb</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/g8sz18zb\" target=\"_blank\">vague-sweep-12</a></strong> to <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 25008)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3000)              75027000  \n",
            "                                                                 \n",
            " activation (Activation)     (None, 3000)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 3000)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3000)              9003000   \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 3000)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 3000)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3000)              9003000   \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 3000)              0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 3000)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 3001      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93,036,001\n",
            "Trainable params: 93,036,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "  5/380 [..............................] - ETA: 13s - loss: 237.4379 - f1: 0.3893 - auc: 0.8312 - accuracy: 0.5375WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0156s vs `on_train_batch_end` time: 0.0193s). Check your callbacks.\n",
            "380/380 [==============================] - 19s 45ms/step - loss: 33.4791 - f1: 0.7400 - auc: 0.8596 - accuracy: 0.7805 - val_loss: 24.8548 - val_f1: 0.2985 - val_auc: 0.8562 - val_accuracy: 0.8587 - _timestamp: 1656365678.0000 - _runtime: 21.0000\n",
            "Epoch 2/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 50.8795 - f1: 0.7630 - auc: 0.8341 - accuracy: 0.7798 - val_loss: 31.8493 - val_f1: 0.4613 - val_auc: 0.8630 - val_accuracy: 0.8426 - _timestamp: 1656365695.0000 - _runtime: 38.0000\n",
            "Epoch 3/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 28.8014 - f1: 0.8833 - auc: 0.9561 - accuracy: 0.8893 - val_loss: 26.1363 - val_f1: 0.3176 - val_auc: 0.8764 - val_accuracy: 0.8571 - _timestamp: 1656365709.0000 - _runtime: 52.0000\n",
            "Epoch 4/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 25.0000 - f1: 0.8903 - auc: 0.9667 - accuracy: 0.8975 - val_loss: 23.4369 - val_f1: 0.4690 - val_auc: 0.8938 - val_accuracy: 0.8676 - _timestamp: 1656365723.0000 - _runtime: 66.0000\n",
            "Epoch 5/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 22.8753 - f1: 0.9032 - auc: 0.9710 - accuracy: 0.9077 - val_loss: 22.0105 - val_f1: 0.5459 - val_auc: 0.8882 - val_accuracy: 0.7798 - _timestamp: 1656365739.0000 - _runtime: 82.0000\n",
            "Epoch 6/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 21.4367 - f1: 0.9001 - auc: 0.9715 - accuracy: 0.9050 - val_loss: 20.4712 - val_f1: 0.5143 - val_auc: 0.8952 - val_accuracy: 0.8704 - _timestamp: 1656365756.0000 - _runtime: 99.0000\n",
            "Epoch 7/100\n",
            "380/380 [==============================] - 19s 51ms/step - loss: 20.3453 - f1: 0.9008 - auc: 0.9703 - accuracy: 0.9063 - val_loss: 19.3591 - val_f1: 0.3519 - val_auc: 0.8950 - val_accuracy: 0.8598 - _timestamp: 1656365772.0000 - _runtime: 115.0000\n",
            "Epoch 8/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 19.2508 - f1: 0.9041 - auc: 0.9734 - accuracy: 0.9085 - val_loss: 18.6632 - val_f1: 0.3723 - val_auc: 0.8907 - val_accuracy: 0.8643 - _timestamp: 1656365791.0000 - _runtime: 134.0000\n",
            "Epoch 9/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 18.5009 - f1: 0.9028 - auc: 0.9722 - accuracy: 0.9083 - val_loss: 17.7465 - val_f1: 0.4329 - val_auc: 0.8994 - val_accuracy: 0.8682 - _timestamp: 1656365808.0000 - _runtime: 151.0000\n",
            "Epoch 10/100\n",
            "380/380 [==============================] - 18s 47ms/step - loss: 17.6945 - f1: 0.9067 - auc: 0.9739 - accuracy: 0.9112 - val_loss: 17.0995 - val_f1: 0.5378 - val_auc: 0.8938 - val_accuracy: 0.8710 - _timestamp: 1656365824.0000 - _runtime: 167.0000\n",
            "Epoch 11/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 17.0837 - f1: 0.9101 - auc: 0.9744 - accuracy: 0.9145 - val_loss: 16.5413 - val_f1: 0.2360 - val_auc: 0.9041 - val_accuracy: 0.8571 - _timestamp: 1656365842.0000 - _runtime: 185.0000\n",
            "Epoch 12/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 16.5787 - f1: 0.9043 - auc: 0.9721 - accuracy: 0.9086 - val_loss: 16.0504 - val_f1: 0.5464 - val_auc: 0.8887 - val_accuracy: 0.8826 - _timestamp: 1656365858.0000 - _runtime: 201.0000\n",
            "Epoch 13/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 15.9760 - f1: 0.9120 - auc: 0.9747 - accuracy: 0.9154 - val_loss: 15.5359 - val_f1: 0.5067 - val_auc: 0.8927 - val_accuracy: 0.8560 - _timestamp: 1656365875.0000 - _runtime: 218.0000\n",
            "Epoch 14/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 15.5235 - f1: 0.9053 - auc: 0.9718 - accuracy: 0.9098 - val_loss: 15.0847 - val_f1: 0.4943 - val_auc: 0.9021 - val_accuracy: 0.8682 - _timestamp: 1656365893.0000 - _runtime: 236.0000\n",
            "Epoch 15/100\n",
            "380/380 [==============================] - 18s 47ms/step - loss: 15.0572 - f1: 0.9126 - auc: 0.9741 - accuracy: 0.9175 - val_loss: 14.6687 - val_f1: 0.5844 - val_auc: 0.9061 - val_accuracy: 0.8571 - _timestamp: 1656365909.0000 - _runtime: 252.0000\n",
            "Epoch 16/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 14.6123 - f1: 0.9077 - auc: 0.9731 - accuracy: 0.9118 - val_loss: 14.3071 - val_f1: 0.4738 - val_auc: 0.8891 - val_accuracy: 0.8509 - _timestamp: 1656365927.0000 - _runtime: 270.0000\n",
            "Epoch 17/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 14.2555 - f1: 0.9079 - auc: 0.9726 - accuracy: 0.9122 - val_loss: 13.8722 - val_f1: 0.5281 - val_auc: 0.9072 - val_accuracy: 0.8726 - _timestamp: 1656365943.0000 - _runtime: 286.0000\n",
            "Epoch 18/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 13.9064 - f1: 0.9034 - auc: 0.9705 - accuracy: 0.9094 - val_loss: 13.5472 - val_f1: 0.4097 - val_auc: 0.8975 - val_accuracy: 0.8665 - _timestamp: 1656365962.0000 - _runtime: 305.0000\n",
            "Epoch 19/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 13.4830 - f1: 0.9112 - auc: 0.9745 - accuracy: 0.9157 - val_loss: 13.2818 - val_f1: 0.4121 - val_auc: 0.8797 - val_accuracy: 0.8648 - _timestamp: 1656365978.0000 - _runtime: 321.0000\n",
            "Epoch 20/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 13.1756 - f1: 0.9114 - auc: 0.9733 - accuracy: 0.9159 - val_loss: 12.8538 - val_f1: 0.4551 - val_auc: 0.8980 - val_accuracy: 0.8626 - _timestamp: 1656365994.0000 - _runtime: 337.0000\n",
            "Epoch 21/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 12.8899 - f1: 0.9062 - auc: 0.9716 - accuracy: 0.9104 - val_loss: 12.6216 - val_f1: 0.4470 - val_auc: 0.9020 - val_accuracy: 0.8648 - _timestamp: 1656366011.0000 - _runtime: 354.0000\n",
            "Epoch 22/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 12.5636 - f1: 0.9138 - auc: 0.9739 - accuracy: 0.9174 - val_loss: 12.2839 - val_f1: 0.4148 - val_auc: 0.8950 - val_accuracy: 0.8637 - _timestamp: 1656366027.0000 - _runtime: 370.0000\n",
            "Epoch 23/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 12.2887 - f1: 0.9103 - auc: 0.9735 - accuracy: 0.9150 - val_loss: 12.0862 - val_f1: 0.5708 - val_auc: 0.8923 - val_accuracy: 0.8398 - _timestamp: 1656366044.0000 - _runtime: 387.0000\n",
            "Epoch 24/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 12.0402 - f1: 0.9092 - auc: 0.9714 - accuracy: 0.9132 - val_loss: 11.7106 - val_f1: 0.4819 - val_auc: 0.8979 - val_accuracy: 0.8682 - _timestamp: 1656366060.0000 - _runtime: 403.0000\n",
            "Epoch 25/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 11.6926 - f1: 0.9142 - auc: 0.9747 - accuracy: 0.9178 - val_loss: 11.4589 - val_f1: 0.4883 - val_auc: 0.8941 - val_accuracy: 0.8771 - _timestamp: 1656366077.0000 - _runtime: 420.0000\n",
            "Epoch 26/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 11.4714 - f1: 0.9129 - auc: 0.9734 - accuracy: 0.9166 - val_loss: 11.2189 - val_f1: 0.5681 - val_auc: 0.8987 - val_accuracy: 0.8582 - _timestamp: 1656366093.0000 - _runtime: 436.0000\n",
            "Epoch 27/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 11.2253 - f1: 0.9116 - auc: 0.9734 - accuracy: 0.9137 - val_loss: 10.9866 - val_f1: 0.5222 - val_auc: 0.9029 - val_accuracy: 0.8710 - _timestamp: 1656366109.0000 - _runtime: 452.0000\n",
            "Epoch 28/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 10.9862 - f1: 0.9110 - auc: 0.9743 - accuracy: 0.9141 - val_loss: 10.9506 - val_f1: 0.5794 - val_auc: 0.8976 - val_accuracy: 0.8348 - _timestamp: 1656366126.0000 - _runtime: 469.0000\n",
            "Epoch 29/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 10.8300 - f1: 0.9023 - auc: 0.9689 - accuracy: 0.9071 - val_loss: 10.6736 - val_f1: 0.5753 - val_auc: 0.8983 - val_accuracy: 0.8326 - _timestamp: 1656366142.0000 - _runtime: 485.0000\n",
            "Epoch 30/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 10.5993 - f1: 0.9108 - auc: 0.9728 - accuracy: 0.9138 - val_loss: 10.3997 - val_f1: 0.4907 - val_auc: 0.9018 - val_accuracy: 0.8732 - _timestamp: 1656366159.0000 - _runtime: 502.0000\n",
            "Epoch 31/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 10.4262 - f1: 0.9092 - auc: 0.9720 - accuracy: 0.9136 - val_loss: 10.3711 - val_f1: 0.5230 - val_auc: 0.8648 - val_accuracy: 0.8037 - _timestamp: 1656366175.0000 - _runtime: 518.0000\n",
            "Epoch 32/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 10.2345 - f1: 0.9100 - auc: 0.9729 - accuracy: 0.9143 - val_loss: 10.1046 - val_f1: 0.4195 - val_auc: 0.8866 - val_accuracy: 0.8610 - _timestamp: 1656366191.0000 - _runtime: 534.0000\n",
            "Epoch 33/100\n",
            "380/380 [==============================] - 17s 44ms/step - loss: 10.0506 - f1: 0.9140 - auc: 0.9730 - accuracy: 0.9175 - val_loss: 9.9533 - val_f1: 0.5533 - val_auc: 0.8982 - val_accuracy: 0.8376 - _timestamp: 1656366208.0000 - _runtime: 551.0000\n",
            "Epoch 34/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 9.8969 - f1: 0.9102 - auc: 0.9738 - accuracy: 0.9140 - val_loss: 9.7615 - val_f1: 0.5852 - val_auc: 0.9028 - val_accuracy: 0.8576 - _timestamp: 1656366225.0000 - _runtime: 568.0000\n",
            "Epoch 35/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 9.7578 - f1: 0.9068 - auc: 0.9711 - accuracy: 0.9110 - val_loss: 9.6187 - val_f1: 0.5700 - val_auc: 0.9036 - val_accuracy: 0.8671 - _timestamp: 1656366241.0000 - _runtime: 584.0000\n",
            "Epoch 36/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 9.5973 - f1: 0.9120 - auc: 0.9733 - accuracy: 0.9154 - val_loss: 9.4383 - val_f1: 0.3855 - val_auc: 0.9011 - val_accuracy: 0.8654 - _timestamp: 1656366258.0000 - _runtime: 601.0000\n",
            "Epoch 37/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 9.4783 - f1: 0.9103 - auc: 0.9716 - accuracy: 0.9145 - val_loss: 9.3277 - val_f1: 0.5061 - val_auc: 0.9005 - val_accuracy: 0.8654 - _timestamp: 1656366274.0000 - _runtime: 617.0000\n",
            "Epoch 38/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 9.3505 - f1: 0.9086 - auc: 0.9733 - accuracy: 0.9131 - val_loss: 9.2128 - val_f1: 0.5956 - val_auc: 0.9081 - val_accuracy: 0.8749 - _timestamp: 1656366291.0000 - _runtime: 634.0000\n",
            "Epoch 39/100\n",
            "380/380 [==============================] - 18s 46ms/step - loss: 9.2549 - f1: 0.9138 - auc: 0.9739 - accuracy: 0.9171 - val_loss: 9.1441 - val_f1: 0.5775 - val_auc: 0.8969 - val_accuracy: 0.8537 - _timestamp: 1656366308.0000 - _runtime: 651.0000\n",
            "Epoch 40/100\n",
            "380/380 [==============================] - 19s 50ms/step - loss: 9.1174 - f1: 0.9135 - auc: 0.9747 - accuracy: 0.9168 - val_loss: 9.0172 - val_f1: 0.4785 - val_auc: 0.8831 - val_accuracy: 0.8459 - _timestamp: 1656366325.0000 - _runtime: 668.0000\n",
            "Epoch 41/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 9.0224 - f1: 0.9087 - auc: 0.9733 - accuracy: 0.9124 - val_loss: 8.9553 - val_f1: 0.5544 - val_auc: 0.8984 - val_accuracy: 0.8682 - _timestamp: 1656366344.0000 - _runtime: 687.0000\n",
            "Epoch 42/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 8.9515 - f1: 0.9104 - auc: 0.9728 - accuracy: 0.9134 - val_loss: 8.8999 - val_f1: 0.5601 - val_auc: 0.8911 - val_accuracy: 0.8504 - _timestamp: 1656366361.0000 - _runtime: 704.0000\n",
            "Epoch 43/100\n",
            "380/380 [==============================] - 19s 50ms/step - loss: 8.8377 - f1: 0.9077 - auc: 0.9724 - accuracy: 0.9117 - val_loss: 8.7243 - val_f1: 0.3816 - val_auc: 0.9026 - val_accuracy: 0.8626 - _timestamp: 1656366377.0000 - _runtime: 720.0000\n",
            "Epoch 44/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 8.7391 - f1: 0.9115 - auc: 0.9737 - accuracy: 0.9145 - val_loss: 8.6661 - val_f1: 0.4230 - val_auc: 0.8961 - val_accuracy: 0.8637 - _timestamp: 1656366396.0000 - _runtime: 739.0000\n",
            "Epoch 45/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 8.6640 - f1: 0.9113 - auc: 0.9729 - accuracy: 0.9146 - val_loss: 8.7009 - val_f1: 0.5172 - val_auc: 0.8633 - val_accuracy: 0.8009 - _timestamp: 1656366412.0000 - _runtime: 755.0000\n",
            "Epoch 46/100\n",
            "380/380 [==============================] - 19s 50ms/step - loss: 8.5998 - f1: 0.9100 - auc: 0.9723 - accuracy: 0.9136 - val_loss: 8.5336 - val_f1: 0.5645 - val_auc: 0.9042 - val_accuracy: 0.8726 - _timestamp: 1656366427.0000 - _runtime: 770.0000\n",
            "Epoch 47/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 8.5463 - f1: 0.9123 - auc: 0.9728 - accuracy: 0.9156 - val_loss: 8.4756 - val_f1: 0.5333 - val_auc: 0.8946 - val_accuracy: 0.8454 - _timestamp: 1656366445.0000 - _runtime: 788.0000\n",
            "Epoch 48/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 8.4665 - f1: 0.9061 - auc: 0.9728 - accuracy: 0.9093 - val_loss: 8.4178 - val_f1: 0.5865 - val_auc: 0.9069 - val_accuracy: 0.8359 - _timestamp: 1656366462.0000 - _runtime: 805.0000\n",
            "Epoch 49/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 8.3833 - f1: 0.9108 - auc: 0.9743 - accuracy: 0.9142 - val_loss: 8.3130 - val_f1: 0.5123 - val_auc: 0.8993 - val_accuracy: 0.8648 - _timestamp: 1656366478.0000 - _runtime: 821.0000\n",
            "Epoch 50/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 8.3463 - f1: 0.9055 - auc: 0.9714 - accuracy: 0.9094 - val_loss: 8.2825 - val_f1: 0.5375 - val_auc: 0.9033 - val_accuracy: 0.8665 - _timestamp: 1656366495.0000 - _runtime: 838.0000\n",
            "Epoch 51/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 8.2785 - f1: 0.9117 - auc: 0.9731 - accuracy: 0.9149 - val_loss: 8.2307 - val_f1: 0.5280 - val_auc: 0.9094 - val_accuracy: 0.8637 - _timestamp: 1656366511.0000 - _runtime: 854.0000\n",
            "Epoch 52/100\n",
            "380/380 [==============================] - 19s 51ms/step - loss: 8.2393 - f1: 0.9091 - auc: 0.9742 - accuracy: 0.9135 - val_loss: 8.1655 - val_f1: 0.5880 - val_auc: 0.9068 - val_accuracy: 0.8548 - _timestamp: 1656366527.0000 - _runtime: 870.0000\n",
            "Epoch 53/100\n",
            "380/380 [==============================] - 19s 50ms/step - loss: 8.1832 - f1: 0.9102 - auc: 0.9736 - accuracy: 0.9135 - val_loss: 8.1401 - val_f1: 0.6115 - val_auc: 0.9130 - val_accuracy: 0.8448 - _timestamp: 1656366547.0000 - _runtime: 890.0000\n",
            "Epoch 54/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 8.1423 - f1: 0.9120 - auc: 0.9734 - accuracy: 0.9151 - val_loss: 8.0991 - val_f1: 0.5666 - val_auc: 0.8973 - val_accuracy: 0.8404 - _timestamp: 1656366566.0000 - _runtime: 909.0000\n",
            "Epoch 55/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 8.1239 - f1: 0.9051 - auc: 0.9709 - accuracy: 0.9079 - val_loss: 8.0464 - val_f1: 0.5316 - val_auc: 0.9043 - val_accuracy: 0.8749 - _timestamp: 1656366582.0000 - _runtime: 925.0000\n",
            "Epoch 56/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 8.0831 - f1: 0.9104 - auc: 0.9732 - accuracy: 0.9141 - val_loss: 8.0367 - val_f1: 0.5759 - val_auc: 0.8946 - val_accuracy: 0.8409 - _timestamp: 1656366598.0000 - _runtime: 941.0000\n",
            "Epoch 57/100\n",
            "380/380 [==============================] - 17s 44ms/step - loss: 8.0207 - f1: 0.9126 - auc: 0.9745 - accuracy: 0.9150 - val_loss: 7.9667 - val_f1: 0.4243 - val_auc: 0.8987 - val_accuracy: 0.8704 - _timestamp: 1656366615.0000 - _runtime: 958.0000\n",
            "Epoch 58/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 7.9807 - f1: 0.9109 - auc: 0.9727 - accuracy: 0.9148 - val_loss: 7.9451 - val_f1: 0.5041 - val_auc: 0.8832 - val_accuracy: 0.8526 - _timestamp: 1656366632.0000 - _runtime: 975.0000\n",
            "Epoch 59/100\n",
            "380/380 [==============================] - 19s 49ms/step - loss: 7.9505 - f1: 0.9116 - auc: 0.9729 - accuracy: 0.9139 - val_loss: 7.9415 - val_f1: 0.5793 - val_auc: 0.9000 - val_accuracy: 0.8699 - _timestamp: 1656366648.0000 - _runtime: 991.0000\n",
            "Epoch 60/100\n",
            "380/380 [==============================] - 19s 50ms/step - loss: 7.9229 - f1: 0.9123 - auc: 0.9735 - accuracy: 0.9159 - val_loss: 7.8594 - val_f1: 0.5902 - val_auc: 0.9139 - val_accuracy: 0.8771 - _timestamp: 1656366667.0000 - _runtime: 1010.0000\n",
            "Epoch 61/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 7.8899 - f1: 0.9099 - auc: 0.9724 - accuracy: 0.9136 - val_loss: 7.8080 - val_f1: 0.5999 - val_auc: 0.9076 - val_accuracy: 0.8637 - _timestamp: 1656366685.0000 - _runtime: 1028.0000\n",
            "Epoch 62/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 7.8491 - f1: 0.9084 - auc: 0.9735 - accuracy: 0.9134 - val_loss: 7.8697 - val_f1: 0.5389 - val_auc: 0.8932 - val_accuracy: 0.8537 - _timestamp: 1656366702.0000 - _runtime: 1045.0000\n",
            "Epoch 63/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 7.8333 - f1: 0.9130 - auc: 0.9728 - accuracy: 0.9157 - val_loss: 7.8273 - val_f1: 0.4838 - val_auc: 0.8677 - val_accuracy: 0.8382 - _timestamp: 1656366716.0000 - _runtime: 1059.0000\n",
            "Epoch 64/100\n",
            "380/380 [==============================] - 18s 46ms/step - loss: 7.8103 - f1: 0.9102 - auc: 0.9728 - accuracy: 0.9141 - val_loss: 7.7944 - val_f1: 0.3751 - val_auc: 0.8662 - val_accuracy: 0.8626 - _timestamp: 1656366730.0000 - _runtime: 1073.0000\n",
            "Epoch 65/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 7.7884 - f1: 0.9111 - auc: 0.9730 - accuracy: 0.9148 - val_loss: 7.7206 - val_f1: 0.4720 - val_auc: 0.9014 - val_accuracy: 0.8715 - _timestamp: 1656366747.0000 - _runtime: 1090.0000\n",
            "Epoch 66/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 7.7610 - f1: 0.9100 - auc: 0.9728 - accuracy: 0.9133 - val_loss: 7.7350 - val_f1: 0.3332 - val_auc: 0.8677 - val_accuracy: 0.8626 - _timestamp: 1656366764.0000 - _runtime: 1107.0000\n",
            "Epoch 67/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 7.7576 - f1: 0.9079 - auc: 0.9721 - accuracy: 0.9120 - val_loss: 7.7406 - val_f1: 0.5200 - val_auc: 0.9033 - val_accuracy: 0.8643 - _timestamp: 1656366778.0000 - _runtime: 1121.0000\n",
            "Epoch 68/100\n",
            "380/380 [==============================] - 18s 49ms/step - loss: 7.7179 - f1: 0.9092 - auc: 0.9741 - accuracy: 0.9134 - val_loss: 7.6913 - val_f1: 0.4681 - val_auc: 0.8864 - val_accuracy: 0.8598 - _timestamp: 1656366792.0000 - _runtime: 1135.0000\n",
            "Epoch 69/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 7.7091 - f1: 0.9041 - auc: 0.9722 - accuracy: 0.9091 - val_loss: 7.6894 - val_f1: 0.5913 - val_auc: 0.9000 - val_accuracy: 0.8654 - _timestamp: 1656366811.0000 - _runtime: 1154.0000\n",
            "Epoch 70/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 7.7019 - f1: 0.9117 - auc: 0.9728 - accuracy: 0.9136 - val_loss: 7.6622 - val_f1: 0.5670 - val_auc: 0.8988 - val_accuracy: 0.8660 - _timestamp: 1656366827.0000 - _runtime: 1170.0000\n",
            "Epoch 71/100\n",
            "380/380 [==============================] - 19s 50ms/step - loss: 7.6694 - f1: 0.9115 - auc: 0.9747 - accuracy: 0.9151 - val_loss: 7.6419 - val_f1: 0.5676 - val_auc: 0.9007 - val_accuracy: 0.8665 - _timestamp: 1656366843.0000 - _runtime: 1186.0000\n",
            "Epoch 72/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 7.6578 - f1: 0.9123 - auc: 0.9735 - accuracy: 0.9166 - val_loss: 7.6283 - val_f1: 0.3983 - val_auc: 0.8940 - val_accuracy: 0.8554 - _timestamp: 1656366862.0000 - _runtime: 1205.0000\n",
            "Epoch 73/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 7.6552 - f1: 0.9104 - auc: 0.9726 - accuracy: 0.9148 - val_loss: 7.6484 - val_f1: 0.4243 - val_auc: 0.8866 - val_accuracy: 0.8437 - _timestamp: 1656366879.0000 - _runtime: 1222.0000\n",
            "Epoch 74/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 7.6347 - f1: 0.9087 - auc: 0.9729 - accuracy: 0.9126 - val_loss: 7.6484 - val_f1: 0.5474 - val_auc: 0.8950 - val_accuracy: 0.8309 - _timestamp: 1656366893.0000 - _runtime: 1236.0000\n",
            "Epoch 75/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 7.6302 - f1: 0.9115 - auc: 0.9728 - accuracy: 0.9161 - val_loss: 7.6179 - val_f1: 0.5873 - val_auc: 0.8988 - val_accuracy: 0.8521 - _timestamp: 1656366907.0000 - _runtime: 1250.0000\n",
            "Epoch 76/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 7.6064 - f1: 0.9113 - auc: 0.9741 - accuracy: 0.9153 - val_loss: 7.5834 - val_f1: 0.5370 - val_auc: 0.8969 - val_accuracy: 0.8582 - _timestamp: 1656366927.0000 - _runtime: 1270.0000\n",
            "Epoch 77/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 7.6007 - f1: 0.9045 - auc: 0.9730 - accuracy: 0.9087 - val_loss: 7.5435 - val_f1: 0.5725 - val_auc: 0.9117 - val_accuracy: 0.8776 - _timestamp: 1656366944.0000 - _runtime: 1287.0000\n",
            "Epoch 78/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 7.5876 - f1: 0.9093 - auc: 0.9725 - accuracy: 0.9127 - val_loss: 7.5663 - val_f1: 0.4740 - val_auc: 0.8938 - val_accuracy: 0.8632 - _timestamp: 1656366960.0000 - _runtime: 1303.0000\n",
            "Epoch 79/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 7.5858 - f1: 0.9065 - auc: 0.9721 - accuracy: 0.9105 - val_loss: 7.5743 - val_f1: 0.4361 - val_auc: 0.8923 - val_accuracy: 0.8704 - _timestamp: 1656366974.0000 - _runtime: 1317.0000\n",
            "Epoch 80/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 7.5686 - f1: 0.9081 - auc: 0.9721 - accuracy: 0.9111 - val_loss: 7.5380 - val_f1: 0.5135 - val_auc: 0.8971 - val_accuracy: 0.8632 - _timestamp: 1656366988.0000 - _runtime: 1331.0000\n",
            "Epoch 81/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 7.5435 - f1: 0.9091 - auc: 0.9747 - accuracy: 0.9133 - val_loss: 7.5417 - val_f1: 0.4847 - val_auc: 0.9036 - val_accuracy: 0.8615 - _timestamp: 1656367005.0000 - _runtime: 1348.0000\n",
            "Epoch 82/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 7.5577 - f1: 0.9075 - auc: 0.9706 - accuracy: 0.9112 - val_loss: 7.5563 - val_f1: 0.5801 - val_auc: 0.8979 - val_accuracy: 0.8626 - _timestamp: 1656367019.0000 - _runtime: 1362.0000\n",
            "Epoch 83/100\n",
            "380/380 [==============================] - 19s 50ms/step - loss: 7.5407 - f1: 0.9142 - auc: 0.9726 - accuracy: 0.9183 - val_loss: 7.4904 - val_f1: 0.5244 - val_auc: 0.9160 - val_accuracy: 0.8821 - _timestamp: 1656367033.0000 - _runtime: 1376.0000\n",
            "Epoch 84/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 7.5305 - f1: 0.9096 - auc: 0.9743 - accuracy: 0.9142 - val_loss: 7.5214 - val_f1: 0.4827 - val_auc: 0.8925 - val_accuracy: 0.8587 - _timestamp: 1656367052.0000 - _runtime: 1395.0000\n",
            "Epoch 85/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 7.5353 - f1: 0.9079 - auc: 0.9717 - accuracy: 0.9124 - val_loss: 7.5041 - val_f1: 0.4258 - val_auc: 0.9018 - val_accuracy: 0.8687 - _timestamp: 1656367066.0000 - _runtime: 1409.0000\n",
            "Epoch 86/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 7.5210 - f1: 0.9062 - auc: 0.9731 - accuracy: 0.9120 - val_loss: 7.4908 - val_f1: 0.4098 - val_auc: 0.9064 - val_accuracy: 0.8682 - _timestamp: 1656367080.0000 - _runtime: 1423.0000\n",
            "Epoch 87/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 7.5134 - f1: 0.9055 - auc: 0.9734 - accuracy: 0.9106 - val_loss: 7.4817 - val_f1: 0.4650 - val_auc: 0.9099 - val_accuracy: 0.8721 - _timestamp: 1656367094.0000 - _runtime: 1437.0000\n",
            "Epoch 88/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 7.5196 - f1: 0.9127 - auc: 0.9734 - accuracy: 0.9163 - val_loss: 7.4707 - val_f1: 0.4395 - val_auc: 0.9003 - val_accuracy: 0.8732 - _timestamp: 1656367111.0000 - _runtime: 1454.0000\n",
            "Epoch 89/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 7.5193 - f1: 0.9051 - auc: 0.9711 - accuracy: 0.9094 - val_loss: 7.5179 - val_f1: 0.5057 - val_auc: 0.8917 - val_accuracy: 0.8560 - _timestamp: 1656367127.0000 - _runtime: 1470.0000\n",
            "Epoch 90/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 7.5012 - f1: 0.9105 - auc: 0.9733 - accuracy: 0.9138 - val_loss: 7.4884 - val_f1: 0.5818 - val_auc: 0.8952 - val_accuracy: 0.8565 - _timestamp: 1656367141.0000 - _runtime: 1484.0000\n",
            "Epoch 91/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 7.4956 - f1: 0.9106 - auc: 0.9722 - accuracy: 0.9140 - val_loss: 7.4787 - val_f1: 0.4116 - val_auc: 0.8980 - val_accuracy: 0.8665 - _timestamp: 1656367155.0000 - _runtime: 1498.0000\n",
            "Epoch 92/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 7.4926 - f1: 0.9108 - auc: 0.9739 - accuracy: 0.9149 - val_loss: 7.4619 - val_f1: 0.4422 - val_auc: 0.8862 - val_accuracy: 0.8493 - _timestamp: 1656367170.0000 - _runtime: 1513.0000\n",
            "Epoch 93/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 7.4763 - f1: 0.9083 - auc: 0.9722 - accuracy: 0.9125 - val_loss: 7.4803 - val_f1: 0.4899 - val_auc: 0.8906 - val_accuracy: 0.8537 - _timestamp: 1656367186.0000 - _runtime: 1529.0000\n",
            "Epoch 94/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 7.4781 - f1: 0.9061 - auc: 0.9711 - accuracy: 0.9118 - val_loss: 7.4831 - val_f1: 0.4386 - val_auc: 0.8918 - val_accuracy: 0.8637 - _timestamp: 1656367200.0000 - _runtime: 1543.0000\n",
            "Epoch 95/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 7.4574 - f1: 0.9078 - auc: 0.9723 - accuracy: 0.9137 - val_loss: 7.4698 - val_f1: 0.4014 - val_auc: 0.8755 - val_accuracy: 0.8432 - _timestamp: 1656367214.0000 - _runtime: 1557.0000\n",
            "Epoch 96/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 7.4638 - f1: 0.9078 - auc: 0.9705 - accuracy: 0.9112 - val_loss: 7.4671 - val_f1: 0.5261 - val_auc: 0.8943 - val_accuracy: 0.8687 - _timestamp: 1656367228.0000 - _runtime: 1571.0000\n",
            "Epoch 97/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 7.4633 - f1: 0.9050 - auc: 0.9713 - accuracy: 0.9096 - val_loss: 7.4452 - val_f1: 0.5598 - val_auc: 0.8883 - val_accuracy: 0.8509 - _timestamp: 1656367242.0000 - _runtime: 1585.0000\n",
            "Epoch 98/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 7.4605 - f1: 0.9037 - auc: 0.9705 - accuracy: 0.9107 - val_loss: 7.4575 - val_f1: 0.5186 - val_auc: 0.8869 - val_accuracy: 0.8532 - _timestamp: 1656367259.0000 - _runtime: 1602.0000\n",
            "Epoch 99/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 7.4562 - f1: 0.9075 - auc: 0.9718 - accuracy: 0.9119 - val_loss: 7.4214 - val_f1: 0.5141 - val_auc: 0.9006 - val_accuracy: 0.8693 - _timestamp: 1656367273.0000 - _runtime: 1616.0000\n",
            "Epoch 100/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 7.4558 - f1: 0.9083 - auc: 0.9711 - accuracy: 0.9124 - val_loss: 7.4405 - val_f1: 0.5406 - val_auc: 0.8927 - val_accuracy: 0.8548 - _timestamp: 1656367289.0000 - _runtime: 1632.0000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a58bc5bb5ecd48c6b1cd9e21f2af7e07",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='1064.764 MB of 1064.764 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▇▇█████████████████████████████████████</td></tr><tr><td>auc</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1</td><td>▁▇▇█████████████████████████████████████</td></tr><tr><td>loss</td><td>█▇▅▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▆▆▇▇▆▆▅▇▇▄▆▄▁▆▇▆▇▇█▇▇▄▅▇▇▇▇▇▆▄█▇▇▆▇▆▅▇▅▆</td></tr><tr><td>val_auc</td><td>▁▄▆▅▇▆▅▆▇▆▆▆▂▇▇▆▆▆▇▆█▆▆▇▇▂▇▇▆▆█▆▆▆█▅▅▅▅▆</td></tr><tr><td>val_f1</td><td>▂▃▆▄▁▆▆▄▅▇▇█▇█▄█▇▅▇▆▇▇███▄▆█▄▇▇▅█▆▅▆▅▅▇▇</td></tr><tr><td>val_loss</td><td>██▆▅▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.9124</td></tr><tr><td>auc</td><td>0.97107</td></tr><tr><td>best_epoch</td><td>98</td></tr><tr><td>best_val_loss</td><td>7.42145</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>f1</td><td>0.90828</td></tr><tr><td>loss</td><td>7.45583</td></tr><tr><td>val_accuracy</td><td>0.85484</td></tr><tr><td>val_auc</td><td>0.89273</td></tr><tr><td>val_f1</td><td>0.54062</td></tr><tr><td>val_loss</td><td>7.44054</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">vague-sweep-12</strong>: <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/g8sz18zb\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/runs/g8sz18zb</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220627_213417-g8sz18zb/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: czpxvedv with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: leaky_relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_value: 0.31098826932757356\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.30000000000000004\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons: 5000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptomizer: adadelta\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_factor: 5e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_type: l1_l2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.19"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220627_220154-czpxvedv</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/czpxvedv\" target=\"_blank\">visionary-sweep-13</a></strong> to <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 25008)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5000)              125045000 \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 5000)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 5001      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 125,050,001\n",
            "Trainable params: 125,050,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "380/380 [==============================] - 17s 41ms/step - loss: 45.3134 - f1: 0.3918 - auc: 0.5753 - accuracy: 0.4883 - val_loss: 45.2913 - val_f1: 0.2272 - val_auc: 0.5104 - val_accuracy: 0.6352 - _timestamp: 1656367332.0000 - _runtime: 18.0000\n",
            "Epoch 2/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.3072 - f1: 0.4297 - auc: 0.5211 - accuracy: 0.5100 - val_loss: 45.2905 - val_f1: 0.2433 - val_auc: 0.5395 - val_accuracy: 0.6224 - _timestamp: 1656367347.0000 - _runtime: 33.0000\n",
            "Epoch 3/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.3031 - f1: 0.4624 - auc: 0.5391 - accuracy: 0.5242 - val_loss: 45.2895 - val_f1: 0.2532 - val_auc: 0.5652 - val_accuracy: 0.6085 - _timestamp: 1656367364.0000 - _runtime: 50.0000\n",
            "Epoch 4/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 45.2993 - f1: 0.4768 - auc: 0.5521 - accuracy: 0.5280 - val_loss: 45.2885 - val_f1: 0.2758 - val_auc: 0.5939 - val_accuracy: 0.6007 - _timestamp: 1656367381.0000 - _runtime: 67.0000\n",
            "Epoch 5/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 45.2939 - f1: 0.5159 - auc: 0.5753 - accuracy: 0.5515 - val_loss: 45.2874 - val_f1: 0.2971 - val_auc: 0.6170 - val_accuracy: 0.5984 - _timestamp: 1656367398.0000 - _runtime: 84.0000\n",
            "Epoch 6/100\n",
            "380/380 [==============================] - 14s 38ms/step - loss: 45.2890 - f1: 0.5436 - auc: 0.5976 - accuracy: 0.5662 - val_loss: 45.2862 - val_f1: 0.3188 - val_auc: 0.6396 - val_accuracy: 0.5940 - _timestamp: 1656367414.0000 - _runtime: 100.0000\n",
            "Epoch 7/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 45.2859 - f1: 0.5668 - auc: 0.6077 - accuracy: 0.5792 - val_loss: 45.2848 - val_f1: 0.3333 - val_auc: 0.6598 - val_accuracy: 0.5868 - _timestamp: 1656367429.0000 - _runtime: 115.0000\n",
            "Epoch 8/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.2802 - f1: 0.5951 - auc: 0.6335 - accuracy: 0.5983 - val_loss: 45.2834 - val_f1: 0.3412 - val_auc: 0.6787 - val_accuracy: 0.5806 - _timestamp: 1656367443.0000 - _runtime: 129.0000\n",
            "Epoch 9/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 45.2759 - f1: 0.6066 - auc: 0.6465 - accuracy: 0.6022 - val_loss: 45.2819 - val_f1: 0.3528 - val_auc: 0.6960 - val_accuracy: 0.5823 - _timestamp: 1656367461.0000 - _runtime: 147.0000\n",
            "Epoch 10/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.2731 - f1: 0.6238 - auc: 0.6550 - accuracy: 0.6121 - val_loss: 45.2803 - val_f1: 0.3561 - val_auc: 0.7126 - val_accuracy: 0.5784 - _timestamp: 1656367475.0000 - _runtime: 161.0000\n",
            "Epoch 11/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.2686 - f1: 0.6446 - auc: 0.6726 - accuracy: 0.6287 - val_loss: 45.2786 - val_f1: 0.3650 - val_auc: 0.7250 - val_accuracy: 0.5734 - _timestamp: 1656367493.0000 - _runtime: 179.0000\n",
            "Epoch 12/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 45.2631 - f1: 0.6587 - auc: 0.6905 - accuracy: 0.6399 - val_loss: 45.2768 - val_f1: 0.3723 - val_auc: 0.7385 - val_accuracy: 0.5740 - _timestamp: 1656367510.0000 - _runtime: 196.0000\n",
            "Epoch 13/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.2605 - f1: 0.6725 - auc: 0.6985 - accuracy: 0.6501 - val_loss: 45.2750 - val_f1: 0.3742 - val_auc: 0.7486 - val_accuracy: 0.5706 - _timestamp: 1656367527.0000 - _runtime: 213.0000\n",
            "Epoch 14/100\n",
            "380/380 [==============================] - 17s 44ms/step - loss: 45.2562 - f1: 0.6794 - auc: 0.7082 - accuracy: 0.6531 - val_loss: 45.2731 - val_f1: 0.3771 - val_auc: 0.7596 - val_accuracy: 0.5684 - _timestamp: 1656367544.0000 - _runtime: 230.0000\n",
            "Epoch 15/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.2517 - f1: 0.6982 - auc: 0.7246 - accuracy: 0.6695 - val_loss: 45.2711 - val_f1: 0.3817 - val_auc: 0.7695 - val_accuracy: 0.5679 - _timestamp: 1656367561.0000 - _runtime: 247.0000\n",
            "Epoch 16/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 45.2482 - f1: 0.7003 - auc: 0.7314 - accuracy: 0.6714 - val_loss: 45.2691 - val_f1: 0.3827 - val_auc: 0.7760 - val_accuracy: 0.5628 - _timestamp: 1656367578.0000 - _runtime: 264.0000\n",
            "Epoch 17/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 45.2434 - f1: 0.7141 - auc: 0.7457 - accuracy: 0.6830 - val_loss: 45.2671 - val_f1: 0.3836 - val_auc: 0.7852 - val_accuracy: 0.5584 - _timestamp: 1656367594.0000 - _runtime: 280.0000\n",
            "Epoch 18/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.2394 - f1: 0.7258 - auc: 0.7558 - accuracy: 0.6946 - val_loss: 45.2649 - val_f1: 0.3896 - val_auc: 0.7917 - val_accuracy: 0.5601 - _timestamp: 1656367610.0000 - _runtime: 296.0000\n",
            "Epoch 19/100\n",
            "380/380 [==============================] - 15s 40ms/step - loss: 45.2362 - f1: 0.7276 - auc: 0.7597 - accuracy: 0.6955 - val_loss: 45.2627 - val_f1: 0.3904 - val_auc: 0.7986 - val_accuracy: 0.5623 - _timestamp: 1656367627.0000 - _runtime: 313.0000\n",
            "Epoch 20/100\n",
            "380/380 [==============================] - 17s 44ms/step - loss: 45.2326 - f1: 0.7337 - auc: 0.7678 - accuracy: 0.6994 - val_loss: 45.2604 - val_f1: 0.3935 - val_auc: 0.8042 - val_accuracy: 0.5640 - _timestamp: 1656367642.0000 - _runtime: 328.0000\n",
            "Epoch 21/100\n",
            "380/380 [==============================] - 18s 46ms/step - loss: 45.2286 - f1: 0.7376 - auc: 0.7740 - accuracy: 0.7055 - val_loss: 45.2582 - val_f1: 0.3947 - val_auc: 0.8095 - val_accuracy: 0.5628 - _timestamp: 1656367659.0000 - _runtime: 345.0000\n",
            "Epoch 22/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 45.2254 - f1: 0.7390 - auc: 0.7767 - accuracy: 0.7045 - val_loss: 45.2558 - val_f1: 0.3944 - val_auc: 0.8131 - val_accuracy: 0.5628 - _timestamp: 1656367677.0000 - _runtime: 363.0000\n",
            "Epoch 23/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.2225 - f1: 0.7422 - auc: 0.7793 - accuracy: 0.7087 - val_loss: 45.2534 - val_f1: 0.3957 - val_auc: 0.8171 - val_accuracy: 0.5662 - _timestamp: 1656367694.0000 - _runtime: 380.0000\n",
            "Epoch 24/100\n",
            "380/380 [==============================] - 17s 44ms/step - loss: 45.2178 - f1: 0.7533 - auc: 0.7909 - accuracy: 0.7183 - val_loss: 45.2509 - val_f1: 0.3961 - val_auc: 0.8202 - val_accuracy: 0.5673 - _timestamp: 1656367711.0000 - _runtime: 397.0000\n",
            "Epoch 25/100\n",
            "380/380 [==============================] - 16s 42ms/step - loss: 45.2128 - f1: 0.7599 - auc: 0.8041 - accuracy: 0.7269 - val_loss: 45.2484 - val_f1: 0.3955 - val_auc: 0.8241 - val_accuracy: 0.5651 - _timestamp: 1656367728.0000 - _runtime: 414.0000\n",
            "Epoch 26/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.2103 - f1: 0.7620 - auc: 0.8041 - accuracy: 0.7290 - val_loss: 45.2459 - val_f1: 0.3949 - val_auc: 0.8275 - val_accuracy: 0.5662 - _timestamp: 1656367744.0000 - _runtime: 430.0000\n",
            "Epoch 27/100\n",
            "380/380 [==============================] - 16s 42ms/step - loss: 45.2069 - f1: 0.7620 - auc: 0.8092 - accuracy: 0.7280 - val_loss: 45.2433 - val_f1: 0.3958 - val_auc: 0.8305 - val_accuracy: 0.5673 - _timestamp: 1656367761.0000 - _runtime: 447.0000\n",
            "Epoch 28/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.2022 - f1: 0.7702 - auc: 0.8171 - accuracy: 0.7370 - val_loss: 45.2407 - val_f1: 0.3973 - val_auc: 0.8330 - val_accuracy: 0.5695 - _timestamp: 1656367777.0000 - _runtime: 463.0000\n",
            "Epoch 29/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 45.2004 - f1: 0.7668 - auc: 0.8148 - accuracy: 0.7318 - val_loss: 45.2380 - val_f1: 0.3997 - val_auc: 0.8348 - val_accuracy: 0.5723 - _timestamp: 1656367794.0000 - _runtime: 480.0000\n",
            "Epoch 30/100\n",
            "380/380 [==============================] - 14s 38ms/step - loss: 45.1974 - f1: 0.7680 - auc: 0.8167 - accuracy: 0.7358 - val_loss: 45.2355 - val_f1: 0.4020 - val_auc: 0.8377 - val_accuracy: 0.5756 - _timestamp: 1656367808.0000 - _runtime: 494.0000\n",
            "Epoch 31/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.1923 - f1: 0.7739 - auc: 0.8259 - accuracy: 0.7407 - val_loss: 45.2328 - val_f1: 0.4056 - val_auc: 0.8394 - val_accuracy: 0.5801 - _timestamp: 1656367823.0000 - _runtime: 509.0000\n",
            "Epoch 32/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.1889 - f1: 0.7745 - auc: 0.8290 - accuracy: 0.7401 - val_loss: 45.2301 - val_f1: 0.4065 - val_auc: 0.8413 - val_accuracy: 0.5818 - _timestamp: 1656367840.0000 - _runtime: 526.0000\n",
            "Epoch 33/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.1861 - f1: 0.7799 - auc: 0.8305 - accuracy: 0.7467 - val_loss: 45.2274 - val_f1: 0.4083 - val_auc: 0.8430 - val_accuracy: 0.5857 - _timestamp: 1656367857.0000 - _runtime: 543.0000\n",
            "Epoch 34/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 45.1822 - f1: 0.7799 - auc: 0.8325 - accuracy: 0.7479 - val_loss: 45.2246 - val_f1: 0.4065 - val_auc: 0.8449 - val_accuracy: 0.5857 - _timestamp: 1656367874.0000 - _runtime: 560.0000\n",
            "Epoch 35/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.1800 - f1: 0.7811 - auc: 0.8340 - accuracy: 0.7472 - val_loss: 45.2219 - val_f1: 0.4086 - val_auc: 0.8467 - val_accuracy: 0.5884 - _timestamp: 1656367891.0000 - _runtime: 577.0000\n",
            "Epoch 36/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 45.1756 - f1: 0.7845 - auc: 0.8402 - accuracy: 0.7518 - val_loss: 45.2191 - val_f1: 0.4109 - val_auc: 0.8479 - val_accuracy: 0.5923 - _timestamp: 1656367909.0000 - _runtime: 595.0000\n",
            "Epoch 37/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 45.1716 - f1: 0.7870 - auc: 0.8456 - accuracy: 0.7571 - val_loss: 45.2163 - val_f1: 0.4120 - val_auc: 0.8488 - val_accuracy: 0.5945 - _timestamp: 1656367924.0000 - _runtime: 610.0000\n",
            "Epoch 38/100\n",
            "380/380 [==============================] - 19s 51ms/step - loss: 45.1681 - f1: 0.7870 - auc: 0.8480 - accuracy: 0.7546 - val_loss: 45.2135 - val_f1: 0.4134 - val_auc: 0.8502 - val_accuracy: 0.5973 - _timestamp: 1656367939.0000 - _runtime: 625.0000\n",
            "Epoch 39/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 45.1664 - f1: 0.7842 - auc: 0.8445 - accuracy: 0.7530 - val_loss: 45.2106 - val_f1: 0.4153 - val_auc: 0.8515 - val_accuracy: 0.6007 - _timestamp: 1656367958.0000 - _runtime: 644.0000\n",
            "Epoch 40/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 45.1620 - f1: 0.7915 - auc: 0.8499 - accuracy: 0.7596 - val_loss: 45.2078 - val_f1: 0.4164 - val_auc: 0.8524 - val_accuracy: 0.6023 - _timestamp: 1656367973.0000 - _runtime: 659.0000\n",
            "Epoch 41/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.1591 - f1: 0.7911 - auc: 0.8524 - accuracy: 0.7590 - val_loss: 45.2049 - val_f1: 0.4183 - val_auc: 0.8536 - val_accuracy: 0.6062 - _timestamp: 1656367988.0000 - _runtime: 674.0000\n",
            "Epoch 42/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.1561 - f1: 0.7934 - auc: 0.8530 - accuracy: 0.7647 - val_loss: 45.2021 - val_f1: 0.4188 - val_auc: 0.8548 - val_accuracy: 0.6090 - _timestamp: 1656368005.0000 - _runtime: 691.0000\n",
            "Epoch 43/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.1519 - f1: 0.7949 - auc: 0.8572 - accuracy: 0.7658 - val_loss: 45.1992 - val_f1: 0.4211 - val_auc: 0.8557 - val_accuracy: 0.6129 - _timestamp: 1656368022.0000 - _runtime: 708.0000\n",
            "Epoch 44/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.1486 - f1: 0.7955 - auc: 0.8588 - accuracy: 0.7672 - val_loss: 45.1963 - val_f1: 0.4234 - val_auc: 0.8558 - val_accuracy: 0.6151 - _timestamp: 1656368039.0000 - _runtime: 725.0000\n",
            "Epoch 45/100\n",
            "380/380 [==============================] - 17s 44ms/step - loss: 45.1461 - f1: 0.7954 - auc: 0.8589 - accuracy: 0.7659 - val_loss: 45.1934 - val_f1: 0.4234 - val_auc: 0.8564 - val_accuracy: 0.6168 - _timestamp: 1656368056.0000 - _runtime: 742.0000\n",
            "Epoch 46/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.1422 - f1: 0.8026 - auc: 0.8616 - accuracy: 0.7746 - val_loss: 45.1905 - val_f1: 0.4257 - val_auc: 0.8570 - val_accuracy: 0.6196 - _timestamp: 1656368073.0000 - _runtime: 759.0000\n",
            "Epoch 47/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 45.1388 - f1: 0.7954 - auc: 0.8627 - accuracy: 0.7670 - val_loss: 45.1876 - val_f1: 0.4268 - val_auc: 0.8577 - val_accuracy: 0.6212 - _timestamp: 1656368090.0000 - _runtime: 776.0000\n",
            "Epoch 48/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.1359 - f1: 0.8001 - auc: 0.8678 - accuracy: 0.7730 - val_loss: 45.1847 - val_f1: 0.4290 - val_auc: 0.8586 - val_accuracy: 0.6246 - _timestamp: 1656368105.0000 - _runtime: 791.0000\n",
            "Epoch 49/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 45.1329 - f1: 0.8043 - auc: 0.8652 - accuracy: 0.7769 - val_loss: 45.1817 - val_f1: 0.4313 - val_auc: 0.8591 - val_accuracy: 0.6285 - _timestamp: 1656368122.0000 - _runtime: 808.0000\n",
            "Epoch 50/100\n",
            "380/380 [==============================] - 16s 42ms/step - loss: 45.1293 - f1: 0.8000 - auc: 0.8667 - accuracy: 0.7725 - val_loss: 45.1788 - val_f1: 0.4331 - val_auc: 0.8596 - val_accuracy: 0.6318 - _timestamp: 1656368137.0000 - _runtime: 823.0000\n",
            "Epoch 51/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 45.1263 - f1: 0.8012 - auc: 0.8689 - accuracy: 0.7740 - val_loss: 45.1759 - val_f1: 0.4351 - val_auc: 0.8603 - val_accuracy: 0.6352 - _timestamp: 1656368153.0000 - _runtime: 839.0000\n",
            "Epoch 52/100\n",
            "380/380 [==============================] - 17s 44ms/step - loss: 45.1235 - f1: 0.8016 - auc: 0.8700 - accuracy: 0.7757 - val_loss: 45.1730 - val_f1: 0.4373 - val_auc: 0.8613 - val_accuracy: 0.6379 - _timestamp: 1656368170.0000 - _runtime: 856.0000\n",
            "Epoch 53/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 45.1206 - f1: 0.8053 - auc: 0.8711 - accuracy: 0.7797 - val_loss: 45.1701 - val_f1: 0.4387 - val_auc: 0.8614 - val_accuracy: 0.6407 - _timestamp: 1656368187.0000 - _runtime: 873.0000\n",
            "Epoch 54/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.1168 - f1: 0.8035 - auc: 0.8716 - accuracy: 0.7781 - val_loss: 45.1672 - val_f1: 0.4402 - val_auc: 0.8620 - val_accuracy: 0.6429 - _timestamp: 1656368203.0000 - _runtime: 889.0000\n",
            "Epoch 55/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.1141 - f1: 0.8068 - auc: 0.8712 - accuracy: 0.7813 - val_loss: 45.1643 - val_f1: 0.4425 - val_auc: 0.8625 - val_accuracy: 0.6457 - _timestamp: 1656368220.0000 - _runtime: 906.0000\n",
            "Epoch 56/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.1106 - f1: 0.8115 - auc: 0.8757 - accuracy: 0.7879 - val_loss: 45.1614 - val_f1: 0.4444 - val_auc: 0.8627 - val_accuracy: 0.6485 - _timestamp: 1656368237.0000 - _runtime: 923.0000\n",
            "Epoch 57/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 45.1079 - f1: 0.8079 - auc: 0.8757 - accuracy: 0.7845 - val_loss: 45.1585 - val_f1: 0.4460 - val_auc: 0.8635 - val_accuracy: 0.6507 - _timestamp: 1656368254.0000 - _runtime: 940.0000\n",
            "Epoch 58/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.1054 - f1: 0.8091 - auc: 0.8746 - accuracy: 0.7861 - val_loss: 45.1556 - val_f1: 0.4473 - val_auc: 0.8637 - val_accuracy: 0.6529 - _timestamp: 1656368270.0000 - _runtime: 956.0000\n",
            "Epoch 59/100\n",
            "380/380 [==============================] - 15s 41ms/step - loss: 45.1007 - f1: 0.8092 - auc: 0.8802 - accuracy: 0.7859 - val_loss: 45.1527 - val_f1: 0.4503 - val_auc: 0.8636 - val_accuracy: 0.6563 - _timestamp: 1656368287.0000 - _runtime: 973.0000\n",
            "Epoch 60/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 45.0988 - f1: 0.8111 - auc: 0.8784 - accuracy: 0.7868 - val_loss: 45.1498 - val_f1: 0.4530 - val_auc: 0.8638 - val_accuracy: 0.6607 - _timestamp: 1656368303.0000 - _runtime: 989.0000\n",
            "Epoch 61/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 45.0953 - f1: 0.8144 - auc: 0.8800 - accuracy: 0.7925 - val_loss: 45.1469 - val_f1: 0.4546 - val_auc: 0.8643 - val_accuracy: 0.6630 - _timestamp: 1656368317.0000 - _runtime: 1003.0000\n",
            "Epoch 62/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 45.0920 - f1: 0.8125 - auc: 0.8836 - accuracy: 0.7879 - val_loss: 45.1441 - val_f1: 0.4572 - val_auc: 0.8644 - val_accuracy: 0.6663 - _timestamp: 1656368332.0000 - _runtime: 1018.0000\n",
            "Epoch 63/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.0891 - f1: 0.8127 - auc: 0.8826 - accuracy: 0.7895 - val_loss: 45.1412 - val_f1: 0.4585 - val_auc: 0.8647 - val_accuracy: 0.6685 - _timestamp: 1656368346.0000 - _runtime: 1032.0000\n",
            "Epoch 64/100\n",
            "380/380 [==============================] - 15s 38ms/step - loss: 45.0854 - f1: 0.8131 - auc: 0.8855 - accuracy: 0.7908 - val_loss: 45.1384 - val_f1: 0.4585 - val_auc: 0.8649 - val_accuracy: 0.6685 - _timestamp: 1656368363.0000 - _runtime: 1049.0000\n",
            "Epoch 65/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 45.0823 - f1: 0.8176 - auc: 0.8866 - accuracy: 0.7962 - val_loss: 45.1355 - val_f1: 0.4600 - val_auc: 0.8653 - val_accuracy: 0.6702 - _timestamp: 1656368378.0000 - _runtime: 1064.0000\n",
            "Epoch 66/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.0815 - f1: 0.8156 - auc: 0.8829 - accuracy: 0.7932 - val_loss: 45.1326 - val_f1: 0.4607 - val_auc: 0.8653 - val_accuracy: 0.6713 - _timestamp: 1656368395.0000 - _runtime: 1081.0000\n",
            "Epoch 67/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.0770 - f1: 0.8186 - auc: 0.8873 - accuracy: 0.7971 - val_loss: 45.1297 - val_f1: 0.4619 - val_auc: 0.8655 - val_accuracy: 0.6735 - _timestamp: 1656368413.0000 - _runtime: 1099.0000\n",
            "Epoch 68/100\n",
            "380/380 [==============================] - 15s 40ms/step - loss: 45.0736 - f1: 0.8182 - auc: 0.8861 - accuracy: 0.7983 - val_loss: 45.1269 - val_f1: 0.4636 - val_auc: 0.8661 - val_accuracy: 0.6758 - _timestamp: 1656368430.0000 - _runtime: 1116.0000\n",
            "Epoch 69/100\n",
            "380/380 [==============================] - 17s 44ms/step - loss: 45.0712 - f1: 0.8171 - auc: 0.8870 - accuracy: 0.7969 - val_loss: 45.1241 - val_f1: 0.4649 - val_auc: 0.8664 - val_accuracy: 0.6780 - _timestamp: 1656368445.0000 - _runtime: 1131.0000\n",
            "Epoch 70/100\n",
            "380/380 [==============================] - 18s 47ms/step - loss: 45.0689 - f1: 0.8187 - auc: 0.8873 - accuracy: 0.7975 - val_loss: 45.1213 - val_f1: 0.4651 - val_auc: 0.8665 - val_accuracy: 0.6791 - _timestamp: 1656368462.0000 - _runtime: 1148.0000\n",
            "Epoch 71/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 45.0653 - f1: 0.8199 - auc: 0.8888 - accuracy: 0.7998 - val_loss: 45.1184 - val_f1: 0.4657 - val_auc: 0.8668 - val_accuracy: 0.6808 - _timestamp: 1656368479.0000 - _runtime: 1165.0000\n",
            "Epoch 72/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.0619 - f1: 0.8235 - auc: 0.8914 - accuracy: 0.8027 - val_loss: 45.1156 - val_f1: 0.4677 - val_auc: 0.8670 - val_accuracy: 0.6830 - _timestamp: 1656368494.0000 - _runtime: 1180.0000\n",
            "Epoch 73/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.0585 - f1: 0.8209 - auc: 0.8926 - accuracy: 0.8003 - val_loss: 45.1127 - val_f1: 0.4703 - val_auc: 0.8670 - val_accuracy: 0.6858 - _timestamp: 1656368511.0000 - _runtime: 1197.0000\n",
            "Epoch 74/100\n",
            "380/380 [==============================] - 15s 38ms/step - loss: 45.0565 - f1: 0.8212 - auc: 0.8898 - accuracy: 0.8019 - val_loss: 45.1099 - val_f1: 0.4709 - val_auc: 0.8673 - val_accuracy: 0.6869 - _timestamp: 1656368528.0000 - _runtime: 1214.0000\n",
            "Epoch 75/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.0539 - f1: 0.8232 - auc: 0.8905 - accuracy: 0.8044 - val_loss: 45.1071 - val_f1: 0.4709 - val_auc: 0.8675 - val_accuracy: 0.6869 - _timestamp: 1656368542.0000 - _runtime: 1228.0000\n",
            "Epoch 76/100\n",
            "380/380 [==============================] - 15s 38ms/step - loss: 45.0507 - f1: 0.8245 - auc: 0.8927 - accuracy: 0.8068 - val_loss: 45.1044 - val_f1: 0.4717 - val_auc: 0.8675 - val_accuracy: 0.6885 - _timestamp: 1656368560.0000 - _runtime: 1246.0000\n",
            "Epoch 77/100\n",
            "380/380 [==============================] - 18s 48ms/step - loss: 45.0479 - f1: 0.8251 - auc: 0.8921 - accuracy: 0.8060 - val_loss: 45.1016 - val_f1: 0.4731 - val_auc: 0.8675 - val_accuracy: 0.6908 - _timestamp: 1656368574.0000 - _runtime: 1260.0000\n",
            "Epoch 78/100\n",
            "380/380 [==============================] - 15s 38ms/step - loss: 45.0455 - f1: 0.8242 - auc: 0.8934 - accuracy: 0.8058 - val_loss: 45.0988 - val_f1: 0.4735 - val_auc: 0.8676 - val_accuracy: 0.6919 - _timestamp: 1656368592.0000 - _runtime: 1278.0000\n",
            "Epoch 79/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 45.0418 - f1: 0.8247 - auc: 0.8941 - accuracy: 0.8061 - val_loss: 45.0960 - val_f1: 0.4758 - val_auc: 0.8678 - val_accuracy: 0.6947 - _timestamp: 1656368607.0000 - _runtime: 1293.0000\n",
            "Epoch 80/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 45.0395 - f1: 0.8246 - auc: 0.8940 - accuracy: 0.8064 - val_loss: 45.0932 - val_f1: 0.4762 - val_auc: 0.8678 - val_accuracy: 0.6958 - _timestamp: 1656368622.0000 - _runtime: 1308.0000\n",
            "Epoch 81/100\n",
            "380/380 [==============================] - 14s 38ms/step - loss: 45.0359 - f1: 0.8251 - auc: 0.8967 - accuracy: 0.8066 - val_loss: 45.0905 - val_f1: 0.4782 - val_auc: 0.8680 - val_accuracy: 0.6974 - _timestamp: 1656368638.0000 - _runtime: 1324.0000\n",
            "Epoch 82/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 45.0330 - f1: 0.8264 - auc: 0.8973 - accuracy: 0.8088 - val_loss: 45.0878 - val_f1: 0.4794 - val_auc: 0.8682 - val_accuracy: 0.6991 - _timestamp: 1656368653.0000 - _runtime: 1339.0000\n",
            "Epoch 83/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.0317 - f1: 0.8265 - auc: 0.8946 - accuracy: 0.8079 - val_loss: 45.0851 - val_f1: 0.4813 - val_auc: 0.8684 - val_accuracy: 0.7019 - _timestamp: 1656368670.0000 - _runtime: 1356.0000\n",
            "Epoch 84/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 45.0281 - f1: 0.8265 - auc: 0.8960 - accuracy: 0.8097 - val_loss: 45.0823 - val_f1: 0.4824 - val_auc: 0.8685 - val_accuracy: 0.7030 - _timestamp: 1656368687.0000 - _runtime: 1373.0000\n",
            "Epoch 85/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 45.0265 - f1: 0.8261 - auc: 0.8934 - accuracy: 0.8095 - val_loss: 45.0796 - val_f1: 0.4824 - val_auc: 0.8686 - val_accuracy: 0.7030 - _timestamp: 1656368702.0000 - _runtime: 1388.0000\n",
            "Epoch 86/100\n",
            "380/380 [==============================] - 17s 44ms/step - loss: 45.0210 - f1: 0.8286 - auc: 0.8997 - accuracy: 0.8116 - val_loss: 45.0769 - val_f1: 0.4830 - val_auc: 0.8688 - val_accuracy: 0.7036 - _timestamp: 1656368719.0000 - _runtime: 1405.0000\n",
            "Epoch 87/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 45.0198 - f1: 0.8273 - auc: 0.8969 - accuracy: 0.8116 - val_loss: 45.0742 - val_f1: 0.4843 - val_auc: 0.8688 - val_accuracy: 0.7047 - _timestamp: 1656368736.0000 - _runtime: 1422.0000\n",
            "Epoch 88/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 45.0178 - f1: 0.8283 - auc: 0.8971 - accuracy: 0.8116 - val_loss: 45.0715 - val_f1: 0.4868 - val_auc: 0.8688 - val_accuracy: 0.7069 - _timestamp: 1656368753.0000 - _runtime: 1439.0000\n",
            "Epoch 89/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 45.0129 - f1: 0.8315 - auc: 0.9010 - accuracy: 0.8150 - val_loss: 45.0688 - val_f1: 0.4878 - val_auc: 0.8690 - val_accuracy: 0.7091 - _timestamp: 1656368768.0000 - _runtime: 1454.0000\n",
            "Epoch 90/100\n",
            "380/380 [==============================] - 18s 47ms/step - loss: 45.0117 - f1: 0.8309 - auc: 0.8987 - accuracy: 0.8149 - val_loss: 45.0661 - val_f1: 0.4878 - val_auc: 0.8692 - val_accuracy: 0.7091 - _timestamp: 1656368784.0000 - _runtime: 1470.0000\n",
            "Epoch 91/100\n",
            "380/380 [==============================] - 17s 44ms/step - loss: 45.0092 - f1: 0.8293 - auc: 0.8975 - accuracy: 0.8131 - val_loss: 45.0634 - val_f1: 0.4882 - val_auc: 0.8695 - val_accuracy: 0.7102 - _timestamp: 1656368802.0000 - _runtime: 1488.0000\n",
            "Epoch 92/100\n",
            "380/380 [==============================] - 18s 46ms/step - loss: 45.0056 - f1: 0.8342 - auc: 0.9008 - accuracy: 0.8185 - val_loss: 45.0608 - val_f1: 0.4882 - val_auc: 0.8693 - val_accuracy: 0.7102 - _timestamp: 1656368819.0000 - _runtime: 1505.0000\n",
            "Epoch 93/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 45.0043 - f1: 0.8288 - auc: 0.8982 - accuracy: 0.8121 - val_loss: 45.0581 - val_f1: 0.4887 - val_auc: 0.8693 - val_accuracy: 0.7113 - _timestamp: 1656368836.0000 - _runtime: 1522.0000\n",
            "Epoch 94/100\n",
            "380/380 [==============================] - 17s 44ms/step - loss: 45.0020 - f1: 0.8304 - auc: 0.8995 - accuracy: 0.8148 - val_loss: 45.0555 - val_f1: 0.4894 - val_auc: 0.8694 - val_accuracy: 0.7119 - _timestamp: 1656368851.0000 - _runtime: 1537.0000\n",
            "Epoch 95/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 44.9981 - f1: 0.8313 - auc: 0.9013 - accuracy: 0.8152 - val_loss: 45.0528 - val_f1: 0.4905 - val_auc: 0.8695 - val_accuracy: 0.7130 - _timestamp: 1656368868.0000 - _runtime: 1554.0000\n",
            "Epoch 96/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 44.9963 - f1: 0.8323 - auc: 0.9009 - accuracy: 0.8167 - val_loss: 45.0502 - val_f1: 0.4905 - val_auc: 0.8692 - val_accuracy: 0.7130 - _timestamp: 1656368882.0000 - _runtime: 1568.0000\n",
            "Epoch 97/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 44.9939 - f1: 0.8314 - auc: 0.8994 - accuracy: 0.8166 - val_loss: 45.0476 - val_f1: 0.4910 - val_auc: 0.8695 - val_accuracy: 0.7136 - _timestamp: 1656368899.0000 - _runtime: 1585.0000\n",
            "Epoch 98/100\n",
            "380/380 [==============================] - 17s 44ms/step - loss: 44.9910 - f1: 0.8332 - auc: 0.9012 - accuracy: 0.8181 - val_loss: 45.0450 - val_f1: 0.4922 - val_auc: 0.8698 - val_accuracy: 0.7152 - _timestamp: 1656368916.0000 - _runtime: 1602.0000\n",
            "Epoch 99/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 44.9876 - f1: 0.8357 - auc: 0.9014 - accuracy: 0.8212 - val_loss: 45.0424 - val_f1: 0.4936 - val_auc: 0.8699 - val_accuracy: 0.7175 - _timestamp: 1656368933.0000 - _runtime: 1619.0000\n",
            "Epoch 100/100\n",
            "380/380 [==============================] - 17s 45ms/step - loss: 44.9859 - f1: 0.8325 - auc: 0.9011 - accuracy: 0.8172 - val_loss: 45.0398 - val_f1: 0.4946 - val_auc: 0.8696 - val_accuracy: 0.7186 - _timestamp: 1656368949.0000 - _runtime: 1635.0000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc19544654fd4ec5a1570f30e61ae58e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='1431.113 MB of 1431.113 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▂▃▃▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>auc</td><td>▂▁▂▃▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1</td><td>▁▂▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇██▇███████████████████</td></tr><tr><td>loss</td><td>██▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▄▃▂▂▂▁▁▁▁▁▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>val_auc</td><td>▁▂▄▄▅▆▆▆▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_f1</td><td>▁▂▃▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>val_loss</td><td>██████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.81722</td></tr><tr><td>auc</td><td>0.90112</td></tr><tr><td>best_epoch</td><td>99</td></tr><tr><td>best_val_loss</td><td>45.03984</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>f1</td><td>0.83249</td></tr><tr><td>loss</td><td>44.98587</td></tr><tr><td>val_accuracy</td><td>0.71858</td></tr><tr><td>val_auc</td><td>0.86961</td></tr><tr><td>val_f1</td><td>0.49459</td></tr><tr><td>val_loss</td><td>45.03984</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">visionary-sweep-13</strong>: <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/czpxvedv\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/runs/czpxvedv</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220627_220154-czpxvedv/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nzy1zfxm with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_value: 0.4996336220214052\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.30000000000000004\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons: 5000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptomizer: adagrad\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_factor: 5e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_type: l1_l2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.19"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220627_223007-nzy1zfxm</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/nzy1zfxm\" target=\"_blank\">likely-sweep-14</a></strong> to <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 25008)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5000)              125045000 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 5000)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5000)              25005000  \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 5000)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5000)              25005000  \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 5000)              0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5000)              25005000  \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 5000)              0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 5000)              25005000  \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 5000)              0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 5001      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 225,070,001\n",
            "Trainable params: 225,070,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "380/380 [==============================] - 27s 66ms/step - loss: 107.5347 - f1: 0.4345 - auc: 0.5457 - accuracy: 0.4973 - val_loss: 107.5106 - val_f1: 0.1657 - val_auc: 0.5061 - val_accuracy: 0.7303 - _timestamp: 1656369033.0000 - _runtime: 26.0000\n",
            "Epoch 2/100\n",
            "380/380 [==============================] - 21s 55ms/step - loss: 107.4978 - f1: 0.4703 - auc: 0.5182 - accuracy: 0.5089 - val_loss: 107.4761 - val_f1: 0.3086 - val_auc: 0.6149 - val_accuracy: 0.7136 - _timestamp: 1656369058.0000 - _runtime: 51.0000\n",
            "Epoch 3/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 107.4612 - f1: 0.5080 - auc: 0.5408 - accuracy: 0.5268 - val_loss: 107.4412 - val_f1: 0.3866 - val_auc: 0.6955 - val_accuracy: 0.6919 - _timestamp: 1656369078.0000 - _runtime: 71.0000\n",
            "Epoch 4/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 107.4238 - f1: 0.5415 - auc: 0.5709 - accuracy: 0.5541 - val_loss: 107.4061 - val_f1: 0.4097 - val_auc: 0.7499 - val_accuracy: 0.6646 - _timestamp: 1656369099.0000 - _runtime: 92.0000\n",
            "Epoch 5/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 107.3875 - f1: 0.5552 - auc: 0.5857 - accuracy: 0.5641 - val_loss: 107.3709 - val_f1: 0.4193 - val_auc: 0.7937 - val_accuracy: 0.6296 - _timestamp: 1656369121.0000 - _runtime: 114.0000\n",
            "Epoch 6/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 107.3507 - f1: 0.5785 - auc: 0.6122 - accuracy: 0.5790 - val_loss: 107.3355 - val_f1: 0.4233 - val_auc: 0.8097 - val_accuracy: 0.6212 - _timestamp: 1656369143.0000 - _runtime: 136.0000\n",
            "Epoch 7/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 107.3142 - f1: 0.5952 - auc: 0.6279 - accuracy: 0.5958 - val_loss: 107.3001 - val_f1: 0.4210 - val_auc: 0.8309 - val_accuracy: 0.6085 - _timestamp: 1656369165.0000 - _runtime: 158.0000\n",
            "Epoch 8/100\n",
            "380/380 [==============================] - 23s 60ms/step - loss: 107.2771 - f1: 0.6178 - auc: 0.6542 - accuracy: 0.6121 - val_loss: 107.2647 - val_f1: 0.4210 - val_auc: 0.8363 - val_accuracy: 0.5996 - _timestamp: 1656369187.0000 - _runtime: 180.0000\n",
            "Epoch 9/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 107.2404 - f1: 0.6300 - auc: 0.6713 - accuracy: 0.6274 - val_loss: 107.2292 - val_f1: 0.4192 - val_auc: 0.8411 - val_accuracy: 0.5923 - _timestamp: 1656369210.0000 - _runtime: 203.0000\n",
            "Epoch 10/100\n",
            "380/380 [==============================] - 23s 60ms/step - loss: 107.2041 - f1: 0.6485 - auc: 0.6829 - accuracy: 0.6372 - val_loss: 107.1936 - val_f1: 0.4210 - val_auc: 0.8484 - val_accuracy: 0.5918 - _timestamp: 1656369230.0000 - _runtime: 223.0000\n",
            "Epoch 11/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 107.1662 - f1: 0.6681 - auc: 0.7137 - accuracy: 0.6605 - val_loss: 107.1582 - val_f1: 0.4169 - val_auc: 0.8508 - val_accuracy: 0.5829 - _timestamp: 1656369253.0000 - _runtime: 246.0000\n",
            "Epoch 12/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 107.1301 - f1: 0.6723 - auc: 0.7203 - accuracy: 0.6620 - val_loss: 107.1227 - val_f1: 0.4135 - val_auc: 0.8547 - val_accuracy: 0.5762 - _timestamp: 1656369273.0000 - _runtime: 266.0000\n",
            "Epoch 13/100\n",
            "380/380 [==============================] - 20s 53ms/step - loss: 107.0926 - f1: 0.6938 - auc: 0.7409 - accuracy: 0.6823 - val_loss: 107.0871 - val_f1: 0.4136 - val_auc: 0.8581 - val_accuracy: 0.5740 - _timestamp: 1656369295.0000 - _runtime: 288.0000\n",
            "Epoch 14/100\n",
            "380/380 [==============================] - 23s 62ms/step - loss: 107.0551 - f1: 0.7096 - auc: 0.7642 - accuracy: 0.6988 - val_loss: 107.0518 - val_f1: 0.4091 - val_auc: 0.8587 - val_accuracy: 0.5656 - _timestamp: 1656369316.0000 - _runtime: 309.0000\n",
            "Epoch 15/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 107.0180 - f1: 0.7215 - auc: 0.7734 - accuracy: 0.7056 - val_loss: 107.0163 - val_f1: 0.4095 - val_auc: 0.8585 - val_accuracy: 0.5645 - _timestamp: 1656369339.0000 - _runtime: 332.0000\n",
            "Epoch 16/100\n",
            "380/380 [==============================] - 23s 59ms/step - loss: 106.9809 - f1: 0.7324 - auc: 0.7877 - accuracy: 0.7182 - val_loss: 106.9807 - val_f1: 0.4113 - val_auc: 0.8610 - val_accuracy: 0.5656 - _timestamp: 1656369359.0000 - _runtime: 352.0000\n",
            "Epoch 17/100\n",
            "380/380 [==============================] - 23s 59ms/step - loss: 106.9437 - f1: 0.7435 - auc: 0.7996 - accuracy: 0.7320 - val_loss: 106.9454 - val_f1: 0.4076 - val_auc: 0.8621 - val_accuracy: 0.5590 - _timestamp: 1656369382.0000 - _runtime: 375.0000\n",
            "Epoch 18/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 106.9058 - f1: 0.7581 - auc: 0.8135 - accuracy: 0.7424 - val_loss: 106.9101 - val_f1: 0.4029 - val_auc: 0.8630 - val_accuracy: 0.5528 - _timestamp: 1656369405.0000 - _runtime: 398.0000\n",
            "Epoch 19/100\n",
            "380/380 [==============================] - 23s 60ms/step - loss: 106.8677 - f1: 0.7679 - auc: 0.8280 - accuracy: 0.7544 - val_loss: 106.8748 - val_f1: 0.4013 - val_auc: 0.8643 - val_accuracy: 0.5495 - _timestamp: 1656369425.0000 - _runtime: 418.0000\n",
            "Epoch 20/100\n",
            "380/380 [==============================] - 23s 60ms/step - loss: 106.8303 - f1: 0.7742 - auc: 0.8339 - accuracy: 0.7582 - val_loss: 106.8392 - val_f1: 0.4034 - val_auc: 0.8629 - val_accuracy: 0.5534 - _timestamp: 1656369448.0000 - _runtime: 441.0000\n",
            "Epoch 21/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 106.7923 - f1: 0.7841 - auc: 0.8415 - accuracy: 0.7685 - val_loss: 106.8039 - val_f1: 0.4026 - val_auc: 0.8651 - val_accuracy: 0.5517 - _timestamp: 1656369470.0000 - _runtime: 463.0000\n",
            "Epoch 22/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 106.7548 - f1: 0.7856 - auc: 0.8457 - accuracy: 0.7678 - val_loss: 106.7684 - val_f1: 0.4025 - val_auc: 0.8654 - val_accuracy: 0.5512 - _timestamp: 1656369491.0000 - _runtime: 484.0000\n",
            "Epoch 23/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 106.7149 - f1: 0.7986 - auc: 0.8613 - accuracy: 0.7817 - val_loss: 106.7329 - val_f1: 0.4002 - val_auc: 0.8662 - val_accuracy: 0.5501 - _timestamp: 1656369513.0000 - _runtime: 506.0000\n",
            "Epoch 24/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 106.6769 - f1: 0.8020 - auc: 0.8640 - accuracy: 0.7871 - val_loss: 106.6973 - val_f1: 0.4011 - val_auc: 0.8656 - val_accuracy: 0.5517 - _timestamp: 1656369535.0000 - _runtime: 528.0000\n",
            "Epoch 25/100\n",
            "380/380 [==============================] - 23s 61ms/step - loss: 106.6376 - f1: 0.8110 - auc: 0.8742 - accuracy: 0.7933 - val_loss: 106.6614 - val_f1: 0.4019 - val_auc: 0.8656 - val_accuracy: 0.5534 - _timestamp: 1656369556.0000 - _runtime: 549.0000\n",
            "Epoch 26/100\n",
            "380/380 [==============================] - 23s 61ms/step - loss: 106.5978 - f1: 0.8120 - auc: 0.8791 - accuracy: 0.7958 - val_loss: 106.6258 - val_f1: 0.4019 - val_auc: 0.8664 - val_accuracy: 0.5534 - _timestamp: 1656369579.0000 - _runtime: 572.0000\n",
            "Epoch 27/100\n",
            "380/380 [==============================] - 23s 61ms/step - loss: 106.5586 - f1: 0.8188 - auc: 0.8839 - accuracy: 0.8022 - val_loss: 106.5901 - val_f1: 0.4031 - val_auc: 0.8663 - val_accuracy: 0.5562 - _timestamp: 1656369602.0000 - _runtime: 595.0000\n",
            "Epoch 28/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 106.5175 - f1: 0.8214 - auc: 0.8919 - accuracy: 0.8062 - val_loss: 106.5539 - val_f1: 0.4042 - val_auc: 0.8667 - val_accuracy: 0.5578 - _timestamp: 1656369625.0000 - _runtime: 618.0000\n",
            "Epoch 29/100\n",
            "380/380 [==============================] - 25s 65ms/step - loss: 106.4778 - f1: 0.8210 - auc: 0.8926 - accuracy: 0.8047 - val_loss: 106.5176 - val_f1: 0.4058 - val_auc: 0.8676 - val_accuracy: 0.5606 - _timestamp: 1656369646.0000 - _runtime: 639.0000\n",
            "Epoch 30/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 106.4371 - f1: 0.8258 - auc: 0.8957 - accuracy: 0.8100 - val_loss: 106.4819 - val_f1: 0.4079 - val_auc: 0.8675 - val_accuracy: 0.5651 - _timestamp: 1656369670.0000 - _runtime: 663.0000\n",
            "Epoch 31/100\n",
            "380/380 [==============================] - 23s 60ms/step - loss: 106.3954 - f1: 0.8299 - auc: 0.9008 - accuracy: 0.8159 - val_loss: 106.4456 - val_f1: 0.4098 - val_auc: 0.8678 - val_accuracy: 0.5690 - _timestamp: 1656369691.0000 - _runtime: 684.0000\n",
            "Epoch 32/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 106.3536 - f1: 0.8317 - auc: 0.9025 - accuracy: 0.8166 - val_loss: 106.4082 - val_f1: 0.4117 - val_auc: 0.8683 - val_accuracy: 0.5729 - _timestamp: 1656369713.0000 - _runtime: 706.0000\n",
            "Epoch 33/100\n",
            "380/380 [==============================] - 23s 60ms/step - loss: 106.3108 - f1: 0.8350 - auc: 0.9073 - accuracy: 0.8227 - val_loss: 106.3714 - val_f1: 0.4142 - val_auc: 0.8684 - val_accuracy: 0.5784 - _timestamp: 1656369736.0000 - _runtime: 729.0000\n",
            "Epoch 34/100\n",
            "380/380 [==============================] - 23s 61ms/step - loss: 106.2687 - f1: 0.8368 - auc: 0.9076 - accuracy: 0.8241 - val_loss: 106.3351 - val_f1: 0.4161 - val_auc: 0.8687 - val_accuracy: 0.5818 - _timestamp: 1656369759.0000 - _runtime: 752.0000\n",
            "Epoch 35/100\n",
            "380/380 [==============================] - 23s 61ms/step - loss: 106.2245 - f1: 0.8381 - auc: 0.9106 - accuracy: 0.8246 - val_loss: 106.2979 - val_f1: 0.4210 - val_auc: 0.8688 - val_accuracy: 0.5901 - _timestamp: 1656369782.0000 - _runtime: 775.0000\n",
            "Epoch 36/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 106.1811 - f1: 0.8401 - auc: 0.9116 - accuracy: 0.8277 - val_loss: 106.2602 - val_f1: 0.4232 - val_auc: 0.8693 - val_accuracy: 0.5962 - _timestamp: 1656369805.0000 - _runtime: 798.0000\n",
            "Epoch 37/100\n",
            "380/380 [==============================] - 23s 61ms/step - loss: 106.1364 - f1: 0.8419 - auc: 0.9134 - accuracy: 0.8316 - val_loss: 106.2215 - val_f1: 0.4283 - val_auc: 0.8696 - val_accuracy: 0.6051 - _timestamp: 1656369825.0000 - _runtime: 818.0000\n",
            "Epoch 38/100\n",
            "380/380 [==============================] - 20s 53ms/step - loss: 106.0915 - f1: 0.8440 - auc: 0.9175 - accuracy: 0.8320 - val_loss: 106.1821 - val_f1: 0.4330 - val_auc: 0.8694 - val_accuracy: 0.6123 - _timestamp: 1656369848.0000 - _runtime: 841.0000\n",
            "Epoch 39/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 106.0452 - f1: 0.8473 - auc: 0.9190 - accuracy: 0.8371 - val_loss: 106.1442 - val_f1: 0.4381 - val_auc: 0.8701 - val_accuracy: 0.6201 - _timestamp: 1656369869.0000 - _runtime: 862.0000\n",
            "Epoch 40/100\n",
            "380/380 [==============================] - 23s 61ms/step - loss: 105.9989 - f1: 0.8509 - auc: 0.9197 - accuracy: 0.8415 - val_loss: 106.1063 - val_f1: 0.4419 - val_auc: 0.8702 - val_accuracy: 0.6263 - _timestamp: 1656369891.0000 - _runtime: 884.0000\n",
            "Epoch 41/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 105.9538 - f1: 0.8495 - auc: 0.9193 - accuracy: 0.8406 - val_loss: 106.0666 - val_f1: 0.4481 - val_auc: 0.8704 - val_accuracy: 0.6374 - _timestamp: 1656369914.0000 - _runtime: 907.0000\n",
            "Epoch 42/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 105.9070 - f1: 0.8491 - auc: 0.9204 - accuracy: 0.8395 - val_loss: 106.0256 - val_f1: 0.4522 - val_auc: 0.8705 - val_accuracy: 0.6457 - _timestamp: 1656369935.0000 - _runtime: 928.0000\n",
            "Epoch 43/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 105.8603 - f1: 0.8494 - auc: 0.9214 - accuracy: 0.8432 - val_loss: 105.9887 - val_f1: 0.4556 - val_auc: 0.8708 - val_accuracy: 0.6507 - _timestamp: 1656369957.0000 - _runtime: 950.0000\n",
            "Epoch 44/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 105.8126 - f1: 0.8543 - auc: 0.9241 - accuracy: 0.8472 - val_loss: 105.9511 - val_f1: 0.4618 - val_auc: 0.8709 - val_accuracy: 0.6596 - _timestamp: 1656369979.0000 - _runtime: 972.0000\n",
            "Epoch 45/100\n",
            "380/380 [==============================] - 23s 61ms/step - loss: 105.7652 - f1: 0.8573 - auc: 0.9256 - accuracy: 0.8505 - val_loss: 105.9112 - val_f1: 0.4673 - val_auc: 0.8711 - val_accuracy: 0.6680 - _timestamp: 1656370001.0000 - _runtime: 994.0000\n",
            "Epoch 46/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 105.7206 - f1: 0.8557 - auc: 0.9244 - accuracy: 0.8498 - val_loss: 105.8713 - val_f1: 0.4688 - val_auc: 0.8714 - val_accuracy: 0.6730 - _timestamp: 1656370025.0000 - _runtime: 1018.0000\n",
            "Epoch 47/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 105.6741 - f1: 0.8556 - auc: 0.9261 - accuracy: 0.8502 - val_loss: 105.8385 - val_f1: 0.4709 - val_auc: 0.8718 - val_accuracy: 0.6758 - _timestamp: 1656370047.0000 - _runtime: 1040.0000\n",
            "Epoch 48/100\n",
            "380/380 [==============================] - 23s 61ms/step - loss: 105.6266 - f1: 0.8580 - auc: 0.9275 - accuracy: 0.8527 - val_loss: 105.7988 - val_f1: 0.4762 - val_auc: 0.8717 - val_accuracy: 0.6835 - _timestamp: 1656370070.0000 - _runtime: 1063.0000\n",
            "Epoch 49/100\n",
            "380/380 [==============================] - 23s 60ms/step - loss: 105.5808 - f1: 0.8590 - auc: 0.9292 - accuracy: 0.8538 - val_loss: 105.7595 - val_f1: 0.4804 - val_auc: 0.8720 - val_accuracy: 0.6897 - _timestamp: 1656370093.0000 - _runtime: 1086.0000\n",
            "Epoch 50/100\n",
            "380/380 [==============================] - 23s 60ms/step - loss: 105.5344 - f1: 0.8624 - auc: 0.9314 - accuracy: 0.8587 - val_loss: 105.7251 - val_f1: 0.4824 - val_auc: 0.8722 - val_accuracy: 0.6930 - _timestamp: 1656370116.0000 - _runtime: 1109.0000\n",
            "Epoch 51/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 105.4938 - f1: 0.8605 - auc: 0.9289 - accuracy: 0.8559 - val_loss: 105.6845 - val_f1: 0.4891 - val_auc: 0.8723 - val_accuracy: 0.7008 - _timestamp: 1656370138.0000 - _runtime: 1131.0000\n",
            "Epoch 52/100\n",
            "380/380 [==============================] - 23s 60ms/step - loss: 105.4496 - f1: 0.8611 - auc: 0.9303 - accuracy: 0.8574 - val_loss: 105.6466 - val_f1: 0.4905 - val_auc: 0.8724 - val_accuracy: 0.7047 - _timestamp: 1656370159.0000 - _runtime: 1152.0000\n",
            "Epoch 53/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 105.4044 - f1: 0.8636 - auc: 0.9329 - accuracy: 0.8598 - val_loss: 105.6103 - val_f1: 0.4943 - val_auc: 0.8722 - val_accuracy: 0.7097 - _timestamp: 1656370181.0000 - _runtime: 1174.0000\n",
            "Epoch 54/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 105.3615 - f1: 0.8621 - auc: 0.9346 - accuracy: 0.8598 - val_loss: 105.5840 - val_f1: 0.4924 - val_auc: 0.8728 - val_accuracy: 0.7086 - _timestamp: 1656370202.0000 - _runtime: 1195.0000\n",
            "Epoch 55/100\n",
            "380/380 [==============================] - 21s 55ms/step - loss: 105.3222 - f1: 0.8652 - auc: 0.9330 - accuracy: 0.8628 - val_loss: 105.5449 - val_f1: 0.4947 - val_auc: 0.8728 - val_accuracy: 0.7136 - _timestamp: 1656370224.0000 - _runtime: 1217.0000\n",
            "Epoch 56/100\n",
            "380/380 [==============================] - 23s 60ms/step - loss: 105.2803 - f1: 0.8660 - auc: 0.9345 - accuracy: 0.8644 - val_loss: 105.5093 - val_f1: 0.4987 - val_auc: 0.8729 - val_accuracy: 0.7197 - _timestamp: 1656370245.0000 - _runtime: 1238.0000\n",
            "Epoch 57/100\n",
            "380/380 [==============================] - 20s 53ms/step - loss: 105.2377 - f1: 0.8660 - auc: 0.9360 - accuracy: 0.8651 - val_loss: 105.4703 - val_f1: 0.5010 - val_auc: 0.8727 - val_accuracy: 0.7241 - _timestamp: 1656370268.0000 - _runtime: 1261.0000\n",
            "Epoch 58/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 105.1973 - f1: 0.8717 - auc: 0.9363 - accuracy: 0.8702 - val_loss: 105.4419 - val_f1: 0.5006 - val_auc: 0.8733 - val_accuracy: 0.7236 - _timestamp: 1656370288.0000 - _runtime: 1281.0000\n",
            "Epoch 59/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 105.1586 - f1: 0.8666 - auc: 0.9373 - accuracy: 0.8660 - val_loss: 105.4124 - val_f1: 0.5023 - val_auc: 0.8735 - val_accuracy: 0.7253 - _timestamp: 1656370310.0000 - _runtime: 1303.0000\n",
            "Epoch 60/100\n",
            "380/380 [==============================] - 21s 55ms/step - loss: 105.1193 - f1: 0.8720 - auc: 0.9377 - accuracy: 0.8710 - val_loss: 105.3698 - val_f1: 0.5083 - val_auc: 0.8734 - val_accuracy: 0.7325 - _timestamp: 1656370332.0000 - _runtime: 1325.0000\n",
            "Epoch 61/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 105.0769 - f1: 0.8732 - auc: 0.9403 - accuracy: 0.8728 - val_loss: 105.3456 - val_f1: 0.5064 - val_auc: 0.8737 - val_accuracy: 0.7303 - _timestamp: 1656370353.0000 - _runtime: 1346.0000\n",
            "Epoch 62/100\n",
            "380/380 [==============================] - 20s 53ms/step - loss: 105.0373 - f1: 0.8723 - auc: 0.9418 - accuracy: 0.8717 - val_loss: 105.3037 - val_f1: 0.5072 - val_auc: 0.8738 - val_accuracy: 0.7358 - _timestamp: 1656370375.0000 - _runtime: 1368.0000\n",
            "Epoch 63/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 105.0007 - f1: 0.8713 - auc: 0.9413 - accuracy: 0.8712 - val_loss: 105.2705 - val_f1: 0.5087 - val_auc: 0.8741 - val_accuracy: 0.7380 - _timestamp: 1656370396.0000 - _runtime: 1389.0000\n",
            "Epoch 64/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 104.9606 - f1: 0.8761 - auc: 0.9429 - accuracy: 0.8753 - val_loss: 105.2368 - val_f1: 0.5101 - val_auc: 0.8740 - val_accuracy: 0.7397 - _timestamp: 1656370418.0000 - _runtime: 1411.0000\n",
            "Epoch 65/100\n",
            "380/380 [==============================] - 23s 62ms/step - loss: 104.9215 - f1: 0.8758 - auc: 0.9442 - accuracy: 0.8745 - val_loss: 105.1895 - val_f1: 0.5102 - val_auc: 0.8740 - val_accuracy: 0.7425 - _timestamp: 1656370440.0000 - _runtime: 1433.0000\n",
            "Epoch 66/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 104.8823 - f1: 0.8740 - auc: 0.9455 - accuracy: 0.8751 - val_loss: 105.1697 - val_f1: 0.5127 - val_auc: 0.8741 - val_accuracy: 0.7430 - _timestamp: 1656370464.0000 - _runtime: 1457.0000\n",
            "Epoch 67/100\n",
            "380/380 [==============================] - 23s 60ms/step - loss: 104.8454 - f1: 0.8764 - auc: 0.9459 - accuracy: 0.8773 - val_loss: 105.1309 - val_f1: 0.5118 - val_auc: 0.8745 - val_accuracy: 0.7436 - _timestamp: 1656370486.0000 - _runtime: 1479.0000\n",
            "Epoch 68/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 104.8059 - f1: 0.8833 - auc: 0.9468 - accuracy: 0.8821 - val_loss: 105.0973 - val_f1: 0.5117 - val_auc: 0.8750 - val_accuracy: 0.7436 - _timestamp: 1656370509.0000 - _runtime: 1502.0000\n",
            "Epoch 69/100\n",
            "380/380 [==============================] - 23s 61ms/step - loss: 104.7687 - f1: 0.8798 - auc: 0.9476 - accuracy: 0.8796 - val_loss: 105.0534 - val_f1: 0.5124 - val_auc: 0.8745 - val_accuracy: 0.7464 - _timestamp: 1656370532.0000 - _runtime: 1525.0000\n",
            "Epoch 70/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 104.7298 - f1: 0.8814 - auc: 0.9492 - accuracy: 0.8820 - val_loss: 105.0200 - val_f1: 0.5144 - val_auc: 0.8748 - val_accuracy: 0.7481 - _timestamp: 1656370555.0000 - _runtime: 1548.0000\n",
            "Epoch 71/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 104.6926 - f1: 0.8850 - auc: 0.9497 - accuracy: 0.8848 - val_loss: 104.9894 - val_f1: 0.5168 - val_auc: 0.8748 - val_accuracy: 0.7497 - _timestamp: 1656370575.0000 - _runtime: 1568.0000\n",
            "Epoch 72/100\n",
            "380/380 [==============================] - 23s 60ms/step - loss: 104.6551 - f1: 0.8826 - auc: 0.9504 - accuracy: 0.8826 - val_loss: 104.9524 - val_f1: 0.5187 - val_auc: 0.8750 - val_accuracy: 0.7525 - _timestamp: 1656370597.0000 - _runtime: 1590.0000\n",
            "Epoch 73/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 104.6180 - f1: 0.8823 - auc: 0.9510 - accuracy: 0.8824 - val_loss: 104.9177 - val_f1: 0.5215 - val_auc: 0.8751 - val_accuracy: 0.7547 - _timestamp: 1656370620.0000 - _runtime: 1613.0000\n",
            "Epoch 74/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 104.5796 - f1: 0.8826 - auc: 0.9527 - accuracy: 0.8839 - val_loss: 104.8902 - val_f1: 0.5208 - val_auc: 0.8758 - val_accuracy: 0.7536 - _timestamp: 1656370641.0000 - _runtime: 1634.0000\n",
            "Epoch 75/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 104.5445 - f1: 0.8863 - auc: 0.9519 - accuracy: 0.8869 - val_loss: 104.8450 - val_f1: 0.5213 - val_auc: 0.8757 - val_accuracy: 0.7553 - _timestamp: 1656370663.0000 - _runtime: 1656.0000\n",
            "Epoch 76/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 104.5049 - f1: 0.8886 - auc: 0.9538 - accuracy: 0.8893 - val_loss: 104.8150 - val_f1: 0.5224 - val_auc: 0.8761 - val_accuracy: 0.7553 - _timestamp: 1656370685.0000 - _runtime: 1678.0000\n",
            "Epoch 77/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 104.4687 - f1: 0.8862 - auc: 0.9542 - accuracy: 0.8868 - val_loss: 104.7758 - val_f1: 0.5217 - val_auc: 0.8758 - val_accuracy: 0.7558 - _timestamp: 1656370708.0000 - _runtime: 1701.0000\n",
            "Epoch 78/100\n",
            "380/380 [==============================] - 23s 60ms/step - loss: 104.4329 - f1: 0.8865 - auc: 0.9543 - accuracy: 0.8874 - val_loss: 104.7467 - val_f1: 0.5211 - val_auc: 0.8766 - val_accuracy: 0.7553 - _timestamp: 1656370728.0000 - _runtime: 1721.0000\n",
            "Epoch 79/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 104.3955 - f1: 0.8882 - auc: 0.9553 - accuracy: 0.8898 - val_loss: 104.7001 - val_f1: 0.5235 - val_auc: 0.8763 - val_accuracy: 0.7592 - _timestamp: 1656370751.0000 - _runtime: 1744.0000\n",
            "Epoch 80/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 104.3598 - f1: 0.8874 - auc: 0.9557 - accuracy: 0.8892 - val_loss: 104.6670 - val_f1: 0.5240 - val_auc: 0.8770 - val_accuracy: 0.7597 - _timestamp: 1656370771.0000 - _runtime: 1764.0000\n",
            "Epoch 81/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 104.3212 - f1: 0.8897 - auc: 0.9568 - accuracy: 0.8910 - val_loss: 104.6383 - val_f1: 0.5230 - val_auc: 0.8775 - val_accuracy: 0.7581 - _timestamp: 1656370793.0000 - _runtime: 1786.0000\n",
            "Epoch 82/100\n",
            "380/380 [==============================] - 23s 61ms/step - loss: 104.2895 - f1: 0.8883 - auc: 0.9552 - accuracy: 0.8907 - val_loss: 104.6065 - val_f1: 0.5213 - val_auc: 0.8778 - val_accuracy: 0.7570 - _timestamp: 1656370816.0000 - _runtime: 1809.0000\n",
            "Epoch 83/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 104.2473 - f1: 0.8892 - auc: 0.9584 - accuracy: 0.8907 - val_loss: 104.5861 - val_f1: 0.5231 - val_auc: 0.8782 - val_accuracy: 0.7564 - _timestamp: 1656370839.0000 - _runtime: 1832.0000\n",
            "Epoch 84/100\n",
            "380/380 [==============================] - 23s 60ms/step - loss: 104.2115 - f1: 0.8920 - auc: 0.9586 - accuracy: 0.8935 - val_loss: 104.5326 - val_f1: 0.5235 - val_auc: 0.8781 - val_accuracy: 0.7592 - _timestamp: 1656370859.0000 - _runtime: 1852.0000\n",
            "Epoch 85/100\n",
            "380/380 [==============================] - 23s 60ms/step - loss: 104.1756 - f1: 0.8892 - auc: 0.9590 - accuracy: 0.8907 - val_loss: 104.4964 - val_f1: 0.5254 - val_auc: 0.8782 - val_accuracy: 0.7614 - _timestamp: 1656370882.0000 - _runtime: 1875.0000\n",
            "Epoch 86/100\n",
            "380/380 [==============================] - 23s 61ms/step - loss: 104.1382 - f1: 0.8943 - auc: 0.9598 - accuracy: 0.8957 - val_loss: 104.4546 - val_f1: 0.5248 - val_auc: 0.8781 - val_accuracy: 0.7625 - _timestamp: 1656370904.0000 - _runtime: 1897.0000\n",
            "Epoch 87/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 104.1019 - f1: 0.8935 - auc: 0.9601 - accuracy: 0.8945 - val_loss: 104.4341 - val_f1: 0.5261 - val_auc: 0.8789 - val_accuracy: 0.7603 - _timestamp: 1656370927.0000 - _runtime: 1920.0000\n",
            "Epoch 88/100\n",
            "380/380 [==============================] - 23s 61ms/step - loss: 104.0645 - f1: 0.8965 - auc: 0.9609 - accuracy: 0.8974 - val_loss: 104.3910 - val_f1: 0.5242 - val_auc: 0.8789 - val_accuracy: 0.7614 - _timestamp: 1656370948.0000 - _runtime: 1941.0000\n",
            "Epoch 89/100\n",
            "380/380 [==============================] - 23s 59ms/step - loss: 104.0286 - f1: 0.8966 - auc: 0.9613 - accuracy: 0.8980 - val_loss: 104.3553 - val_f1: 0.5236 - val_auc: 0.8790 - val_accuracy: 0.7620 - _timestamp: 1656370971.0000 - _runtime: 1964.0000\n",
            "Epoch 90/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 103.9963 - f1: 0.8940 - auc: 0.9604 - accuracy: 0.8959 - val_loss: 104.3258 - val_f1: 0.5248 - val_auc: 0.8796 - val_accuracy: 0.7614 - _timestamp: 1656370994.0000 - _runtime: 1987.0000\n",
            "Epoch 91/100\n",
            "380/380 [==============================] - 21s 56ms/step - loss: 103.9599 - f1: 0.8955 - auc: 0.9610 - accuracy: 0.8977 - val_loss: 104.2836 - val_f1: 0.5263 - val_auc: 0.8792 - val_accuracy: 0.7636 - _timestamp: 1656371014.0000 - _runtime: 2007.0000\n",
            "Epoch 92/100\n",
            "380/380 [==============================] - 23s 59ms/step - loss: 103.9207 - f1: 0.8962 - auc: 0.9625 - accuracy: 0.8989 - val_loss: 104.2477 - val_f1: 0.5259 - val_auc: 0.8791 - val_accuracy: 0.7631 - _timestamp: 1656371035.0000 - _runtime: 2028.0000\n",
            "Epoch 93/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 103.8831 - f1: 0.8993 - auc: 0.9634 - accuracy: 0.9007 - val_loss: 104.2239 - val_f1: 0.5278 - val_auc: 0.8795 - val_accuracy: 0.7625 - _timestamp: 1656371058.0000 - _runtime: 2051.0000\n",
            "Epoch 94/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 103.8499 - f1: 0.8978 - auc: 0.9630 - accuracy: 0.8997 - val_loss: 104.1851 - val_f1: 0.5257 - val_auc: 0.8795 - val_accuracy: 0.7620 - _timestamp: 1656371078.0000 - _runtime: 2071.0000\n",
            "Epoch 95/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 103.8118 - f1: 0.9002 - auc: 0.9641 - accuracy: 0.9014 - val_loss: 104.1443 - val_f1: 0.5277 - val_auc: 0.8800 - val_accuracy: 0.7653 - _timestamp: 1656371100.0000 - _runtime: 2093.0000\n",
            "Epoch 96/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 103.7758 - f1: 0.9014 - auc: 0.9647 - accuracy: 0.9029 - val_loss: 104.1041 - val_f1: 0.5290 - val_auc: 0.8797 - val_accuracy: 0.7664 - _timestamp: 1656371123.0000 - _runtime: 2116.0000\n",
            "Epoch 97/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 103.7422 - f1: 0.8975 - auc: 0.9642 - accuracy: 0.8989 - val_loss: 104.0774 - val_f1: 0.5286 - val_auc: 0.8805 - val_accuracy: 0.7647 - _timestamp: 1656371145.0000 - _runtime: 2138.0000\n",
            "Epoch 98/100\n",
            "380/380 [==============================] - 21s 56ms/step - loss: 103.7049 - f1: 0.9018 - auc: 0.9651 - accuracy: 0.9029 - val_loss: 104.0276 - val_f1: 0.5334 - val_auc: 0.8799 - val_accuracy: 0.7720 - _timestamp: 1656371167.0000 - _runtime: 2160.0000\n",
            "Epoch 99/100\n",
            "380/380 [==============================] - 23s 62ms/step - loss: 103.6724 - f1: 0.8999 - auc: 0.9641 - accuracy: 0.9018 - val_loss: 103.9965 - val_f1: 0.5321 - val_auc: 0.8801 - val_accuracy: 0.7703 - _timestamp: 1656371188.0000 - _runtime: 2181.0000\n",
            "Epoch 100/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 103.6343 - f1: 0.9017 - auc: 0.9653 - accuracy: 0.9039 - val_loss: 103.9751 - val_f1: 0.5283 - val_auc: 0.8808 - val_accuracy: 0.7647 - _timestamp: 1656371212.0000 - _runtime: 2205.0000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3395603d8d954854847bbabd92a439c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='1717.214 MB of 1717.214 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▂▂▃▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>auc</td><td>▁▁▂▃▄▄▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1</td><td>▁▂▃▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>loss</td><td>████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▇▆▃▃▂▂▂▁▁▁▁▁▂▂▃▃▄▅▅▆▆▆▇▇▇▇▇▇████████████</td></tr><tr><td>val_auc</td><td>▁▅▇▇▇███████████████████████████████████</td></tr><tr><td>val_f1</td><td>▁▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇████████████████</td></tr><tr><td>val_loss</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.90392</td></tr><tr><td>auc</td><td>0.96528</td></tr><tr><td>best_epoch</td><td>99</td></tr><tr><td>best_val_loss</td><td>103.9751</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>f1</td><td>0.90166</td></tr><tr><td>loss</td><td>103.63427</td></tr><tr><td>val_accuracy</td><td>0.76474</td></tr><tr><td>val_auc</td><td>0.88084</td></tr><tr><td>val_f1</td><td>0.5283</td></tr><tr><td>val_loss</td><td>103.9751</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">likely-sweep-14</strong>: <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/nzy1zfxm\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/runs/nzy1zfxm</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220627_223007-nzy1zfxm/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ak7kb41o with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_value: 0.4823823070153497\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-06\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons: 3000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptomizer: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_factor: 5e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_type: l1_l2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.19"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220627_230750-ak7kb41o</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/ak7kb41o\" target=\"_blank\">peach-sweep-15</a></strong> to <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 25008)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3000)              75027000  \n",
            "                                                                 \n",
            " activation (Activation)     (None, 3000)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 3000)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3000)              9003000   \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 3000)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 3000)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3000)              9003000   \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 3000)              0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 3000)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3000)              9003000   \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 3000)              0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 3000)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 3001      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 102,039,001\n",
            "Trainable params: 102,039,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "380/380 [==============================] - 13s 31ms/step - loss: 49.5842 - f1: 0.4712 - auc: 0.5863 - accuracy: 0.5193 - val_loss: 48.9974 - val_f1: 0.3380 - val_auc: 0.8439 - val_accuracy: 0.3888 - _timestamp: 1656371289.0000 - _runtime: 19.0000\n",
            "Epoch 2/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 48.4290 - f1: 0.5589 - auc: 0.5891 - accuracy: 0.5659 - val_loss: 47.8994 - val_f1: 0.3671 - val_auc: 0.8691 - val_accuracy: 0.4666 - _timestamp: 1656371300.0000 - _runtime: 30.0000\n",
            "Epoch 3/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 47.3463 - f1: 0.6090 - auc: 0.6537 - accuracy: 0.6136 - val_loss: 46.8491 - val_f1: 0.3880 - val_auc: 0.8714 - val_accuracy: 0.5167 - _timestamp: 1656371312.0000 - _runtime: 42.0000\n",
            "Epoch 4/100\n",
            "380/380 [==============================] - 12s 33ms/step - loss: 46.3032 - f1: 0.6611 - auc: 0.7189 - accuracy: 0.6663 - val_loss: 45.8350 - val_f1: 0.4026 - val_auc: 0.8730 - val_accuracy: 0.5462 - _timestamp: 1656371323.0000 - _runtime: 53.0000\n",
            "Epoch 5/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 45.2842 - f1: 0.7131 - auc: 0.7845 - accuracy: 0.7149 - val_loss: 44.8475 - val_f1: 0.4115 - val_auc: 0.8741 - val_accuracy: 0.5701 - _timestamp: 1656371335.0000 - _runtime: 65.0000\n",
            "Epoch 6/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 44.2878 - f1: 0.7576 - auc: 0.8329 - accuracy: 0.7584 - val_loss: 43.8880 - val_f1: 0.4235 - val_auc: 0.8742 - val_accuracy: 0.5973 - _timestamp: 1656371347.0000 - _runtime: 77.0000\n",
            "Epoch 7/100\n",
            "380/380 [==============================] - 14s 36ms/step - loss: 43.3085 - f1: 0.7959 - auc: 0.8633 - accuracy: 0.7919 - val_loss: 42.9497 - val_f1: 0.4430 - val_auc: 0.8735 - val_accuracy: 0.6329 - _timestamp: 1656371361.0000 - _runtime: 91.0000\n",
            "Epoch 8/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 42.3453 - f1: 0.8216 - auc: 0.8893 - accuracy: 0.8180 - val_loss: 42.0462 - val_f1: 0.4562 - val_auc: 0.8729 - val_accuracy: 0.6591 - _timestamp: 1656371375.0000 - _runtime: 105.0000\n",
            "Epoch 9/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 41.4145 - f1: 0.8379 - auc: 0.9040 - accuracy: 0.8353 - val_loss: 41.1970 - val_f1: 0.4617 - val_auc: 0.8731 - val_accuracy: 0.6702 - _timestamp: 1656371386.0000 - _runtime: 116.0000\n",
            "Epoch 10/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 40.5195 - f1: 0.8488 - auc: 0.9111 - accuracy: 0.8464 - val_loss: 40.3539 - val_f1: 0.4748 - val_auc: 0.8721 - val_accuracy: 0.6891 - _timestamp: 1656371397.0000 - _runtime: 127.0000\n",
            "Epoch 11/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 39.6517 - f1: 0.8532 - auc: 0.9200 - accuracy: 0.8520 - val_loss: 39.5400 - val_f1: 0.4879 - val_auc: 0.8720 - val_accuracy: 0.7052 - _timestamp: 1656371409.0000 - _runtime: 139.0000\n",
            "Epoch 12/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 38.8125 - f1: 0.8608 - auc: 0.9294 - accuracy: 0.8604 - val_loss: 38.7543 - val_f1: 0.4917 - val_auc: 0.8719 - val_accuracy: 0.7130 - _timestamp: 1656371420.0000 - _runtime: 150.0000\n",
            "Epoch 13/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 38.0111 - f1: 0.8618 - auc: 0.9310 - accuracy: 0.8617 - val_loss: 37.9619 - val_f1: 0.4956 - val_auc: 0.8709 - val_accuracy: 0.7236 - _timestamp: 1656371431.0000 - _runtime: 161.0000\n",
            "Epoch 14/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 37.2314 - f1: 0.8685 - auc: 0.9361 - accuracy: 0.8693 - val_loss: 37.2613 - val_f1: 0.4883 - val_auc: 0.8724 - val_accuracy: 0.7141 - _timestamp: 1656371443.0000 - _runtime: 173.0000\n",
            "Epoch 15/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 36.4809 - f1: 0.8680 - auc: 0.9376 - accuracy: 0.8689 - val_loss: 36.5201 - val_f1: 0.4986 - val_auc: 0.8721 - val_accuracy: 0.7258 - _timestamp: 1656371454.0000 - _runtime: 184.0000\n",
            "Epoch 16/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 35.7485 - f1: 0.8741 - auc: 0.9418 - accuracy: 0.8756 - val_loss: 35.8237 - val_f1: 0.4974 - val_auc: 0.8727 - val_accuracy: 0.7241 - _timestamp: 1656371465.0000 - _runtime: 195.0000\n",
            "Epoch 17/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 35.0395 - f1: 0.8817 - auc: 0.9452 - accuracy: 0.8823 - val_loss: 35.1243 - val_f1: 0.4974 - val_auc: 0.8725 - val_accuracy: 0.7291 - _timestamp: 1656371477.0000 - _runtime: 207.0000\n",
            "Epoch 18/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 34.3548 - f1: 0.8838 - auc: 0.9473 - accuracy: 0.8847 - val_loss: 34.4560 - val_f1: 0.4995 - val_auc: 0.8725 - val_accuracy: 0.7325 - _timestamp: 1656371488.0000 - _runtime: 218.0000\n",
            "Epoch 19/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 33.6885 - f1: 0.8839 - auc: 0.9497 - accuracy: 0.8856 - val_loss: 33.8064 - val_f1: 0.4988 - val_auc: 0.8735 - val_accuracy: 0.7336 - _timestamp: 1656371499.0000 - _runtime: 229.0000\n",
            "Epoch 20/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 33.0472 - f1: 0.8870 - auc: 0.9508 - accuracy: 0.8882 - val_loss: 33.1767 - val_f1: 0.5013 - val_auc: 0.8742 - val_accuracy: 0.7347 - _timestamp: 1656371511.0000 - _runtime: 241.0000\n",
            "Epoch 21/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 32.4226 - f1: 0.8906 - auc: 0.9540 - accuracy: 0.8923 - val_loss: 32.5580 - val_f1: 0.5034 - val_auc: 0.8748 - val_accuracy: 0.7414 - _timestamp: 1656371522.0000 - _runtime: 252.0000\n",
            "Epoch 22/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 31.8278 - f1: 0.8891 - auc: 0.9533 - accuracy: 0.8903 - val_loss: 31.9770 - val_f1: 0.5076 - val_auc: 0.8760 - val_accuracy: 0.7430 - _timestamp: 1656371534.0000 - _runtime: 264.0000\n",
            "Epoch 23/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 31.2454 - f1: 0.8914 - auc: 0.9562 - accuracy: 0.8935 - val_loss: 31.4232 - val_f1: 0.5076 - val_auc: 0.8767 - val_accuracy: 0.7425 - _timestamp: 1656371545.0000 - _runtime: 275.0000\n",
            "Epoch 24/100\n",
            "380/380 [==============================] - 14s 36ms/step - loss: 30.6910 - f1: 0.8918 - auc: 0.9562 - accuracy: 0.8933 - val_loss: 30.8643 - val_f1: 0.5099 - val_auc: 0.8768 - val_accuracy: 0.7453 - _timestamp: 1656371556.0000 - _runtime: 286.0000\n",
            "Epoch 25/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 30.1540 - f1: 0.8918 - auc: 0.9573 - accuracy: 0.8943 - val_loss: 30.3525 - val_f1: 0.5076 - val_auc: 0.8776 - val_accuracy: 0.7436 - _timestamp: 1656371570.0000 - _runtime: 300.0000\n",
            "Epoch 26/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 29.6320 - f1: 0.8987 - auc: 0.9602 - accuracy: 0.9005 - val_loss: 29.8342 - val_f1: 0.5044 - val_auc: 0.8774 - val_accuracy: 0.7464 - _timestamp: 1656371582.0000 - _runtime: 312.0000\n",
            "Epoch 27/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 29.1372 - f1: 0.8960 - auc: 0.9600 - accuracy: 0.8990 - val_loss: 29.3776 - val_f1: 0.5067 - val_auc: 0.8787 - val_accuracy: 0.7436 - _timestamp: 1656371593.0000 - _runtime: 323.0000\n",
            "Epoch 28/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 28.6630 - f1: 0.9003 - auc: 0.9598 - accuracy: 0.9022 - val_loss: 28.8941 - val_f1: 0.5075 - val_auc: 0.8785 - val_accuracy: 0.7453 - _timestamp: 1656371604.0000 - _runtime: 334.0000\n",
            "Epoch 29/100\n",
            "380/380 [==============================] - 15s 38ms/step - loss: 28.1989 - f1: 0.9041 - auc: 0.9627 - accuracy: 0.9062 - val_loss: 28.4405 - val_f1: 0.5114 - val_auc: 0.8791 - val_accuracy: 0.7486 - _timestamp: 1656371616.0000 - _runtime: 346.0000\n",
            "Epoch 30/100\n",
            "380/380 [==============================] - 14s 36ms/step - loss: 27.7615 - f1: 0.9012 - auc: 0.9631 - accuracy: 0.9036 - val_loss: 28.0163 - val_f1: 0.5104 - val_auc: 0.8799 - val_accuracy: 0.7481 - _timestamp: 1656371630.0000 - _runtime: 360.0000\n",
            "Epoch 31/100\n",
            "380/380 [==============================] - 12s 30ms/step - loss: 27.3475 - f1: 0.9016 - auc: 0.9624 - accuracy: 0.9042 - val_loss: 27.6212 - val_f1: 0.5098 - val_auc: 0.8806 - val_accuracy: 0.7464 - _timestamp: 1656371644.0000 - _runtime: 374.0000\n",
            "Epoch 32/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 26.9441 - f1: 0.9061 - auc: 0.9645 - accuracy: 0.9088 - val_loss: 27.2319 - val_f1: 0.5132 - val_auc: 0.8808 - val_accuracy: 0.7497 - _timestamp: 1656371656.0000 - _runtime: 386.0000\n",
            "Epoch 33/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 26.5700 - f1: 0.9043 - auc: 0.9638 - accuracy: 0.9065 - val_loss: 26.8555 - val_f1: 0.5170 - val_auc: 0.8811 - val_accuracy: 0.7536 - _timestamp: 1656371667.0000 - _runtime: 397.0000\n",
            "Epoch 34/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 26.2072 - f1: 0.9066 - auc: 0.9651 - accuracy: 0.9075 - val_loss: 26.4865 - val_f1: 0.5223 - val_auc: 0.8809 - val_accuracy: 0.7603 - _timestamp: 1656371679.0000 - _runtime: 409.0000\n",
            "Epoch 35/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 25.8610 - f1: 0.9095 - auc: 0.9674 - accuracy: 0.9124 - val_loss: 26.2055 - val_f1: 0.5160 - val_auc: 0.8819 - val_accuracy: 0.7469 - _timestamp: 1656371690.0000 - _runtime: 420.0000\n",
            "Epoch 36/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 25.5425 - f1: 0.9110 - auc: 0.9667 - accuracy: 0.9126 - val_loss: 25.8693 - val_f1: 0.5201 - val_auc: 0.8822 - val_accuracy: 0.7547 - _timestamp: 1656371701.0000 - _runtime: 431.0000\n",
            "Epoch 37/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 25.2394 - f1: 0.9098 - auc: 0.9669 - accuracy: 0.9111 - val_loss: 25.5519 - val_f1: 0.5256 - val_auc: 0.8817 - val_accuracy: 0.7614 - _timestamp: 1656371713.0000 - _runtime: 443.0000\n",
            "Epoch 38/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 24.9518 - f1: 0.9103 - auc: 0.9681 - accuracy: 0.9125 - val_loss: 25.2924 - val_f1: 0.5238 - val_auc: 0.8825 - val_accuracy: 0.7581 - _timestamp: 1656371724.0000 - _runtime: 454.0000\n",
            "Epoch 39/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 24.6829 - f1: 0.9108 - auc: 0.9693 - accuracy: 0.9131 - val_loss: 25.0223 - val_f1: 0.5255 - val_auc: 0.8815 - val_accuracy: 0.7625 - _timestamp: 1656371736.0000 - _runtime: 466.0000\n",
            "Epoch 40/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 24.4453 - f1: 0.9079 - auc: 0.9659 - accuracy: 0.9108 - val_loss: 24.7810 - val_f1: 0.5256 - val_auc: 0.8822 - val_accuracy: 0.7614 - _timestamp: 1656371747.0000 - _runtime: 477.0000\n",
            "Epoch 41/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 24.1994 - f1: 0.9117 - auc: 0.9687 - accuracy: 0.9138 - val_loss: 24.5478 - val_f1: 0.5248 - val_auc: 0.8822 - val_accuracy: 0.7620 - _timestamp: 1656371758.0000 - _runtime: 488.0000\n",
            "Epoch 42/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 23.9695 - f1: 0.9141 - auc: 0.9692 - accuracy: 0.9149 - val_loss: 24.3330 - val_f1: 0.5272 - val_auc: 0.8832 - val_accuracy: 0.7608 - _timestamp: 1656371770.0000 - _runtime: 500.0000\n",
            "Epoch 43/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 23.7476 - f1: 0.9142 - auc: 0.9698 - accuracy: 0.9159 - val_loss: 24.1181 - val_f1: 0.5278 - val_auc: 0.8829 - val_accuracy: 0.7614 - _timestamp: 1656371781.0000 - _runtime: 511.0000\n",
            "Epoch 44/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 23.5315 - f1: 0.9148 - auc: 0.9706 - accuracy: 0.9164 - val_loss: 23.8891 - val_f1: 0.5298 - val_auc: 0.8827 - val_accuracy: 0.7659 - _timestamp: 1656371793.0000 - _runtime: 523.0000\n",
            "Epoch 45/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 23.3258 - f1: 0.9143 - auc: 0.9701 - accuracy: 0.9159 - val_loss: 23.6614 - val_f1: 0.5326 - val_auc: 0.8822 - val_accuracy: 0.7714 - _timestamp: 1656371804.0000 - _runtime: 534.0000\n",
            "Epoch 46/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 23.1191 - f1: 0.9160 - auc: 0.9719 - accuracy: 0.9182 - val_loss: 23.4975 - val_f1: 0.5298 - val_auc: 0.8832 - val_accuracy: 0.7653 - _timestamp: 1656371815.0000 - _runtime: 545.0000\n",
            "Epoch 47/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 22.9303 - f1: 0.9147 - auc: 0.9696 - accuracy: 0.9160 - val_loss: 23.2858 - val_f1: 0.5321 - val_auc: 0.8836 - val_accuracy: 0.7686 - _timestamp: 1656371827.0000 - _runtime: 557.0000\n",
            "Epoch 48/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 22.7387 - f1: 0.9130 - auc: 0.9701 - accuracy: 0.9149 - val_loss: 23.1124 - val_f1: 0.5286 - val_auc: 0.8842 - val_accuracy: 0.7636 - _timestamp: 1656371840.0000 - _runtime: 570.0000\n",
            "Epoch 49/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 22.5462 - f1: 0.9148 - auc: 0.9718 - accuracy: 0.9164 - val_loss: 22.9275 - val_f1: 0.5317 - val_auc: 0.8850 - val_accuracy: 0.7653 - _timestamp: 1656371852.0000 - _runtime: 582.0000\n",
            "Epoch 50/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 22.3606 - f1: 0.9157 - auc: 0.9726 - accuracy: 0.9182 - val_loss: 22.7231 - val_f1: 0.5326 - val_auc: 0.8846 - val_accuracy: 0.7709 - _timestamp: 1656371863.0000 - _runtime: 593.0000\n",
            "Epoch 51/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 22.1814 - f1: 0.9173 - auc: 0.9726 - accuracy: 0.9198 - val_loss: 22.5380 - val_f1: 0.5368 - val_auc: 0.8847 - val_accuracy: 0.7747 - _timestamp: 1656371877.0000 - _runtime: 607.0000\n",
            "Epoch 52/100\n",
            "380/380 [==============================] - 16s 42ms/step - loss: 22.0058 - f1: 0.9177 - auc: 0.9724 - accuracy: 0.9196 - val_loss: 22.3511 - val_f1: 0.5371 - val_auc: 0.8845 - val_accuracy: 0.7759 - _timestamp: 1656371888.0000 - _runtime: 618.0000\n",
            "Epoch 53/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 21.8302 - f1: 0.9178 - auc: 0.9731 - accuracy: 0.9190 - val_loss: 22.2036 - val_f1: 0.5376 - val_auc: 0.8855 - val_accuracy: 0.7720 - _timestamp: 1656371904.0000 - _runtime: 634.0000\n",
            "Epoch 54/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 21.6611 - f1: 0.9170 - auc: 0.9725 - accuracy: 0.9191 - val_loss: 22.0268 - val_f1: 0.5377 - val_auc: 0.8850 - val_accuracy: 0.7736 - _timestamp: 1656371916.0000 - _runtime: 646.0000\n",
            "Epoch 55/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 21.4895 - f1: 0.9148 - auc: 0.9739 - accuracy: 0.9165 - val_loss: 21.8354 - val_f1: 0.5432 - val_auc: 0.8845 - val_accuracy: 0.7814 - _timestamp: 1656371927.0000 - _runtime: 657.0000\n",
            "Epoch 56/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 21.3250 - f1: 0.9178 - auc: 0.9732 - accuracy: 0.9201 - val_loss: 21.6744 - val_f1: 0.5414 - val_auc: 0.8849 - val_accuracy: 0.7781 - _timestamp: 1656371938.0000 - _runtime: 668.0000\n",
            "Epoch 57/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 21.1623 - f1: 0.9180 - auc: 0.9729 - accuracy: 0.9204 - val_loss: 21.5167 - val_f1: 0.5404 - val_auc: 0.8852 - val_accuracy: 0.7770 - _timestamp: 1656371950.0000 - _runtime: 680.0000\n",
            "Epoch 58/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 20.9948 - f1: 0.9185 - auc: 0.9751 - accuracy: 0.9205 - val_loss: 21.3771 - val_f1: 0.5373 - val_auc: 0.8858 - val_accuracy: 0.7731 - _timestamp: 1656371961.0000 - _runtime: 691.0000\n",
            "Epoch 59/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 20.8368 - f1: 0.9186 - auc: 0.9746 - accuracy: 0.9210 - val_loss: 21.2064 - val_f1: 0.5401 - val_auc: 0.8858 - val_accuracy: 0.7759 - _timestamp: 1656371972.0000 - _runtime: 702.0000\n",
            "Epoch 60/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 20.6826 - f1: 0.9153 - auc: 0.9743 - accuracy: 0.9180 - val_loss: 21.0346 - val_f1: 0.5430 - val_auc: 0.8859 - val_accuracy: 0.7792 - _timestamp: 1656371984.0000 - _runtime: 714.0000\n",
            "Epoch 61/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 20.5290 - f1: 0.9164 - auc: 0.9741 - accuracy: 0.9178 - val_loss: 20.8718 - val_f1: 0.5443 - val_auc: 0.8865 - val_accuracy: 0.7809 - _timestamp: 1656371995.0000 - _runtime: 725.0000\n",
            "Epoch 62/100\n",
            "380/380 [==============================] - 14s 37ms/step - loss: 20.3707 - f1: 0.9184 - auc: 0.9756 - accuracy: 0.9210 - val_loss: 20.7262 - val_f1: 0.5426 - val_auc: 0.8864 - val_accuracy: 0.7792 - _timestamp: 1656372006.0000 - _runtime: 736.0000\n",
            "Epoch 63/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 20.2148 - f1: 0.9201 - auc: 0.9769 - accuracy: 0.9236 - val_loss: 20.5927 - val_f1: 0.5410 - val_auc: 0.8864 - val_accuracy: 0.7764 - _timestamp: 1656372020.0000 - _runtime: 750.0000\n",
            "Epoch 64/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 20.0684 - f1: 0.9224 - auc: 0.9760 - accuracy: 0.9234 - val_loss: 20.4375 - val_f1: 0.5423 - val_auc: 0.8865 - val_accuracy: 0.7775 - _timestamp: 1656372032.0000 - _runtime: 762.0000\n",
            "Epoch 65/100\n",
            "380/380 [==============================] - 14s 38ms/step - loss: 19.9227 - f1: 0.9203 - auc: 0.9755 - accuracy: 0.9219 - val_loss: 20.2753 - val_f1: 0.5414 - val_auc: 0.8867 - val_accuracy: 0.7786 - _timestamp: 1656372043.0000 - _runtime: 773.0000\n",
            "Epoch 66/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 19.7709 - f1: 0.9227 - auc: 0.9769 - accuracy: 0.9234 - val_loss: 20.1404 - val_f1: 0.5410 - val_auc: 0.8869 - val_accuracy: 0.7770 - _timestamp: 1656372057.0000 - _runtime: 787.0000\n",
            "Epoch 67/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 19.6296 - f1: 0.9240 - auc: 0.9757 - accuracy: 0.9249 - val_loss: 19.9763 - val_f1: 0.5441 - val_auc: 0.8871 - val_accuracy: 0.7842 - _timestamp: 1656372069.0000 - _runtime: 799.0000\n",
            "Epoch 68/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 19.4857 - f1: 0.9242 - auc: 0.9757 - accuracy: 0.9258 - val_loss: 19.8510 - val_f1: 0.5429 - val_auc: 0.8880 - val_accuracy: 0.7781 - _timestamp: 1656372080.0000 - _runtime: 810.0000\n",
            "Epoch 69/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 19.3361 - f1: 0.9235 - auc: 0.9779 - accuracy: 0.9254 - val_loss: 19.6652 - val_f1: 0.5500 - val_auc: 0.8873 - val_accuracy: 0.7914 - _timestamp: 1656372091.0000 - _runtime: 821.0000\n",
            "Epoch 70/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 19.1993 - f1: 0.9239 - auc: 0.9768 - accuracy: 0.9260 - val_loss: 19.5527 - val_f1: 0.5417 - val_auc: 0.8878 - val_accuracy: 0.7836 - _timestamp: 1656372103.0000 - _runtime: 833.0000\n",
            "Epoch 71/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 19.0610 - f1: 0.9222 - auc: 0.9766 - accuracy: 0.9250 - val_loss: 19.4119 - val_f1: 0.5421 - val_auc: 0.8881 - val_accuracy: 0.7842 - _timestamp: 1656372114.0000 - _runtime: 844.0000\n",
            "Epoch 72/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 18.9244 - f1: 0.9222 - auc: 0.9762 - accuracy: 0.9244 - val_loss: 19.2686 - val_f1: 0.5439 - val_auc: 0.8889 - val_accuracy: 0.7859 - _timestamp: 1656372125.0000 - _runtime: 855.0000\n",
            "Epoch 73/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 18.7859 - f1: 0.9217 - auc: 0.9771 - accuracy: 0.9238 - val_loss: 19.1246 - val_f1: 0.5478 - val_auc: 0.8887 - val_accuracy: 0.7892 - _timestamp: 1656372137.0000 - _runtime: 867.0000\n",
            "Epoch 74/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 18.6544 - f1: 0.9203 - auc: 0.9764 - accuracy: 0.9219 - val_loss: 18.9858 - val_f1: 0.5475 - val_auc: 0.8889 - val_accuracy: 0.7892 - _timestamp: 1656372148.0000 - _runtime: 878.0000\n",
            "Epoch 75/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 18.5142 - f1: 0.9245 - auc: 0.9778 - accuracy: 0.9271 - val_loss: 18.8535 - val_f1: 0.5475 - val_auc: 0.8890 - val_accuracy: 0.7892 - _timestamp: 1656372159.0000 - _runtime: 889.0000\n",
            "Epoch 76/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 18.3832 - f1: 0.9241 - auc: 0.9775 - accuracy: 0.9266 - val_loss: 18.7244 - val_f1: 0.5467 - val_auc: 0.8887 - val_accuracy: 0.7887 - _timestamp: 1656372171.0000 - _runtime: 901.0000\n",
            "Epoch 77/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 18.2492 - f1: 0.9232 - auc: 0.9782 - accuracy: 0.9266 - val_loss: 18.5733 - val_f1: 0.5488 - val_auc: 0.8884 - val_accuracy: 0.7925 - _timestamp: 1656372182.0000 - _runtime: 912.0000\n",
            "Epoch 78/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 18.1153 - f1: 0.9272 - auc: 0.9790 - accuracy: 0.9295 - val_loss: 18.4561 - val_f1: 0.5451 - val_auc: 0.8880 - val_accuracy: 0.7892 - _timestamp: 1656372194.0000 - _runtime: 924.0000\n",
            "Epoch 79/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 17.9916 - f1: 0.9232 - auc: 0.9777 - accuracy: 0.9247 - val_loss: 18.3397 - val_f1: 0.5477 - val_auc: 0.8890 - val_accuracy: 0.7881 - _timestamp: 1656372205.0000 - _runtime: 935.0000\n",
            "Epoch 80/100\n",
            "380/380 [==============================] - 14s 36ms/step - loss: 17.8549 - f1: 0.9268 - auc: 0.9797 - accuracy: 0.9285 - val_loss: 18.2048 - val_f1: 0.5437 - val_auc: 0.8887 - val_accuracy: 0.7875 - _timestamp: 1656372216.0000 - _runtime: 946.0000\n",
            "Epoch 81/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 17.7304 - f1: 0.9234 - auc: 0.9788 - accuracy: 0.9258 - val_loss: 18.0527 - val_f1: 0.5508 - val_auc: 0.8887 - val_accuracy: 0.7942 - _timestamp: 1656372230.0000 - _runtime: 960.0000\n",
            "Epoch 82/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 17.6031 - f1: 0.9249 - auc: 0.9789 - accuracy: 0.9275 - val_loss: 17.9545 - val_f1: 0.5459 - val_auc: 0.8896 - val_accuracy: 0.7870 - _timestamp: 1656372241.0000 - _runtime: 971.0000\n",
            "Epoch 83/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 17.4799 - f1: 0.9235 - auc: 0.9784 - accuracy: 0.9256 - val_loss: 17.8102 - val_f1: 0.5466 - val_auc: 0.8896 - val_accuracy: 0.7903 - _timestamp: 1656372253.0000 - _runtime: 983.0000\n",
            "Epoch 84/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 17.3543 - f1: 0.9258 - auc: 0.9787 - accuracy: 0.9286 - val_loss: 17.6933 - val_f1: 0.5467 - val_auc: 0.8896 - val_accuracy: 0.7892 - _timestamp: 1656372264.0000 - _runtime: 994.0000\n",
            "Epoch 85/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 17.2344 - f1: 0.9263 - auc: 0.9779 - accuracy: 0.9280 - val_loss: 17.5603 - val_f1: 0.5497 - val_auc: 0.8898 - val_accuracy: 0.7920 - _timestamp: 1656372275.0000 - _runtime: 1005.0000\n",
            "Epoch 86/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 17.1075 - f1: 0.9264 - auc: 0.9790 - accuracy: 0.9288 - val_loss: 17.4348 - val_f1: 0.5500 - val_auc: 0.8898 - val_accuracy: 0.7937 - _timestamp: 1656372287.0000 - _runtime: 1017.0000\n",
            "Epoch 87/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 16.9824 - f1: 0.9275 - auc: 0.9801 - accuracy: 0.9294 - val_loss: 17.3242 - val_f1: 0.5496 - val_auc: 0.8903 - val_accuracy: 0.7909 - _timestamp: 1656372298.0000 - _runtime: 1028.0000\n",
            "Epoch 88/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 16.8623 - f1: 0.9258 - auc: 0.9800 - accuracy: 0.9285 - val_loss: 17.1846 - val_f1: 0.5528 - val_auc: 0.8895 - val_accuracy: 0.7964 - _timestamp: 1656372310.0000 - _runtime: 1040.0000\n",
            "Epoch 89/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 16.7444 - f1: 0.9286 - auc: 0.9795 - accuracy: 0.9299 - val_loss: 17.0677 - val_f1: 0.5496 - val_auc: 0.8898 - val_accuracy: 0.7948 - _timestamp: 1656372321.0000 - _runtime: 1051.0000\n",
            "Epoch 90/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 16.6233 - f1: 0.9275 - auc: 0.9798 - accuracy: 0.9297 - val_loss: 16.9569 - val_f1: 0.5513 - val_auc: 0.8902 - val_accuracy: 0.7942 - _timestamp: 1656372332.0000 - _runtime: 1062.0000\n",
            "Epoch 91/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 16.5014 - f1: 0.9286 - auc: 0.9806 - accuracy: 0.9303 - val_loss: 16.8494 - val_f1: 0.5458 - val_auc: 0.8906 - val_accuracy: 0.7892 - _timestamp: 1656372344.0000 - _runtime: 1074.0000\n",
            "Epoch 92/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 16.3895 - f1: 0.9242 - auc: 0.9798 - accuracy: 0.9258 - val_loss: 16.7058 - val_f1: 0.5541 - val_auc: 0.8893 - val_accuracy: 0.7992 - _timestamp: 1656372355.0000 - _runtime: 1085.0000\n",
            "Epoch 93/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 16.2684 - f1: 0.9295 - auc: 0.9803 - accuracy: 0.9312 - val_loss: 16.6078 - val_f1: 0.5489 - val_auc: 0.8906 - val_accuracy: 0.7920 - _timestamp: 1656372367.0000 - _runtime: 1097.0000\n",
            "Epoch 94/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 16.1606 - f1: 0.9232 - auc: 0.9786 - accuracy: 0.9253 - val_loss: 16.4801 - val_f1: 0.5520 - val_auc: 0.8910 - val_accuracy: 0.7970 - _timestamp: 1656372380.0000 - _runtime: 1110.0000\n",
            "Epoch 95/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 16.0382 - f1: 0.9249 - auc: 0.9805 - accuracy: 0.9270 - val_loss: 16.3553 - val_f1: 0.5515 - val_auc: 0.8904 - val_accuracy: 0.7987 - _timestamp: 1656372392.0000 - _runtime: 1122.0000\n",
            "Epoch 96/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 15.9292 - f1: 0.9288 - auc: 0.9793 - accuracy: 0.9313 - val_loss: 16.2388 - val_f1: 0.5515 - val_auc: 0.8904 - val_accuracy: 0.7987 - _timestamp: 1656372403.0000 - _runtime: 1133.0000\n",
            "Epoch 97/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 15.8082 - f1: 0.9323 - auc: 0.9809 - accuracy: 0.9341 - val_loss: 16.1329 - val_f1: 0.5496 - val_auc: 0.8906 - val_accuracy: 0.7970 - _timestamp: 1656372414.0000 - _runtime: 1144.0000\n",
            "Epoch 98/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 15.7013 - f1: 0.9281 - auc: 0.9796 - accuracy: 0.9303 - val_loss: 16.0135 - val_f1: 0.5500 - val_auc: 0.8913 - val_accuracy: 0.7981 - _timestamp: 1656372426.0000 - _runtime: 1156.0000\n",
            "Epoch 99/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 15.5861 - f1: 0.9283 - auc: 0.9808 - accuracy: 0.9292 - val_loss: 15.9137 - val_f1: 0.5495 - val_auc: 0.8913 - val_accuracy: 0.7953 - _timestamp: 1656372437.0000 - _runtime: 1167.0000\n",
            "Epoch 100/100\n",
            "380/380 [==============================] - 11s 30ms/step - loss: 15.4676 - f1: 0.9343 - auc: 0.9819 - accuracy: 0.9360 - val_loss: 15.7869 - val_f1: 0.5526 - val_auc: 0.8917 - val_accuracy: 0.8003 - _timestamp: 1656372448.0000 - _runtime: 1178.0000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd994673e05e44dc92e9e78de8211f6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='1167.806 MB of 1167.806 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▅▆▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>auc</td><td>▁▂▅▆▇▇▇▇████████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1</td><td>▁▃▅▆▇▇▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>loss</td><td>██▇▇▆▆▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>val_auc</td><td>▁▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>val_f1</td><td>▁▃▄▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████████████</td></tr><tr><td>val_loss</td><td>██▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.93603</td></tr><tr><td>auc</td><td>0.98189</td></tr><tr><td>best_epoch</td><td>99</td></tr><tr><td>best_val_loss</td><td>15.78693</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>f1</td><td>0.93425</td></tr><tr><td>loss</td><td>15.46756</td></tr><tr><td>val_accuracy</td><td>0.80033</td></tr><tr><td>val_auc</td><td>0.8917</td></tr><tr><td>val_f1</td><td>0.55256</td></tr><tr><td>val_loss</td><td>15.78693</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">peach-sweep-15</strong>: <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/ak7kb41o\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/runs/ak7kb41o</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220627_230750-ak7kb41o/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b9kht09y with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: leaky_relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_value: 0.1923981891090668\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons: 3500\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptomizer: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_factor: 0.005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_type: l2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.19"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220627_232822-b9kht09y</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/b9kht09y\" target=\"_blank\">amber-sweep-16</a></strong> to <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 25008)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3500)              87531500  \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 3500)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 3500)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3500)              12253500  \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 3500)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 3500)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3500)              12253500  \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 3500)              0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 3500)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3500)              12253500  \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 3500)              0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 3500)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 3501      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 124,295,501\n",
            "Trainable params: 124,295,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "380/380 [==============================] - 17s 42ms/step - loss: 38.3109 - f1: 0.8771 - auc: 0.9362 - accuracy: 0.8823 - val_loss: 15.9014 - val_f1: 0.5446 - val_auc: 0.8736 - val_accuracy: 0.8532 - _timestamp: 1656372521.0000 - _runtime: 18.0000\n",
            "Epoch 2/100\n",
            "380/380 [==============================] - 14s 38ms/step - loss: 8.7452 - f1: 0.9201 - auc: 0.9765 - accuracy: 0.9218 - val_loss: 4.5012 - val_f1: 0.5790 - val_auc: 0.8945 - val_accuracy: 0.8660 - _timestamp: 1656372536.0000 - _runtime: 33.0000\n",
            "Epoch 3/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 2.7140 - f1: 0.9308 - auc: 0.9820 - accuracy: 0.9322 - val_loss: 1.7894 - val_f1: 0.5811 - val_auc: 0.8958 - val_accuracy: 0.8699 - _timestamp: 1656372550.0000 - _runtime: 47.0000\n",
            "Epoch 4/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 1.2119 - f1: 0.9274 - auc: 0.9829 - accuracy: 0.9298 - val_loss: 1.0042 - val_f1: 0.5931 - val_auc: 0.9058 - val_accuracy: 0.8793 - _timestamp: 1656372562.0000 - _runtime: 59.0000\n",
            "Epoch 5/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 0.7314 - f1: 0.9333 - auc: 0.9847 - accuracy: 0.9356 - val_loss: 0.7492 - val_f1: 0.5808 - val_auc: 0.8997 - val_accuracy: 0.8648 - _timestamp: 1656372574.0000 - _runtime: 71.0000\n",
            "Epoch 6/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 0.5356 - f1: 0.9354 - auc: 0.9854 - accuracy: 0.9372 - val_loss: 0.6204 - val_f1: 0.5586 - val_auc: 0.8978 - val_accuracy: 0.8743 - _timestamp: 1656372586.0000 - _runtime: 83.0000\n",
            "Epoch 7/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 0.4364 - f1: 0.9373 - auc: 0.9862 - accuracy: 0.9397 - val_loss: 0.5300 - val_f1: 0.5711 - val_auc: 0.9057 - val_accuracy: 0.8743 - _timestamp: 1656372598.0000 - _runtime: 95.0000\n",
            "Epoch 8/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 0.3792 - f1: 0.9398 - auc: 0.9870 - accuracy: 0.9413 - val_loss: 0.5140 - val_f1: 0.4778 - val_auc: 0.9008 - val_accuracy: 0.8810 - _timestamp: 1656372609.0000 - _runtime: 106.0000\n",
            "Epoch 9/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 0.3467 - f1: 0.9407 - auc: 0.9871 - accuracy: 0.9428 - val_loss: 0.4888 - val_f1: 0.5801 - val_auc: 0.9000 - val_accuracy: 0.8726 - _timestamp: 1656372621.0000 - _runtime: 118.0000\n",
            "Epoch 10/100\n",
            "380/380 [==============================] - 14s 38ms/step - loss: 0.3246 - f1: 0.9398 - auc: 0.9872 - accuracy: 0.9417 - val_loss: 0.4635 - val_f1: 0.5003 - val_auc: 0.8998 - val_accuracy: 0.8749 - _timestamp: 1656372633.0000 - _runtime: 130.0000\n",
            "Epoch 11/100\n",
            "380/380 [==============================] - 12s 33ms/step - loss: 0.3039 - f1: 0.9434 - auc: 0.9885 - accuracy: 0.9455 - val_loss: 0.4622 - val_f1: 0.5848 - val_auc: 0.9012 - val_accuracy: 0.8710 - _timestamp: 1656372648.0000 - _runtime: 145.0000\n",
            "Epoch 12/100\n",
            "380/380 [==============================] - 12s 31ms/step - loss: 0.2937 - f1: 0.9411 - auc: 0.9886 - accuracy: 0.9440 - val_loss: 0.4273 - val_f1: 0.5928 - val_auc: 0.9061 - val_accuracy: 0.8799 - _timestamp: 1656372660.0000 - _runtime: 157.0000\n",
            "Epoch 13/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.2806 - f1: 0.9447 - auc: 0.9891 - accuracy: 0.9465 - val_loss: 0.4547 - val_f1: 0.5537 - val_auc: 0.9015 - val_accuracy: 0.8826 - _timestamp: 1656372672.0000 - _runtime: 169.0000\n",
            "Epoch 14/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.2731 - f1: 0.9457 - auc: 0.9900 - accuracy: 0.9466 - val_loss: 0.4447 - val_f1: 0.6013 - val_auc: 0.9042 - val_accuracy: 0.8676 - _timestamp: 1656372680.0000 - _runtime: 177.0000\n",
            "Epoch 15/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.2691 - f1: 0.9462 - auc: 0.9901 - accuracy: 0.9481 - val_loss: 0.4378 - val_f1: 0.5816 - val_auc: 0.9036 - val_accuracy: 0.8793 - _timestamp: 1656372687.0000 - _runtime: 184.0000\n",
            "Epoch 16/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 0.2624 - f1: 0.9478 - auc: 0.9908 - accuracy: 0.9494 - val_loss: 0.4152 - val_f1: 0.5550 - val_auc: 0.9089 - val_accuracy: 0.8832 - _timestamp: 1656372695.0000 - _runtime: 192.0000\n",
            "Epoch 17/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.2521 - f1: 0.9514 - auc: 0.9915 - accuracy: 0.9531 - val_loss: 0.4339 - val_f1: 0.6001 - val_auc: 0.9031 - val_accuracy: 0.8810 - _timestamp: 1656372710.0000 - _runtime: 207.0000\n",
            "Epoch 18/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.2469 - f1: 0.9538 - auc: 0.9922 - accuracy: 0.9555 - val_loss: 0.4527 - val_f1: 0.5866 - val_auc: 0.8968 - val_accuracy: 0.8732 - _timestamp: 1656372718.0000 - _runtime: 215.0000\n",
            "Epoch 19/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.2450 - f1: 0.9555 - auc: 0.9921 - accuracy: 0.9563 - val_loss: 0.4359 - val_f1: 0.5454 - val_auc: 0.8981 - val_accuracy: 0.8832 - _timestamp: 1656372725.0000 - _runtime: 222.0000\n",
            "Epoch 20/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.2363 - f1: 0.9556 - auc: 0.9930 - accuracy: 0.9571 - val_loss: 0.4325 - val_f1: 0.5665 - val_auc: 0.9020 - val_accuracy: 0.8726 - _timestamp: 1656372733.0000 - _runtime: 230.0000\n",
            "Epoch 21/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.2333 - f1: 0.9579 - auc: 0.9934 - accuracy: 0.9583 - val_loss: 0.4570 - val_f1: 0.4801 - val_auc: 0.8984 - val_accuracy: 0.8776 - _timestamp: 1656372741.0000 - _runtime: 238.0000\n",
            "Epoch 22/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.2313 - f1: 0.9603 - auc: 0.9937 - accuracy: 0.9616 - val_loss: 0.4660 - val_f1: 0.4478 - val_auc: 0.8930 - val_accuracy: 0.8726 - _timestamp: 1656372749.0000 - _runtime: 246.0000\n",
            "Epoch 23/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.2279 - f1: 0.9598 - auc: 0.9936 - accuracy: 0.9608 - val_loss: 0.4263 - val_f1: 0.5910 - val_auc: 0.9013 - val_accuracy: 0.8760 - _timestamp: 1656372757.0000 - _runtime: 254.0000\n",
            "Epoch 24/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.2246 - f1: 0.9603 - auc: 0.9940 - accuracy: 0.9616 - val_loss: 0.4666 - val_f1: 0.4286 - val_auc: 0.8939 - val_accuracy: 0.8760 - _timestamp: 1656372764.0000 - _runtime: 261.0000\n",
            "Epoch 25/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.2241 - f1: 0.9602 - auc: 0.9936 - accuracy: 0.9608 - val_loss: 0.4175 - val_f1: 0.5663 - val_auc: 0.9004 - val_accuracy: 0.8799 - _timestamp: 1656372772.0000 - _runtime: 269.0000\n",
            "Epoch 26/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.2121 - f1: 0.9653 - auc: 0.9949 - accuracy: 0.9664 - val_loss: 0.4260 - val_f1: 0.5476 - val_auc: 0.9003 - val_accuracy: 0.8771 - _timestamp: 1656372780.0000 - _runtime: 277.0000\n",
            "Epoch 27/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.2132 - f1: 0.9644 - auc: 0.9949 - accuracy: 0.9656 - val_loss: 0.4721 - val_f1: 0.4857 - val_auc: 0.8900 - val_accuracy: 0.8788 - _timestamp: 1656372788.0000 - _runtime: 285.0000\n",
            "Epoch 28/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.2166 - f1: 0.9634 - auc: 0.9948 - accuracy: 0.9644 - val_loss: 0.4529 - val_f1: 0.6027 - val_auc: 0.9013 - val_accuracy: 0.8660 - _timestamp: 1656372795.0000 - _runtime: 292.0000\n",
            "Epoch 29/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.2076 - f1: 0.9664 - auc: 0.9955 - accuracy: 0.9674 - val_loss: 0.4782 - val_f1: 0.5911 - val_auc: 0.8914 - val_accuracy: 0.8615 - _timestamp: 1656372803.0000 - _runtime: 300.0000\n",
            "Epoch 30/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.2069 - f1: 0.9661 - auc: 0.9956 - accuracy: 0.9667 - val_loss: 0.4362 - val_f1: 0.5039 - val_auc: 0.8944 - val_accuracy: 0.8743 - _timestamp: 1656372811.0000 - _runtime: 308.0000\n",
            "Epoch 31/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1993 - f1: 0.9678 - auc: 0.9962 - accuracy: 0.9685 - val_loss: 0.4703 - val_f1: 0.5309 - val_auc: 0.8880 - val_accuracy: 0.8838 - _timestamp: 1656372819.0000 - _runtime: 316.0000\n",
            "Epoch 32/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1937 - f1: 0.9684 - auc: 0.9961 - accuracy: 0.9696 - val_loss: 0.4551 - val_f1: 0.5839 - val_auc: 0.8903 - val_accuracy: 0.8721 - _timestamp: 1656372826.0000 - _runtime: 323.0000\n",
            "Epoch 33/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1997 - f1: 0.9686 - auc: 0.9958 - accuracy: 0.9696 - val_loss: 0.4701 - val_f1: 0.4827 - val_auc: 0.8932 - val_accuracy: 0.8771 - _timestamp: 1656372834.0000 - _runtime: 331.0000\n",
            "Epoch 34/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.2010 - f1: 0.9693 - auc: 0.9962 - accuracy: 0.9704 - val_loss: 0.4556 - val_f1: 0.5160 - val_auc: 0.8991 - val_accuracy: 0.8782 - _timestamp: 1656372842.0000 - _runtime: 339.0000\n",
            "Epoch 35/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1955 - f1: 0.9683 - auc: 0.9962 - accuracy: 0.9695 - val_loss: 0.4576 - val_f1: 0.5462 - val_auc: 0.9022 - val_accuracy: 0.8732 - _timestamp: 1656372850.0000 - _runtime: 347.0000\n",
            "Epoch 36/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1901 - f1: 0.9721 - auc: 0.9968 - accuracy: 0.9727 - val_loss: 0.4525 - val_f1: 0.5606 - val_auc: 0.8963 - val_accuracy: 0.8788 - _timestamp: 1656372857.0000 - _runtime: 354.0000\n",
            "Epoch 37/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1900 - f1: 0.9729 - auc: 0.9963 - accuracy: 0.9735 - val_loss: 0.4525 - val_f1: 0.5563 - val_auc: 0.8972 - val_accuracy: 0.8749 - _timestamp: 1656372865.0000 - _runtime: 362.0000\n",
            "Epoch 38/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1839 - f1: 0.9732 - auc: 0.9970 - accuracy: 0.9743 - val_loss: 0.4728 - val_f1: 0.4525 - val_auc: 0.8830 - val_accuracy: 0.8765 - _timestamp: 1656372873.0000 - _runtime: 370.0000\n",
            "Epoch 39/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1853 - f1: 0.9735 - auc: 0.9968 - accuracy: 0.9740 - val_loss: 0.4451 - val_f1: 0.5446 - val_auc: 0.8934 - val_accuracy: 0.8765 - _timestamp: 1656372881.0000 - _runtime: 378.0000\n",
            "Epoch 40/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1829 - f1: 0.9728 - auc: 0.9970 - accuracy: 0.9737 - val_loss: 0.4587 - val_f1: 0.5722 - val_auc: 0.8959 - val_accuracy: 0.8737 - _timestamp: 1656372889.0000 - _runtime: 386.0000\n",
            "Epoch 41/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1903 - f1: 0.9713 - auc: 0.9964 - accuracy: 0.9727 - val_loss: 0.4433 - val_f1: 0.5798 - val_auc: 0.8920 - val_accuracy: 0.8765 - _timestamp: 1656372896.0000 - _runtime: 393.0000\n",
            "Epoch 42/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1864 - f1: 0.9722 - auc: 0.9970 - accuracy: 0.9732 - val_loss: 0.4748 - val_f1: 0.5925 - val_auc: 0.9009 - val_accuracy: 0.8743 - _timestamp: 1656372904.0000 - _runtime: 401.0000\n",
            "Epoch 43/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1792 - f1: 0.9735 - auc: 0.9973 - accuracy: 0.9745 - val_loss: 0.4691 - val_f1: 0.5512 - val_auc: 0.8922 - val_accuracy: 0.8687 - _timestamp: 1656372912.0000 - _runtime: 409.0000\n",
            "Epoch 44/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1791 - f1: 0.9739 - auc: 0.9970 - accuracy: 0.9750 - val_loss: 0.4527 - val_f1: 0.5380 - val_auc: 0.8954 - val_accuracy: 0.8710 - _timestamp: 1656372920.0000 - _runtime: 417.0000\n",
            "Epoch 45/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1719 - f1: 0.9750 - auc: 0.9974 - accuracy: 0.9759 - val_loss: 0.4586 - val_f1: 0.5359 - val_auc: 0.8921 - val_accuracy: 0.8715 - _timestamp: 1656372927.0000 - _runtime: 424.0000\n",
            "Epoch 46/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1791 - f1: 0.9734 - auc: 0.9972 - accuracy: 0.9741 - val_loss: 0.4710 - val_f1: 0.5651 - val_auc: 0.8969 - val_accuracy: 0.8788 - _timestamp: 1656372935.0000 - _runtime: 432.0000\n",
            "Epoch 47/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1802 - f1: 0.9765 - auc: 0.9974 - accuracy: 0.9772 - val_loss: 0.4775 - val_f1: 0.5564 - val_auc: 0.8866 - val_accuracy: 0.8749 - _timestamp: 1656372943.0000 - _runtime: 440.0000\n",
            "Epoch 48/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.1736 - f1: 0.9746 - auc: 0.9975 - accuracy: 0.9759 - val_loss: 0.4924 - val_f1: 0.5441 - val_auc: 0.8773 - val_accuracy: 0.8865 - _timestamp: 1656372951.0000 - _runtime: 448.0000\n",
            "Epoch 49/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1697 - f1: 0.9775 - auc: 0.9977 - accuracy: 0.9785 - val_loss: 0.4875 - val_f1: 0.5708 - val_auc: 0.8897 - val_accuracy: 0.8826 - _timestamp: 1656372959.0000 - _runtime: 456.0000\n",
            "Epoch 50/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1749 - f1: 0.9753 - auc: 0.9971 - accuracy: 0.9763 - val_loss: 0.4581 - val_f1: 0.5807 - val_auc: 0.9004 - val_accuracy: 0.8782 - _timestamp: 1656372966.0000 - _runtime: 463.0000\n",
            "Epoch 51/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1815 - f1: 0.9744 - auc: 0.9971 - accuracy: 0.9754 - val_loss: 0.4679 - val_f1: 0.5720 - val_auc: 0.8948 - val_accuracy: 0.8788 - _timestamp: 1656372974.0000 - _runtime: 471.0000\n",
            "Epoch 52/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1692 - f1: 0.9778 - auc: 0.9980 - accuracy: 0.9782 - val_loss: 0.4756 - val_f1: 0.5881 - val_auc: 0.8986 - val_accuracy: 0.8788 - _timestamp: 1656372982.0000 - _runtime: 479.0000\n",
            "Epoch 53/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1693 - f1: 0.9782 - auc: 0.9975 - accuracy: 0.9788 - val_loss: 0.5195 - val_f1: 0.4660 - val_auc: 0.8720 - val_accuracy: 0.8810 - _timestamp: 1656372990.0000 - _runtime: 487.0000\n",
            "Epoch 54/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1691 - f1: 0.9783 - auc: 0.9976 - accuracy: 0.9789 - val_loss: 0.4412 - val_f1: 0.5400 - val_auc: 0.8981 - val_accuracy: 0.8804 - _timestamp: 1656372997.0000 - _runtime: 494.0000\n",
            "Epoch 55/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1759 - f1: 0.9749 - auc: 0.9974 - accuracy: 0.9755 - val_loss: 0.4831 - val_f1: 0.5729 - val_auc: 0.8911 - val_accuracy: 0.8621 - _timestamp: 1656373005.0000 - _runtime: 502.0000\n",
            "Epoch 56/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1734 - f1: 0.9761 - auc: 0.9975 - accuracy: 0.9769 - val_loss: 0.4659 - val_f1: 0.5578 - val_auc: 0.8922 - val_accuracy: 0.8793 - _timestamp: 1656373013.0000 - _runtime: 510.0000\n",
            "Epoch 57/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1649 - f1: 0.9794 - auc: 0.9979 - accuracy: 0.9801 - val_loss: 0.4654 - val_f1: 0.5653 - val_auc: 0.8902 - val_accuracy: 0.8832 - _timestamp: 1656373021.0000 - _runtime: 518.0000\n",
            "Epoch 58/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1696 - f1: 0.9792 - auc: 0.9978 - accuracy: 0.9801 - val_loss: 0.4420 - val_f1: 0.5563 - val_auc: 0.8924 - val_accuracy: 0.8793 - _timestamp: 1656373028.0000 - _runtime: 525.0000\n",
            "Epoch 59/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1720 - f1: 0.9766 - auc: 0.9975 - accuracy: 0.9776 - val_loss: 0.5036 - val_f1: 0.4769 - val_auc: 0.8818 - val_accuracy: 0.8815 - _timestamp: 1656373036.0000 - _runtime: 533.0000\n",
            "Epoch 60/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1655 - f1: 0.9773 - auc: 0.9979 - accuracy: 0.9776 - val_loss: 0.4570 - val_f1: 0.5802 - val_auc: 0.8979 - val_accuracy: 0.8799 - _timestamp: 1656373044.0000 - _runtime: 541.0000\n",
            "Epoch 61/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.1671 - f1: 0.9794 - auc: 0.9977 - accuracy: 0.9798 - val_loss: 0.4904 - val_f1: 0.5144 - val_auc: 0.8779 - val_accuracy: 0.8804 - _timestamp: 1656373052.0000 - _runtime: 549.0000\n",
            "Epoch 62/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1637 - f1: 0.9787 - auc: 0.9980 - accuracy: 0.9797 - val_loss: 0.5501 - val_f1: 0.4592 - val_auc: 0.8551 - val_accuracy: 0.8782 - _timestamp: 1656373060.0000 - _runtime: 557.0000\n",
            "Epoch 63/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1791 - f1: 0.9746 - auc: 0.9974 - accuracy: 0.9755 - val_loss: 0.4926 - val_f1: 0.5240 - val_auc: 0.8730 - val_accuracy: 0.8865 - _timestamp: 1656373067.0000 - _runtime: 564.0000\n",
            "Epoch 64/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1683 - f1: 0.9778 - auc: 0.9978 - accuracy: 0.9783 - val_loss: 0.4928 - val_f1: 0.5585 - val_auc: 0.8810 - val_accuracy: 0.8799 - _timestamp: 1656373075.0000 - _runtime: 572.0000\n",
            "Epoch 65/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1634 - f1: 0.9791 - auc: 0.9981 - accuracy: 0.9796 - val_loss: 0.4596 - val_f1: 0.5524 - val_auc: 0.8881 - val_accuracy: 0.8754 - _timestamp: 1656373083.0000 - _runtime: 580.0000\n",
            "Epoch 66/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1653 - f1: 0.9776 - auc: 0.9979 - accuracy: 0.9783 - val_loss: 0.4934 - val_f1: 0.5386 - val_auc: 0.8693 - val_accuracy: 0.8810 - _timestamp: 1656373091.0000 - _runtime: 588.0000\n",
            "Epoch 67/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1690 - f1: 0.9765 - auc: 0.9974 - accuracy: 0.9769 - val_loss: 0.4731 - val_f1: 0.5525 - val_auc: 0.8815 - val_accuracy: 0.8793 - _timestamp: 1656373098.0000 - _runtime: 595.0000\n",
            "Epoch 68/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1605 - f1: 0.9781 - auc: 0.9981 - accuracy: 0.9793 - val_loss: 0.4767 - val_f1: 0.5360 - val_auc: 0.8850 - val_accuracy: 0.8799 - _timestamp: 1656373106.0000 - _runtime: 603.0000\n",
            "Epoch 69/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1703 - f1: 0.9769 - auc: 0.9978 - accuracy: 0.9774 - val_loss: 0.4638 - val_f1: 0.5209 - val_auc: 0.8907 - val_accuracy: 0.8788 - _timestamp: 1656373114.0000 - _runtime: 611.0000\n",
            "Epoch 70/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1717 - f1: 0.9761 - auc: 0.9978 - accuracy: 0.9773 - val_loss: 0.5031 - val_f1: 0.4992 - val_auc: 0.8735 - val_accuracy: 0.8804 - _timestamp: 1656373122.0000 - _runtime: 619.0000\n",
            "Epoch 71/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1607 - f1: 0.9793 - auc: 0.9980 - accuracy: 0.9803 - val_loss: 0.4568 - val_f1: 0.5562 - val_auc: 0.8946 - val_accuracy: 0.8776 - _timestamp: 1656373130.0000 - _runtime: 627.0000\n",
            "Epoch 72/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1632 - f1: 0.9796 - auc: 0.9979 - accuracy: 0.9800 - val_loss: 0.4792 - val_f1: 0.5722 - val_auc: 0.8909 - val_accuracy: 0.8710 - _timestamp: 1656373137.0000 - _runtime: 634.0000\n",
            "Epoch 73/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1600 - f1: 0.9802 - auc: 0.9980 - accuracy: 0.9808 - val_loss: 0.4736 - val_f1: 0.5249 - val_auc: 0.8802 - val_accuracy: 0.8782 - _timestamp: 1656373145.0000 - _runtime: 642.0000\n",
            "Epoch 74/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1595 - f1: 0.9778 - auc: 0.9981 - accuracy: 0.9793 - val_loss: 0.4436 - val_f1: 0.5464 - val_auc: 0.8952 - val_accuracy: 0.8815 - _timestamp: 1656373153.0000 - _runtime: 650.0000\n",
            "Epoch 75/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1672 - f1: 0.9787 - auc: 0.9978 - accuracy: 0.9793 - val_loss: 0.5002 - val_f1: 0.5225 - val_auc: 0.8655 - val_accuracy: 0.8765 - _timestamp: 1656373161.0000 - _runtime: 658.0000\n",
            "Epoch 76/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1646 - f1: 0.9797 - auc: 0.9978 - accuracy: 0.9805 - val_loss: 0.4896 - val_f1: 0.5349 - val_auc: 0.8774 - val_accuracy: 0.8810 - _timestamp: 1656373168.0000 - _runtime: 665.0000\n",
            "Epoch 77/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1609 - f1: 0.9793 - auc: 0.9980 - accuracy: 0.9797 - val_loss: 0.4937 - val_f1: 0.5059 - val_auc: 0.8757 - val_accuracy: 0.8799 - _timestamp: 1656373176.0000 - _runtime: 673.0000\n",
            "Epoch 78/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1642 - f1: 0.9778 - auc: 0.9979 - accuracy: 0.9783 - val_loss: 0.4968 - val_f1: 0.4885 - val_auc: 0.8744 - val_accuracy: 0.8793 - _timestamp: 1656373184.0000 - _runtime: 681.0000\n",
            "Epoch 79/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1662 - f1: 0.9805 - auc: 0.9978 - accuracy: 0.9808 - val_loss: 0.4923 - val_f1: 0.5424 - val_auc: 0.8758 - val_accuracy: 0.8821 - _timestamp: 1656373192.0000 - _runtime: 689.0000\n",
            "Epoch 80/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1601 - f1: 0.9802 - auc: 0.9983 - accuracy: 0.9805 - val_loss: 0.5045 - val_f1: 0.5119 - val_auc: 0.8729 - val_accuracy: 0.8754 - _timestamp: 1656373199.0000 - _runtime: 696.0000\n",
            "Epoch 81/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1529 - f1: 0.9822 - auc: 0.9981 - accuracy: 0.9828 - val_loss: 0.4966 - val_f1: 0.5556 - val_auc: 0.8693 - val_accuracy: 0.8804 - _timestamp: 1656373207.0000 - _runtime: 704.0000\n",
            "Epoch 82/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1587 - f1: 0.9793 - auc: 0.9982 - accuracy: 0.9802 - val_loss: 0.4885 - val_f1: 0.5588 - val_auc: 0.8766 - val_accuracy: 0.8821 - _timestamp: 1656373215.0000 - _runtime: 712.0000\n",
            "Epoch 83/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1557 - f1: 0.9817 - auc: 0.9983 - accuracy: 0.9820 - val_loss: 0.4437 - val_f1: 0.5569 - val_auc: 0.8963 - val_accuracy: 0.8804 - _timestamp: 1656373223.0000 - _runtime: 720.0000\n",
            "Epoch 84/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1719 - f1: 0.9778 - auc: 0.9976 - accuracy: 0.9787 - val_loss: 0.4716 - val_f1: 0.5821 - val_auc: 0.8974 - val_accuracy: 0.8799 - _timestamp: 1656373230.0000 - _runtime: 727.0000\n",
            "Epoch 85/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1595 - f1: 0.9804 - auc: 0.9981 - accuracy: 0.9811 - val_loss: 0.4616 - val_f1: 0.5288 - val_auc: 0.8910 - val_accuracy: 0.8832 - _timestamp: 1656373238.0000 - _runtime: 735.0000\n",
            "Epoch 86/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1567 - f1: 0.9795 - auc: 0.9983 - accuracy: 0.9802 - val_loss: 0.5175 - val_f1: 0.4398 - val_auc: 0.8670 - val_accuracy: 0.8726 - _timestamp: 1656373246.0000 - _runtime: 743.0000\n",
            "Epoch 87/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1583 - f1: 0.9809 - auc: 0.9983 - accuracy: 0.9813 - val_loss: 0.5162 - val_f1: 0.5207 - val_auc: 0.8649 - val_accuracy: 0.8765 - _timestamp: 1656373254.0000 - _runtime: 751.0000\n",
            "Epoch 88/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1615 - f1: 0.9788 - auc: 0.9977 - accuracy: 0.9797 - val_loss: 0.4656 - val_f1: 0.5180 - val_auc: 0.8894 - val_accuracy: 0.8760 - _timestamp: 1656373261.0000 - _runtime: 758.0000\n",
            "Epoch 89/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1642 - f1: 0.9782 - auc: 0.9978 - accuracy: 0.9791 - val_loss: 0.4936 - val_f1: 0.5465 - val_auc: 0.8860 - val_accuracy: 0.8782 - _timestamp: 1656373269.0000 - _runtime: 766.0000\n",
            "Epoch 90/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1569 - f1: 0.9812 - auc: 0.9982 - accuracy: 0.9821 - val_loss: 0.4857 - val_f1: 0.5557 - val_auc: 0.8895 - val_accuracy: 0.8793 - _timestamp: 1656373277.0000 - _runtime: 774.0000\n",
            "Epoch 91/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1577 - f1: 0.9798 - auc: 0.9980 - accuracy: 0.9806 - val_loss: 0.5077 - val_f1: 0.5052 - val_auc: 0.8658 - val_accuracy: 0.8776 - _timestamp: 1656373285.0000 - _runtime: 782.0000\n",
            "Epoch 92/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1517 - f1: 0.9811 - auc: 0.9983 - accuracy: 0.9821 - val_loss: 0.4787 - val_f1: 0.5579 - val_auc: 0.8928 - val_accuracy: 0.8737 - _timestamp: 1656373293.0000 - _runtime: 790.0000\n",
            "Epoch 93/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1580 - f1: 0.9802 - auc: 0.9981 - accuracy: 0.9809 - val_loss: 0.5165 - val_f1: 0.4944 - val_auc: 0.8628 - val_accuracy: 0.8693 - _timestamp: 1656373300.0000 - _runtime: 797.0000\n",
            "Epoch 94/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1625 - f1: 0.9791 - auc: 0.9980 - accuracy: 0.9801 - val_loss: 0.5549 - val_f1: 0.4708 - val_auc: 0.8495 - val_accuracy: 0.8776 - _timestamp: 1656373308.0000 - _runtime: 805.0000\n",
            "Epoch 95/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1600 - f1: 0.9804 - auc: 0.9981 - accuracy: 0.9807 - val_loss: 0.4844 - val_f1: 0.5568 - val_auc: 0.8811 - val_accuracy: 0.8782 - _timestamp: 1656373316.0000 - _runtime: 813.0000\n",
            "Epoch 96/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1600 - f1: 0.9795 - auc: 0.9980 - accuracy: 0.9806 - val_loss: 0.4953 - val_f1: 0.5871 - val_auc: 0.8849 - val_accuracy: 0.8737 - _timestamp: 1656373324.0000 - _runtime: 821.0000\n",
            "Epoch 97/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1554 - f1: 0.9810 - auc: 0.9983 - accuracy: 0.9816 - val_loss: 0.4892 - val_f1: 0.5416 - val_auc: 0.8656 - val_accuracy: 0.8838 - _timestamp: 1656373331.0000 - _runtime: 828.0000\n",
            "Epoch 98/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1498 - f1: 0.9818 - auc: 0.9985 - accuracy: 0.9823 - val_loss: 0.5064 - val_f1: 0.5624 - val_auc: 0.8763 - val_accuracy: 0.8749 - _timestamp: 1656373339.0000 - _runtime: 836.0000\n",
            "Epoch 99/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1523 - f1: 0.9826 - auc: 0.9986 - accuracy: 0.9831 - val_loss: 0.5225 - val_f1: 0.5982 - val_auc: 0.8994 - val_accuracy: 0.8637 - _timestamp: 1656373347.0000 - _runtime: 844.0000\n",
            "Epoch 100/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1583 - f1: 0.9808 - auc: 0.9979 - accuracy: 0.9817 - val_loss: 0.4939 - val_f1: 0.5434 - val_auc: 0.8727 - val_accuracy: 0.8760 - _timestamp: 1656373355.0000 - _runtime: 852.0000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cafb262aaade4926a3233e70930f42eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='1422.511 MB of 1422.511 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>auc</td><td>▁▆▇▇▇▇▇▇▇▇██████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1</td><td>▁▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇█▇█████████████████████</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▇▅██▆▇▆▆▄█▇▇▆▆▅▇█▇▇▇▇▇▇▇▇▅▇▇██▇▆▇▆▇█▆</td></tr><tr><td>val_auc</td><td>▄▆▇▇▇▇█▇▇▇▇▇▆▇▇▆▆▆▇▆▆▇▆▅▄▅▅▆▆▆▄▄▄▇▃▅▆▁▃▄</td></tr><tr><td>val_f1</td><td>▅▇▆▁▇▅▅▇▁▇▅█▄▃▆▅▇▅▆▆▆▅▆▁▃▆▅▄▆▅▃▅▆▇▄▅▆▁▅▅</td></tr><tr><td>val_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.98172</td></tr><tr><td>auc</td><td>0.99793</td></tr><tr><td>best_epoch</td><td>15</td></tr><tr><td>best_val_loss</td><td>0.41515</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>f1</td><td>0.98082</td></tr><tr><td>loss</td><td>0.15829</td></tr><tr><td>val_accuracy</td><td>0.87597</td></tr><tr><td>val_auc</td><td>0.87266</td></tr><tr><td>val_f1</td><td>0.54339</td></tr><tr><td>val_loss</td><td>0.49395</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">amber-sweep-16</strong>: <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/b9kht09y\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/runs/b9kht09y</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220627_232822-b9kht09y/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s69qj7ya with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_value: 0.3416086603409366\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons: 2500\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptomizer: nadam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_factor: 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_type: l1_l2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.19"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220627_234326-s69qj7ya</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/s69qj7ya\" target=\"_blank\">fiery-sweep-17</a></strong> to <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 25008)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2500)              62522500  \n",
            "                                                                 \n",
            " activation (Activation)     (None, 2500)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 2500)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2500)              6252500   \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 2500)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2500)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 2501      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,777,501\n",
            "Trainable params: 68,777,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "  5/380 [..............................] - ETA: 10s - loss: 6.3456 - f1: 0.5743 - auc: 0.8727 - accuracy: 0.5125WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0126s vs `on_train_batch_end` time: 0.0147s). Check your callbacks.\n",
            "380/380 [==============================] - 15s 34ms/step - loss: 2.5727 - f1: 0.8935 - auc: 0.9521 - accuracy: 0.8945 - val_loss: 1.8829 - val_f1: 0.5764 - val_auc: 0.8847 - val_accuracy: 0.8576 - _timestamp: 1656373428.0000 - _runtime: 22.0000\n",
            "Epoch 2/100\n",
            "380/380 [==============================] - 13s 33ms/step - loss: 1.5537 - f1: 0.9254 - auc: 0.9805 - accuracy: 0.9271 - val_loss: 1.5319 - val_f1: 0.5981 - val_auc: 0.9018 - val_accuracy: 0.8576 - _timestamp: 1656373441.0000 - _runtime: 35.0000\n",
            "Epoch 3/100\n",
            "380/380 [==============================] - 15s 39ms/step - loss: 1.2417 - f1: 0.9392 - auc: 0.9865 - accuracy: 0.9405 - val_loss: 1.2776 - val_f1: 0.5963 - val_auc: 0.8994 - val_accuracy: 0.8704 - _timestamp: 1656373453.0000 - _runtime: 47.0000\n",
            "Epoch 4/100\n",
            "380/380 [==============================] - 13s 33ms/step - loss: 1.0326 - f1: 0.9412 - auc: 0.9884 - accuracy: 0.9427 - val_loss: 1.0767 - val_f1: 0.5996 - val_auc: 0.9176 - val_accuracy: 0.8821 - _timestamp: 1656373468.0000 - _runtime: 62.0000\n",
            "Epoch 5/100\n",
            "380/380 [==============================] - 13s 33ms/step - loss: 0.8747 - f1: 0.9454 - auc: 0.9901 - accuracy: 0.9471 - val_loss: 1.0541 - val_f1: 0.5807 - val_auc: 0.8953 - val_accuracy: 0.8365 - _timestamp: 1656373481.0000 - _runtime: 75.0000\n",
            "Epoch 6/100\n",
            "380/380 [==============================] - 12s 33ms/step - loss: 0.7469 - f1: 0.9519 - auc: 0.9918 - accuracy: 0.9533 - val_loss: 0.8710 - val_f1: 0.5519 - val_auc: 0.9069 - val_accuracy: 0.8737 - _timestamp: 1656373493.0000 - _runtime: 87.0000\n",
            "Epoch 7/100\n",
            "380/380 [==============================] - 13s 33ms/step - loss: 0.6459 - f1: 0.9540 - auc: 0.9932 - accuracy: 0.9559 - val_loss: 0.7997 - val_f1: 0.5822 - val_auc: 0.9107 - val_accuracy: 0.8782 - _timestamp: 1656373506.0000 - _runtime: 100.0000\n",
            "Epoch 8/100\n",
            "380/380 [==============================] - 13s 33ms/step - loss: 0.5720 - f1: 0.9587 - auc: 0.9942 - accuracy: 0.9601 - val_loss: 0.7580 - val_f1: 0.5249 - val_auc: 0.8981 - val_accuracy: 0.8782 - _timestamp: 1656373518.0000 - _runtime: 112.0000\n",
            "Epoch 9/100\n",
            "380/380 [==============================] - 13s 33ms/step - loss: 0.5099 - f1: 0.9627 - auc: 0.9951 - accuracy: 0.9642 - val_loss: 0.7130 - val_f1: 0.5926 - val_auc: 0.9014 - val_accuracy: 0.8765 - _timestamp: 1656373531.0000 - _runtime: 125.0000\n",
            "Epoch 10/100\n",
            "380/380 [==============================] - 13s 33ms/step - loss: 0.4611 - f1: 0.9647 - auc: 0.9956 - accuracy: 0.9658 - val_loss: 0.6883 - val_f1: 0.5812 - val_auc: 0.9028 - val_accuracy: 0.8682 - _timestamp: 1656373543.0000 - _runtime: 137.0000\n",
            "Epoch 11/100\n",
            "380/380 [==============================] - 13s 33ms/step - loss: 0.4143 - f1: 0.9690 - auc: 0.9966 - accuracy: 0.9700 - val_loss: 0.6765 - val_f1: 0.5858 - val_auc: 0.9065 - val_accuracy: 0.8582 - _timestamp: 1656373556.0000 - _runtime: 150.0000\n",
            "Epoch 12/100\n",
            "380/380 [==============================] - 12s 33ms/step - loss: 0.3676 - f1: 0.9754 - auc: 0.9974 - accuracy: 0.9760 - val_loss: 0.6635 - val_f1: 0.5800 - val_auc: 0.8956 - val_accuracy: 0.8615 - _timestamp: 1656373568.0000 - _runtime: 162.0000\n",
            "Epoch 13/100\n",
            "380/380 [==============================] - 13s 33ms/step - loss: 0.3430 - f1: 0.9728 - auc: 0.9975 - accuracy: 0.9741 - val_loss: 0.6141 - val_f1: 0.5836 - val_auc: 0.8998 - val_accuracy: 0.8660 - _timestamp: 1656373581.0000 - _runtime: 175.0000\n",
            "Epoch 14/100\n",
            "380/380 [==============================] - 13s 33ms/step - loss: 0.3110 - f1: 0.9799 - auc: 0.9980 - accuracy: 0.9802 - val_loss: 0.5901 - val_f1: 0.5400 - val_auc: 0.8916 - val_accuracy: 0.8704 - _timestamp: 1656373593.0000 - _runtime: 187.0000\n",
            "Epoch 15/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.2880 - f1: 0.9808 - auc: 0.9985 - accuracy: 0.9815 - val_loss: 0.6096 - val_f1: 0.5416 - val_auc: 0.8870 - val_accuracy: 0.8788 - _timestamp: 1656373606.0000 - _runtime: 200.0000\n",
            "Epoch 16/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.2697 - f1: 0.9807 - auc: 0.9985 - accuracy: 0.9814 - val_loss: 0.5937 - val_f1: 0.5265 - val_auc: 0.8790 - val_accuracy: 0.8726 - _timestamp: 1656373617.0000 - _runtime: 211.0000\n",
            "Epoch 17/100\n",
            "380/380 [==============================] - 13s 33ms/step - loss: 0.2506 - f1: 0.9848 - auc: 0.9988 - accuracy: 0.9854 - val_loss: 0.5551 - val_f1: 0.5526 - val_auc: 0.8898 - val_accuracy: 0.8665 - _timestamp: 1656373628.0000 - _runtime: 222.0000\n",
            "Epoch 18/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.2426 - f1: 0.9812 - auc: 0.9986 - accuracy: 0.9816 - val_loss: 0.5716 - val_f1: 0.5728 - val_auc: 0.8843 - val_accuracy: 0.8721 - _timestamp: 1656373641.0000 - _runtime: 235.0000\n",
            "Epoch 19/100\n",
            "380/380 [==============================] - 13s 33ms/step - loss: 0.2288 - f1: 0.9842 - auc: 0.9988 - accuracy: 0.9846 - val_loss: 0.5402 - val_f1: 0.5679 - val_auc: 0.8953 - val_accuracy: 0.8810 - _timestamp: 1656373652.0000 - _runtime: 246.0000\n",
            "Epoch 20/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.2171 - f1: 0.9858 - auc: 0.9989 - accuracy: 0.9862 - val_loss: 0.5454 - val_f1: 0.5079 - val_auc: 0.8815 - val_accuracy: 0.8737 - _timestamp: 1656373664.0000 - _runtime: 258.0000\n",
            "Epoch 21/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.2080 - f1: 0.9867 - auc: 0.9991 - accuracy: 0.9867 - val_loss: 0.5587 - val_f1: 0.5100 - val_auc: 0.8668 - val_accuracy: 0.8793 - _timestamp: 1656373675.0000 - _runtime: 269.0000\n",
            "Epoch 22/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1999 - f1: 0.9882 - auc: 0.9993 - accuracy: 0.9886 - val_loss: 0.5628 - val_f1: 0.5162 - val_auc: 0.8740 - val_accuracy: 0.8793 - _timestamp: 1656373686.0000 - _runtime: 280.0000\n",
            "Epoch 23/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1966 - f1: 0.9872 - auc: 0.9991 - accuracy: 0.9878 - val_loss: 0.5825 - val_f1: 0.4954 - val_auc: 0.8532 - val_accuracy: 0.8765 - _timestamp: 1656373697.0000 - _runtime: 291.0000\n",
            "Epoch 24/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1892 - f1: 0.9863 - auc: 0.9992 - accuracy: 0.9867 - val_loss: 0.5427 - val_f1: 0.5767 - val_auc: 0.8898 - val_accuracy: 0.8693 - _timestamp: 1656373709.0000 - _runtime: 303.0000\n",
            "Epoch 25/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1817 - f1: 0.9880 - auc: 0.9994 - accuracy: 0.9885 - val_loss: 0.5712 - val_f1: 0.5516 - val_auc: 0.8656 - val_accuracy: 0.8782 - _timestamp: 1656373720.0000 - _runtime: 314.0000\n",
            "Epoch 26/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1751 - f1: 0.9892 - auc: 0.9993 - accuracy: 0.9893 - val_loss: 0.5417 - val_f1: 0.5353 - val_auc: 0.8762 - val_accuracy: 0.8721 - _timestamp: 1656373731.0000 - _runtime: 325.0000\n",
            "Epoch 27/100\n",
            "380/380 [==============================] - 12s 33ms/step - loss: 0.1773 - f1: 0.9872 - auc: 0.9991 - accuracy: 0.9879 - val_loss: 0.5376 - val_f1: 0.5392 - val_auc: 0.8762 - val_accuracy: 0.8715 - _timestamp: 1656373742.0000 - _runtime: 336.0000\n",
            "Epoch 28/100\n",
            "380/380 [==============================] - 12s 33ms/step - loss: 0.1729 - f1: 0.9872 - auc: 0.9993 - accuracy: 0.9878 - val_loss: 0.5213 - val_f1: 0.5405 - val_auc: 0.8816 - val_accuracy: 0.8793 - _timestamp: 1656373754.0000 - _runtime: 348.0000\n",
            "Epoch 29/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1650 - f1: 0.9894 - auc: 0.9995 - accuracy: 0.9897 - val_loss: 0.5551 - val_f1: 0.5257 - val_auc: 0.8558 - val_accuracy: 0.8788 - _timestamp: 1656373767.0000 - _runtime: 361.0000\n",
            "Epoch 30/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1633 - f1: 0.9889 - auc: 0.9992 - accuracy: 0.9895 - val_loss: 0.5220 - val_f1: 0.5615 - val_auc: 0.8868 - val_accuracy: 0.8826 - _timestamp: 1656373778.0000 - _runtime: 372.0000\n",
            "Epoch 31/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1586 - f1: 0.9899 - auc: 0.9995 - accuracy: 0.9897 - val_loss: 0.5352 - val_f1: 0.5607 - val_auc: 0.8822 - val_accuracy: 0.8671 - _timestamp: 1656373789.0000 - _runtime: 383.0000\n",
            "Epoch 32/100\n",
            "380/380 [==============================] - 12s 33ms/step - loss: 0.1563 - f1: 0.9902 - auc: 0.9993 - accuracy: 0.9904 - val_loss: 0.5078 - val_f1: 0.5260 - val_auc: 0.8843 - val_accuracy: 0.8760 - _timestamp: 1656373800.0000 - _runtime: 394.0000\n",
            "Epoch 33/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1513 - f1: 0.9892 - auc: 0.9996 - accuracy: 0.9894 - val_loss: 0.5095 - val_f1: 0.5224 - val_auc: 0.8849 - val_accuracy: 0.8743 - _timestamp: 1656373812.0000 - _runtime: 406.0000\n",
            "Epoch 34/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1526 - f1: 0.9886 - auc: 0.9994 - accuracy: 0.9889 - val_loss: 0.5085 - val_f1: 0.5720 - val_auc: 0.8870 - val_accuracy: 0.8782 - _timestamp: 1656373824.0000 - _runtime: 418.0000\n",
            "Epoch 35/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1458 - f1: 0.9919 - auc: 0.9996 - accuracy: 0.9923 - val_loss: 0.5240 - val_f1: 0.5680 - val_auc: 0.8890 - val_accuracy: 0.8682 - _timestamp: 1656373835.0000 - _runtime: 429.0000\n",
            "Epoch 36/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1424 - f1: 0.9900 - auc: 0.9996 - accuracy: 0.9904 - val_loss: 0.5448 - val_f1: 0.5568 - val_auc: 0.8785 - val_accuracy: 0.8732 - _timestamp: 1656373846.0000 - _runtime: 440.0000\n",
            "Epoch 37/100\n",
            "380/380 [==============================] - 13s 33ms/step - loss: 0.1441 - f1: 0.9895 - auc: 0.9992 - accuracy: 0.9902 - val_loss: 0.4990 - val_f1: 0.5664 - val_auc: 0.8860 - val_accuracy: 0.8749 - _timestamp: 1656373857.0000 - _runtime: 451.0000\n",
            "Epoch 38/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1389 - f1: 0.9904 - auc: 0.9996 - accuracy: 0.9907 - val_loss: 0.5395 - val_f1: 0.5504 - val_auc: 0.8698 - val_accuracy: 0.8743 - _timestamp: 1656373869.0000 - _runtime: 463.0000\n",
            "Epoch 39/100\n",
            "380/380 [==============================] - 13s 33ms/step - loss: 0.1409 - f1: 0.9895 - auc: 0.9994 - accuracy: 0.9900 - val_loss: 0.4906 - val_f1: 0.5567 - val_auc: 0.8904 - val_accuracy: 0.8793 - _timestamp: 1656373880.0000 - _runtime: 474.0000\n",
            "Epoch 40/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1392 - f1: 0.9906 - auc: 0.9995 - accuracy: 0.9909 - val_loss: 0.4996 - val_f1: 0.5538 - val_auc: 0.8835 - val_accuracy: 0.8765 - _timestamp: 1656373893.0000 - _runtime: 487.0000\n",
            "Epoch 41/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1305 - f1: 0.9927 - auc: 0.9998 - accuracy: 0.9930 - val_loss: 0.5472 - val_f1: 0.5449 - val_auc: 0.8748 - val_accuracy: 0.8788 - _timestamp: 1656373904.0000 - _runtime: 498.0000\n",
            "Epoch 42/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1346 - f1: 0.9904 - auc: 0.9993 - accuracy: 0.9907 - val_loss: 0.5053 - val_f1: 0.5721 - val_auc: 0.8948 - val_accuracy: 0.8749 - _timestamp: 1656373915.0000 - _runtime: 509.0000\n",
            "Epoch 43/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1317 - f1: 0.9908 - auc: 0.9995 - accuracy: 0.9911 - val_loss: 0.5098 - val_f1: 0.5313 - val_auc: 0.8761 - val_accuracy: 0.8743 - _timestamp: 1656373926.0000 - _runtime: 520.0000\n",
            "Epoch 44/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1300 - f1: 0.9908 - auc: 0.9994 - accuracy: 0.9911 - val_loss: 0.5058 - val_f1: 0.5431 - val_auc: 0.8827 - val_accuracy: 0.8721 - _timestamp: 1656373937.0000 - _runtime: 531.0000\n",
            "Epoch 45/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1254 - f1: 0.9914 - auc: 0.9998 - accuracy: 0.9916 - val_loss: 0.5128 - val_f1: 0.5646 - val_auc: 0.8765 - val_accuracy: 0.8815 - _timestamp: 1656373948.0000 - _runtime: 542.0000\n",
            "Epoch 46/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1252 - f1: 0.9918 - auc: 0.9997 - accuracy: 0.9922 - val_loss: 0.5447 - val_f1: 0.5025 - val_auc: 0.8575 - val_accuracy: 0.8749 - _timestamp: 1656373959.0000 - _runtime: 553.0000\n",
            "Epoch 47/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1300 - f1: 0.9906 - auc: 0.9995 - accuracy: 0.9911 - val_loss: 0.4962 - val_f1: 0.5760 - val_auc: 0.8823 - val_accuracy: 0.8776 - _timestamp: 1656373971.0000 - _runtime: 565.0000\n",
            "Epoch 48/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1248 - f1: 0.9925 - auc: 0.9995 - accuracy: 0.9927 - val_loss: 0.5233 - val_f1: 0.5368 - val_auc: 0.8747 - val_accuracy: 0.8760 - _timestamp: 1656373982.0000 - _runtime: 576.0000\n",
            "Epoch 49/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1224 - f1: 0.9924 - auc: 0.9995 - accuracy: 0.9927 - val_loss: 0.5198 - val_f1: 0.5740 - val_auc: 0.8852 - val_accuracy: 0.8765 - _timestamp: 1656373993.0000 - _runtime: 587.0000\n",
            "Epoch 50/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1215 - f1: 0.9932 - auc: 0.9997 - accuracy: 0.9933 - val_loss: 0.5028 - val_f1: 0.5558 - val_auc: 0.8770 - val_accuracy: 0.8832 - _timestamp: 1656374004.0000 - _runtime: 598.0000\n",
            "Epoch 51/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1230 - f1: 0.9907 - auc: 0.9994 - accuracy: 0.9910 - val_loss: 0.5283 - val_f1: 0.5196 - val_auc: 0.8688 - val_accuracy: 0.8771 - _timestamp: 1656374015.0000 - _runtime: 609.0000\n",
            "Epoch 52/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1164 - f1: 0.9931 - auc: 0.9998 - accuracy: 0.9933 - val_loss: 0.5320 - val_f1: 0.5262 - val_auc: 0.8684 - val_accuracy: 0.8776 - _timestamp: 1656374026.0000 - _runtime: 620.0000\n",
            "Epoch 53/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1177 - f1: 0.9920 - auc: 0.9996 - accuracy: 0.9923 - val_loss: 0.5324 - val_f1: 0.5349 - val_auc: 0.8687 - val_accuracy: 0.8788 - _timestamp: 1656374037.0000 - _runtime: 631.0000\n",
            "Epoch 54/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1180 - f1: 0.9922 - auc: 0.9995 - accuracy: 0.9925 - val_loss: 0.5108 - val_f1: 0.5587 - val_auc: 0.8748 - val_accuracy: 0.8776 - _timestamp: 1656374048.0000 - _runtime: 642.0000\n",
            "Epoch 55/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1174 - f1: 0.9915 - auc: 0.9997 - accuracy: 0.9916 - val_loss: 0.5122 - val_f1: 0.5286 - val_auc: 0.8745 - val_accuracy: 0.8810 - _timestamp: 1656374059.0000 - _runtime: 653.0000\n",
            "Epoch 56/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1120 - f1: 0.9941 - auc: 0.9998 - accuracy: 0.9942 - val_loss: 0.5196 - val_f1: 0.5660 - val_auc: 0.8798 - val_accuracy: 0.8776 - _timestamp: 1656374070.0000 - _runtime: 664.0000\n",
            "Epoch 57/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1128 - f1: 0.9928 - auc: 0.9996 - accuracy: 0.9929 - val_loss: 0.5161 - val_f1: 0.5175 - val_auc: 0.8765 - val_accuracy: 0.8749 - _timestamp: 1656374081.0000 - _runtime: 675.0000\n",
            "Epoch 58/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1119 - f1: 0.9918 - auc: 0.9996 - accuracy: 0.9919 - val_loss: 0.5166 - val_f1: 0.5653 - val_auc: 0.8750 - val_accuracy: 0.8788 - _timestamp: 1656374093.0000 - _runtime: 687.0000\n",
            "Epoch 59/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1152 - f1: 0.9916 - auc: 0.9996 - accuracy: 0.9919 - val_loss: 0.5343 - val_f1: 0.5395 - val_auc: 0.8645 - val_accuracy: 0.8788 - _timestamp: 1656374104.0000 - _runtime: 698.0000\n",
            "Epoch 60/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1110 - f1: 0.9931 - auc: 0.9997 - accuracy: 0.9931 - val_loss: 0.5431 - val_f1: 0.4874 - val_auc: 0.8645 - val_accuracy: 0.8749 - _timestamp: 1656374115.0000 - _runtime: 709.0000\n",
            "Epoch 61/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1102 - f1: 0.9929 - auc: 0.9998 - accuracy: 0.9931 - val_loss: 0.5672 - val_f1: 0.4953 - val_auc: 0.8494 - val_accuracy: 0.8788 - _timestamp: 1656374126.0000 - _runtime: 720.0000\n",
            "Epoch 62/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1138 - f1: 0.9924 - auc: 0.9995 - accuracy: 0.9926 - val_loss: 0.5418 - val_f1: 0.5281 - val_auc: 0.8676 - val_accuracy: 0.8765 - _timestamp: 1656374137.0000 - _runtime: 731.0000\n",
            "Epoch 63/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1144 - f1: 0.9907 - auc: 0.9995 - accuracy: 0.9910 - val_loss: 0.5249 - val_f1: 0.5371 - val_auc: 0.8582 - val_accuracy: 0.8726 - _timestamp: 1656374148.0000 - _runtime: 742.0000\n",
            "Epoch 64/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1100 - f1: 0.9933 - auc: 0.9995 - accuracy: 0.9936 - val_loss: 0.5105 - val_f1: 0.5600 - val_auc: 0.8767 - val_accuracy: 0.8804 - _timestamp: 1656374159.0000 - _runtime: 753.0000\n",
            "Epoch 65/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1094 - f1: 0.9929 - auc: 0.9996 - accuracy: 0.9932 - val_loss: 0.4998 - val_f1: 0.5730 - val_auc: 0.8860 - val_accuracy: 0.8804 - _timestamp: 1656374170.0000 - _runtime: 764.0000\n",
            "Epoch 66/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1092 - f1: 0.9915 - auc: 0.9997 - accuracy: 0.9918 - val_loss: 0.5005 - val_f1: 0.5408 - val_auc: 0.8781 - val_accuracy: 0.8760 - _timestamp: 1656374181.0000 - _runtime: 775.0000\n",
            "Epoch 67/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1052 - f1: 0.9936 - auc: 0.9998 - accuracy: 0.9937 - val_loss: 0.5320 - val_f1: 0.5372 - val_auc: 0.8671 - val_accuracy: 0.8788 - _timestamp: 1656374192.0000 - _runtime: 786.0000\n",
            "Epoch 68/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1092 - f1: 0.9922 - auc: 0.9994 - accuracy: 0.9923 - val_loss: 0.5433 - val_f1: 0.4902 - val_auc: 0.8613 - val_accuracy: 0.8732 - _timestamp: 1656374203.0000 - _runtime: 797.0000\n",
            "Epoch 69/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1051 - f1: 0.9941 - auc: 0.9997 - accuracy: 0.9941 - val_loss: 0.5377 - val_f1: 0.5583 - val_auc: 0.8605 - val_accuracy: 0.8810 - _timestamp: 1656374214.0000 - _runtime: 808.0000\n",
            "Epoch 70/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1071 - f1: 0.9918 - auc: 0.9996 - accuracy: 0.9920 - val_loss: 0.5056 - val_f1: 0.5730 - val_auc: 0.8765 - val_accuracy: 0.8771 - _timestamp: 1656374225.0000 - _runtime: 819.0000\n",
            "Epoch 71/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1040 - f1: 0.9930 - auc: 0.9998 - accuracy: 0.9931 - val_loss: 0.5438 - val_f1: 0.4807 - val_auc: 0.8549 - val_accuracy: 0.8782 - _timestamp: 1656374237.0000 - _runtime: 831.0000\n",
            "Epoch 72/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1058 - f1: 0.9924 - auc: 0.9996 - accuracy: 0.9925 - val_loss: 0.5229 - val_f1: 0.5099 - val_auc: 0.8647 - val_accuracy: 0.8726 - _timestamp: 1656374248.0000 - _runtime: 842.0000\n",
            "Epoch 73/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1053 - f1: 0.9934 - auc: 0.9996 - accuracy: 0.9937 - val_loss: 0.5374 - val_f1: 0.5399 - val_auc: 0.8592 - val_accuracy: 0.8760 - _timestamp: 1656374259.0000 - _runtime: 853.0000\n",
            "Epoch 74/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1064 - f1: 0.9924 - auc: 0.9994 - accuracy: 0.9926 - val_loss: 0.5059 - val_f1: 0.5369 - val_auc: 0.8661 - val_accuracy: 0.8760 - _timestamp: 1656374270.0000 - _runtime: 864.0000\n",
            "Epoch 75/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1022 - f1: 0.9936 - auc: 0.9997 - accuracy: 0.9937 - val_loss: 0.5213 - val_f1: 0.5092 - val_auc: 0.8632 - val_accuracy: 0.8754 - _timestamp: 1656374281.0000 - _runtime: 875.0000\n",
            "Epoch 76/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1032 - f1: 0.9930 - auc: 0.9997 - accuracy: 0.9931 - val_loss: 0.5382 - val_f1: 0.5191 - val_auc: 0.8535 - val_accuracy: 0.8782 - _timestamp: 1656374292.0000 - _runtime: 886.0000\n",
            "Epoch 77/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1040 - f1: 0.9924 - auc: 0.9997 - accuracy: 0.9925 - val_loss: 0.5269 - val_f1: 0.5121 - val_auc: 0.8638 - val_accuracy: 0.8726 - _timestamp: 1656374303.0000 - _runtime: 897.0000\n",
            "Epoch 78/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1014 - f1: 0.9938 - auc: 0.9997 - accuracy: 0.9938 - val_loss: 0.5506 - val_f1: 0.5222 - val_auc: 0.8590 - val_accuracy: 0.8799 - _timestamp: 1656374314.0000 - _runtime: 908.0000\n",
            "Epoch 79/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1016 - f1: 0.9932 - auc: 0.9998 - accuracy: 0.9932 - val_loss: 0.5191 - val_f1: 0.5582 - val_auc: 0.8677 - val_accuracy: 0.8776 - _timestamp: 1656374325.0000 - _runtime: 919.0000\n",
            "Epoch 80/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1007 - f1: 0.9930 - auc: 0.9997 - accuracy: 0.9933 - val_loss: 0.5394 - val_f1: 0.5317 - val_auc: 0.8513 - val_accuracy: 0.8771 - _timestamp: 1656374336.0000 - _runtime: 930.0000\n",
            "Epoch 81/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.0979 - f1: 0.9939 - auc: 0.9998 - accuracy: 0.9942 - val_loss: 0.5535 - val_f1: 0.5221 - val_auc: 0.8541 - val_accuracy: 0.8782 - _timestamp: 1656374347.0000 - _runtime: 941.0000\n",
            "Epoch 82/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.0986 - f1: 0.9944 - auc: 0.9996 - accuracy: 0.9946 - val_loss: 0.5456 - val_f1: 0.5294 - val_auc: 0.8559 - val_accuracy: 0.8771 - _timestamp: 1656374358.0000 - _runtime: 952.0000\n",
            "Epoch 83/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.0967 - f1: 0.9934 - auc: 0.9998 - accuracy: 0.9937 - val_loss: 0.5720 - val_f1: 0.5347 - val_auc: 0.8552 - val_accuracy: 0.8760 - _timestamp: 1656374369.0000 - _runtime: 963.0000\n",
            "Epoch 84/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.0975 - f1: 0.9943 - auc: 0.9998 - accuracy: 0.9944 - val_loss: 0.6085 - val_f1: 0.4649 - val_auc: 0.8355 - val_accuracy: 0.8732 - _timestamp: 1656374380.0000 - _runtime: 974.0000\n",
            "Epoch 85/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1029 - f1: 0.9927 - auc: 0.9994 - accuracy: 0.9928 - val_loss: 0.5142 - val_f1: 0.5302 - val_auc: 0.8685 - val_accuracy: 0.8788 - _timestamp: 1656374391.0000 - _runtime: 985.0000\n",
            "Epoch 86/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.0998 - f1: 0.9926 - auc: 0.9998 - accuracy: 0.9932 - val_loss: 0.5128 - val_f1: 0.5480 - val_auc: 0.8665 - val_accuracy: 0.8765 - _timestamp: 1656374403.0000 - _runtime: 997.0000\n",
            "Epoch 87/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.0983 - f1: 0.9937 - auc: 0.9996 - accuracy: 0.9940 - val_loss: 0.5913 - val_f1: 0.5200 - val_auc: 0.8448 - val_accuracy: 0.8776 - _timestamp: 1656374414.0000 - _runtime: 1008.0000\n",
            "Epoch 88/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1011 - f1: 0.9932 - auc: 0.9994 - accuracy: 0.9936 - val_loss: 0.5587 - val_f1: 0.4820 - val_auc: 0.8477 - val_accuracy: 0.8743 - _timestamp: 1656374425.0000 - _runtime: 1019.0000\n",
            "Epoch 89/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.0970 - f1: 0.9941 - auc: 0.9998 - accuracy: 0.9941 - val_loss: 0.5266 - val_f1: 0.5693 - val_auc: 0.8733 - val_accuracy: 0.8737 - _timestamp: 1656374436.0000 - _runtime: 1030.0000\n",
            "Epoch 90/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.0944 - f1: 0.9946 - auc: 0.9998 - accuracy: 0.9947 - val_loss: 0.5681 - val_f1: 0.5427 - val_auc: 0.8487 - val_accuracy: 0.8804 - _timestamp: 1656374447.0000 - _runtime: 1041.0000\n",
            "Epoch 91/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1008 - f1: 0.9918 - auc: 0.9992 - accuracy: 0.9919 - val_loss: 0.5390 - val_f1: 0.5227 - val_auc: 0.8527 - val_accuracy: 0.8788 - _timestamp: 1656374458.0000 - _runtime: 1052.0000\n",
            "Epoch 92/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.1015 - f1: 0.9922 - auc: 0.9994 - accuracy: 0.9926 - val_loss: 0.5213 - val_f1: 0.5164 - val_auc: 0.8571 - val_accuracy: 0.8771 - _timestamp: 1656374469.0000 - _runtime: 1063.0000\n",
            "Epoch 93/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.0983 - f1: 0.9931 - auc: 0.9996 - accuracy: 0.9937 - val_loss: 0.5636 - val_f1: 0.4816 - val_auc: 0.8404 - val_accuracy: 0.8732 - _timestamp: 1656374480.0000 - _runtime: 1074.0000\n",
            "Epoch 94/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.0947 - f1: 0.9941 - auc: 0.9997 - accuracy: 0.9943 - val_loss: 0.5359 - val_f1: 0.4992 - val_auc: 0.8563 - val_accuracy: 0.8754 - _timestamp: 1656374491.0000 - _runtime: 1085.0000\n",
            "Epoch 95/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.0976 - f1: 0.9929 - auc: 0.9996 - accuracy: 0.9932 - val_loss: 0.5237 - val_f1: 0.5379 - val_auc: 0.8686 - val_accuracy: 0.8776 - _timestamp: 1656374502.0000 - _runtime: 1096.0000\n",
            "Epoch 96/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.0936 - f1: 0.9934 - auc: 0.9998 - accuracy: 0.9937 - val_loss: 0.5551 - val_f1: 0.5652 - val_auc: 0.8663 - val_accuracy: 0.8826 - _timestamp: 1656374513.0000 - _runtime: 1107.0000\n",
            "Epoch 97/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.0987 - f1: 0.9918 - auc: 0.9996 - accuracy: 0.9923 - val_loss: 0.5632 - val_f1: 0.4949 - val_auc: 0.8468 - val_accuracy: 0.8737 - _timestamp: 1656374524.0000 - _runtime: 1118.0000\n",
            "Epoch 98/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.0967 - f1: 0.9933 - auc: 0.9994 - accuracy: 0.9937 - val_loss: 0.5503 - val_f1: 0.5536 - val_auc: 0.8601 - val_accuracy: 0.8771 - _timestamp: 1656374535.0000 - _runtime: 1129.0000\n",
            "Epoch 99/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.0969 - f1: 0.9931 - auc: 0.9997 - accuracy: 0.9932 - val_loss: 0.5572 - val_f1: 0.5388 - val_auc: 0.8602 - val_accuracy: 0.8804 - _timestamp: 1656374546.0000 - _runtime: 1140.0000\n",
            "Epoch 100/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.0930 - f1: 0.9940 - auc: 0.9998 - accuracy: 0.9945 - val_loss: 0.5824 - val_f1: 0.4815 - val_auc: 0.8357 - val_accuracy: 0.8754 - _timestamp: 1656374557.0000 - _runtime: 1151.0000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4bd6b4028642412abb13c51888a628d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='262.384 MB of 262.384 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▄▅▆▆▇▇▇▇███████████████████████████████</td></tr><tr><td>auc</td><td>▁▆▇▇████████████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1</td><td>▁▄▅▆▆▆▇▇▇███████████████████████████████</td></tr><tr><td>loss</td><td>█▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▇▁▄▅▅█▇▅█▄▇▆█▇▅▆▇▇▇▇▇▇█▇█▅▆▅▇▇▆▇▆▇▆▆▆</td></tr><tr><td>val_auc</td><td>▆▇█▇█▇▅▆▄▃▅▆▆▆▅▆▅▆▃▆▄▅▅▄▂▅▄▃▄▄▄▄▃▁▂▅▃▃▂▁</td></tr><tr><td>val_f1</td><td>▇█▆▄▇▇▄▇▃▃▅▅▆▇▆▆▅▅▃▇▄▆▆▅▃▆▅▆▃▅▄▆▄▁▄▇▄▃▃▂</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.99448</td></tr><tr><td>auc</td><td>0.99985</td></tr><tr><td>best_epoch</td><td>38</td></tr><tr><td>best_val_loss</td><td>0.49063</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>f1</td><td>0.99404</td></tr><tr><td>loss</td><td>0.09302</td></tr><tr><td>val_accuracy</td><td>0.87542</td></tr><tr><td>val_auc</td><td>0.83569</td></tr><tr><td>val_f1</td><td>0.48146</td></tr><tr><td>val_loss</td><td>0.5824</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">fiery-sweep-17</strong>: <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/s69qj7ya\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/runs/s69qj7ya</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220627_234326-s69qj7ya/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w7ib2l03 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_value: 0.48699995296228105\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-07\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons: 4500\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptomizer: adamax\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_factor: 0.005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_type: l1_l2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.19"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220628_000310-w7ib2l03</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/w7ib2l03\" target=\"_blank\">solar-sweep-18</a></strong> to <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 25008)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4500)              112540500 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 4500)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4500)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4500)              20254500  \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 4500)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4500)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4500)              20254500  \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 4500)              0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 4500)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4500)              20254500  \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 4500)              0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 4500)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 4501      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 173,308,501\n",
            "Trainable params: 173,308,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "380/380 [==============================] - 24s 58ms/step - loss: 7957.3726 - f1: 0.3490 - auc: 0.5977 - accuracy: 0.5053 - val_loss: 7875.2515 - val_f1: 0.1857 - val_auc: 0.4582 - val_accuracy: 0.6858 - _timestamp: 1656374615.0000 - _runtime: 25.0000\n",
            "Epoch 2/100\n",
            "380/380 [==============================] - 21s 56ms/step - loss: 7794.3462 - f1: 0.3647 - auc: 0.5077 - accuracy: 0.5094 - val_loss: 7713.1025 - val_f1: 0.1808 - val_auc: 0.4528 - val_accuracy: 0.6674 - _timestamp: 1656374636.0000 - _runtime: 46.0000\n",
            "Epoch 3/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 7633.0669 - f1: 0.3750 - auc: 0.5169 - accuracy: 0.5129 - val_loss: 7552.6904 - val_f1: 0.1742 - val_auc: 0.4456 - val_accuracy: 0.6307 - _timestamp: 1656374657.0000 - _runtime: 67.0000\n",
            "Epoch 4/100\n",
            "380/380 [==============================] - 20s 53ms/step - loss: 7473.5312 - f1: 0.3778 - auc: 0.5119 - accuracy: 0.5019 - val_loss: 7394.0371 - val_f1: 0.1735 - val_auc: 0.4454 - val_accuracy: 0.5929 - _timestamp: 1656374679.0000 - _runtime: 89.0000\n",
            "Epoch 5/100\n",
            "380/380 [==============================] - 23s 60ms/step - loss: 7315.7466 - f1: 0.3846 - auc: 0.5079 - accuracy: 0.5039 - val_loss: 7237.1494 - val_f1: 0.1802 - val_auc: 0.4397 - val_accuracy: 0.5656 - _timestamp: 1656374699.0000 - _runtime: 109.0000\n",
            "Epoch 6/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 7159.7324 - f1: 0.3974 - auc: 0.5057 - accuracy: 0.5030 - val_loss: 7082.0229 - val_f1: 0.1941 - val_auc: 0.4334 - val_accuracy: 0.5284 - _timestamp: 1656374722.0000 - _runtime: 132.0000\n",
            "Epoch 7/100\n",
            "380/380 [==============================] - 20s 52ms/step - loss: 7005.4780 - f1: 0.4188 - auc: 0.5110 - accuracy: 0.5114 - val_loss: 6928.6479 - val_f1: 0.1945 - val_auc: 0.4293 - val_accuracy: 0.4933 - _timestamp: 1656374744.0000 - _runtime: 154.0000\n",
            "Epoch 8/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 6852.9951 - f1: 0.4138 - auc: 0.4959 - accuracy: 0.5007 - val_loss: 6777.0571 - val_f1: 0.1935 - val_auc: 0.4292 - val_accuracy: 0.4655 - _timestamp: 1656374763.0000 - _runtime: 173.0000\n",
            "Epoch 9/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 6702.2847 - f1: 0.4208 - auc: 0.4935 - accuracy: 0.4983 - val_loss: 6627.2437 - val_f1: 0.1953 - val_auc: 0.4263 - val_accuracy: 0.4444 - _timestamp: 1656374786.0000 - _runtime: 196.0000\n",
            "Epoch 10/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 6553.3516 - f1: 0.4229 - auc: 0.4866 - accuracy: 0.4941 - val_loss: 6479.2041 - val_f1: 0.1899 - val_auc: 0.4264 - val_accuracy: 0.4188 - _timestamp: 1656374807.0000 - _runtime: 217.0000\n",
            "Epoch 11/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 6406.2046 - f1: 0.4385 - auc: 0.4981 - accuracy: 0.5003 - val_loss: 6332.9585 - val_f1: 0.1926 - val_auc: 0.4148 - val_accuracy: 0.4027 - _timestamp: 1656374829.0000 - _runtime: 239.0000\n",
            "Epoch 12/100\n",
            "380/380 [==============================] - 22s 57ms/step - loss: 6260.8423 - f1: 0.4302 - auc: 0.4807 - accuracy: 0.4895 - val_loss: 6188.4888 - val_f1: 0.2014 - val_auc: 0.4120 - val_accuracy: 0.3932 - _timestamp: 1656374851.0000 - _runtime: 261.0000\n",
            "Epoch 13/100\n",
            "380/380 [==============================] - 20s 52ms/step - loss: 6117.2681 - f1: 0.4359 - auc: 0.4791 - accuracy: 0.4859 - val_loss: 6045.8232 - val_f1: 0.2004 - val_auc: 0.4224 - val_accuracy: 0.3704 - _timestamp: 1656374873.0000 - _runtime: 283.0000\n",
            "Epoch 14/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 5975.5034 - f1: 0.4422 - auc: 0.4788 - accuracy: 0.4863 - val_loss: 5904.9551 - val_f1: 0.1966 - val_auc: 0.4090 - val_accuracy: 0.3593 - _timestamp: 1656374893.0000 - _runtime: 303.0000\n",
            "Epoch 15/100\n",
            "380/380 [==============================] - 21s 57ms/step - loss: 5835.5312 - f1: 0.4414 - auc: 0.4830 - accuracy: 0.4845 - val_loss: 5765.8853 - val_f1: 0.1963 - val_auc: 0.4095 - val_accuracy: 0.3471 - _timestamp: 1656374915.0000 - _runtime: 325.0000\n",
            "Epoch 16/100\n",
            "380/380 [==============================] - 22s 57ms/step - loss: 5697.3623 - f1: 0.4398 - auc: 0.4769 - accuracy: 0.4837 - val_loss: 5628.6230 - val_f1: 0.2036 - val_auc: 0.4127 - val_accuracy: 0.3343 - _timestamp: 1656374937.0000 - _runtime: 347.0000\n",
            "Epoch 17/100\n",
            "380/380 [==============================] - 20s 52ms/step - loss: 5560.9980 - f1: 0.4607 - auc: 0.4948 - accuracy: 0.4989 - val_loss: 5493.1689 - val_f1: 0.2061 - val_auc: 0.4129 - val_accuracy: 0.3287 - _timestamp: 1656374958.0000 - _runtime: 368.0000\n",
            "Epoch 18/100\n",
            "380/380 [==============================] - 21s 55ms/step - loss: 5426.4507 - f1: 0.4533 - auc: 0.4781 - accuracy: 0.4886 - val_loss: 5359.5327 - val_f1: 0.2090 - val_auc: 0.4115 - val_accuracy: 0.3220 - _timestamp: 1656374978.0000 - _runtime: 388.0000\n",
            "Epoch 19/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 5293.7251 - f1: 0.4575 - auc: 0.4740 - accuracy: 0.4900 - val_loss: 5227.7192 - val_f1: 0.2105 - val_auc: 0.4188 - val_accuracy: 0.3092 - _timestamp: 1656374999.0000 - _runtime: 409.0000\n",
            "Epoch 20/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 5162.8154 - f1: 0.4570 - auc: 0.4732 - accuracy: 0.4890 - val_loss: 5097.7236 - val_f1: 0.2152 - val_auc: 0.4251 - val_accuracy: 0.3059 - _timestamp: 1656375021.0000 - _runtime: 431.0000\n",
            "Epoch 21/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 5033.7271 - f1: 0.4578 - auc: 0.4796 - accuracy: 0.4890 - val_loss: 4969.5552 - val_f1: 0.2170 - val_auc: 0.4294 - val_accuracy: 0.3026 - _timestamp: 1656375043.0000 - _runtime: 453.0000\n",
            "Epoch 22/100\n",
            "380/380 [==============================] - 20s 52ms/step - loss: 4906.4678 - f1: 0.4585 - auc: 0.4704 - accuracy: 0.4815 - val_loss: 4843.2163 - val_f1: 0.2229 - val_auc: 0.4313 - val_accuracy: 0.2953 - _timestamp: 1656375065.0000 - _runtime: 475.0000\n",
            "Epoch 23/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 4781.0405 - f1: 0.4640 - auc: 0.4836 - accuracy: 0.4878 - val_loss: 4718.7031 - val_f1: 0.2237 - val_auc: 0.4347 - val_accuracy: 0.2870 - _timestamp: 1656375085.0000 - _runtime: 495.0000\n",
            "Epoch 24/100\n",
            "380/380 [==============================] - 23s 60ms/step - loss: 4657.4482 - f1: 0.4638 - auc: 0.4716 - accuracy: 0.4887 - val_loss: 4596.0327 - val_f1: 0.2288 - val_auc: 0.4334 - val_accuracy: 0.2798 - _timestamp: 1656375107.0000 - _runtime: 517.0000\n",
            "Epoch 25/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 4535.6890 - f1: 0.4723 - auc: 0.4768 - accuracy: 0.4889 - val_loss: 4475.2021 - val_f1: 0.2309 - val_auc: 0.4366 - val_accuracy: 0.2736 - _timestamp: 1656375130.0000 - _runtime: 540.0000\n",
            "Epoch 26/100\n",
            "380/380 [==============================] - 21s 56ms/step - loss: 4415.7729 - f1: 0.4637 - auc: 0.4725 - accuracy: 0.4835 - val_loss: 4356.2065 - val_f1: 0.2313 - val_auc: 0.4481 - val_accuracy: 0.2664 - _timestamp: 1656375152.0000 - _runtime: 562.0000\n",
            "Epoch 27/100\n",
            "380/380 [==============================] - 20s 52ms/step - loss: 4297.7021 - f1: 0.4777 - auc: 0.4887 - accuracy: 0.4931 - val_loss: 4239.0625 - val_f1: 0.2394 - val_auc: 0.4504 - val_accuracy: 0.2692 - _timestamp: 1656375173.0000 - _runtime: 583.0000\n",
            "Epoch 28/100\n",
            "380/380 [==============================] - 22s 57ms/step - loss: 4181.4741 - f1: 0.4828 - auc: 0.4787 - accuracy: 0.4915 - val_loss: 4123.7603 - val_f1: 0.2441 - val_auc: 0.4592 - val_accuracy: 0.2659 - _timestamp: 1656375193.0000 - _runtime: 603.0000\n",
            "Epoch 29/100\n",
            "380/380 [==============================] - 28s 74ms/step - loss: 4067.0920 - f1: 0.4985 - auc: 0.4929 - accuracy: 0.4993 - val_loss: 4010.3081 - val_f1: 0.2449 - val_auc: 0.4678 - val_accuracy: 0.2592 - _timestamp: 1656375215.0000 - _runtime: 625.0000\n",
            "Epoch 30/100\n",
            "380/380 [==============================] - 21s 55ms/step - loss: 3954.5605 - f1: 0.4997 - auc: 0.4956 - accuracy: 0.5043 - val_loss: 3898.7000 - val_f1: 0.2472 - val_auc: 0.4746 - val_accuracy: 0.2514 - _timestamp: 1656375243.0000 - _runtime: 653.0000\n",
            "Epoch 31/100\n",
            "380/380 [==============================] - 20s 52ms/step - loss: 3843.8723 - f1: 0.4996 - auc: 0.4865 - accuracy: 0.4947 - val_loss: 3788.9419 - val_f1: 0.2458 - val_auc: 0.4869 - val_accuracy: 0.2414 - _timestamp: 1656375263.0000 - _runtime: 673.0000\n",
            "Epoch 32/100\n",
            "380/380 [==============================] - 20s 52ms/step - loss: 3735.0410 - f1: 0.5031 - auc: 0.4901 - accuracy: 0.4987 - val_loss: 3681.0457 - val_f1: 0.2487 - val_auc: 0.4919 - val_accuracy: 0.2341 - _timestamp: 1656375283.0000 - _runtime: 693.0000\n",
            "Epoch 33/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 3628.0645 - f1: 0.5090 - auc: 0.4881 - accuracy: 0.5003 - val_loss: 3574.9995 - val_f1: 0.2538 - val_auc: 0.5017 - val_accuracy: 0.2347 - _timestamp: 1656375303.0000 - _runtime: 713.0000\n",
            "Epoch 34/100\n",
            "380/380 [==============================] - 20s 52ms/step - loss: 3522.9448 - f1: 0.5206 - auc: 0.4995 - accuracy: 0.5080 - val_loss: 3470.8115 - val_f1: 0.2570 - val_auc: 0.5114 - val_accuracy: 0.2325 - _timestamp: 1656375323.0000 - _runtime: 733.0000\n",
            "Epoch 35/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 3419.6819 - f1: 0.5359 - auc: 0.4994 - accuracy: 0.5151 - val_loss: 3368.4802 - val_f1: 0.2598 - val_auc: 0.5121 - val_accuracy: 0.2325 - _timestamp: 1656375343.0000 - _runtime: 753.0000\n",
            "Epoch 36/100\n",
            "380/380 [==============================] - 21s 56ms/step - loss: 3318.2773 - f1: 0.5470 - auc: 0.4982 - accuracy: 0.5239 - val_loss: 3268.0107 - val_f1: 0.2624 - val_auc: 0.5170 - val_accuracy: 0.2286 - _timestamp: 1656375365.0000 - _runtime: 775.0000\n",
            "Epoch 37/100\n",
            "380/380 [==============================] - 20s 52ms/step - loss: 3218.7356 - f1: 0.5559 - auc: 0.5081 - accuracy: 0.5256 - val_loss: 3169.4026 - val_f1: 0.2706 - val_auc: 0.5092 - val_accuracy: 0.2308 - _timestamp: 1656375386.0000 - _runtime: 796.0000\n",
            "Epoch 38/100\n",
            "380/380 [==============================] - 22s 57ms/step - loss: 3121.0554 - f1: 0.5649 - auc: 0.5075 - accuracy: 0.5321 - val_loss: 3072.6567 - val_f1: 0.2756 - val_auc: 0.5097 - val_accuracy: 0.2253 - _timestamp: 1656375406.0000 - _runtime: 816.0000\n",
            "Epoch 39/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 3025.2429 - f1: 0.5737 - auc: 0.5095 - accuracy: 0.5338 - val_loss: 2977.7773 - val_f1: 0.2803 - val_auc: 0.5115 - val_accuracy: 0.2297 - _timestamp: 1656375428.0000 - _runtime: 838.0000\n",
            "Epoch 40/100\n",
            "380/380 [==============================] - 21s 56ms/step - loss: 2931.2883 - f1: 0.5933 - auc: 0.5095 - accuracy: 0.5499 - val_loss: 2884.7632 - val_f1: 0.2818 - val_auc: 0.5155 - val_accuracy: 0.2303 - _timestamp: 1656375450.0000 - _runtime: 860.0000\n",
            "Epoch 41/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 2839.2034 - f1: 0.6029 - auc: 0.5139 - accuracy: 0.5581 - val_loss: 2793.6147 - val_f1: 0.2888 - val_auc: 0.5184 - val_accuracy: 0.2369 - _timestamp: 1656375472.0000 - _runtime: 882.0000\n",
            "Epoch 42/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 2748.9854 - f1: 0.6181 - auc: 0.5087 - accuracy: 0.5626 - val_loss: 2704.3340 - val_f1: 0.2896 - val_auc: 0.5111 - val_accuracy: 0.2392 - _timestamp: 1656375494.0000 - _runtime: 904.0000\n",
            "Epoch 43/100\n",
            "380/380 [==============================] - 21s 56ms/step - loss: 2660.6353 - f1: 0.6254 - auc: 0.5119 - accuracy: 0.5690 - val_loss: 2616.9216 - val_f1: 0.2919 - val_auc: 0.5110 - val_accuracy: 0.2430 - _timestamp: 1656375516.0000 - _runtime: 926.0000\n",
            "Epoch 44/100\n",
            "380/380 [==============================] - 20s 52ms/step - loss: 2574.1526 - f1: 0.6416 - auc: 0.5094 - accuracy: 0.5827 - val_loss: 2531.3748 - val_f1: 0.2945 - val_auc: 0.5098 - val_accuracy: 0.2481 - _timestamp: 1656375537.0000 - _runtime: 947.0000\n",
            "Epoch 45/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 2489.5388 - f1: 0.6483 - auc: 0.5085 - accuracy: 0.5843 - val_loss: 2447.6960 - val_f1: 0.2968 - val_auc: 0.5022 - val_accuracy: 0.2547 - _timestamp: 1656375557.0000 - _runtime: 967.0000\n",
            "Epoch 46/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 2406.7886 - f1: 0.6585 - auc: 0.5032 - accuracy: 0.5932 - val_loss: 2365.8853 - val_f1: 0.3000 - val_auc: 0.5025 - val_accuracy: 0.2631 - _timestamp: 1656375579.0000 - _runtime: 989.0000\n",
            "Epoch 47/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 2325.9084 - f1: 0.6665 - auc: 0.5043 - accuracy: 0.5956 - val_loss: 2285.9448 - val_f1: 0.3018 - val_auc: 0.5028 - val_accuracy: 0.2675 - _timestamp: 1656375601.0000 - _runtime: 1011.0000\n",
            "Epoch 48/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 2246.8987 - f1: 0.6815 - auc: 0.5035 - accuracy: 0.6146 - val_loss: 2207.8745 - val_f1: 0.3046 - val_auc: 0.4983 - val_accuracy: 0.2781 - _timestamp: 1656375623.0000 - _runtime: 1033.0000\n",
            "Epoch 49/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 2169.7605 - f1: 0.6917 - auc: 0.5023 - accuracy: 0.6184 - val_loss: 2131.6724 - val_f1: 0.3073 - val_auc: 0.4993 - val_accuracy: 0.2864 - _timestamp: 1656375645.0000 - _runtime: 1055.0000\n",
            "Epoch 50/100\n",
            "380/380 [==============================] - 23s 60ms/step - loss: 2094.4922 - f1: 0.6995 - auc: 0.5016 - accuracy: 0.6220 - val_loss: 2057.3440 - val_f1: 0.3102 - val_auc: 0.5000 - val_accuracy: 0.2959 - _timestamp: 1656375667.0000 - _runtime: 1077.0000\n",
            "Epoch 51/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 2021.0947 - f1: 0.7019 - auc: 0.5011 - accuracy: 0.6227 - val_loss: 1984.8849 - val_f1: 0.3144 - val_auc: 0.5000 - val_accuracy: 0.3098 - _timestamp: 1656375690.0000 - _runtime: 1100.0000\n",
            "Epoch 52/100\n",
            "380/380 [==============================] - 22s 57ms/step - loss: 1949.5674 - f1: 0.7135 - auc: 0.5005 - accuracy: 0.6358 - val_loss: 1914.2968 - val_f1: 0.3175 - val_auc: 0.5000 - val_accuracy: 0.3215 - _timestamp: 1656375712.0000 - _runtime: 1122.0000\n",
            "Epoch 53/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 1879.9099 - f1: 0.7209 - auc: 0.5001 - accuracy: 0.6440 - val_loss: 1845.5781 - val_f1: 0.3204 - val_auc: 0.5000 - val_accuracy: 0.3315 - _timestamp: 1656375734.0000 - _runtime: 1144.0000\n",
            "Epoch 54/100\n",
            "380/380 [==============================] - 21s 56ms/step - loss: 1812.1237 - f1: 0.7241 - auc: 0.5002 - accuracy: 0.6468 - val_loss: 1778.7319 - val_f1: 0.3228 - val_auc: 0.5000 - val_accuracy: 0.3398 - _timestamp: 1656375756.0000 - _runtime: 1166.0000\n",
            "Epoch 55/100\n",
            "380/380 [==============================] - 20s 52ms/step - loss: 1746.2085 - f1: 0.7321 - auc: 0.5000 - accuracy: 0.6579 - val_loss: 1713.7520 - val_f1: 0.3298 - val_auc: 0.5000 - val_accuracy: 0.3615 - _timestamp: 1656375777.0000 - _runtime: 1187.0000\n",
            "Epoch 56/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 1682.1589 - f1: 0.7320 - auc: 0.5000 - accuracy: 0.6567 - val_loss: 1650.6406 - val_f1: 0.3348 - val_auc: 0.5000 - val_accuracy: 0.3754 - _timestamp: 1656375797.0000 - _runtime: 1207.0000\n",
            "Epoch 57/100\n",
            "380/380 [==============================] - 27s 72ms/step - loss: 1619.9773 - f1: 0.7422 - auc: 0.5000 - accuracy: 0.6704 - val_loss: 1589.3964 - val_f1: 0.3392 - val_auc: 0.5000 - val_accuracy: 0.3893 - _timestamp: 1656375819.0000 - _runtime: 1229.0000\n",
            "Epoch 58/100\n",
            "380/380 [==============================] - 20s 54ms/step - loss: 1559.6630 - f1: 0.7469 - auc: 0.5000 - accuracy: 0.6800 - val_loss: 1530.0204 - val_f1: 0.3515 - val_auc: 0.5000 - val_accuracy: 0.4210 - _timestamp: 1656375846.0000 - _runtime: 1256.0000\n",
            "Epoch 59/100\n",
            "380/380 [==============================] - 20s 52ms/step - loss: 1501.2184 - f1: 0.7499 - auc: 0.5000 - accuracy: 0.6868 - val_loss: 1472.5132 - val_f1: 0.3592 - val_auc: 0.5000 - val_accuracy: 0.4405 - _timestamp: 1656375867.0000 - _runtime: 1277.0000\n",
            "Epoch 60/100\n",
            "380/380 [==============================] - 22s 57ms/step - loss: 1444.6428 - f1: 0.7571 - auc: 0.5000 - accuracy: 0.6983 - val_loss: 1416.8752 - val_f1: 0.3727 - val_auc: 0.5000 - val_accuracy: 0.4766 - _timestamp: 1656375886.0000 - _runtime: 1296.0000\n",
            "Epoch 61/100\n",
            "380/380 [==============================] - 21s 55ms/step - loss: 1389.9369 - f1: 0.7695 - auc: 0.5000 - accuracy: 0.7206 - val_loss: 1363.1090 - val_f1: 0.3871 - val_auc: 0.5000 - val_accuracy: 0.5150 - _timestamp: 1656375908.0000 - _runtime: 1318.0000\n",
            "Epoch 62/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 1337.1003 - f1: 0.7755 - auc: 0.5000 - accuracy: 0.7330 - val_loss: 1311.2081 - val_f1: 0.4046 - val_auc: 0.5000 - val_accuracy: 0.5556 - _timestamp: 1656375929.0000 - _runtime: 1339.0000\n",
            "Epoch 63/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 1286.1299 - f1: 0.7876 - auc: 0.5000 - accuracy: 0.7611 - val_loss: 1261.1744 - val_f1: 0.4343 - val_auc: 0.5000 - val_accuracy: 0.6179 - _timestamp: 1656375951.0000 - _runtime: 1361.0000\n",
            "Epoch 64/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 1237.0270 - f1: 0.7909 - auc: 0.5000 - accuracy: 0.7731 - val_loss: 1213.0046 - val_f1: 0.4755 - val_auc: 0.5000 - val_accuracy: 0.6930 - _timestamp: 1656375973.0000 - _runtime: 1383.0000\n",
            "Epoch 65/100\n",
            "380/380 [==============================] - 21s 56ms/step - loss: 1189.7849 - f1: 0.7654 - auc: 0.5000 - accuracy: 0.7677 - val_loss: 1166.7008 - val_f1: 0.4916 - val_auc: 0.5000 - val_accuracy: 0.7430 - _timestamp: 1656375995.0000 - _runtime: 1405.0000\n",
            "Epoch 66/100\n",
            "380/380 [==============================] - 20s 53ms/step - loss: 1144.4108 - f1: 0.7071 - auc: 0.5000 - accuracy: 0.7389 - val_loss: 1122.2632 - val_f1: 0.5163 - val_auc: 0.5000 - val_accuracy: 0.8070 - _timestamp: 1656376016.0000 - _runtime: 1426.0000\n",
            "Epoch 67/100\n",
            "380/380 [==============================] - 21s 56ms/step - loss: 1100.9022 - f1: 0.5843 - auc: 0.5000 - accuracy: 0.6809 - val_loss: 1079.6909 - val_f1: 0.4777 - val_auc: 0.5000 - val_accuracy: 0.8459 - _timestamp: 1656376036.0000 - _runtime: 1446.0000\n",
            "Epoch 68/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 1059.2583 - f1: 0.4106 - auc: 0.5000 - accuracy: 0.6114 - val_loss: 1038.9816 - val_f1: 0.2748 - val_auc: 0.5000 - val_accuracy: 0.8537 - _timestamp: 1656376058.0000 - _runtime: 1468.0000\n",
            "Epoch 69/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 1019.4776 - f1: 0.2101 - auc: 0.5000 - accuracy: 0.5509 - val_loss: 1000.1366 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8376 - _timestamp: 1656376080.0000 - _runtime: 1490.0000\n",
            "Epoch 70/100\n",
            "380/380 [==============================] - 20s 52ms/step - loss: 981.5595 - f1: 0.0611 - auc: 0.5000 - accuracy: 0.5137 - val_loss: 963.1525 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376102.0000 - _runtime: 1512.0000\n",
            "Epoch 71/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 945.5040 - f1: 0.0149 - auc: 0.5000 - accuracy: 0.5035 - val_loss: 928.0315 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376122.0000 - _runtime: 1532.0000\n",
            "Epoch 72/100\n",
            "380/380 [==============================] - 22s 57ms/step - loss: 911.3103 - f1: 7.8080e-04 - auc: 0.5000 - accuracy: 0.5002 - val_loss: 894.7724 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376144.0000 - _runtime: 1554.0000\n",
            "Epoch 73/100\n",
            "380/380 [==============================] - 20s 52ms/step - loss: 878.9775 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 863.3733 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376166.0000 - _runtime: 1576.0000\n",
            "Epoch 74/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 848.5045 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 833.8329 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376186.0000 - _runtime: 1596.0000\n",
            "Epoch 75/100\n",
            "380/380 [==============================] - 20s 53ms/step - loss: 819.8907 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 806.1525 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376208.0000 - _runtime: 1618.0000\n",
            "Epoch 76/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 792.9756 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 779.8035 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376228.0000 - _runtime: 1638.0000\n",
            "Epoch 77/100\n",
            "380/380 [==============================] - 20s 52ms/step - loss: 766.9106 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 754.0013 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376250.0000 - _runtime: 1660.0000\n",
            "Epoch 78/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 741.3497 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 728.6783 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376270.0000 - _runtime: 1680.0000\n",
            "Epoch 79/100\n",
            "380/380 [==============================] - 22s 57ms/step - loss: 716.2556 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 703.8124 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376292.0000 - _runtime: 1702.0000\n",
            "Epoch 80/100\n",
            "380/380 [==============================] - 21s 56ms/step - loss: 691.6133 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 679.3945 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376313.0000 - _runtime: 1723.0000\n",
            "Epoch 81/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 667.4158 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 655.4184 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376335.0000 - _runtime: 1745.0000\n",
            "Epoch 82/100\n",
            "380/380 [==============================] - 23s 60ms/step - loss: 643.6591 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 631.8815 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376357.0000 - _runtime: 1767.0000\n",
            "Epoch 83/100\n",
            "380/380 [==============================] - 22s 59ms/step - loss: 620.3390 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 608.7797 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376379.0000 - _runtime: 1789.0000\n",
            "Epoch 84/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 597.4539 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 586.1133 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376402.0000 - _runtime: 1812.0000\n",
            "Epoch 85/100\n",
            "380/380 [==============================] - 27s 71ms/step - loss: 575.0033 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 563.8795 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376424.0000 - _runtime: 1834.0000\n",
            "Epoch 86/100\n",
            "380/380 [==============================] - 20s 52ms/step - loss: 552.9857 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 542.0801 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376451.0000 - _runtime: 1861.0000\n",
            "Epoch 87/100\n",
            "380/380 [==============================] - 23s 60ms/step - loss: 531.4020 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 520.7144 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376471.0000 - _runtime: 1881.0000\n",
            "Epoch 88/100\n",
            "380/380 [==============================] - 20s 52ms/step - loss: 510.2516 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 499.7812 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376493.0000 - _runtime: 1903.0000\n",
            "Epoch 89/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 489.5350 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 479.2825 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376513.0000 - _runtime: 1923.0000\n",
            "Epoch 90/100\n",
            "380/380 [==============================] - 21s 56ms/step - loss: 469.2515 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 459.2153 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376535.0000 - _runtime: 1945.0000\n",
            "Epoch 91/100\n",
            "380/380 [==============================] - 20s 52ms/step - loss: 449.3998 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 439.5807 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376556.0000 - _runtime: 1966.0000\n",
            "Epoch 92/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 429.9806 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 420.3785 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376576.0000 - _runtime: 1986.0000\n",
            "Epoch 93/100\n",
            "380/380 [==============================] - 23s 60ms/step - loss: 410.9933 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 401.6085 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376598.0000 - _runtime: 2008.0000\n",
            "Epoch 94/100\n",
            "380/380 [==============================] - 23s 60ms/step - loss: 392.4390 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 383.2709 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376621.0000 - _runtime: 2031.0000\n",
            "Epoch 95/100\n",
            "380/380 [==============================] - 22s 57ms/step - loss: 374.3166 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 365.3650 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376644.0000 - _runtime: 2054.0000\n",
            "Epoch 96/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 356.6249 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 347.8898 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376665.0000 - _runtime: 2075.0000\n",
            "Epoch 97/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 339.3644 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 330.8456 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376687.0000 - _runtime: 2097.0000\n",
            "Epoch 98/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 322.5351 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 314.2328 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376709.0000 - _runtime: 2119.0000\n",
            "Epoch 99/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 306.1375 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 298.0518 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376731.0000 - _runtime: 2141.0000\n",
            "Epoch 100/100\n",
            "380/380 [==============================] - 22s 58ms/step - loss: 290.1713 - f1: 0.0000e+00 - auc: 0.5000 - accuracy: 0.5000 - val_loss: 282.3018 - val_f1: 0.0000e+00 - val_auc: 0.5000 - val_accuracy: 0.8382 - _timestamp: 1656376753.0000 - _runtime: 2163.0000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28ca99c6d9244cdd9071fc4379d32529",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='1983.420 MB of 1983.420 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▄▄▄▅▅▆▇█▆▃▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>auc</td><td>█▃▃▂▂▁▁▁▁▂▁▁▂▃▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1</td><td>▄▄▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇███▆▃▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>██▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▆▆▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▂▂▂▃▃▄▆██████████████</td></tr><tr><td>val_auc</td><td>▄▃▂▂▁▂▁▁▂▃▃▄▆████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▇██▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>██▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.5</td></tr><tr><td>auc</td><td>0.5</td></tr><tr><td>best_epoch</td><td>99</td></tr><tr><td>best_val_loss</td><td>282.30179</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>f1</td><td>0.0</td></tr><tr><td>loss</td><td>290.1713</td></tr><tr><td>val_accuracy</td><td>0.83815</td></tr><tr><td>val_auc</td><td>0.5</td></tr><tr><td>val_f1</td><td>0.0</td></tr><tr><td>val_loss</td><td>282.30179</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">solar-sweep-18</strong>: <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/w7ib2l03\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/runs/w7ib2l03</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220628_000310-w7ib2l03/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: t44woaya with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: leaky_relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_value: 0.1948546033034144\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons: 3000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptomizer: adamax\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_factor: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_type: l1_l2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.19"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220628_004021-t44woaya</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/t44woaya\" target=\"_blank\">glorious-sweep-19</a></strong> to <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 25008)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3000)              75027000  \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 3000)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 3000)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3000)              9003000   \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 3000)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 3000)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3000)              9003000   \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 3000)              0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 3000)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3000)              9003000   \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 3000)              0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 3000)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 3000)              9003000   \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 3000)              0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 3000)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 3001      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 111,042,001\n",
            "Trainable params: 111,042,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "380/380 [==============================] - 16s 38ms/step - loss: 76.7653 - f1: 0.8443 - auc: 0.9014 - accuracy: 0.8376 - val_loss: 61.3636 - val_f1: 0.5206 - val_auc: 0.8706 - val_accuracy: 0.7753 - _timestamp: 1656376842.0000 - _runtime: 21.0000\n",
            "Epoch 2/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 56.5035 - f1: 0.8988 - auc: 0.9609 - accuracy: 0.9017 - val_loss: 52.7320 - val_f1: 0.5304 - val_auc: 0.8839 - val_accuracy: 0.7697 - _timestamp: 1656376855.0000 - _runtime: 34.0000\n",
            "Epoch 3/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 48.8572 - f1: 0.9055 - auc: 0.9666 - accuracy: 0.9080 - val_loss: 45.6572 - val_f1: 0.5580 - val_auc: 0.8847 - val_accuracy: 0.8165 - _timestamp: 1656376868.0000 - _runtime: 47.0000\n",
            "Epoch 4/100\n",
            "380/380 [==============================] - 15s 41ms/step - loss: 42.2807 - f1: 0.9144 - auc: 0.9721 - accuracy: 0.9168 - val_loss: 39.4783 - val_f1: 0.5423 - val_auc: 0.8874 - val_accuracy: 0.7920 - _timestamp: 1656376881.0000 - _runtime: 60.0000\n",
            "Epoch 5/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 36.2749 - f1: 0.9207 - auc: 0.9760 - accuracy: 0.9232 - val_loss: 33.7107 - val_f1: 0.5473 - val_auc: 0.8878 - val_accuracy: 0.7953 - _timestamp: 1656376897.0000 - _runtime: 76.0000\n",
            "Epoch 6/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 30.7722 - f1: 0.9218 - auc: 0.9773 - accuracy: 0.9235 - val_loss: 28.4084 - val_f1: 0.5549 - val_auc: 0.8889 - val_accuracy: 0.8192 - _timestamp: 1656376913.0000 - _runtime: 92.0000\n",
            "Epoch 7/100\n",
            "380/380 [==============================] - 16s 42ms/step - loss: 25.8114 - f1: 0.9269 - auc: 0.9795 - accuracy: 0.9297 - val_loss: 23.7381 - val_f1: 0.5700 - val_auc: 0.8934 - val_accuracy: 0.8287 - _timestamp: 1656376926.0000 - _runtime: 105.0000\n",
            "Epoch 8/100\n",
            "380/380 [==============================] - 12s 33ms/step - loss: 21.4645 - f1: 0.9300 - auc: 0.9811 - accuracy: 0.9321 - val_loss: 19.7012 - val_f1: 0.5765 - val_auc: 0.8908 - val_accuracy: 0.8465 - _timestamp: 1656376941.0000 - _runtime: 120.0000\n",
            "Epoch 9/100\n",
            "380/380 [==============================] - 14s 38ms/step - loss: 17.8053 - f1: 0.9315 - auc: 0.9822 - accuracy: 0.9327 - val_loss: 16.3781 - val_f1: 0.5719 - val_auc: 0.8875 - val_accuracy: 0.8415 - _timestamp: 1656376954.0000 - _runtime: 133.0000\n",
            "Epoch 10/100\n",
            "380/380 [==============================] - 15s 40ms/step - loss: 14.7520 - f1: 0.9344 - auc: 0.9830 - accuracy: 0.9351 - val_loss: 13.6303 - val_f1: 0.5677 - val_auc: 0.8911 - val_accuracy: 0.8320 - _timestamp: 1656376968.0000 - _runtime: 147.0000\n",
            "Epoch 11/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 12.2501 - f1: 0.9318 - auc: 0.9820 - accuracy: 0.9336 - val_loss: 11.4197 - val_f1: 0.5482 - val_auc: 0.8917 - val_accuracy: 0.8020 - _timestamp: 1656376983.0000 - _runtime: 162.0000\n",
            "Epoch 12/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 10.1904 - f1: 0.9350 - auc: 0.9844 - accuracy: 0.9377 - val_loss: 9.5038 - val_f1: 0.5781 - val_auc: 0.8887 - val_accuracy: 0.8432 - _timestamp: 1656376999.0000 - _runtime: 178.0000\n",
            "Epoch 13/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 8.5408 - f1: 0.9333 - auc: 0.9838 - accuracy: 0.9355 - val_loss: 7.9967 - val_f1: 0.6048 - val_auc: 0.8933 - val_accuracy: 0.8621 - _timestamp: 1656377012.0000 - _runtime: 191.0000\n",
            "Epoch 14/100\n",
            "380/380 [==============================] - 15s 40ms/step - loss: 7.2243 - f1: 0.9325 - auc: 0.9833 - accuracy: 0.9352 - val_loss: 6.8384 - val_f1: 0.5793 - val_auc: 0.8921 - val_accuracy: 0.8426 - _timestamp: 1656377025.0000 - _runtime: 204.0000\n",
            "Epoch 15/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 6.1570 - f1: 0.9350 - auc: 0.9836 - accuracy: 0.9363 - val_loss: 5.8949 - val_f1: 0.5776 - val_auc: 0.8886 - val_accuracy: 0.8420 - _timestamp: 1656377040.0000 - _runtime: 219.0000\n",
            "Epoch 16/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 5.2934 - f1: 0.9343 - auc: 0.9831 - accuracy: 0.9360 - val_loss: 5.0789 - val_f1: 0.5830 - val_auc: 0.8900 - val_accuracy: 0.8582 - _timestamp: 1656377053.0000 - _runtime: 232.0000\n",
            "Epoch 17/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 4.5922 - f1: 0.9335 - auc: 0.9825 - accuracy: 0.9349 - val_loss: 4.4266 - val_f1: 0.5902 - val_auc: 0.8887 - val_accuracy: 0.8682 - _timestamp: 1656377066.0000 - _runtime: 245.0000\n",
            "Epoch 18/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 4.0102 - f1: 0.9362 - auc: 0.9840 - accuracy: 0.9379 - val_loss: 3.9344 - val_f1: 0.5663 - val_auc: 0.8904 - val_accuracy: 0.8487 - _timestamp: 1656377079.0000 - _runtime: 258.0000\n",
            "Epoch 19/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 3.5407 - f1: 0.9328 - auc: 0.9834 - accuracy: 0.9345 - val_loss: 3.4720 - val_f1: 0.5696 - val_auc: 0.8932 - val_accuracy: 0.8710 - _timestamp: 1656377095.0000 - _runtime: 274.0000\n",
            "Epoch 20/100\n",
            "380/380 [==============================] - 15s 40ms/step - loss: 3.1503 - f1: 0.9347 - auc: 0.9837 - accuracy: 0.9371 - val_loss: 3.1373 - val_f1: 0.5963 - val_auc: 0.8934 - val_accuracy: 0.8643 - _timestamp: 1656377108.0000 - _runtime: 287.0000\n",
            "Epoch 21/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 2.8198 - f1: 0.9377 - auc: 0.9844 - accuracy: 0.9392 - val_loss: 2.8372 - val_f1: 0.5925 - val_auc: 0.8905 - val_accuracy: 0.8637 - _timestamp: 1656377123.0000 - _runtime: 302.0000\n",
            "Epoch 22/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 2.5449 - f1: 0.9356 - auc: 0.9842 - accuracy: 0.9383 - val_loss: 2.5646 - val_f1: 0.5873 - val_auc: 0.8917 - val_accuracy: 0.8754 - _timestamp: 1656377136.0000 - _runtime: 315.0000\n",
            "Epoch 23/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 2.3173 - f1: 0.9355 - auc: 0.9837 - accuracy: 0.9378 - val_loss: 2.3681 - val_f1: 0.5915 - val_auc: 0.8943 - val_accuracy: 0.8632 - _timestamp: 1656377152.0000 - _runtime: 331.0000\n",
            "Epoch 24/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 2.1139 - f1: 0.9391 - auc: 0.9847 - accuracy: 0.9408 - val_loss: 2.1872 - val_f1: 0.5916 - val_auc: 0.8936 - val_accuracy: 0.8632 - _timestamp: 1656377165.0000 - _runtime: 344.0000\n",
            "Epoch 25/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 1.9460 - f1: 0.9365 - auc: 0.9838 - accuracy: 0.9380 - val_loss: 2.0581 - val_f1: 0.5830 - val_auc: 0.8946 - val_accuracy: 0.8426 - _timestamp: 1656377178.0000 - _runtime: 357.0000\n",
            "Epoch 26/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 1.7915 - f1: 0.9385 - auc: 0.9851 - accuracy: 0.9396 - val_loss: 1.8682 - val_f1: 0.5904 - val_auc: 0.8977 - val_accuracy: 0.8726 - _timestamp: 1656377191.0000 - _runtime: 370.0000\n",
            "Epoch 27/100\n",
            "380/380 [==============================] - 15s 40ms/step - loss: 1.6637 - f1: 0.9363 - auc: 0.9850 - accuracy: 0.9387 - val_loss: 1.7431 - val_f1: 0.5844 - val_auc: 0.8946 - val_accuracy: 0.8782 - _timestamp: 1656377204.0000 - _runtime: 383.0000\n",
            "Epoch 28/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 1.5558 - f1: 0.9356 - auc: 0.9839 - accuracy: 0.9373 - val_loss: 1.6329 - val_f1: 0.5880 - val_auc: 0.8992 - val_accuracy: 0.8782 - _timestamp: 1656377219.0000 - _runtime: 398.0000\n",
            "Epoch 29/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 1.4513 - f1: 0.9378 - auc: 0.9853 - accuracy: 0.9399 - val_loss: 1.5559 - val_f1: 0.5914 - val_auc: 0.8973 - val_accuracy: 0.8682 - _timestamp: 1656377232.0000 - _runtime: 411.0000\n",
            "Epoch 30/100\n",
            "380/380 [==============================] - 16s 42ms/step - loss: 1.3623 - f1: 0.9386 - auc: 0.9853 - accuracy: 0.9399 - val_loss: 1.4630 - val_f1: 0.5956 - val_auc: 0.8962 - val_accuracy: 0.8749 - _timestamp: 1656377245.0000 - _runtime: 424.0000\n",
            "Epoch 31/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 1.2863 - f1: 0.9388 - auc: 0.9850 - accuracy: 0.9406 - val_loss: 1.3974 - val_f1: 0.5887 - val_auc: 0.8940 - val_accuracy: 0.8715 - _timestamp: 1656377261.0000 - _runtime: 440.0000\n",
            "Epoch 32/100\n",
            "380/380 [==============================] - 15s 41ms/step - loss: 1.2176 - f1: 0.9384 - auc: 0.9848 - accuracy: 0.9407 - val_loss: 1.3292 - val_f1: 0.5978 - val_auc: 0.8982 - val_accuracy: 0.8732 - _timestamp: 1656377274.0000 - _runtime: 453.0000\n",
            "Epoch 33/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 1.1574 - f1: 0.9373 - auc: 0.9845 - accuracy: 0.9396 - val_loss: 1.2561 - val_f1: 0.5690 - val_auc: 0.8994 - val_accuracy: 0.8776 - _timestamp: 1656377289.0000 - _runtime: 468.0000\n",
            "Epoch 34/100\n",
            "380/380 [==============================] - 15s 40ms/step - loss: 1.0946 - f1: 0.9378 - auc: 0.9857 - accuracy: 0.9402 - val_loss: 1.2108 - val_f1: 0.5947 - val_auc: 0.9004 - val_accuracy: 0.8710 - _timestamp: 1656377302.0000 - _runtime: 481.0000\n",
            "Epoch 35/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 1.0491 - f1: 0.9368 - auc: 0.9848 - accuracy: 0.9382 - val_loss: 1.1581 - val_f1: 0.5779 - val_auc: 0.9005 - val_accuracy: 0.8776 - _timestamp: 1656377317.0000 - _runtime: 496.0000\n",
            "Epoch 36/100\n",
            "380/380 [==============================] - 15s 40ms/step - loss: 1.0004 - f1: 0.9383 - auc: 0.9850 - accuracy: 0.9409 - val_loss: 1.1227 - val_f1: 0.5816 - val_auc: 0.8990 - val_accuracy: 0.8687 - _timestamp: 1656377330.0000 - _runtime: 509.0000\n",
            "Epoch 37/100\n",
            "380/380 [==============================] - 16s 42ms/step - loss: 0.9544 - f1: 0.9404 - auc: 0.9857 - accuracy: 0.9423 - val_loss: 1.0715 - val_f1: 0.5833 - val_auc: 0.9016 - val_accuracy: 0.8788 - _timestamp: 1656377345.0000 - _runtime: 524.0000\n",
            "Epoch 38/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.9206 - f1: 0.9382 - auc: 0.9853 - accuracy: 0.9401 - val_loss: 1.0451 - val_f1: 0.5916 - val_auc: 0.9021 - val_accuracy: 0.8715 - _timestamp: 1656377362.0000 - _runtime: 541.0000\n",
            "Epoch 39/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.8842 - f1: 0.9398 - auc: 0.9859 - accuracy: 0.9415 - val_loss: 0.9993 - val_f1: 0.5743 - val_auc: 0.9029 - val_accuracy: 0.8815 - _timestamp: 1656377375.0000 - _runtime: 554.0000\n",
            "Epoch 40/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 0.8568 - f1: 0.9373 - auc: 0.9852 - accuracy: 0.9393 - val_loss: 0.9836 - val_f1: 0.5971 - val_auc: 0.9046 - val_accuracy: 0.8737 - _timestamp: 1656377388.0000 - _runtime: 567.0000\n",
            "Epoch 41/100\n",
            "380/380 [==============================] - 16s 42ms/step - loss: 0.8246 - f1: 0.9384 - auc: 0.9863 - accuracy: 0.9414 - val_loss: 0.9599 - val_f1: 0.5889 - val_auc: 0.9035 - val_accuracy: 0.8693 - _timestamp: 1656377403.0000 - _runtime: 582.0000\n",
            "Epoch 42/100\n",
            "380/380 [==============================] - 13s 35ms/step - loss: 0.7986 - f1: 0.9403 - auc: 0.9859 - accuracy: 0.9424 - val_loss: 0.9181 - val_f1: 0.5588 - val_auc: 0.9036 - val_accuracy: 0.8810 - _timestamp: 1656377419.0000 - _runtime: 598.0000\n",
            "Epoch 43/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.7772 - f1: 0.9387 - auc: 0.9857 - accuracy: 0.9404 - val_loss: 0.8959 - val_f1: 0.5620 - val_auc: 0.9027 - val_accuracy: 0.8776 - _timestamp: 1656377432.0000 - _runtime: 611.0000\n",
            "Epoch 44/100\n",
            "380/380 [==============================] - 17s 44ms/step - loss: 0.7559 - f1: 0.9396 - auc: 0.9854 - accuracy: 0.9414 - val_loss: 0.8874 - val_f1: 0.5914 - val_auc: 0.9032 - val_accuracy: 0.8693 - _timestamp: 1656377445.0000 - _runtime: 624.0000\n",
            "Epoch 45/100\n",
            "380/380 [==============================] - 16s 43ms/step - loss: 0.7298 - f1: 0.9416 - auc: 0.9869 - accuracy: 0.9437 - val_loss: 0.8761 - val_f1: 0.5844 - val_auc: 0.8998 - val_accuracy: 0.8715 - _timestamp: 1656377462.0000 - _runtime: 641.0000\n",
            "Epoch 46/100\n",
            "380/380 [==============================] - 15s 40ms/step - loss: 0.7081 - f1: 0.9436 - auc: 0.9873 - accuracy: 0.9457 - val_loss: 0.8560 - val_f1: 0.5928 - val_auc: 0.9021 - val_accuracy: 0.8693 - _timestamp: 1656377478.0000 - _runtime: 657.0000\n",
            "Epoch 47/100\n",
            "380/380 [==============================] - 16s 42ms/step - loss: 0.6915 - f1: 0.9408 - auc: 0.9873 - accuracy: 0.9427 - val_loss: 0.8269 - val_f1: 0.5734 - val_auc: 0.9021 - val_accuracy: 0.8749 - _timestamp: 1656377493.0000 - _runtime: 672.0000\n",
            "Epoch 48/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.6805 - f1: 0.9369 - auc: 0.9862 - accuracy: 0.9401 - val_loss: 0.8042 - val_f1: 0.5731 - val_auc: 0.9064 - val_accuracy: 0.8793 - _timestamp: 1656377509.0000 - _runtime: 688.0000\n",
            "Epoch 49/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.6623 - f1: 0.9415 - auc: 0.9870 - accuracy: 0.9436 - val_loss: 0.8002 - val_f1: 0.5785 - val_auc: 0.9036 - val_accuracy: 0.8732 - _timestamp: 1656377522.0000 - _runtime: 701.0000\n",
            "Epoch 50/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.6484 - f1: 0.9413 - auc: 0.9870 - accuracy: 0.9432 - val_loss: 0.7838 - val_f1: 0.5880 - val_auc: 0.9037 - val_accuracy: 0.8754 - _timestamp: 1656377535.0000 - _runtime: 714.0000\n",
            "Epoch 51/100\n",
            "380/380 [==============================] - 15s 40ms/step - loss: 0.6364 - f1: 0.9408 - auc: 0.9870 - accuracy: 0.9428 - val_loss: 0.7663 - val_f1: 0.5838 - val_auc: 0.9064 - val_accuracy: 0.8760 - _timestamp: 1656377548.0000 - _runtime: 727.0000\n",
            "Epoch 52/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.6239 - f1: 0.9395 - auc: 0.9869 - accuracy: 0.9419 - val_loss: 0.7657 - val_f1: 0.6007 - val_auc: 0.9042 - val_accuracy: 0.8726 - _timestamp: 1656377563.0000 - _runtime: 742.0000\n",
            "Epoch 53/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.6146 - f1: 0.9405 - auc: 0.9864 - accuracy: 0.9426 - val_loss: 0.7416 - val_f1: 0.5763 - val_auc: 0.9046 - val_accuracy: 0.8810 - _timestamp: 1656377576.0000 - _runtime: 755.0000\n",
            "Epoch 54/100\n",
            "380/380 [==============================] - 10s 25ms/step - loss: 0.6019 - f1: 0.9427 - auc: 0.9867 - accuracy: 0.9442 - val_loss: 0.7417 - val_f1: 0.5743 - val_auc: 0.9031 - val_accuracy: 0.8737 - _timestamp: 1656377589.0000 - _runtime: 768.0000\n",
            "Epoch 55/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.5914 - f1: 0.9405 - auc: 0.9869 - accuracy: 0.9429 - val_loss: 0.7262 - val_f1: 0.5872 - val_auc: 0.9048 - val_accuracy: 0.8765 - _timestamp: 1656377599.0000 - _runtime: 778.0000\n",
            "Epoch 56/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.5767 - f1: 0.9434 - auc: 0.9876 - accuracy: 0.9449 - val_loss: 0.7166 - val_f1: 0.5765 - val_auc: 0.9048 - val_accuracy: 0.8765 - _timestamp: 1656377611.0000 - _runtime: 790.0000\n",
            "Epoch 57/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.5640 - f1: 0.9442 - auc: 0.9886 - accuracy: 0.9457 - val_loss: 0.7049 - val_f1: 0.5519 - val_auc: 0.9051 - val_accuracy: 0.8737 - _timestamp: 1656377624.0000 - _runtime: 803.0000\n",
            "Epoch 58/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.5583 - f1: 0.9441 - auc: 0.9881 - accuracy: 0.9458 - val_loss: 0.6994 - val_f1: 0.5770 - val_auc: 0.9052 - val_accuracy: 0.8749 - _timestamp: 1656377637.0000 - _runtime: 816.0000\n",
            "Epoch 59/100\n",
            "380/380 [==============================] - 10s 25ms/step - loss: 0.5508 - f1: 0.9456 - auc: 0.9877 - accuracy: 0.9472 - val_loss: 0.7081 - val_f1: 0.5987 - val_auc: 0.9034 - val_accuracy: 0.8682 - _timestamp: 1656377650.0000 - _runtime: 829.0000\n",
            "Epoch 60/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.5410 - f1: 0.9444 - auc: 0.9886 - accuracy: 0.9464 - val_loss: 0.6863 - val_f1: 0.5528 - val_auc: 0.9042 - val_accuracy: 0.8721 - _timestamp: 1656377660.0000 - _runtime: 839.0000\n",
            "Epoch 61/100\n",
            "380/380 [==============================] - 16s 42ms/step - loss: 0.5354 - f1: 0.9437 - auc: 0.9882 - accuracy: 0.9451 - val_loss: 0.6795 - val_f1: 0.5318 - val_auc: 0.9055 - val_accuracy: 0.8771 - _timestamp: 1656377673.0000 - _runtime: 852.0000\n",
            "Epoch 62/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.5315 - f1: 0.9423 - auc: 0.9873 - accuracy: 0.9447 - val_loss: 0.6630 - val_f1: 0.5809 - val_auc: 0.9075 - val_accuracy: 0.8832 - _timestamp: 1656377689.0000 - _runtime: 868.0000\n",
            "Epoch 63/100\n",
            "380/380 [==============================] - 10s 25ms/step - loss: 0.5213 - f1: 0.9447 - auc: 0.9885 - accuracy: 0.9462 - val_loss: 0.6659 - val_f1: 0.5810 - val_auc: 0.9051 - val_accuracy: 0.8782 - _timestamp: 1656377701.0000 - _runtime: 880.0000\n",
            "Epoch 64/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.5192 - f1: 0.9435 - auc: 0.9874 - accuracy: 0.9455 - val_loss: 0.6567 - val_f1: 0.5642 - val_auc: 0.9053 - val_accuracy: 0.8782 - _timestamp: 1656377711.0000 - _runtime: 890.0000\n",
            "Epoch 65/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.5107 - f1: 0.9421 - auc: 0.9881 - accuracy: 0.9439 - val_loss: 0.6443 - val_f1: 0.5396 - val_auc: 0.9083 - val_accuracy: 0.8821 - _timestamp: 1656377724.0000 - _runtime: 903.0000\n",
            "Epoch 66/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 0.5072 - f1: 0.9422 - auc: 0.9875 - accuracy: 0.9441 - val_loss: 0.6393 - val_f1: 0.5922 - val_auc: 0.9084 - val_accuracy: 0.8826 - _timestamp: 1656377737.0000 - _runtime: 916.0000\n",
            "Epoch 67/100\n",
            "380/380 [==============================] - 10s 25ms/step - loss: 0.4956 - f1: 0.9480 - auc: 0.9881 - accuracy: 0.9501 - val_loss: 0.6434 - val_f1: 0.5739 - val_auc: 0.9051 - val_accuracy: 0.8760 - _timestamp: 1656377753.0000 - _runtime: 932.0000\n",
            "Epoch 68/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.4869 - f1: 0.9474 - auc: 0.9891 - accuracy: 0.9493 - val_loss: 0.6332 - val_f1: 0.5208 - val_auc: 0.9061 - val_accuracy: 0.8743 - _timestamp: 1656377762.0000 - _runtime: 941.0000\n",
            "Epoch 69/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 0.4866 - f1: 0.9451 - auc: 0.9885 - accuracy: 0.9466 - val_loss: 0.6322 - val_f1: 0.5926 - val_auc: 0.9066 - val_accuracy: 0.8804 - _timestamp: 1656377775.0000 - _runtime: 954.0000\n",
            "Epoch 70/100\n",
            "380/380 [==============================] - 10s 25ms/step - loss: 0.4772 - f1: 0.9477 - auc: 0.9895 - accuracy: 0.9496 - val_loss: 0.6433 - val_f1: 0.6075 - val_auc: 0.9061 - val_accuracy: 0.8721 - _timestamp: 1656377791.0000 - _runtime: 970.0000\n",
            "Epoch 71/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.4774 - f1: 0.9447 - auc: 0.9887 - accuracy: 0.9459 - val_loss: 0.6202 - val_f1: 0.5557 - val_auc: 0.9073 - val_accuracy: 0.8737 - _timestamp: 1656377800.0000 - _runtime: 979.0000\n",
            "Epoch 72/100\n",
            "380/380 [==============================] - 10s 25ms/step - loss: 0.4725 - f1: 0.9459 - auc: 0.9888 - accuracy: 0.9477 - val_loss: 0.6247 - val_f1: 0.5746 - val_auc: 0.9046 - val_accuracy: 0.8682 - _timestamp: 1656377813.0000 - _runtime: 992.0000\n",
            "Epoch 73/100\n",
            "380/380 [==============================] - 10s 25ms/step - loss: 0.4655 - f1: 0.9470 - auc: 0.9893 - accuracy: 0.9486 - val_loss: 0.6209 - val_f1: 0.5861 - val_auc: 0.9066 - val_accuracy: 0.8754 - _timestamp: 1656377823.0000 - _runtime: 1002.0000\n",
            "Epoch 74/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.4641 - f1: 0.9451 - auc: 0.9890 - accuracy: 0.9470 - val_loss: 0.6179 - val_f1: 0.6082 - val_auc: 0.9071 - val_accuracy: 0.8749 - _timestamp: 1656377832.0000 - _runtime: 1011.0000\n",
            "Epoch 75/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 0.4614 - f1: 0.9461 - auc: 0.9887 - accuracy: 0.9479 - val_loss: 0.6075 - val_f1: 0.5774 - val_auc: 0.9072 - val_accuracy: 0.8771 - _timestamp: 1656377845.0000 - _runtime: 1024.0000\n",
            "Epoch 76/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.4516 - f1: 0.9469 - auc: 0.9897 - accuracy: 0.9480 - val_loss: 0.6065 - val_f1: 0.5979 - val_auc: 0.9068 - val_accuracy: 0.8788 - _timestamp: 1656377861.0000 - _runtime: 1040.0000\n",
            "Epoch 77/100\n",
            "380/380 [==============================] - 10s 25ms/step - loss: 0.4485 - f1: 0.9486 - auc: 0.9899 - accuracy: 0.9496 - val_loss: 0.6116 - val_f1: 0.5856 - val_auc: 0.9067 - val_accuracy: 0.8715 - _timestamp: 1656377874.0000 - _runtime: 1053.0000\n",
            "Epoch 78/100\n",
            "380/380 [==============================] - 16s 42ms/step - loss: 0.4445 - f1: 0.9484 - auc: 0.9898 - accuracy: 0.9504 - val_loss: 0.6037 - val_f1: 0.5631 - val_auc: 0.9057 - val_accuracy: 0.8754 - _timestamp: 1656377883.0000 - _runtime: 1062.0000\n",
            "Epoch 79/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.4427 - f1: 0.9479 - auc: 0.9896 - accuracy: 0.9502 - val_loss: 0.5902 - val_f1: 0.5451 - val_auc: 0.9083 - val_accuracy: 0.8760 - _timestamp: 1656377899.0000 - _runtime: 1078.0000\n",
            "Epoch 80/100\n",
            "380/380 [==============================] - 10s 25ms/step - loss: 0.4393 - f1: 0.9508 - auc: 0.9895 - accuracy: 0.9520 - val_loss: 0.5926 - val_f1: 0.6048 - val_auc: 0.9087 - val_accuracy: 0.8788 - _timestamp: 1656377912.0000 - _runtime: 1091.0000\n",
            "Epoch 81/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.4386 - f1: 0.9464 - auc: 0.9896 - accuracy: 0.9475 - val_loss: 0.5868 - val_f1: 0.5765 - val_auc: 0.9079 - val_accuracy: 0.8793 - _timestamp: 1656377922.0000 - _runtime: 1101.0000\n",
            "Epoch 82/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.4307 - f1: 0.9495 - auc: 0.9903 - accuracy: 0.9515 - val_loss: 0.5848 - val_f1: 0.5764 - val_auc: 0.9093 - val_accuracy: 0.8799 - _timestamp: 1656377935.0000 - _runtime: 1114.0000\n",
            "Epoch 83/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.4306 - f1: 0.9509 - auc: 0.9897 - accuracy: 0.9521 - val_loss: 0.5826 - val_f1: 0.5909 - val_auc: 0.9101 - val_accuracy: 0.8821 - _timestamp: 1656377948.0000 - _runtime: 1127.0000\n",
            "Epoch 84/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.4286 - f1: 0.9511 - auc: 0.9896 - accuracy: 0.9528 - val_loss: 0.5747 - val_f1: 0.5763 - val_auc: 0.9093 - val_accuracy: 0.8793 - _timestamp: 1656377961.0000 - _runtime: 1140.0000\n",
            "Epoch 85/100\n",
            "380/380 [==============================] - 10s 25ms/step - loss: 0.4206 - f1: 0.9512 - auc: 0.9907 - accuracy: 0.9527 - val_loss: 0.5900 - val_f1: 0.6071 - val_auc: 0.9101 - val_accuracy: 0.8743 - _timestamp: 1656377974.0000 - _runtime: 1153.0000\n",
            "Epoch 86/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.4201 - f1: 0.9500 - auc: 0.9904 - accuracy: 0.9515 - val_loss: 0.5735 - val_f1: 0.5717 - val_auc: 0.9109 - val_accuracy: 0.8765 - _timestamp: 1656377984.0000 - _runtime: 1163.0000\n",
            "Epoch 87/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.4169 - f1: 0.9507 - auc: 0.9904 - accuracy: 0.9525 - val_loss: 0.5720 - val_f1: 0.5314 - val_auc: 0.9090 - val_accuracy: 0.8804 - _timestamp: 1656377997.0000 - _runtime: 1176.0000\n",
            "Epoch 88/100\n",
            "380/380 [==============================] - 10s 25ms/step - loss: 0.4154 - f1: 0.9506 - auc: 0.9902 - accuracy: 0.9525 - val_loss: 0.5723 - val_f1: 0.5173 - val_auc: 0.9104 - val_accuracy: 0.8788 - _timestamp: 1656378010.0000 - _runtime: 1189.0000\n",
            "Epoch 89/100\n",
            "380/380 [==============================] - 10s 25ms/step - loss: 0.4095 - f1: 0.9491 - auc: 0.9912 - accuracy: 0.9510 - val_loss: 0.5757 - val_f1: 0.5609 - val_auc: 0.9074 - val_accuracy: 0.8732 - _timestamp: 1656378019.0000 - _runtime: 1198.0000\n",
            "Epoch 90/100\n",
            "380/380 [==============================] - 10s 25ms/step - loss: 0.4057 - f1: 0.9530 - auc: 0.9914 - accuracy: 0.9543 - val_loss: 0.5747 - val_f1: 0.5555 - val_auc: 0.9082 - val_accuracy: 0.8721 - _timestamp: 1656378029.0000 - _runtime: 1208.0000\n",
            "Epoch 91/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.4092 - f1: 0.9493 - auc: 0.9904 - accuracy: 0.9513 - val_loss: 0.5690 - val_f1: 0.5392 - val_auc: 0.9078 - val_accuracy: 0.8754 - _timestamp: 1656378038.0000 - _runtime: 1217.0000\n",
            "Epoch 92/100\n",
            "380/380 [==============================] - 15s 41ms/step - loss: 0.4022 - f1: 0.9522 - auc: 0.9911 - accuracy: 0.9546 - val_loss: 0.5683 - val_f1: 0.5726 - val_auc: 0.9093 - val_accuracy: 0.8743 - _timestamp: 1656378052.0000 - _runtime: 1231.0000\n",
            "Epoch 93/100\n",
            "380/380 [==============================] - 14s 38ms/step - loss: 0.4010 - f1: 0.9528 - auc: 0.9912 - accuracy: 0.9538 - val_loss: 0.5645 - val_f1: 0.5343 - val_auc: 0.9084 - val_accuracy: 0.8715 - _timestamp: 1656378067.0000 - _runtime: 1246.0000\n",
            "Epoch 94/100\n",
            "380/380 [==============================] - 15s 41ms/step - loss: 0.3964 - f1: 0.9537 - auc: 0.9914 - accuracy: 0.9552 - val_loss: 0.5610 - val_f1: 0.5436 - val_auc: 0.9090 - val_accuracy: 0.8771 - _timestamp: 1656378081.0000 - _runtime: 1260.0000\n",
            "Epoch 95/100\n",
            "380/380 [==============================] - 16s 41ms/step - loss: 0.3959 - f1: 0.9539 - auc: 0.9913 - accuracy: 0.9551 - val_loss: 0.5600 - val_f1: 0.5406 - val_auc: 0.9094 - val_accuracy: 0.8754 - _timestamp: 1656378097.0000 - _runtime: 1276.0000\n",
            "Epoch 96/100\n",
            "380/380 [==============================] - 10s 25ms/step - loss: 0.3907 - f1: 0.9535 - auc: 0.9919 - accuracy: 0.9547 - val_loss: 0.5721 - val_f1: 0.5054 - val_auc: 0.9079 - val_accuracy: 0.8815 - _timestamp: 1656378112.0000 - _runtime: 1291.0000\n",
            "Epoch 97/100\n",
            "380/380 [==============================] - 10s 25ms/step - loss: 0.3912 - f1: 0.9550 - auc: 0.9914 - accuracy: 0.9561 - val_loss: 0.5634 - val_f1: 0.5350 - val_auc: 0.9067 - val_accuracy: 0.8737 - _timestamp: 1656378122.0000 - _runtime: 1301.0000\n",
            "Epoch 98/100\n",
            "380/380 [==============================] - 10s 25ms/step - loss: 0.3897 - f1: 0.9526 - auc: 0.9916 - accuracy: 0.9544 - val_loss: 0.5651 - val_f1: 0.5652 - val_auc: 0.9078 - val_accuracy: 0.8732 - _timestamp: 1656378132.0000 - _runtime: 1311.0000\n",
            "Epoch 99/100\n",
            "380/380 [==============================] - 17s 46ms/step - loss: 0.3885 - f1: 0.9549 - auc: 0.9911 - accuracy: 0.9565 - val_loss: 0.5598 - val_f1: 0.5850 - val_auc: 0.9096 - val_accuracy: 0.8782 - _timestamp: 1656378141.0000 - _runtime: 1320.0000\n",
            "Epoch 100/100\n",
            "380/380 [==============================] - 13s 34ms/step - loss: 0.3888 - f1: 0.9519 - auc: 0.9911 - accuracy: 0.9537 - val_loss: 0.5564 - val_f1: 0.5715 - val_auc: 0.9094 - val_accuracy: 0.8788 - _timestamp: 1656378159.0000 - _runtime: 1338.0000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d999e27b3a54b0f95e8f68627b31ae3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='508.636 MB of 1270.846 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.4…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇██████████</td></tr><tr><td>auc</td><td>▁▆▇▇▇▇▇▇▇▇█▇████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██████████</td></tr><tr><td>loss</td><td>█▅▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▄▆▃▇▆▆▇▇▇█▇▇▇█▇▇▇▇█▇█▇████▇█▇████▇██▇█</td></tr><tr><td>val_auc</td><td>▁▄▄▅▅▅▄▅▅▅▆▆▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>val_f1</td><td>▁▄▄▅▃█▆▅▇▇▇▆▆▇▆▅▆▇▇▆▆▅▅▇▂▄▅▇▅█▆▃▅▅▂▄▅▃▂▅</td></tr><tr><td>val_loss</td><td>█▆▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.95373</td></tr><tr><td>auc</td><td>0.99112</td></tr><tr><td>best_epoch</td><td>99</td></tr><tr><td>best_val_loss</td><td>0.55636</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>f1</td><td>0.95188</td></tr><tr><td>loss</td><td>0.38881</td></tr><tr><td>val_accuracy</td><td>0.87875</td></tr><tr><td>val_auc</td><td>0.90941</td></tr><tr><td>val_f1</td><td>0.57148</td></tr><tr><td>val_loss</td><td>0.55636</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">glorious-sweep-19</strong>: <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/t44woaya\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/runs/t44woaya</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220628_004021-t44woaya/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f3hlijxn with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_function: elu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \talpha_value: 0.32546741788452194\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-06\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_neurons: 2500\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptomizer: adamax\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_factor: 1e-08\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tregularization_type: l2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.19"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220628_010336-f3hlijxn</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/f3hlijxn\" target=\"_blank\">worldly-sweep-20</a></strong> to <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/sweeps/3yaw2lxr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 25008)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2500)              62522500  \n",
            "                                                                 \n",
            " activation (Activation)     (None, 2500)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 2500)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2500)              6252500   \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 2500)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2500)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2500)              6252500   \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 2500)              0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 2500)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2500)              6252500   \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 2500)              0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 2500)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 2501      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 81,282,501\n",
            "Trainable params: 81,282,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "380/380 [==============================] - 10s 23ms/step - loss: 0.6463 - f1: 0.6600 - auc: 0.7327 - accuracy: 0.6313 - val_loss: 0.6512 - val_f1: 0.4235 - val_auc: 0.8527 - val_accuracy: 0.6029 - _timestamp: 1656378233.0000 - _runtime: 16.0000\n",
            "Epoch 2/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.5780 - f1: 0.7603 - auc: 0.8074 - accuracy: 0.7374 - val_loss: 0.5886 - val_f1: 0.4798 - val_auc: 0.8633 - val_accuracy: 0.6935 - _timestamp: 1656378241.0000 - _runtime: 24.0000\n",
            "Epoch 3/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.5261 - f1: 0.7959 - auc: 0.8554 - accuracy: 0.7814 - val_loss: 0.5442 - val_f1: 0.4994 - val_auc: 0.8667 - val_accuracy: 0.7253 - _timestamp: 1656378249.0000 - _runtime: 32.0000\n",
            "Epoch 4/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.4859 - f1: 0.8112 - auc: 0.8788 - accuracy: 0.7998 - val_loss: 0.5058 - val_f1: 0.5175 - val_auc: 0.8671 - val_accuracy: 0.7553 - _timestamp: 1656378257.0000 - _runtime: 40.0000\n",
            "Epoch 5/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.4502 - f1: 0.8265 - auc: 0.8934 - accuracy: 0.8181 - val_loss: 0.4784 - val_f1: 0.5206 - val_auc: 0.8668 - val_accuracy: 0.7681 - _timestamp: 1656378265.0000 - _runtime: 48.0000\n",
            "Epoch 6/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.4240 - f1: 0.8360 - auc: 0.9041 - accuracy: 0.8305 - val_loss: 0.4565 - val_f1: 0.5117 - val_auc: 0.8660 - val_accuracy: 0.7703 - _timestamp: 1656378273.0000 - _runtime: 56.0000\n",
            "Epoch 7/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.4022 - f1: 0.8460 - auc: 0.9129 - accuracy: 0.8410 - val_loss: 0.4415 - val_f1: 0.5166 - val_auc: 0.8656 - val_accuracy: 0.7764 - _timestamp: 1656378281.0000 - _runtime: 64.0000\n",
            "Epoch 8/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.3844 - f1: 0.8500 - auc: 0.9182 - accuracy: 0.8479 - val_loss: 0.4292 - val_f1: 0.5181 - val_auc: 0.8646 - val_accuracy: 0.7836 - _timestamp: 1656378289.0000 - _runtime: 72.0000\n",
            "Epoch 9/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.3665 - f1: 0.8568 - auc: 0.9253 - accuracy: 0.8543 - val_loss: 0.4219 - val_f1: 0.5084 - val_auc: 0.8645 - val_accuracy: 0.7842 - _timestamp: 1656378297.0000 - _runtime: 80.0000\n",
            "Epoch 10/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.3544 - f1: 0.8619 - auc: 0.9292 - accuracy: 0.8595 - val_loss: 0.4057 - val_f1: 0.5135 - val_auc: 0.8630 - val_accuracy: 0.7942 - _timestamp: 1656378305.0000 - _runtime: 88.0000\n",
            "Epoch 11/100\n",
            "380/380 [==============================] - 9s 24ms/step - loss: 0.3443 - f1: 0.8633 - auc: 0.9323 - accuracy: 0.8620 - val_loss: 0.4042 - val_f1: 0.5151 - val_auc: 0.8633 - val_accuracy: 0.7953 - _timestamp: 1656378313.0000 - _runtime: 96.0000\n",
            "Epoch 12/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.3348 - f1: 0.8678 - auc: 0.9357 - accuracy: 0.8681 - val_loss: 0.3984 - val_f1: 0.5142 - val_auc: 0.8630 - val_accuracy: 0.7981 - _timestamp: 1656378322.0000 - _runtime: 105.0000\n",
            "Epoch 13/100\n",
            "380/380 [==============================] - 10s 28ms/step - loss: 0.3256 - f1: 0.8690 - auc: 0.9387 - accuracy: 0.8684 - val_loss: 0.3943 - val_f1: 0.5156 - val_auc: 0.8629 - val_accuracy: 0.8009 - _timestamp: 1656378330.0000 - _runtime: 113.0000\n",
            "Epoch 14/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.3174 - f1: 0.8731 - auc: 0.9409 - accuracy: 0.8730 - val_loss: 0.3931 - val_f1: 0.5205 - val_auc: 0.8628 - val_accuracy: 0.8037 - _timestamp: 1656378340.0000 - _runtime: 123.0000\n",
            "Epoch 15/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.3164 - f1: 0.8715 - auc: 0.9406 - accuracy: 0.8716 - val_loss: 0.3842 - val_f1: 0.5259 - val_auc: 0.8621 - val_accuracy: 0.8137 - _timestamp: 1656378348.0000 - _runtime: 131.0000\n",
            "Epoch 16/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.3086 - f1: 0.8756 - auc: 0.9435 - accuracy: 0.8758 - val_loss: 0.3827 - val_f1: 0.5205 - val_auc: 0.8620 - val_accuracy: 0.8137 - _timestamp: 1656378356.0000 - _runtime: 139.0000\n",
            "Epoch 17/100\n",
            "380/380 [==============================] - 11s 28ms/step - loss: 0.2985 - f1: 0.8819 - auc: 0.9481 - accuracy: 0.8816 - val_loss: 0.3814 - val_f1: 0.5199 - val_auc: 0.8625 - val_accuracy: 0.8142 - _timestamp: 1656378364.0000 - _runtime: 147.0000\n",
            "Epoch 18/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.2966 - f1: 0.8796 - auc: 0.9476 - accuracy: 0.8807 - val_loss: 0.3779 - val_f1: 0.5234 - val_auc: 0.8626 - val_accuracy: 0.8187 - _timestamp: 1656378375.0000 - _runtime: 158.0000\n",
            "Epoch 19/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.2932 - f1: 0.8817 - auc: 0.9489 - accuracy: 0.8816 - val_loss: 0.3724 - val_f1: 0.5213 - val_auc: 0.8618 - val_accuracy: 0.8231 - _timestamp: 1656378382.0000 - _runtime: 165.0000\n",
            "Epoch 20/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2842 - f1: 0.8832 - auc: 0.9524 - accuracy: 0.8834 - val_loss: 0.3730 - val_f1: 0.5241 - val_auc: 0.8624 - val_accuracy: 0.8242 - _timestamp: 1656378390.0000 - _runtime: 173.0000\n",
            "Epoch 21/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2833 - f1: 0.8814 - auc: 0.9520 - accuracy: 0.8826 - val_loss: 0.3748 - val_f1: 0.5270 - val_auc: 0.8633 - val_accuracy: 0.8248 - _timestamp: 1656378396.0000 - _runtime: 179.0000\n",
            "Epoch 22/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.2751 - f1: 0.8877 - auc: 0.9551 - accuracy: 0.8881 - val_loss: 0.3703 - val_f1: 0.5191 - val_auc: 0.8629 - val_accuracy: 0.8287 - _timestamp: 1656378403.0000 - _runtime: 186.0000\n",
            "Epoch 23/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.2768 - f1: 0.8884 - auc: 0.9540 - accuracy: 0.8893 - val_loss: 0.3679 - val_f1: 0.5217 - val_auc: 0.8623 - val_accuracy: 0.8315 - _timestamp: 1656378411.0000 - _runtime: 194.0000\n",
            "Epoch 24/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.2697 - f1: 0.8890 - auc: 0.9565 - accuracy: 0.8896 - val_loss: 0.3678 - val_f1: 0.5193 - val_auc: 0.8626 - val_accuracy: 0.8315 - _timestamp: 1656378418.0000 - _runtime: 201.0000\n",
            "Epoch 25/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.2629 - f1: 0.8974 - auc: 0.9587 - accuracy: 0.8979 - val_loss: 0.3650 - val_f1: 0.5203 - val_auc: 0.8623 - val_accuracy: 0.8331 - _timestamp: 1656378426.0000 - _runtime: 209.0000\n",
            "Epoch 26/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2635 - f1: 0.8948 - auc: 0.9581 - accuracy: 0.8966 - val_loss: 0.3656 - val_f1: 0.5184 - val_auc: 0.8631 - val_accuracy: 0.8326 - _timestamp: 1656378434.0000 - _runtime: 217.0000\n",
            "Epoch 27/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.2616 - f1: 0.8948 - auc: 0.9590 - accuracy: 0.8955 - val_loss: 0.3616 - val_f1: 0.5163 - val_auc: 0.8623 - val_accuracy: 0.8343 - _timestamp: 1656378440.0000 - _runtime: 223.0000\n",
            "Epoch 28/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2622 - f1: 0.8938 - auc: 0.9585 - accuracy: 0.8955 - val_loss: 0.3645 - val_f1: 0.5247 - val_auc: 0.8629 - val_accuracy: 0.8359 - _timestamp: 1656378448.0000 - _runtime: 231.0000\n",
            "Epoch 29/100\n",
            "380/380 [==============================] - 8s 22ms/step - loss: 0.2558 - f1: 0.8968 - auc: 0.9607 - accuracy: 0.8975 - val_loss: 0.3606 - val_f1: 0.5108 - val_auc: 0.8630 - val_accuracy: 0.8343 - _timestamp: 1656378454.0000 - _runtime: 237.0000\n",
            "Epoch 30/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.2499 - f1: 0.9014 - auc: 0.9624 - accuracy: 0.9022 - val_loss: 0.3590 - val_f1: 0.5077 - val_auc: 0.8629 - val_accuracy: 0.8343 - _timestamp: 1656378463.0000 - _runtime: 246.0000\n",
            "Epoch 31/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2509 - f1: 0.8975 - auc: 0.9619 - accuracy: 0.8993 - val_loss: 0.3630 - val_f1: 0.5197 - val_auc: 0.8645 - val_accuracy: 0.8370 - _timestamp: 1656378471.0000 - _runtime: 254.0000\n",
            "Epoch 32/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2526 - f1: 0.8978 - auc: 0.9613 - accuracy: 0.8996 - val_loss: 0.3605 - val_f1: 0.5076 - val_auc: 0.8637 - val_accuracy: 0.8343 - _timestamp: 1656378477.0000 - _runtime: 260.0000\n",
            "Epoch 33/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.2489 - f1: 0.9008 - auc: 0.9622 - accuracy: 0.9018 - val_loss: 0.3590 - val_f1: 0.5037 - val_auc: 0.8635 - val_accuracy: 0.8343 - _timestamp: 1656378483.0000 - _runtime: 266.0000\n",
            "Epoch 34/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.2443 - f1: 0.9012 - auc: 0.9637 - accuracy: 0.9026 - val_loss: 0.3572 - val_f1: 0.5052 - val_auc: 0.8630 - val_accuracy: 0.8376 - _timestamp: 1656378491.0000 - _runtime: 274.0000\n",
            "Epoch 35/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.2455 - f1: 0.9018 - auc: 0.9632 - accuracy: 0.9038 - val_loss: 0.3568 - val_f1: 0.5042 - val_auc: 0.8633 - val_accuracy: 0.8376 - _timestamp: 1656378499.0000 - _runtime: 282.0000\n",
            "Epoch 36/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2419 - f1: 0.9038 - auc: 0.9645 - accuracy: 0.9068 - val_loss: 0.3576 - val_f1: 0.5033 - val_auc: 0.8637 - val_accuracy: 0.8370 - _timestamp: 1656378507.0000 - _runtime: 290.0000\n",
            "Epoch 37/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2399 - f1: 0.9044 - auc: 0.9650 - accuracy: 0.9059 - val_loss: 0.3585 - val_f1: 0.5075 - val_auc: 0.8632 - val_accuracy: 0.8376 - _timestamp: 1656378513.0000 - _runtime: 296.0000\n",
            "Epoch 38/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.2416 - f1: 0.9036 - auc: 0.9644 - accuracy: 0.9052 - val_loss: 0.3563 - val_f1: 0.5074 - val_auc: 0.8638 - val_accuracy: 0.8398 - _timestamp: 1656378519.0000 - _runtime: 302.0000\n",
            "Epoch 39/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.2386 - f1: 0.9036 - auc: 0.9652 - accuracy: 0.9055 - val_loss: 0.3552 - val_f1: 0.4993 - val_auc: 0.8633 - val_accuracy: 0.8393 - _timestamp: 1656378527.0000 - _runtime: 310.0000\n",
            "Epoch 40/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.2356 - f1: 0.9061 - auc: 0.9662 - accuracy: 0.9076 - val_loss: 0.3540 - val_f1: 0.5017 - val_auc: 0.8629 - val_accuracy: 0.8420 - _timestamp: 1656378535.0000 - _runtime: 318.0000\n",
            "Epoch 41/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2366 - f1: 0.9030 - auc: 0.9660 - accuracy: 0.9044 - val_loss: 0.3567 - val_f1: 0.5152 - val_auc: 0.8642 - val_accuracy: 0.8415 - _timestamp: 1656378543.0000 - _runtime: 326.0000\n",
            "Epoch 42/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.2375 - f1: 0.9053 - auc: 0.9653 - accuracy: 0.9076 - val_loss: 0.3535 - val_f1: 0.5017 - val_auc: 0.8645 - val_accuracy: 0.8420 - _timestamp: 1656378549.0000 - _runtime: 332.0000\n",
            "Epoch 43/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.2317 - f1: 0.9057 - auc: 0.9669 - accuracy: 0.9072 - val_loss: 0.3522 - val_f1: 0.5054 - val_auc: 0.8651 - val_accuracy: 0.8454 - _timestamp: 1656378557.0000 - _runtime: 340.0000\n",
            "Epoch 44/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.2319 - f1: 0.9057 - auc: 0.9673 - accuracy: 0.9072 - val_loss: 0.3509 - val_f1: 0.5073 - val_auc: 0.8640 - val_accuracy: 0.8465 - _timestamp: 1656378565.0000 - _runtime: 348.0000\n",
            "Epoch 45/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2292 - f1: 0.9081 - auc: 0.9678 - accuracy: 0.9109 - val_loss: 0.3529 - val_f1: 0.5152 - val_auc: 0.8656 - val_accuracy: 0.8459 - _timestamp: 1656378573.0000 - _runtime: 356.0000\n",
            "Epoch 46/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2309 - f1: 0.9080 - auc: 0.9672 - accuracy: 0.9089 - val_loss: 0.3528 - val_f1: 0.5164 - val_auc: 0.8663 - val_accuracy: 0.8454 - _timestamp: 1656378579.0000 - _runtime: 362.0000\n",
            "Epoch 47/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2333 - f1: 0.9080 - auc: 0.9664 - accuracy: 0.9097 - val_loss: 0.3518 - val_f1: 0.5163 - val_auc: 0.8655 - val_accuracy: 0.8465 - _timestamp: 1656378585.0000 - _runtime: 368.0000\n",
            "Epoch 48/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.2282 - f1: 0.9086 - auc: 0.9681 - accuracy: 0.9097 - val_loss: 0.3495 - val_f1: 0.5165 - val_auc: 0.8661 - val_accuracy: 0.8515 - _timestamp: 1656378592.0000 - _runtime: 375.0000\n",
            "Epoch 49/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2271 - f1: 0.9083 - auc: 0.9683 - accuracy: 0.9103 - val_loss: 0.3497 - val_f1: 0.5160 - val_auc: 0.8667 - val_accuracy: 0.8509 - _timestamp: 1656378600.0000 - _runtime: 383.0000\n",
            "Epoch 50/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2248 - f1: 0.9134 - auc: 0.9688 - accuracy: 0.9152 - val_loss: 0.3514 - val_f1: 0.5220 - val_auc: 0.8671 - val_accuracy: 0.8476 - _timestamp: 1656378606.0000 - _runtime: 389.0000\n",
            "Epoch 51/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2254 - f1: 0.9098 - auc: 0.9687 - accuracy: 0.9119 - val_loss: 0.3511 - val_f1: 0.5182 - val_auc: 0.8670 - val_accuracy: 0.8509 - _timestamp: 1656378612.0000 - _runtime: 395.0000\n",
            "Epoch 52/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.2231 - f1: 0.9106 - auc: 0.9698 - accuracy: 0.9117 - val_loss: 0.3495 - val_f1: 0.5169 - val_auc: 0.8670 - val_accuracy: 0.8521 - _timestamp: 1656378618.0000 - _runtime: 401.0000\n",
            "Epoch 53/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2255 - f1: 0.9102 - auc: 0.9685 - accuracy: 0.9122 - val_loss: 0.3506 - val_f1: 0.5159 - val_auc: 0.8674 - val_accuracy: 0.8504 - _timestamp: 1656378626.0000 - _runtime: 409.0000\n",
            "Epoch 54/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2236 - f1: 0.9115 - auc: 0.9693 - accuracy: 0.9134 - val_loss: 0.3520 - val_f1: 0.5252 - val_auc: 0.8685 - val_accuracy: 0.8493 - _timestamp: 1656378632.0000 - _runtime: 415.0000\n",
            "Epoch 55/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.2266 - f1: 0.9108 - auc: 0.9681 - accuracy: 0.9118 - val_loss: 0.3493 - val_f1: 0.5146 - val_auc: 0.8682 - val_accuracy: 0.8509 - _timestamp: 1656378638.0000 - _runtime: 421.0000\n",
            "Epoch 56/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.2187 - f1: 0.9121 - auc: 0.9706 - accuracy: 0.9153 - val_loss: 0.3484 - val_f1: 0.5135 - val_auc: 0.8685 - val_accuracy: 0.8509 - _timestamp: 1656378646.0000 - _runtime: 429.0000\n",
            "Epoch 57/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2238 - f1: 0.9120 - auc: 0.9690 - accuracy: 0.9138 - val_loss: 0.3503 - val_f1: 0.5226 - val_auc: 0.8693 - val_accuracy: 0.8498 - _timestamp: 1656378654.0000 - _runtime: 437.0000\n",
            "Epoch 58/100\n",
            "380/380 [==============================] - 8s 21ms/step - loss: 0.2210 - f1: 0.9135 - auc: 0.9698 - accuracy: 0.9150 - val_loss: 0.3473 - val_f1: 0.5169 - val_auc: 0.8685 - val_accuracy: 0.8526 - _timestamp: 1656378660.0000 - _runtime: 443.0000\n",
            "Epoch 59/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2206 - f1: 0.9116 - auc: 0.9699 - accuracy: 0.9137 - val_loss: 0.3485 - val_f1: 0.5225 - val_auc: 0.8696 - val_accuracy: 0.8521 - _timestamp: 1656378668.0000 - _runtime: 451.0000\n",
            "Epoch 60/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2151 - f1: 0.9135 - auc: 0.9717 - accuracy: 0.9152 - val_loss: 0.3497 - val_f1: 0.5242 - val_auc: 0.8701 - val_accuracy: 0.8504 - _timestamp: 1656378674.0000 - _runtime: 457.0000\n",
            "Epoch 61/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2201 - f1: 0.9114 - auc: 0.9700 - accuracy: 0.9125 - val_loss: 0.3480 - val_f1: 0.5229 - val_auc: 0.8698 - val_accuracy: 0.8526 - _timestamp: 1656378681.0000 - _runtime: 464.0000\n",
            "Epoch 62/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2152 - f1: 0.9147 - auc: 0.9713 - accuracy: 0.9167 - val_loss: 0.3475 - val_f1: 0.5251 - val_auc: 0.8701 - val_accuracy: 0.8532 - _timestamp: 1656378687.0000 - _runtime: 470.0000\n",
            "Epoch 63/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2171 - f1: 0.9139 - auc: 0.9710 - accuracy: 0.9156 - val_loss: 0.3495 - val_f1: 0.5257 - val_auc: 0.8711 - val_accuracy: 0.8509 - _timestamp: 1656378693.0000 - _runtime: 476.0000\n",
            "Epoch 64/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2113 - f1: 0.9149 - auc: 0.9726 - accuracy: 0.9169 - val_loss: 0.3475 - val_f1: 0.5251 - val_auc: 0.8698 - val_accuracy: 0.8532 - _timestamp: 1656378699.0000 - _runtime: 482.0000\n",
            "Epoch 65/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.2134 - f1: 0.9163 - auc: 0.9720 - accuracy: 0.9178 - val_loss: 0.3473 - val_f1: 0.5219 - val_auc: 0.8690 - val_accuracy: 0.8532 - _timestamp: 1656378705.0000 - _runtime: 488.0000\n",
            "Epoch 66/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2147 - f1: 0.9148 - auc: 0.9717 - accuracy: 0.9168 - val_loss: 0.3480 - val_f1: 0.5254 - val_auc: 0.8692 - val_accuracy: 0.8532 - _timestamp: 1656378713.0000 - _runtime: 496.0000\n",
            "Epoch 67/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2129 - f1: 0.9151 - auc: 0.9721 - accuracy: 0.9174 - val_loss: 0.3502 - val_f1: 0.5254 - val_auc: 0.8700 - val_accuracy: 0.8509 - _timestamp: 1656378719.0000 - _runtime: 502.0000\n",
            "Epoch 68/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2140 - f1: 0.9149 - auc: 0.9715 - accuracy: 0.9163 - val_loss: 0.3487 - val_f1: 0.5268 - val_auc: 0.8695 - val_accuracy: 0.8532 - _timestamp: 1656378725.0000 - _runtime: 508.0000\n",
            "Epoch 69/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2134 - f1: 0.9152 - auc: 0.9716 - accuracy: 0.9183 - val_loss: 0.3474 - val_f1: 0.5277 - val_auc: 0.8690 - val_accuracy: 0.8548 - _timestamp: 1656378731.0000 - _runtime: 514.0000\n",
            "Epoch 70/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.2166 - f1: 0.9145 - auc: 0.9708 - accuracy: 0.9172 - val_loss: 0.3468 - val_f1: 0.5146 - val_auc: 0.8690 - val_accuracy: 0.8537 - _timestamp: 1656378737.0000 - _runtime: 520.0000\n",
            "Epoch 71/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2167 - f1: 0.9131 - auc: 0.9710 - accuracy: 0.9150 - val_loss: 0.3478 - val_f1: 0.5272 - val_auc: 0.8693 - val_accuracy: 0.8537 - _timestamp: 1656378745.0000 - _runtime: 528.0000\n",
            "Epoch 72/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2090 - f1: 0.9179 - auc: 0.9730 - accuracy: 0.9196 - val_loss: 0.3476 - val_f1: 0.5271 - val_auc: 0.8692 - val_accuracy: 0.8548 - _timestamp: 1656378751.0000 - _runtime: 534.0000\n",
            "Epoch 73/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2095 - f1: 0.9167 - auc: 0.9729 - accuracy: 0.9188 - val_loss: 0.3489 - val_f1: 0.5245 - val_auc: 0.8699 - val_accuracy: 0.8515 - _timestamp: 1656378757.0000 - _runtime: 540.0000\n",
            "Epoch 74/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.2105 - f1: 0.9153 - auc: 0.9728 - accuracy: 0.9173 - val_loss: 0.3458 - val_f1: 0.5080 - val_auc: 0.8690 - val_accuracy: 0.8537 - _timestamp: 1656378764.0000 - _runtime: 547.0000\n",
            "Epoch 75/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2079 - f1: 0.9182 - auc: 0.9731 - accuracy: 0.9195 - val_loss: 0.3464 - val_f1: 0.5203 - val_auc: 0.8692 - val_accuracy: 0.8548 - _timestamp: 1656378771.0000 - _runtime: 554.0000\n",
            "Epoch 76/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.2116 - f1: 0.9174 - auc: 0.9722 - accuracy: 0.9190 - val_loss: 0.3453 - val_f1: 0.5093 - val_auc: 0.8696 - val_accuracy: 0.8543 - _timestamp: 1656378777.0000 - _runtime: 560.0000\n",
            "Epoch 77/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2027 - f1: 0.9206 - auc: 0.9744 - accuracy: 0.9226 - val_loss: 0.3462 - val_f1: 0.5198 - val_auc: 0.8700 - val_accuracy: 0.8537 - _timestamp: 1656378785.0000 - _runtime: 568.0000\n",
            "Epoch 78/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.2070 - f1: 0.9194 - auc: 0.9733 - accuracy: 0.9213 - val_loss: 0.3449 - val_f1: 0.5188 - val_auc: 0.8705 - val_accuracy: 0.8560 - _timestamp: 1656378791.0000 - _runtime: 574.0000\n",
            "Epoch 79/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2105 - f1: 0.9158 - auc: 0.9724 - accuracy: 0.9183 - val_loss: 0.3453 - val_f1: 0.5235 - val_auc: 0.8702 - val_accuracy: 0.8554 - _timestamp: 1656378799.0000 - _runtime: 582.0000\n",
            "Epoch 80/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2077 - f1: 0.9130 - auc: 0.9737 - accuracy: 0.9159 - val_loss: 0.3463 - val_f1: 0.5211 - val_auc: 0.8713 - val_accuracy: 0.8543 - _timestamp: 1656378805.0000 - _runtime: 588.0000\n",
            "Epoch 81/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2083 - f1: 0.9179 - auc: 0.9732 - accuracy: 0.9193 - val_loss: 0.3458 - val_f1: 0.5254 - val_auc: 0.8715 - val_accuracy: 0.8560 - _timestamp: 1656378811.0000 - _runtime: 594.0000\n",
            "Epoch 82/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2076 - f1: 0.9177 - auc: 0.9732 - accuracy: 0.9195 - val_loss: 0.3467 - val_f1: 0.5222 - val_auc: 0.8720 - val_accuracy: 0.8537 - _timestamp: 1656378818.0000 - _runtime: 601.0000\n",
            "Epoch 83/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.2051 - f1: 0.9182 - auc: 0.9740 - accuracy: 0.9201 - val_loss: 0.3447 - val_f1: 0.5210 - val_auc: 0.8718 - val_accuracy: 0.8554 - _timestamp: 1656378824.0000 - _runtime: 607.0000\n",
            "Epoch 84/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2050 - f1: 0.9226 - auc: 0.9739 - accuracy: 0.9241 - val_loss: 0.3454 - val_f1: 0.5226 - val_auc: 0.8713 - val_accuracy: 0.8554 - _timestamp: 1656378831.0000 - _runtime: 614.0000\n",
            "Epoch 85/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2033 - f1: 0.9157 - auc: 0.9746 - accuracy: 0.9179 - val_loss: 0.3466 - val_f1: 0.5219 - val_auc: 0.8714 - val_accuracy: 0.8548 - _timestamp: 1656378837.0000 - _runtime: 620.0000\n",
            "Epoch 86/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2041 - f1: 0.9197 - auc: 0.9741 - accuracy: 0.9216 - val_loss: 0.3450 - val_f1: 0.5219 - val_auc: 0.8715 - val_accuracy: 0.8571 - _timestamp: 1656378844.0000 - _runtime: 627.0000\n",
            "Epoch 87/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2005 - f1: 0.9190 - auc: 0.9752 - accuracy: 0.9219 - val_loss: 0.3453 - val_f1: 0.5242 - val_auc: 0.8718 - val_accuracy: 0.8571 - _timestamp: 1656378850.0000 - _runtime: 633.0000\n",
            "Epoch 88/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2022 - f1: 0.9218 - auc: 0.9747 - accuracy: 0.9239 - val_loss: 0.3457 - val_f1: 0.5242 - val_auc: 0.8718 - val_accuracy: 0.8571 - _timestamp: 1656378856.0000 - _runtime: 639.0000\n",
            "Epoch 89/100\n",
            "380/380 [==============================] - 11s 29ms/step - loss: 0.2069 - f1: 0.9191 - auc: 0.9735 - accuracy: 0.9206 - val_loss: 0.3442 - val_f1: 0.5241 - val_auc: 0.8721 - val_accuracy: 0.8582 - _timestamp: 1656378862.0000 - _runtime: 645.0000\n",
            "Epoch 90/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2053 - f1: 0.9189 - auc: 0.9741 - accuracy: 0.9204 - val_loss: 0.3446 - val_f1: 0.5278 - val_auc: 0.8723 - val_accuracy: 0.8582 - _timestamp: 1656378873.0000 - _runtime: 656.0000\n",
            "Epoch 91/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.1990 - f1: 0.9211 - auc: 0.9753 - accuracy: 0.9230 - val_loss: 0.3445 - val_f1: 0.5278 - val_auc: 0.8724 - val_accuracy: 0.8582 - _timestamp: 1656378879.0000 - _runtime: 662.0000\n",
            "Epoch 92/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.1993 - f1: 0.9208 - auc: 0.9753 - accuracy: 0.9232 - val_loss: 0.3439 - val_f1: 0.5223 - val_auc: 0.8727 - val_accuracy: 0.8576 - _timestamp: 1656378886.0000 - _runtime: 669.0000\n",
            "Epoch 93/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2003 - f1: 0.9193 - auc: 0.9752 - accuracy: 0.9211 - val_loss: 0.3446 - val_f1: 0.5278 - val_auc: 0.8725 - val_accuracy: 0.8582 - _timestamp: 1656378893.0000 - _runtime: 676.0000\n",
            "Epoch 94/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.1981 - f1: 0.9224 - auc: 0.9757 - accuracy: 0.9241 - val_loss: 0.3444 - val_f1: 0.5230 - val_auc: 0.8724 - val_accuracy: 0.8587 - _timestamp: 1656378899.0000 - _runtime: 682.0000\n",
            "Epoch 95/100\n",
            "380/380 [==============================] - 8s 20ms/step - loss: 0.2020 - f1: 0.9222 - auc: 0.9746 - accuracy: 0.9234 - val_loss: 0.3436 - val_f1: 0.5142 - val_auc: 0.8725 - val_accuracy: 0.8582 - _timestamp: 1656378906.0000 - _runtime: 689.0000\n",
            "Epoch 96/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.2050 - f1: 0.9164 - auc: 0.9742 - accuracy: 0.9189 - val_loss: 0.3443 - val_f1: 0.5304 - val_auc: 0.8726 - val_accuracy: 0.8604 - _timestamp: 1656378913.0000 - _runtime: 696.0000\n",
            "Epoch 97/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.1991 - f1: 0.9188 - auc: 0.9755 - accuracy: 0.9211 - val_loss: 0.3437 - val_f1: 0.5150 - val_auc: 0.8724 - val_accuracy: 0.8587 - _timestamp: 1656378919.0000 - _runtime: 702.0000\n",
            "Epoch 98/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.1993 - f1: 0.9206 - auc: 0.9756 - accuracy: 0.9224 - val_loss: 0.3442 - val_f1: 0.5260 - val_auc: 0.8725 - val_accuracy: 0.8598 - _timestamp: 1656378926.0000 - _runtime: 709.0000\n",
            "Epoch 99/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.1992 - f1: 0.9211 - auc: 0.9755 - accuracy: 0.9228 - val_loss: 0.3440 - val_f1: 0.5265 - val_auc: 0.8727 - val_accuracy: 0.8587 - _timestamp: 1656378932.0000 - _runtime: 715.0000\n",
            "Epoch 100/100\n",
            "380/380 [==============================] - 6s 16ms/step - loss: 0.1974 - f1: 0.9195 - auc: 0.9761 - accuracy: 0.9216 - val_loss: 0.3447 - val_f1: 0.5375 - val_auc: 0.8737 - val_accuracy: 0.8604 - _timestamp: 1656378938.0000 - _runtime: 721.0000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5137676b8917446183104dc3d4647755",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='930.266 MB of 930.266 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>auc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇█▇▇███████████████████████</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████████████████</td></tr><tr><td>val_auc</td><td>▁▆▅▅▅▄▄▄▅▄▄▄▅▄▅▅▅▅▆▆▆▆▆▇▇▇▇▆▇▆▇▇▇▇▇▇████</td></tr><tr><td>val_f1</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>val_loss</td><td>█▆▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.92162</td></tr><tr><td>auc</td><td>0.97609</td></tr><tr><td>best_epoch</td><td>94</td></tr><tr><td>best_val_loss</td><td>0.34358</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>f1</td><td>0.91947</td></tr><tr><td>loss</td><td>0.19742</td></tr><tr><td>val_accuracy</td><td>0.8604</td></tr><tr><td>val_auc</td><td>0.87366</td></tr><tr><td>val_f1</td><td>0.53747</td></tr><tr><td>val_loss</td><td>0.3447</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">worldly-sweep-20</strong>: <a href=\"https://wandb.ai/zachs_team/keras_covid_project_smote/runs/f3hlijxn\" target=\"_blank\">https://wandb.ai/zachs_team/keras_covid_project_smote/runs/f3hlijxn</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220628_010336-f3hlijxn/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.agent(sweep_id, train, count=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAGUI43R7PB-"
      },
      "source": [
        "Here is the results of sweeping for every combination of data, please view the WandB results\n",
        "Raw training data:\n",
        "https://wandb.ai/zachs_team/keras_covid_project_imb?workspace=user-zfarahany\n",
        "Weighted training:\n",
        "https://wandb.ai/zachs_team/keras_covid_project_weights?workspace=user-zfarahany\n",
        "Oversampled:\n",
        "https://wandb.ai/zachs_team/keras_covid_project_oversampling?workspace=user-zfarahany\n",
        "Undersampled:\n",
        "https://wandb.ai/zachs_team/keras_covid_project_undersampling?workspace=user-zfarahany\n",
        "SMOTE-NC data:\n",
        "https://wandb.ai/zachs_team/keras_covid_project_smote?workspace=user-zfarahany"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "l-F0C1kvfa6c",
        "outputId": "90d669e8-b53c-4f7b-eac7-585b7e807e3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 25008)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4000)              100036000 \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 4000)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4000)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4000)              16004000  \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 4000)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4000)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4000)              16004000  \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 4000)              0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 4000)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 4001      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 132,048,001\n",
            "Trainable params: 132,048,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "225/225 [==============================] - 13s 32ms/step - loss: 54.8866 - f1: 0.0027 - auc: 0.6370 - accuracy: 0.8438 - val_loss: 51.3702 - val_f1: 0.0190 - val_auc: 0.8647 - val_accuracy: 0.8398\n",
            "Epoch 2/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 48.6845 - f1: 0.0894 - auc: 0.8722 - accuracy: 0.8508 - val_loss: 46.2421 - val_f1: 0.4757 - val_auc: 0.8818 - val_accuracy: 0.8648\n",
            "Epoch 3/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 44.2141 - f1: 0.3589 - auc: 0.8903 - accuracy: 0.8723 - val_loss: 42.3687 - val_f1: 0.5467 - val_auc: 0.8866 - val_accuracy: 0.8626\n",
            "Epoch 4/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 40.7773 - f1: 0.4619 - auc: 0.8963 - accuracy: 0.8782 - val_loss: 39.3438 - val_f1: 0.5520 - val_auc: 0.8901 - val_accuracy: 0.8648\n",
            "Epoch 5/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 38.0930 - f1: 0.4774 - auc: 0.9032 - accuracy: 0.8800 - val_loss: 37.0012 - val_f1: 0.5747 - val_auc: 0.8927 - val_accuracy: 0.8632\n",
            "Epoch 6/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 36.0377 - f1: 0.4969 - auc: 0.9052 - accuracy: 0.8847 - val_loss: 35.2295 - val_f1: 0.5750 - val_auc: 0.8963 - val_accuracy: 0.8693\n",
            "Epoch 7/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 34.5417 - f1: 0.5027 - auc: 0.9076 - accuracy: 0.8832 - val_loss: 33.9725 - val_f1: 0.5968 - val_auc: 0.8990 - val_accuracy: 0.8637\n",
            "Epoch 8/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 33.3670 - f1: 0.5444 - auc: 0.9110 - accuracy: 0.8873 - val_loss: 32.8592 - val_f1: 0.5999 - val_auc: 0.9015 - val_accuracy: 0.8682\n",
            "Epoch 9/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 32.3061 - f1: 0.5466 - auc: 0.9150 - accuracy: 0.8917 - val_loss: 31.8499 - val_f1: 0.5986 - val_auc: 0.9036 - val_accuracy: 0.8660\n",
            "Epoch 10/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 31.3292 - f1: 0.5661 - auc: 0.9188 - accuracy: 0.8926 - val_loss: 30.9023 - val_f1: 0.6142 - val_auc: 0.9047 - val_accuracy: 0.8776\n",
            "Epoch 11/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 30.4198 - f1: 0.5642 - auc: 0.9221 - accuracy: 0.8929 - val_loss: 30.0301 - val_f1: 0.6029 - val_auc: 0.9071 - val_accuracy: 0.8710\n",
            "Epoch 12/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 29.5705 - f1: 0.5805 - auc: 0.9244 - accuracy: 0.8955 - val_loss: 29.2093 - val_f1: 0.6073 - val_auc: 0.9087 - val_accuracy: 0.8715\n",
            "Epoch 13/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 28.7701 - f1: 0.5875 - auc: 0.9290 - accuracy: 0.8967 - val_loss: 28.4497 - val_f1: 0.6070 - val_auc: 0.9098 - val_accuracy: 0.8654\n",
            "Epoch 14/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 28.0211 - f1: 0.5968 - auc: 0.9298 - accuracy: 0.8987 - val_loss: 27.7062 - val_f1: 0.6164 - val_auc: 0.9102 - val_accuracy: 0.8788\n",
            "Epoch 15/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 27.3141 - f1: 0.6041 - auc: 0.9332 - accuracy: 0.9011 - val_loss: 27.0229 - val_f1: 0.6156 - val_auc: 0.9117 - val_accuracy: 0.8804\n",
            "Epoch 16/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 26.6420 - f1: 0.6075 - auc: 0.9363 - accuracy: 0.9013 - val_loss: 26.3748 - val_f1: 0.6185 - val_auc: 0.9131 - val_accuracy: 0.8788\n",
            "Epoch 17/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 26.0066 - f1: 0.6122 - auc: 0.9352 - accuracy: 0.9004 - val_loss: 25.7500 - val_f1: 0.6257 - val_auc: 0.9135 - val_accuracy: 0.8832\n",
            "Epoch 18/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 25.3982 - f1: 0.6147 - auc: 0.9383 - accuracy: 0.9042 - val_loss: 25.1771 - val_f1: 0.6306 - val_auc: 0.9146 - val_accuracy: 0.8704\n",
            "Epoch 19/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 24.8192 - f1: 0.6096 - auc: 0.9404 - accuracy: 0.9039 - val_loss: 24.6018 - val_f1: 0.6258 - val_auc: 0.9154 - val_accuracy: 0.8810\n",
            "Epoch 20/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 24.2683 - f1: 0.6255 - auc: 0.9396 - accuracy: 0.9029 - val_loss: 24.0811 - val_f1: 0.6308 - val_auc: 0.9155 - val_accuracy: 0.8671\n",
            "Epoch 21/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 23.7343 - f1: 0.6310 - auc: 0.9427 - accuracy: 0.9049 - val_loss: 23.5435 - val_f1: 0.6300 - val_auc: 0.9161 - val_accuracy: 0.8804\n",
            "Epoch 22/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 23.2193 - f1: 0.6336 - auc: 0.9466 - accuracy: 0.9056 - val_loss: 23.0305 - val_f1: 0.6232 - val_auc: 0.9162 - val_accuracy: 0.8860\n",
            "Epoch 23/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 22.7234 - f1: 0.6661 - auc: 0.9472 - accuracy: 0.9113 - val_loss: 22.5701 - val_f1: 0.6354 - val_auc: 0.9165 - val_accuracy: 0.8737\n",
            "Epoch 24/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 22.2443 - f1: 0.6446 - auc: 0.9493 - accuracy: 0.9090 - val_loss: 22.0963 - val_f1: 0.6425 - val_auc: 0.9168 - val_accuracy: 0.8799\n",
            "Epoch 25/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 21.7741 - f1: 0.6471 - auc: 0.9520 - accuracy: 0.9159 - val_loss: 21.6488 - val_f1: 0.6326 - val_auc: 0.9172 - val_accuracy: 0.8682\n",
            "Epoch 26/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 21.3200 - f1: 0.6703 - auc: 0.9521 - accuracy: 0.9157 - val_loss: 21.2020 - val_f1: 0.6382 - val_auc: 0.9174 - val_accuracy: 0.8726\n",
            "Epoch 27/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 20.8827 - f1: 0.6736 - auc: 0.9540 - accuracy: 0.9164 - val_loss: 20.7539 - val_f1: 0.6320 - val_auc: 0.9172 - val_accuracy: 0.8832\n",
            "Epoch 28/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 20.4615 - f1: 0.6656 - auc: 0.9551 - accuracy: 0.9163 - val_loss: 20.3518 - val_f1: 0.6488 - val_auc: 0.9166 - val_accuracy: 0.8832\n",
            "Epoch 29/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 20.0566 - f1: 0.6905 - auc: 0.9556 - accuracy: 0.9202 - val_loss: 19.9624 - val_f1: 0.6410 - val_auc: 0.9166 - val_accuracy: 0.8754\n",
            "Epoch 30/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 19.6602 - f1: 0.6917 - auc: 0.9580 - accuracy: 0.9211 - val_loss: 19.5546 - val_f1: 0.6286 - val_auc: 0.9160 - val_accuracy: 0.8860\n",
            "Epoch 31/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 19.2710 - f1: 0.7019 - auc: 0.9604 - accuracy: 0.9223 - val_loss: 19.1962 - val_f1: 0.6387 - val_auc: 0.9167 - val_accuracy: 0.8760\n",
            "Epoch 32/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 18.8957 - f1: 0.7041 - auc: 0.9608 - accuracy: 0.9234 - val_loss: 18.8242 - val_f1: 0.6408 - val_auc: 0.9170 - val_accuracy: 0.8776\n",
            "Epoch 33/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 18.5261 - f1: 0.7219 - auc: 0.9634 - accuracy: 0.9275 - val_loss: 18.4726 - val_f1: 0.6371 - val_auc: 0.9167 - val_accuracy: 0.8737\n",
            "Epoch 34/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 18.1737 - f1: 0.7182 - auc: 0.9631 - accuracy: 0.9268 - val_loss: 18.1021 - val_f1: 0.6298 - val_auc: 0.9150 - val_accuracy: 0.8877\n",
            "Epoch 35/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 17.8292 - f1: 0.7201 - auc: 0.9644 - accuracy: 0.9268 - val_loss: 17.7802 - val_f1: 0.6361 - val_auc: 0.9163 - val_accuracy: 0.8782\n",
            "Epoch 36/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 17.4917 - f1: 0.7082 - auc: 0.9670 - accuracy: 0.9261 - val_loss: 17.4572 - val_f1: 0.6313 - val_auc: 0.9155 - val_accuracy: 0.8749\n",
            "Epoch 37/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 17.1715 - f1: 0.7170 - auc: 0.9642 - accuracy: 0.9261 - val_loss: 17.1407 - val_f1: 0.6339 - val_auc: 0.9156 - val_accuracy: 0.8743\n",
            "Epoch 38/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 16.8514 - f1: 0.7206 - auc: 0.9671 - accuracy: 0.9287 - val_loss: 16.8194 - val_f1: 0.6350 - val_auc: 0.9157 - val_accuracy: 0.8799\n",
            "Epoch 39/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 16.5422 - f1: 0.7364 - auc: 0.9680 - accuracy: 0.9306 - val_loss: 16.5114 - val_f1: 0.6437 - val_auc: 0.9147 - val_accuracy: 0.8865\n",
            "Epoch 40/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 16.2392 - f1: 0.7425 - auc: 0.9697 - accuracy: 0.9327 - val_loss: 16.2322 - val_f1: 0.6310 - val_auc: 0.9161 - val_accuracy: 0.8749\n",
            "Epoch 41/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 15.9507 - f1: 0.7425 - auc: 0.9682 - accuracy: 0.9318 - val_loss: 15.9409 - val_f1: 0.6357 - val_auc: 0.9147 - val_accuracy: 0.8771\n",
            "Epoch 42/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 15.6635 - f1: 0.7558 - auc: 0.9711 - accuracy: 0.9332 - val_loss: 15.6546 - val_f1: 0.6381 - val_auc: 0.9136 - val_accuracy: 0.8838\n",
            "Epoch 43/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 15.3841 - f1: 0.7464 - auc: 0.9723 - accuracy: 0.9369 - val_loss: 15.3841 - val_f1: 0.6398 - val_auc: 0.9135 - val_accuracy: 0.8815\n",
            "Epoch 44/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 15.1080 - f1: 0.7460 - auc: 0.9733 - accuracy: 0.9349 - val_loss: 15.1222 - val_f1: 0.6346 - val_auc: 0.9143 - val_accuracy: 0.8760\n",
            "Epoch 45/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 14.8385 - f1: 0.7797 - auc: 0.9737 - accuracy: 0.9406 - val_loss: 14.8610 - val_f1: 0.6386 - val_auc: 0.9133 - val_accuracy: 0.8771\n",
            "Epoch 46/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 14.5829 - f1: 0.7424 - auc: 0.9734 - accuracy: 0.9356 - val_loss: 14.6056 - val_f1: 0.6360 - val_auc: 0.9129 - val_accuracy: 0.8771\n",
            "Epoch 47/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 14.3247 - f1: 0.7755 - auc: 0.9766 - accuracy: 0.9402 - val_loss: 14.3566 - val_f1: 0.6420 - val_auc: 0.9132 - val_accuracy: 0.8793\n",
            "Epoch 48/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 14.0765 - f1: 0.7651 - auc: 0.9769 - accuracy: 0.9395 - val_loss: 14.1158 - val_f1: 0.6370 - val_auc: 0.9135 - val_accuracy: 0.8765\n",
            "Epoch 49/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 13.8325 - f1: 0.7795 - auc: 0.9766 - accuracy: 0.9431 - val_loss: 13.8656 - val_f1: 0.6428 - val_auc: 0.9128 - val_accuracy: 0.8882\n",
            "Epoch 50/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 13.6017 - f1: 0.7779 - auc: 0.9762 - accuracy: 0.9423 - val_loss: 13.6505 - val_f1: 0.6389 - val_auc: 0.9125 - val_accuracy: 0.8782\n",
            "Epoch 51/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 13.3734 - f1: 0.7810 - auc: 0.9773 - accuracy: 0.9417 - val_loss: 13.4375 - val_f1: 0.6338 - val_auc: 0.9127 - val_accuracy: 0.8726\n",
            "Epoch 52/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 13.1491 - f1: 0.7920 - auc: 0.9782 - accuracy: 0.9465 - val_loss: 13.2078 - val_f1: 0.6309 - val_auc: 0.9120 - val_accuracy: 0.8754\n",
            "Epoch 53/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 12.9255 - f1: 0.7953 - auc: 0.9794 - accuracy: 0.9446 - val_loss: 12.9831 - val_f1: 0.6384 - val_auc: 0.9111 - val_accuracy: 0.8826\n",
            "Epoch 54/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 12.7097 - f1: 0.7866 - auc: 0.9786 - accuracy: 0.9462 - val_loss: 12.7807 - val_f1: 0.6363 - val_auc: 0.9121 - val_accuracy: 0.8737\n",
            "Epoch 55/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 12.4934 - f1: 0.8039 - auc: 0.9805 - accuracy: 0.9488 - val_loss: 12.5661 - val_f1: 0.6450 - val_auc: 0.9119 - val_accuracy: 0.8832\n",
            "Epoch 56/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 12.2856 - f1: 0.7967 - auc: 0.9805 - accuracy: 0.9502 - val_loss: 12.3550 - val_f1: 0.6463 - val_auc: 0.9102 - val_accuracy: 0.8871\n",
            "Epoch 57/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 12.0796 - f1: 0.8015 - auc: 0.9819 - accuracy: 0.9478 - val_loss: 12.1475 - val_f1: 0.6343 - val_auc: 0.9093 - val_accuracy: 0.8877\n",
            "Epoch 58/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 11.8765 - f1: 0.8047 - auc: 0.9816 - accuracy: 0.9488 - val_loss: 11.9608 - val_f1: 0.6442 - val_auc: 0.9101 - val_accuracy: 0.8838\n",
            "Epoch 59/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 11.6733 - f1: 0.8063 - auc: 0.9840 - accuracy: 0.9502 - val_loss: 11.7594 - val_f1: 0.6368 - val_auc: 0.9093 - val_accuracy: 0.8849\n",
            "Epoch 60/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 11.4838 - f1: 0.7965 - auc: 0.9823 - accuracy: 0.9492 - val_loss: 11.5753 - val_f1: 0.6449 - val_auc: 0.9087 - val_accuracy: 0.8843\n",
            "Epoch 61/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 11.2958 - f1: 0.8119 - auc: 0.9817 - accuracy: 0.9516 - val_loss: 11.4066 - val_f1: 0.6360 - val_auc: 0.9105 - val_accuracy: 0.8721\n",
            "Epoch 62/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 11.1082 - f1: 0.8295 - auc: 0.9852 - accuracy: 0.9551 - val_loss: 11.2110 - val_f1: 0.6404 - val_auc: 0.9080 - val_accuracy: 0.8865\n",
            "Epoch 63/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 10.9366 - f1: 0.8197 - auc: 0.9831 - accuracy: 0.9509 - val_loss: 11.0396 - val_f1: 0.6457 - val_auc: 0.9068 - val_accuracy: 0.8860\n",
            "Epoch 64/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 10.7536 - f1: 0.8276 - auc: 0.9864 - accuracy: 0.9559 - val_loss: 10.8652 - val_f1: 0.6375 - val_auc: 0.9073 - val_accuracy: 0.8843\n",
            "Epoch 65/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 10.5888 - f1: 0.7976 - auc: 0.9842 - accuracy: 0.9492 - val_loss: 10.6875 - val_f1: 0.6168 - val_auc: 0.9068 - val_accuracy: 0.8826\n",
            "Epoch 66/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 10.4141 - f1: 0.8198 - auc: 0.9863 - accuracy: 0.9534 - val_loss: 10.5308 - val_f1: 0.6286 - val_auc: 0.9057 - val_accuracy: 0.8821\n",
            "Epoch 67/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 10.2431 - f1: 0.8385 - auc: 0.9876 - accuracy: 0.9581 - val_loss: 10.3729 - val_f1: 0.6368 - val_auc: 0.9078 - val_accuracy: 0.8804\n",
            "Epoch 68/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 10.0806 - f1: 0.8492 - auc: 0.9869 - accuracy: 0.9563 - val_loss: 10.2023 - val_f1: 0.6234 - val_auc: 0.9058 - val_accuracy: 0.8832\n",
            "Epoch 69/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 9.9195 - f1: 0.8308 - auc: 0.9876 - accuracy: 0.9558 - val_loss: 10.0565 - val_f1: 0.6344 - val_auc: 0.9075 - val_accuracy: 0.8776\n",
            "Epoch 70/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 9.7698 - f1: 0.8374 - auc: 0.9864 - accuracy: 0.9552 - val_loss: 9.8915 - val_f1: 0.6200 - val_auc: 0.9062 - val_accuracy: 0.8832\n",
            "Epoch 71/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 9.6193 - f1: 0.8338 - auc: 0.9868 - accuracy: 0.9586 - val_loss: 9.7649 - val_f1: 0.6262 - val_auc: 0.9074 - val_accuracy: 0.8732\n",
            "Epoch 72/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 9.4718 - f1: 0.8391 - auc: 0.9871 - accuracy: 0.9566 - val_loss: 9.6032 - val_f1: 0.6186 - val_auc: 0.9039 - val_accuracy: 0.8826\n",
            "Epoch 73/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 9.3272 - f1: 0.8227 - auc: 0.9882 - accuracy: 0.9570 - val_loss: 9.4729 - val_f1: 0.6290 - val_auc: 0.9061 - val_accuracy: 0.8776\n",
            "Epoch 74/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 9.1868 - f1: 0.8553 - auc: 0.9881 - accuracy: 0.9612 - val_loss: 9.3228 - val_f1: 0.5992 - val_auc: 0.9040 - val_accuracy: 0.8832\n",
            "Epoch 75/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 9.0461 - f1: 0.8458 - auc: 0.9895 - accuracy: 0.9601 - val_loss: 9.1862 - val_f1: 0.6033 - val_auc: 0.9005 - val_accuracy: 0.8865\n",
            "Epoch 76/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 8.9108 - f1: 0.8497 - auc: 0.9894 - accuracy: 0.9591 - val_loss: 9.0528 - val_f1: 0.6119 - val_auc: 0.9052 - val_accuracy: 0.8821\n",
            "Epoch 77/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 8.7767 - f1: 0.8498 - auc: 0.9896 - accuracy: 0.9611 - val_loss: 8.9259 - val_f1: 0.6125 - val_auc: 0.9045 - val_accuracy: 0.8799\n",
            "Epoch 78/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 8.6482 - f1: 0.8498 - auc: 0.9898 - accuracy: 0.9624 - val_loss: 8.8025 - val_f1: 0.6137 - val_auc: 0.9041 - val_accuracy: 0.8782\n",
            "Epoch 79/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 8.5225 - f1: 0.8479 - auc: 0.9893 - accuracy: 0.9612 - val_loss: 8.6890 - val_f1: 0.6226 - val_auc: 0.9041 - val_accuracy: 0.8737\n",
            "Epoch 80/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 8.3978 - f1: 0.8506 - auc: 0.9902 - accuracy: 0.9636 - val_loss: 8.5527 - val_f1: 0.6133 - val_auc: 0.9038 - val_accuracy: 0.8826\n",
            "Epoch 81/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 8.2740 - f1: 0.8542 - auc: 0.9907 - accuracy: 0.9636 - val_loss: 8.4415 - val_f1: 0.6305 - val_auc: 0.9042 - val_accuracy: 0.8799\n",
            "Epoch 82/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 8.1554 - f1: 0.8628 - auc: 0.9893 - accuracy: 0.9643 - val_loss: 8.3134 - val_f1: 0.6159 - val_auc: 0.9039 - val_accuracy: 0.8826\n",
            "Epoch 83/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 8.0428 - f1: 0.8458 - auc: 0.9892 - accuracy: 0.9602 - val_loss: 8.2049 - val_f1: 0.6166 - val_auc: 0.9040 - val_accuracy: 0.8793\n",
            "Epoch 84/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 7.9261 - f1: 0.8610 - auc: 0.9901 - accuracy: 0.9651 - val_loss: 8.0906 - val_f1: 0.6094 - val_auc: 0.9028 - val_accuracy: 0.8793\n",
            "Epoch 85/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 7.8138 - f1: 0.8512 - auc: 0.9909 - accuracy: 0.9634 - val_loss: 7.9767 - val_f1: 0.6134 - val_auc: 0.9020 - val_accuracy: 0.8832\n",
            "Epoch 86/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 7.7006 - f1: 0.8790 - auc: 0.9915 - accuracy: 0.9655 - val_loss: 7.8681 - val_f1: 0.6125 - val_auc: 0.9030 - val_accuracy: 0.8810\n",
            "Epoch 87/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 7.5920 - f1: 0.8779 - auc: 0.9917 - accuracy: 0.9670 - val_loss: 7.7672 - val_f1: 0.6134 - val_auc: 0.9048 - val_accuracy: 0.8804\n",
            "Epoch 88/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 7.4911 - f1: 0.8672 - auc: 0.9904 - accuracy: 0.9661 - val_loss: 7.6645 - val_f1: 0.6172 - val_auc: 0.9027 - val_accuracy: 0.8804\n",
            "Epoch 89/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 7.3826 - f1: 0.8780 - auc: 0.9928 - accuracy: 0.9677 - val_loss: 7.5609 - val_f1: 0.6051 - val_auc: 0.9003 - val_accuracy: 0.8810\n",
            "Epoch 90/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 7.2840 - f1: 0.8838 - auc: 0.9921 - accuracy: 0.9675 - val_loss: 7.4691 - val_f1: 0.6219 - val_auc: 0.9023 - val_accuracy: 0.8776\n",
            "Epoch 91/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 7.1857 - f1: 0.8710 - auc: 0.9920 - accuracy: 0.9676 - val_loss: 7.3635 - val_f1: 0.5971 - val_auc: 0.9012 - val_accuracy: 0.8788\n",
            "Epoch 92/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 7.0888 - f1: 0.8862 - auc: 0.9928 - accuracy: 0.9694 - val_loss: 7.2732 - val_f1: 0.6093 - val_auc: 0.9018 - val_accuracy: 0.8793\n",
            "Epoch 93/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 6.9962 - f1: 0.8711 - auc: 0.9924 - accuracy: 0.9669 - val_loss: 7.1798 - val_f1: 0.6167 - val_auc: 0.9024 - val_accuracy: 0.8810\n",
            "Epoch 94/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 6.9014 - f1: 0.8739 - auc: 0.9928 - accuracy: 0.9683 - val_loss: 7.0844 - val_f1: 0.6029 - val_auc: 0.9013 - val_accuracy: 0.8793\n",
            "Epoch 95/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 6.8098 - f1: 0.8925 - auc: 0.9928 - accuracy: 0.9695 - val_loss: 6.9949 - val_f1: 0.6000 - val_auc: 0.9018 - val_accuracy: 0.8782\n",
            "Epoch 96/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 6.7221 - f1: 0.8715 - auc: 0.9927 - accuracy: 0.9675 - val_loss: 6.9086 - val_f1: 0.6106 - val_auc: 0.9031 - val_accuracy: 0.8771\n",
            "Epoch 97/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 6.6268 - f1: 0.9026 - auc: 0.9944 - accuracy: 0.9729 - val_loss: 6.8167 - val_f1: 0.5960 - val_auc: 0.9017 - val_accuracy: 0.8821\n",
            "Epoch 98/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 6.5421 - f1: 0.8840 - auc: 0.9935 - accuracy: 0.9701 - val_loss: 6.7318 - val_f1: 0.5961 - val_auc: 0.9023 - val_accuracy: 0.8788\n",
            "Epoch 99/100\n",
            "225/225 [==============================] - 7s 29ms/step - loss: 6.4570 - f1: 0.8769 - auc: 0.9934 - accuracy: 0.9677 - val_loss: 6.6523 - val_f1: 0.6203 - val_auc: 0.9041 - val_accuracy: 0.8788\n",
            "Epoch 100/100\n",
            "225/225 [==============================] - 6s 29ms/step - loss: 6.3737 - f1: 0.8842 - auc: 0.9936 - accuracy: 0.9711 - val_loss: 6.5649 - val_f1: 0.6047 - val_auc: 0.9009 - val_accuracy: 0.8793\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa5d370df10>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##Raw training data model##\n",
        "\n",
        "from keras.layers import Dropout,Dense,LeakyReLU,PReLU,InputLayer, Activation\n",
        "from keras.regularizers import l1,l2,l1_l2\n",
        "from tensorflow.keras.optimizers import Adagrad, Adam, Adamax, Nadam, RMSprop, Adadelta\n",
        "from keras.models import Sequential\n",
        "\n",
        "#parameters\n",
        "dropout_rate = .3\n",
        "activation_function = 'leaky_relu'\n",
        "num_layers = 3\n",
        "num_neurons = 4000\n",
        "alpha_value = .04\n",
        "regularization_type = 'l1_l2'\n",
        "regularization_factor = 5e-5\n",
        "optomizer = 'adamax'\n",
        "learning_rate = 1e-5\n",
        "epochs = 100\n",
        "\n",
        "num_columns = 25008\n",
        "model1= Sequential()\n",
        "model1.add(InputLayer(input_shape = (num_columns)))\n",
        "model1 = create_layers(model1,dropout_rate,activation_function,num_layers,\n",
        "    num_neurons,\n",
        "    regularization_wrapper(regularization_type,regularization_factor),\n",
        "    alpha_value)\n",
        "model1 = choose_optimizer(model1,optomizer,learning_rate)\n",
        "model1.add(Dropout(dropout_rate))\n",
        "model1.add(Dense(1,activation='sigmoid'))\n",
        "print(model1.summary())\n",
        "model1.fit(x_train,y_train,epochs = epochs,\n",
        "          validation_data=(x_val,y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubMSIUIdbtbS"
      },
      "outputs": [],
      "source": [
        "def gen_roc_auc(model, x,y):\n",
        "  from sklearn.metrics import roc_curve,roc_auc_score\n",
        "  y_proba = model.predict(x)\n",
        "  fpr , tpr , thresholds = roc_curve(y, y_proba)\n",
        "  return fpr, tpr, thresholds\n",
        "\n",
        "fpr1, tpr1, thresh1 = gen_roc_auc(model1,x_test,y_test)\n",
        "fpr2,tpr2,thresh2 =  gen_roc_auc(model2,x_test,y_test)\n",
        "fpr3,tpr3,thresh3 =  gen_roc_auc(model3,x_test,y_test)\n",
        "fpr4,tpr4,thresh4 =  gen_roc_auc(model4,x_test,y_test)\n",
        "fpr5,tpr5,thresh5 =  gen_roc_auc(model5,x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "tvweNBmceZnV",
        "outputId": "aa542bd6-16ce-4df3-e645-51f3c413f422"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.plot(fpr1,tpr1) \n",
        "plt.plot(fpr2,tpr2) \n",
        "plt.plot(np.arange(0,1,.01),np.arange(0,1,.01))\n",
        "plt.axis([0,1,0,1])\n",
        "plt.legend([\"Model#1\",\"Model#2\", \"Random\"])\n",
        "plt.xlabel('False Positive Rate') \n",
        "plt.ylabel('True Positive Rate') \n",
        "plt.show()    \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRVbORZTqhNw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, precision_score, recall_score\n",
        "#Eval test set\n",
        "def eval_model(model,x_val,y_val,x_test,y_test):\n",
        "\n",
        "  y_pred = model.predict(x_val)\n",
        "  y_pred = np.round(y_pred)\n",
        "  print(\"Validation scores\")\n",
        "  print(\"F1 score \" +str(f1_score(y_pred,y_val)))\n",
        "  print(\"Accuracy score \" +str(accuracy_score(y_pred,y_val)))\n",
        "  print(\"AUC score \" +str(roc_auc_score(y_pred,y_val)))\n",
        "\n",
        "\n",
        "  y_pred = model.predict(x_test)\n",
        "  y_pred = np.round(y_pred)\n",
        "  print(\"Test scores\")\n",
        "  print(\"F1 score \" +str(f1_score(y_pred,y_test)))\n",
        "  print(\"Accuracy score \" +str(accuracy_score(y_pred,y_test)))\n",
        "  print(\"Precision score \" +str(precision_score(y_pred,y_test)))\n",
        "  print(\"Recall score \" +str(recall_score(y_pred,y_test)))\n",
        "  print(\"AUC score \" +str(roc_auc_score(y_pred,y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Beg0y5rHuF29",
        "outputId": "770a2762-3a98-41ff-9fc6-1f01e5c6c091"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation scores\n",
            "F1 score 0.6239168110918544\n",
            "Accuracy score 0.8793103448275862\n",
            "AUC score 0.7779789654789655\n",
            "Test scores\n",
            "F1 score 0.8579465541490858\n",
            "Accuracy score 0.9550511793502447\n",
            "Precision score 0.8664772727272727\n",
            "Recall score 0.8495821727019499\n",
            "AUC score 0.9123440524526699\n"
          ]
        }
      ],
      "source": [
        "eval_model(x_val,y_val,x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2CZ16PxjjLdF"
      },
      "outputs": [],
      "source": [
        "class_weights = {\n",
        "    0:1,\n",
        "    1:6073/1117\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3QmcLN_9irj7",
        "outputId": "fc281639-0750-4c01-fb72-eb8079e72a5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout_4 (Dropout)         (None, 25008)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2000)              50018000  \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 2000)              0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 2000)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 2001      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,020,001\n",
            "Trainable params: 50,020,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "225/225 [==============================] - 4s 13ms/step - loss: 2.7364 - f1: 0.4584 - auc: 0.8269 - accuracy: 0.6950 - val_loss: 2.1828 - val_f1: 0.5402 - val_auc: 0.8804 - val_accuracy: 0.7836\n",
            "Epoch 2/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 2.3319 - f1: 0.5572 - auc: 0.8937 - accuracy: 0.8038 - val_loss: 1.9668 - val_f1: 0.5536 - val_auc: 0.8880 - val_accuracy: 0.7976\n",
            "Epoch 3/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 2.1310 - f1: 0.5757 - auc: 0.9046 - accuracy: 0.8220 - val_loss: 1.8227 - val_f1: 0.5599 - val_auc: 0.8923 - val_accuracy: 0.8037\n",
            "Epoch 4/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 1.9892 - f1: 0.5969 - auc: 0.9113 - accuracy: 0.8280 - val_loss: 1.7025 - val_f1: 0.5713 - val_auc: 0.8957 - val_accuracy: 0.8131\n",
            "Epoch 5/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 1.8642 - f1: 0.6011 - auc: 0.9210 - accuracy: 0.8349 - val_loss: 1.6319 - val_f1: 0.5687 - val_auc: 0.9001 - val_accuracy: 0.8065\n",
            "Epoch 6/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 1.7689 - f1: 0.6032 - auc: 0.9257 - accuracy: 0.8412 - val_loss: 1.5280 - val_f1: 0.5788 - val_auc: 0.9018 - val_accuracy: 0.8254\n",
            "Epoch 7/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 1.6920 - f1: 0.6171 - auc: 0.9291 - accuracy: 0.8481 - val_loss: 1.4843 - val_f1: 0.5760 - val_auc: 0.9046 - val_accuracy: 0.8170\n",
            "Epoch 8/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 1.6215 - f1: 0.6225 - auc: 0.9335 - accuracy: 0.8487 - val_loss: 1.4117 - val_f1: 0.5873 - val_auc: 0.9060 - val_accuracy: 0.8293\n",
            "Epoch 9/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 1.5561 - f1: 0.6388 - auc: 0.9378 - accuracy: 0.8586 - val_loss: 1.3759 - val_f1: 0.5811 - val_auc: 0.9070 - val_accuracy: 0.8242\n",
            "Epoch 10/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 1.5039 - f1: 0.6322 - auc: 0.9399 - accuracy: 0.8551 - val_loss: 1.3094 - val_f1: 0.5859 - val_auc: 0.9067 - val_accuracy: 0.8343\n",
            "Epoch 11/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 1.4481 - f1: 0.6572 - auc: 0.9449 - accuracy: 0.8648 - val_loss: 1.2749 - val_f1: 0.5845 - val_auc: 0.9078 - val_accuracy: 0.8331\n",
            "Epoch 12/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 1.4006 - f1: 0.6623 - auc: 0.9480 - accuracy: 0.8680 - val_loss: 1.2381 - val_f1: 0.5911 - val_auc: 0.9088 - val_accuracy: 0.8376\n",
            "Epoch 13/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 1.3529 - f1: 0.6750 - auc: 0.9522 - accuracy: 0.8762 - val_loss: 1.2128 - val_f1: 0.5937 - val_auc: 0.9095 - val_accuracy: 0.8370\n",
            "Epoch 14/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 1.3333 - f1: 0.6655 - auc: 0.9490 - accuracy: 0.8705 - val_loss: 1.1821 - val_f1: 0.5972 - val_auc: 0.9092 - val_accuracy: 0.8398\n",
            "Epoch 15/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 1.2884 - f1: 0.6696 - auc: 0.9540 - accuracy: 0.8758 - val_loss: 1.1570 - val_f1: 0.5945 - val_auc: 0.9093 - val_accuracy: 0.8393\n",
            "Epoch 16/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 1.2548 - f1: 0.6872 - auc: 0.9564 - accuracy: 0.8815 - val_loss: 1.1296 - val_f1: 0.5973 - val_auc: 0.9094 - val_accuracy: 0.8409\n",
            "Epoch 17/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 1.2362 - f1: 0.6901 - auc: 0.9555 - accuracy: 0.8814 - val_loss: 1.1060 - val_f1: 0.5990 - val_auc: 0.9098 - val_accuracy: 0.8426\n",
            "Epoch 18/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 1.2074 - f1: 0.6895 - auc: 0.9572 - accuracy: 0.8825 - val_loss: 1.1095 - val_f1: 0.6010 - val_auc: 0.9102 - val_accuracy: 0.8354\n",
            "Epoch 19/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 1.1826 - f1: 0.6842 - auc: 0.9580 - accuracy: 0.8821 - val_loss: 1.0578 - val_f1: 0.6022 - val_auc: 0.9087 - val_accuracy: 0.8471\n",
            "Epoch 20/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 1.1603 - f1: 0.7033 - auc: 0.9594 - accuracy: 0.8879 - val_loss: 1.0660 - val_f1: 0.6070 - val_auc: 0.9101 - val_accuracy: 0.8404\n",
            "Epoch 21/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 1.1331 - f1: 0.6895 - auc: 0.9612 - accuracy: 0.8853 - val_loss: 1.0290 - val_f1: 0.6106 - val_auc: 0.9095 - val_accuracy: 0.8504\n",
            "Epoch 22/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 1.1073 - f1: 0.7072 - auc: 0.9637 - accuracy: 0.8890 - val_loss: 0.9950 - val_f1: 0.6141 - val_auc: 0.9085 - val_accuracy: 0.8576\n",
            "Epoch 23/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 1.0916 - f1: 0.7132 - auc: 0.9637 - accuracy: 0.8929 - val_loss: 1.0013 - val_f1: 0.6093 - val_auc: 0.9098 - val_accuracy: 0.8476\n",
            "Epoch 24/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 1.0708 - f1: 0.7036 - auc: 0.9651 - accuracy: 0.8922 - val_loss: 0.9861 - val_f1: 0.6181 - val_auc: 0.9102 - val_accuracy: 0.8509\n",
            "Epoch 25/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 1.0520 - f1: 0.7148 - auc: 0.9659 - accuracy: 0.8961 - val_loss: 0.9851 - val_f1: 0.6132 - val_auc: 0.9103 - val_accuracy: 0.8465\n",
            "Epoch 26/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 1.0259 - f1: 0.7271 - auc: 0.9687 - accuracy: 0.9008 - val_loss: 0.9608 - val_f1: 0.6147 - val_auc: 0.9103 - val_accuracy: 0.8493\n",
            "Epoch 27/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 1.0203 - f1: 0.7269 - auc: 0.9672 - accuracy: 0.8996 - val_loss: 0.9429 - val_f1: 0.6150 - val_auc: 0.9097 - val_accuracy: 0.8521\n",
            "Epoch 28/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 1.0063 - f1: 0.7165 - auc: 0.9675 - accuracy: 0.8981 - val_loss: 0.9299 - val_f1: 0.6154 - val_auc: 0.9094 - val_accuracy: 0.8532\n",
            "Epoch 29/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 0.9865 - f1: 0.7176 - auc: 0.9689 - accuracy: 0.8975 - val_loss: 0.9235 - val_f1: 0.6149 - val_auc: 0.9090 - val_accuracy: 0.8515\n",
            "Epoch 30/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.9677 - f1: 0.7291 - auc: 0.9705 - accuracy: 0.9010 - val_loss: 0.9089 - val_f1: 0.6138 - val_auc: 0.9087 - val_accuracy: 0.8526\n",
            "Epoch 31/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 0.9559 - f1: 0.7333 - auc: 0.9703 - accuracy: 0.9019 - val_loss: 0.9069 - val_f1: 0.6134 - val_auc: 0.9093 - val_accuracy: 0.8498\n",
            "Epoch 32/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 0.9376 - f1: 0.7505 - auc: 0.9719 - accuracy: 0.9076 - val_loss: 0.8860 - val_f1: 0.6137 - val_auc: 0.9078 - val_accuracy: 0.8543\n",
            "Epoch 33/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 0.9248 - f1: 0.7307 - auc: 0.9729 - accuracy: 0.9024 - val_loss: 0.8794 - val_f1: 0.6176 - val_auc: 0.9080 - val_accuracy: 0.8554\n",
            "Epoch 34/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.9120 - f1: 0.7402 - auc: 0.9732 - accuracy: 0.9060 - val_loss: 0.8483 - val_f1: 0.6224 - val_auc: 0.9063 - val_accuracy: 0.8660\n",
            "Epoch 35/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.9021 - f1: 0.7537 - auc: 0.9730 - accuracy: 0.9113 - val_loss: 0.8641 - val_f1: 0.6173 - val_auc: 0.9075 - val_accuracy: 0.8548\n",
            "Epoch 36/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.8962 - f1: 0.7367 - auc: 0.9728 - accuracy: 0.9056 - val_loss: 0.8545 - val_f1: 0.6208 - val_auc: 0.9076 - val_accuracy: 0.8565\n",
            "Epoch 37/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.8876 - f1: 0.7358 - auc: 0.9726 - accuracy: 0.9068 - val_loss: 0.8536 - val_f1: 0.6149 - val_auc: 0.9083 - val_accuracy: 0.8526\n",
            "Epoch 38/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.8719 - f1: 0.7456 - auc: 0.9743 - accuracy: 0.9103 - val_loss: 0.8266 - val_f1: 0.6169 - val_auc: 0.9062 - val_accuracy: 0.8615\n",
            "Epoch 39/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.8641 - f1: 0.7526 - auc: 0.9737 - accuracy: 0.9124 - val_loss: 0.8178 - val_f1: 0.6226 - val_auc: 0.9059 - val_accuracy: 0.8637\n",
            "Epoch 40/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.8473 - f1: 0.7571 - auc: 0.9759 - accuracy: 0.9138 - val_loss: 0.8232 - val_f1: 0.6181 - val_auc: 0.9076 - val_accuracy: 0.8582\n",
            "Epoch 41/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.8356 - f1: 0.7601 - auc: 0.9766 - accuracy: 0.9166 - val_loss: 0.8047 - val_f1: 0.6260 - val_auc: 0.9072 - val_accuracy: 0.8654\n",
            "Epoch 42/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.8342 - f1: 0.7508 - auc: 0.9751 - accuracy: 0.9095 - val_loss: 0.8013 - val_f1: 0.6192 - val_auc: 0.9069 - val_accuracy: 0.8610\n",
            "Epoch 43/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.8200 - f1: 0.7654 - auc: 0.9768 - accuracy: 0.9170 - val_loss: 0.8062 - val_f1: 0.6196 - val_auc: 0.9080 - val_accuracy: 0.8576\n",
            "Epoch 44/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 0.8075 - f1: 0.7494 - auc: 0.9774 - accuracy: 0.9138 - val_loss: 0.8063 - val_f1: 0.6138 - val_auc: 0.9086 - val_accuracy: 0.8532\n",
            "Epoch 45/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 0.8070 - f1: 0.7563 - auc: 0.9767 - accuracy: 0.9157 - val_loss: 0.8020 - val_f1: 0.6145 - val_auc: 0.9085 - val_accuracy: 0.8532\n",
            "Epoch 46/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.7994 - f1: 0.7603 - auc: 0.9771 - accuracy: 0.9177 - val_loss: 0.7892 - val_f1: 0.6165 - val_auc: 0.9076 - val_accuracy: 0.8565\n",
            "Epoch 47/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.7842 - f1: 0.7606 - auc: 0.9786 - accuracy: 0.9168 - val_loss: 0.7776 - val_f1: 0.6129 - val_auc: 0.9080 - val_accuracy: 0.8582\n",
            "Epoch 48/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.7750 - f1: 0.7714 - auc: 0.9795 - accuracy: 0.9213 - val_loss: 0.7751 - val_f1: 0.6165 - val_auc: 0.9081 - val_accuracy: 0.8587\n",
            "Epoch 49/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.7565 - f1: 0.7749 - auc: 0.9809 - accuracy: 0.9211 - val_loss: 0.7477 - val_f1: 0.6223 - val_auc: 0.9066 - val_accuracy: 0.8676\n",
            "Epoch 50/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.7631 - f1: 0.7742 - auc: 0.9790 - accuracy: 0.9210 - val_loss: 0.7683 - val_f1: 0.6169 - val_auc: 0.9081 - val_accuracy: 0.8582\n",
            "Epoch 51/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 0.7585 - f1: 0.7622 - auc: 0.9789 - accuracy: 0.9161 - val_loss: 0.7543 - val_f1: 0.6189 - val_auc: 0.9055 - val_accuracy: 0.8610\n",
            "Epoch 52/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.7543 - f1: 0.7682 - auc: 0.9789 - accuracy: 0.9166 - val_loss: 0.7488 - val_f1: 0.6173 - val_auc: 0.9058 - val_accuracy: 0.8604\n",
            "Epoch 53/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.7424 - f1: 0.7919 - auc: 0.9798 - accuracy: 0.9243 - val_loss: 0.7410 - val_f1: 0.6177 - val_auc: 0.9051 - val_accuracy: 0.8632\n",
            "Epoch 54/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 0.7338 - f1: 0.7669 - auc: 0.9803 - accuracy: 0.9217 - val_loss: 0.7366 - val_f1: 0.6186 - val_auc: 0.9052 - val_accuracy: 0.8626\n",
            "Epoch 55/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.7240 - f1: 0.7695 - auc: 0.9812 - accuracy: 0.9210 - val_loss: 0.7418 - val_f1: 0.6158 - val_auc: 0.9062 - val_accuracy: 0.8598\n",
            "Epoch 56/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 0.7296 - f1: 0.7742 - auc: 0.9793 - accuracy: 0.9232 - val_loss: 0.7258 - val_f1: 0.6245 - val_auc: 0.9050 - val_accuracy: 0.8654\n",
            "Epoch 57/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.7166 - f1: 0.7751 - auc: 0.9810 - accuracy: 0.9241 - val_loss: 0.7304 - val_f1: 0.6175 - val_auc: 0.9050 - val_accuracy: 0.8610\n",
            "Epoch 58/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.7121 - f1: 0.7815 - auc: 0.9809 - accuracy: 0.9249 - val_loss: 0.7418 - val_f1: 0.6197 - val_auc: 0.9060 - val_accuracy: 0.8576\n",
            "Epoch 59/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.6973 - f1: 0.7901 - auc: 0.9821 - accuracy: 0.9305 - val_loss: 0.7257 - val_f1: 0.6162 - val_auc: 0.9037 - val_accuracy: 0.8610\n",
            "Epoch 60/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.6951 - f1: 0.7822 - auc: 0.9820 - accuracy: 0.9264 - val_loss: 0.7182 - val_f1: 0.6169 - val_auc: 0.9039 - val_accuracy: 0.8621\n",
            "Epoch 61/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.6982 - f1: 0.7674 - auc: 0.9812 - accuracy: 0.9211 - val_loss: 0.7125 - val_f1: 0.6213 - val_auc: 0.9043 - val_accuracy: 0.8637\n",
            "Epoch 62/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.6905 - f1: 0.7858 - auc: 0.9814 - accuracy: 0.9253 - val_loss: 0.7074 - val_f1: 0.6228 - val_auc: 0.9041 - val_accuracy: 0.8637\n",
            "Epoch 63/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.6783 - f1: 0.7966 - auc: 0.9824 - accuracy: 0.9288 - val_loss: 0.7045 - val_f1: 0.6210 - val_auc: 0.9043 - val_accuracy: 0.8637\n",
            "Epoch 64/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 0.6825 - f1: 0.7687 - auc: 0.9813 - accuracy: 0.9223 - val_loss: 0.6947 - val_f1: 0.6241 - val_auc: 0.9038 - val_accuracy: 0.8665\n",
            "Epoch 65/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.6765 - f1: 0.7787 - auc: 0.9819 - accuracy: 0.9259 - val_loss: 0.6966 - val_f1: 0.6205 - val_auc: 0.9044 - val_accuracy: 0.8648\n",
            "Epoch 66/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 0.6665 - f1: 0.7869 - auc: 0.9827 - accuracy: 0.9284 - val_loss: 0.6946 - val_f1: 0.6185 - val_auc: 0.9021 - val_accuracy: 0.8637\n",
            "Epoch 67/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.6661 - f1: 0.7850 - auc: 0.9821 - accuracy: 0.9277 - val_loss: 0.7127 - val_f1: 0.6106 - val_auc: 0.9044 - val_accuracy: 0.8537\n",
            "Epoch 68/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.6651 - f1: 0.7841 - auc: 0.9818 - accuracy: 0.9249 - val_loss: 0.6978 - val_f1: 0.6173 - val_auc: 0.9045 - val_accuracy: 0.8610\n",
            "Epoch 69/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.6533 - f1: 0.7974 - auc: 0.9832 - accuracy: 0.9325 - val_loss: 0.6943 - val_f1: 0.6187 - val_auc: 0.9047 - val_accuracy: 0.8610\n",
            "Epoch 70/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.6585 - f1: 0.7879 - auc: 0.9819 - accuracy: 0.9255 - val_loss: 0.6871 - val_f1: 0.6220 - val_auc: 0.9045 - val_accuracy: 0.8643\n",
            "Epoch 71/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.6524 - f1: 0.7845 - auc: 0.9822 - accuracy: 0.9282 - val_loss: 0.6901 - val_f1: 0.6187 - val_auc: 0.9043 - val_accuracy: 0.8610\n",
            "Epoch 72/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 0.6478 - f1: 0.7877 - auc: 0.9824 - accuracy: 0.9271 - val_loss: 0.6840 - val_f1: 0.6197 - val_auc: 0.9038 - val_accuracy: 0.8621\n",
            "Epoch 73/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 0.6335 - f1: 0.7934 - auc: 0.9841 - accuracy: 0.9289 - val_loss: 0.6742 - val_f1: 0.6228 - val_auc: 0.9035 - val_accuracy: 0.8654\n",
            "Epoch 74/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.6376 - f1: 0.7861 - auc: 0.9830 - accuracy: 0.9291 - val_loss: 0.6698 - val_f1: 0.6228 - val_auc: 0.9023 - val_accuracy: 0.8660\n",
            "Epoch 75/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.6260 - f1: 0.8034 - auc: 0.9841 - accuracy: 0.9346 - val_loss: 0.6619 - val_f1: 0.6186 - val_auc: 0.9019 - val_accuracy: 0.8660\n",
            "Epoch 76/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.6252 - f1: 0.7931 - auc: 0.9837 - accuracy: 0.9289 - val_loss: 0.6533 - val_f1: 0.6254 - val_auc: 0.9009 - val_accuracy: 0.8721\n",
            "Epoch 77/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.6318 - f1: 0.7959 - auc: 0.9826 - accuracy: 0.9313 - val_loss: 0.6640 - val_f1: 0.6223 - val_auc: 0.9027 - val_accuracy: 0.8654\n",
            "Epoch 78/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.6138 - f1: 0.7925 - auc: 0.9850 - accuracy: 0.9316 - val_loss: 0.6502 - val_f1: 0.6248 - val_auc: 0.9014 - val_accuracy: 0.8704\n",
            "Epoch 79/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 0.6294 - f1: 0.7899 - auc: 0.9814 - accuracy: 0.9302 - val_loss: 0.6594 - val_f1: 0.6194 - val_auc: 0.9031 - val_accuracy: 0.8643\n",
            "Epoch 80/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 0.6129 - f1: 0.7926 - auc: 0.9842 - accuracy: 0.9305 - val_loss: 0.6561 - val_f1: 0.6216 - val_auc: 0.9029 - val_accuracy: 0.8648\n",
            "Epoch 81/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.6186 - f1: 0.7880 - auc: 0.9830 - accuracy: 0.9274 - val_loss: 0.6628 - val_f1: 0.6204 - val_auc: 0.9032 - val_accuracy: 0.8626\n",
            "Epoch 82/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.6049 - f1: 0.7949 - auc: 0.9847 - accuracy: 0.9289 - val_loss: 0.6415 - val_f1: 0.6131 - val_auc: 0.9005 - val_accuracy: 0.8676\n",
            "Epoch 83/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 0.6035 - f1: 0.7884 - auc: 0.9843 - accuracy: 0.9307 - val_loss: 0.6485 - val_f1: 0.6180 - val_auc: 0.9028 - val_accuracy: 0.8643\n",
            "Epoch 84/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.5971 - f1: 0.7901 - auc: 0.9853 - accuracy: 0.9338 - val_loss: 0.6518 - val_f1: 0.6211 - val_auc: 0.9035 - val_accuracy: 0.8637\n",
            "Epoch 85/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 0.6013 - f1: 0.7993 - auc: 0.9840 - accuracy: 0.9321 - val_loss: 0.6554 - val_f1: 0.6187 - val_auc: 0.9037 - val_accuracy: 0.8610\n",
            "Epoch 86/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.5822 - f1: 0.8116 - auc: 0.9862 - accuracy: 0.9366 - val_loss: 0.6311 - val_f1: 0.6211 - val_auc: 0.9001 - val_accuracy: 0.8704\n",
            "Epoch 87/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 0.5937 - f1: 0.7882 - auc: 0.9845 - accuracy: 0.9302 - val_loss: 0.6415 - val_f1: 0.6153 - val_auc: 0.9030 - val_accuracy: 0.8632\n",
            "Epoch 88/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.5921 - f1: 0.7978 - auc: 0.9840 - accuracy: 0.9337 - val_loss: 0.6478 - val_f1: 0.6175 - val_auc: 0.9031 - val_accuracy: 0.8621\n",
            "Epoch 89/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.5811 - f1: 0.8079 - auc: 0.9850 - accuracy: 0.9348 - val_loss: 0.6366 - val_f1: 0.6125 - val_auc: 0.9014 - val_accuracy: 0.8643\n",
            "Epoch 90/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.5849 - f1: 0.7966 - auc: 0.9845 - accuracy: 0.9299 - val_loss: 0.6281 - val_f1: 0.6152 - val_auc: 0.9012 - val_accuracy: 0.8676\n",
            "Epoch 91/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.5781 - f1: 0.7930 - auc: 0.9851 - accuracy: 0.9335 - val_loss: 0.6429 - val_f1: 0.6130 - val_auc: 0.9034 - val_accuracy: 0.8604\n",
            "Epoch 92/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.5749 - f1: 0.8026 - auc: 0.9854 - accuracy: 0.9350 - val_loss: 0.6376 - val_f1: 0.6149 - val_auc: 0.9023 - val_accuracy: 0.8621\n",
            "Epoch 93/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.5667 - f1: 0.8067 - auc: 0.9864 - accuracy: 0.9345 - val_loss: 0.6294 - val_f1: 0.6151 - val_auc: 0.9014 - val_accuracy: 0.8637\n",
            "Epoch 94/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 0.5743 - f1: 0.7967 - auc: 0.9847 - accuracy: 0.9332 - val_loss: 0.6253 - val_f1: 0.6148 - val_auc: 0.9012 - val_accuracy: 0.8648\n",
            "Epoch 95/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 0.5722 - f1: 0.8058 - auc: 0.9847 - accuracy: 0.9334 - val_loss: 0.6327 - val_f1: 0.6158 - val_auc: 0.9017 - val_accuracy: 0.8615\n",
            "Epoch 96/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.5667 - f1: 0.7992 - auc: 0.9854 - accuracy: 0.9355 - val_loss: 0.6340 - val_f1: 0.6239 - val_auc: 0.9022 - val_accuracy: 0.8637\n",
            "Epoch 97/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.5567 - f1: 0.8066 - auc: 0.9864 - accuracy: 0.9350 - val_loss: 0.6149 - val_f1: 0.6150 - val_auc: 0.8996 - val_accuracy: 0.8676\n",
            "Epoch 98/100\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 0.5642 - f1: 0.8028 - auc: 0.9853 - accuracy: 0.9321 - val_loss: 0.6235 - val_f1: 0.6191 - val_auc: 0.9010 - val_accuracy: 0.8654\n",
            "Epoch 99/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.5518 - f1: 0.8151 - auc: 0.9864 - accuracy: 0.9373 - val_loss: 0.6251 - val_f1: 0.6187 - val_auc: 0.9015 - val_accuracy: 0.8637\n",
            "Epoch 100/100\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.5578 - f1: 0.8049 - auc: 0.9855 - accuracy: 0.9353 - val_loss: 0.6315 - val_f1: 0.6207 - val_auc: 0.9021 - val_accuracy: 0.8615\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa5621b7cd0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##Raw training with weights data model##\n",
        "from keras.layers import Dropout,Dense,LeakyReLU,PReLU,InputLayer, Activation\n",
        "from keras.regularizers import l1,l2,l1_l2\n",
        "from tensorflow.keras.optimizers import Adagrad, Adam, Adamax, Nadam, RMSprop, Adadelta\n",
        "from keras.models import Sequential\n",
        "\n",
        "#parameters\n",
        "dropout_rate = .5\n",
        "activation_function = 'elu'\n",
        "num_layers = 1\n",
        "num_neurons = 2000\n",
        "alpha_value = .038\n",
        "regularization_type = 'l2'\n",
        "regularization_factor = 1e-3\n",
        "optomizer = 'adam'\n",
        "learning_rate = 5e-6\n",
        "epochs = 100\n",
        "\n",
        "num_columns = 25008\n",
        "model2= Sequential()\n",
        "model2.add(InputLayer(input_shape = (num_columns)))\n",
        "model2 = create_layers(model2,dropout_rate,activation_function,num_layers,\n",
        "    num_neurons,\n",
        "    regularization_wrapper(regularization_type,regularization_factor),\n",
        "    alpha_value)\n",
        "model2 = choose_optimizer(model2,optomizer,learning_rate)\n",
        "model2.add(Dropout(dropout_rate))\n",
        "model2.add(Dense(1,activation='sigmoid'))\n",
        "print(model2.summary())\n",
        "model2.fit(x_train,y_train,epochs = epochs,\n",
        "          validation_data=(x_val,y_val),\n",
        "          class_weight = class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TFrp5jvkxxT3",
        "outputId": "bd6f4fbd-c25f-48fa-fb4c-18df9ee95e50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation scores\n",
            "F1 score 0.6406015037593984\n",
            "Accuracy score 0.8670745272525028\n",
            "AUC score 0.7573717178393318\n",
            "Test scores\n",
            "F1 score 0.7911001236093942\n",
            "Accuracy score 0.9247886070315977\n",
            "Precision score 0.9090909090909091\n",
            "Recall score 0.700218818380744\n",
            "AUC score 0.8411708617043385\n"
          ]
        }
      ],
      "source": [
        "eval_model(x_val,y_val,x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Kmc99tZ81QXg",
        "outputId": "326e3823-f3ce-43df-c05c-3158a531f626"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imblearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (from imblearn) (0.8.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install imblearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C-tXA6mykX95"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "ros = RandomOverSampler()\n",
        "x_over, y_over = ros.fit_resample(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "J6rI6iPxi4Oj",
        "outputId": "fb7a4c24-6e4f-4680-b6da-6b1344bd8d3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout_6 (Dropout)         (None, 25008)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 2000)              50018000  \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 2000)              0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 2000)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 2001      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,020,001\n",
            "Trainable params: 50,020,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "380/380 [==============================] - 6s 14ms/step - loss: 0.7439 - f1: 0.4348 - auc: 0.5401 - accuracy: 0.4576 - val_loss: 0.7346 - val_f1: 0.1762 - val_auc: 0.3973 - val_accuracy: 0.4794\n",
            "Epoch 2/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7447 - f1: 0.4336 - auc: 0.4396 - accuracy: 0.4561 - val_loss: 0.7347 - val_f1: 0.1762 - val_auc: 0.3989 - val_accuracy: 0.4794\n",
            "Epoch 3/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7439 - f1: 0.4332 - auc: 0.4433 - accuracy: 0.4569 - val_loss: 0.7347 - val_f1: 0.1760 - val_auc: 0.4001 - val_accuracy: 0.4783\n",
            "Epoch 4/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7435 - f1: 0.4423 - auc: 0.4486 - accuracy: 0.4625 - val_loss: 0.7348 - val_f1: 0.1756 - val_auc: 0.4029 - val_accuracy: 0.4766\n",
            "Epoch 5/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7430 - f1: 0.4375 - auc: 0.4507 - accuracy: 0.4604 - val_loss: 0.7348 - val_f1: 0.1767 - val_auc: 0.4043 - val_accuracy: 0.4761\n",
            "Epoch 6/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7443 - f1: 0.4380 - auc: 0.4400 - accuracy: 0.4580 - val_loss: 0.7349 - val_f1: 0.1781 - val_auc: 0.4045 - val_accuracy: 0.4755\n",
            "Epoch 7/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7433 - f1: 0.4446 - auc: 0.4489 - accuracy: 0.4628 - val_loss: 0.7349 - val_f1: 0.1781 - val_auc: 0.4054 - val_accuracy: 0.4755\n",
            "Epoch 8/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7414 - f1: 0.4462 - auc: 0.4543 - accuracy: 0.4662 - val_loss: 0.7350 - val_f1: 0.1807 - val_auc: 0.4060 - val_accuracy: 0.4766\n",
            "Epoch 9/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7437 - f1: 0.4408 - auc: 0.4459 - accuracy: 0.4645 - val_loss: 0.7350 - val_f1: 0.1831 - val_auc: 0.4066 - val_accuracy: 0.4761\n",
            "Epoch 10/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7421 - f1: 0.4490 - auc: 0.4568 - accuracy: 0.4711 - val_loss: 0.7350 - val_f1: 0.1860 - val_auc: 0.4079 - val_accuracy: 0.4766\n",
            "Epoch 11/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7430 - f1: 0.4412 - auc: 0.4476 - accuracy: 0.4635 - val_loss: 0.7351 - val_f1: 0.1910 - val_auc: 0.4082 - val_accuracy: 0.4772\n",
            "Epoch 12/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7424 - f1: 0.4483 - auc: 0.4541 - accuracy: 0.4665 - val_loss: 0.7351 - val_f1: 0.1924 - val_auc: 0.4092 - val_accuracy: 0.4778\n",
            "Epoch 13/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7422 - f1: 0.4461 - auc: 0.4542 - accuracy: 0.4648 - val_loss: 0.7352 - val_f1: 0.1924 - val_auc: 0.4098 - val_accuracy: 0.4778\n",
            "Epoch 14/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7420 - f1: 0.4502 - auc: 0.4559 - accuracy: 0.4665 - val_loss: 0.7352 - val_f1: 0.1934 - val_auc: 0.4110 - val_accuracy: 0.4766\n",
            "Epoch 15/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7427 - f1: 0.4419 - auc: 0.4490 - accuracy: 0.4592 - val_loss: 0.7353 - val_f1: 0.1942 - val_auc: 0.4121 - val_accuracy: 0.4755\n",
            "Epoch 16/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7422 - f1: 0.4481 - auc: 0.4539 - accuracy: 0.4646 - val_loss: 0.7353 - val_f1: 0.1942 - val_auc: 0.4130 - val_accuracy: 0.4755\n",
            "Epoch 17/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7428 - f1: 0.4527 - auc: 0.4514 - accuracy: 0.4666 - val_loss: 0.7353 - val_f1: 0.1936 - val_auc: 0.4144 - val_accuracy: 0.4739\n",
            "Epoch 18/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7419 - f1: 0.4506 - auc: 0.4557 - accuracy: 0.4667 - val_loss: 0.7354 - val_f1: 0.1935 - val_auc: 0.4156 - val_accuracy: 0.4733\n",
            "Epoch 19/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7437 - f1: 0.4476 - auc: 0.4462 - accuracy: 0.4636 - val_loss: 0.7354 - val_f1: 0.1934 - val_auc: 0.4166 - val_accuracy: 0.4727\n",
            "Epoch 20/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7411 - f1: 0.4524 - auc: 0.4579 - accuracy: 0.4672 - val_loss: 0.7354 - val_f1: 0.1932 - val_auc: 0.4174 - val_accuracy: 0.4722\n",
            "Epoch 21/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7415 - f1: 0.4575 - auc: 0.4567 - accuracy: 0.4695 - val_loss: 0.7355 - val_f1: 0.1930 - val_auc: 0.4185 - val_accuracy: 0.4716\n",
            "Epoch 22/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7431 - f1: 0.4440 - auc: 0.4480 - accuracy: 0.4617 - val_loss: 0.7355 - val_f1: 0.1940 - val_auc: 0.4202 - val_accuracy: 0.4716\n",
            "Epoch 23/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7424 - f1: 0.4505 - auc: 0.4525 - accuracy: 0.4670 - val_loss: 0.7356 - val_f1: 0.1948 - val_auc: 0.4216 - val_accuracy: 0.4705\n",
            "Epoch 24/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7413 - f1: 0.4551 - auc: 0.4587 - accuracy: 0.4654 - val_loss: 0.7356 - val_f1: 0.1941 - val_auc: 0.4211 - val_accuracy: 0.4689\n",
            "Epoch 25/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7406 - f1: 0.4622 - auc: 0.4625 - accuracy: 0.4709 - val_loss: 0.7356 - val_f1: 0.1953 - val_auc: 0.4221 - val_accuracy: 0.4689\n",
            "Epoch 26/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7417 - f1: 0.4473 - auc: 0.4545 - accuracy: 0.4633 - val_loss: 0.7357 - val_f1: 0.1965 - val_auc: 0.4231 - val_accuracy: 0.4689\n",
            "Epoch 27/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7411 - f1: 0.4582 - auc: 0.4595 - accuracy: 0.4711 - val_loss: 0.7357 - val_f1: 0.1964 - val_auc: 0.4235 - val_accuracy: 0.4677\n",
            "Epoch 28/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7409 - f1: 0.4576 - auc: 0.4609 - accuracy: 0.4678 - val_loss: 0.7357 - val_f1: 0.1962 - val_auc: 0.4237 - val_accuracy: 0.4672\n",
            "Epoch 29/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7401 - f1: 0.4686 - auc: 0.4681 - accuracy: 0.4779 - val_loss: 0.7358 - val_f1: 0.1962 - val_auc: 0.4249 - val_accuracy: 0.4672\n",
            "Epoch 30/100\n",
            "380/380 [==============================] - 5s 13ms/step - loss: 0.7398 - f1: 0.4600 - auc: 0.4675 - accuracy: 0.4734 - val_loss: 0.7358 - val_f1: 0.1957 - val_auc: 0.4272 - val_accuracy: 0.4661\n",
            "Epoch 31/100\n",
            "380/380 [==============================] - 5s 13ms/step - loss: 0.7411 - f1: 0.4620 - auc: 0.4626 - accuracy: 0.4722 - val_loss: 0.7358 - val_f1: 0.1971 - val_auc: 0.4280 - val_accuracy: 0.4666\n",
            "Epoch 32/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7407 - f1: 0.4627 - auc: 0.4628 - accuracy: 0.4704 - val_loss: 0.7359 - val_f1: 0.1995 - val_auc: 0.4298 - val_accuracy: 0.4677\n",
            "Epoch 33/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7407 - f1: 0.4594 - auc: 0.4631 - accuracy: 0.4732 - val_loss: 0.7359 - val_f1: 0.1991 - val_auc: 0.4300 - val_accuracy: 0.4666\n",
            "Epoch 34/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7410 - f1: 0.4599 - auc: 0.4605 - accuracy: 0.4701 - val_loss: 0.7359 - val_f1: 0.1989 - val_auc: 0.4303 - val_accuracy: 0.4650\n",
            "Epoch 35/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7416 - f1: 0.4605 - auc: 0.4576 - accuracy: 0.4684 - val_loss: 0.7360 - val_f1: 0.2006 - val_auc: 0.4317 - val_accuracy: 0.4655\n",
            "Epoch 36/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7407 - f1: 0.4596 - auc: 0.4638 - accuracy: 0.4707 - val_loss: 0.7360 - val_f1: 0.2006 - val_auc: 0.4329 - val_accuracy: 0.4650\n",
            "Epoch 37/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7405 - f1: 0.4683 - auc: 0.4656 - accuracy: 0.4760 - val_loss: 0.7360 - val_f1: 0.2019 - val_auc: 0.4334 - val_accuracy: 0.4650\n",
            "Epoch 38/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7407 - f1: 0.4613 - auc: 0.4632 - accuracy: 0.4695 - val_loss: 0.7360 - val_f1: 0.2018 - val_auc: 0.4341 - val_accuracy: 0.4644\n",
            "Epoch 39/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7404 - f1: 0.4632 - auc: 0.4637 - accuracy: 0.4737 - val_loss: 0.7361 - val_f1: 0.2033 - val_auc: 0.4350 - val_accuracy: 0.4644\n",
            "Epoch 40/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7391 - f1: 0.4743 - auc: 0.4727 - accuracy: 0.4811 - val_loss: 0.7361 - val_f1: 0.2032 - val_auc: 0.4369 - val_accuracy: 0.4622\n",
            "Epoch 41/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7408 - f1: 0.4624 - auc: 0.4628 - accuracy: 0.4694 - val_loss: 0.7361 - val_f1: 0.2029 - val_auc: 0.4369 - val_accuracy: 0.4611\n",
            "Epoch 42/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7403 - f1: 0.4686 - auc: 0.4651 - accuracy: 0.4753 - val_loss: 0.7362 - val_f1: 0.2024 - val_auc: 0.4378 - val_accuracy: 0.4605\n",
            "Epoch 43/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7393 - f1: 0.4732 - auc: 0.4696 - accuracy: 0.4793 - val_loss: 0.7362 - val_f1: 0.2036 - val_auc: 0.4396 - val_accuracy: 0.4611\n",
            "Epoch 44/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7401 - f1: 0.4689 - auc: 0.4670 - accuracy: 0.4744 - val_loss: 0.7362 - val_f1: 0.2049 - val_auc: 0.4405 - val_accuracy: 0.4605\n",
            "Epoch 45/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7408 - f1: 0.4656 - auc: 0.4623 - accuracy: 0.4732 - val_loss: 0.7362 - val_f1: 0.2045 - val_auc: 0.4419 - val_accuracy: 0.4594\n",
            "Epoch 46/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7397 - f1: 0.4628 - auc: 0.4629 - accuracy: 0.4665 - val_loss: 0.7363 - val_f1: 0.2056 - val_auc: 0.4433 - val_accuracy: 0.4594\n",
            "Epoch 47/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7394 - f1: 0.4746 - auc: 0.4715 - accuracy: 0.4784 - val_loss: 0.7363 - val_f1: 0.2054 - val_auc: 0.4449 - val_accuracy: 0.4588\n",
            "Epoch 48/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7396 - f1: 0.4694 - auc: 0.4708 - accuracy: 0.4751 - val_loss: 0.7363 - val_f1: 0.2051 - val_auc: 0.4454 - val_accuracy: 0.4577\n",
            "Epoch 49/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7395 - f1: 0.4720 - auc: 0.4685 - accuracy: 0.4767 - val_loss: 0.7363 - val_f1: 0.2045 - val_auc: 0.4456 - val_accuracy: 0.4555\n",
            "Epoch 50/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7387 - f1: 0.4781 - auc: 0.4769 - accuracy: 0.4807 - val_loss: 0.7364 - val_f1: 0.2045 - val_auc: 0.4466 - val_accuracy: 0.4555\n",
            "Epoch 51/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7403 - f1: 0.4710 - auc: 0.4666 - accuracy: 0.4753 - val_loss: 0.7364 - val_f1: 0.2061 - val_auc: 0.4473 - val_accuracy: 0.4561\n",
            "Epoch 52/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7396 - f1: 0.4755 - auc: 0.4689 - accuracy: 0.4764 - val_loss: 0.7364 - val_f1: 0.2055 - val_auc: 0.4480 - val_accuracy: 0.4544\n",
            "Epoch 53/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7393 - f1: 0.4760 - auc: 0.4710 - accuracy: 0.4765 - val_loss: 0.7364 - val_f1: 0.2071 - val_auc: 0.4492 - val_accuracy: 0.4538\n",
            "Epoch 54/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7384 - f1: 0.4821 - auc: 0.4749 - accuracy: 0.4803 - val_loss: 0.7365 - val_f1: 0.2070 - val_auc: 0.4492 - val_accuracy: 0.4533\n",
            "Epoch 55/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7391 - f1: 0.4768 - auc: 0.4711 - accuracy: 0.4782 - val_loss: 0.7365 - val_f1: 0.2080 - val_auc: 0.4498 - val_accuracy: 0.4533\n",
            "Epoch 56/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7386 - f1: 0.4859 - auc: 0.4749 - accuracy: 0.4822 - val_loss: 0.7365 - val_f1: 0.2079 - val_auc: 0.4502 - val_accuracy: 0.4522\n",
            "Epoch 57/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7392 - f1: 0.4765 - auc: 0.4697 - accuracy: 0.4747 - val_loss: 0.7365 - val_f1: 0.2088 - val_auc: 0.4506 - val_accuracy: 0.4516\n",
            "Epoch 58/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7385 - f1: 0.4782 - auc: 0.4745 - accuracy: 0.4769 - val_loss: 0.7366 - val_f1: 0.2099 - val_auc: 0.4505 - val_accuracy: 0.4527\n",
            "Epoch 59/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7376 - f1: 0.4851 - auc: 0.4802 - accuracy: 0.4807 - val_loss: 0.7366 - val_f1: 0.2097 - val_auc: 0.4515 - val_accuracy: 0.4516\n",
            "Epoch 60/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7394 - f1: 0.4774 - auc: 0.4698 - accuracy: 0.4765 - val_loss: 0.7366 - val_f1: 0.2097 - val_auc: 0.4520 - val_accuracy: 0.4516\n",
            "Epoch 61/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7374 - f1: 0.4794 - auc: 0.4829 - accuracy: 0.4845 - val_loss: 0.7366 - val_f1: 0.2103 - val_auc: 0.4529 - val_accuracy: 0.4511\n",
            "Epoch 62/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7381 - f1: 0.4806 - auc: 0.4761 - accuracy: 0.4803 - val_loss: 0.7366 - val_f1: 0.2099 - val_auc: 0.4539 - val_accuracy: 0.4494\n",
            "Epoch 63/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7399 - f1: 0.4760 - auc: 0.4694 - accuracy: 0.4765 - val_loss: 0.7367 - val_f1: 0.2109 - val_auc: 0.4538 - val_accuracy: 0.4488\n",
            "Epoch 64/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7373 - f1: 0.4905 - auc: 0.4845 - accuracy: 0.4881 - val_loss: 0.7367 - val_f1: 0.2107 - val_auc: 0.4546 - val_accuracy: 0.4477\n",
            "Epoch 65/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7375 - f1: 0.4860 - auc: 0.4814 - accuracy: 0.4853 - val_loss: 0.7367 - val_f1: 0.2107 - val_auc: 0.4549 - val_accuracy: 0.4477\n",
            "Epoch 66/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7376 - f1: 0.4852 - auc: 0.4811 - accuracy: 0.4856 - val_loss: 0.7367 - val_f1: 0.2116 - val_auc: 0.4560 - val_accuracy: 0.4483\n",
            "Epoch 67/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7377 - f1: 0.4820 - auc: 0.4804 - accuracy: 0.4822 - val_loss: 0.7368 - val_f1: 0.2114 - val_auc: 0.4568 - val_accuracy: 0.4477\n",
            "Epoch 68/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7383 - f1: 0.4776 - auc: 0.4741 - accuracy: 0.4767 - val_loss: 0.7368 - val_f1: 0.2108 - val_auc: 0.4573 - val_accuracy: 0.4455\n",
            "Epoch 69/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7364 - f1: 0.4949 - auc: 0.4900 - accuracy: 0.4903 - val_loss: 0.7368 - val_f1: 0.2103 - val_auc: 0.4581 - val_accuracy: 0.4444\n",
            "Epoch 70/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7368 - f1: 0.4872 - auc: 0.4845 - accuracy: 0.4839 - val_loss: 0.7368 - val_f1: 0.2102 - val_auc: 0.4597 - val_accuracy: 0.4438\n",
            "Epoch 71/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7367 - f1: 0.4876 - auc: 0.4869 - accuracy: 0.4850 - val_loss: 0.7368 - val_f1: 0.2100 - val_auc: 0.4603 - val_accuracy: 0.4433\n",
            "Epoch 72/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7377 - f1: 0.4815 - auc: 0.4792 - accuracy: 0.4799 - val_loss: 0.7369 - val_f1: 0.2113 - val_auc: 0.4609 - val_accuracy: 0.4438\n",
            "Epoch 73/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7368 - f1: 0.4958 - auc: 0.4896 - accuracy: 0.4892 - val_loss: 0.7369 - val_f1: 0.2113 - val_auc: 0.4622 - val_accuracy: 0.4438\n",
            "Epoch 74/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7385 - f1: 0.4841 - auc: 0.4759 - accuracy: 0.4790 - val_loss: 0.7369 - val_f1: 0.2113 - val_auc: 0.4631 - val_accuracy: 0.4438\n",
            "Epoch 75/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7378 - f1: 0.4852 - auc: 0.4785 - accuracy: 0.4808 - val_loss: 0.7369 - val_f1: 0.2124 - val_auc: 0.4636 - val_accuracy: 0.4433\n",
            "Epoch 76/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7361 - f1: 0.4950 - auc: 0.4903 - accuracy: 0.4904 - val_loss: 0.7369 - val_f1: 0.2122 - val_auc: 0.4645 - val_accuracy: 0.4427\n",
            "Epoch 77/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7371 - f1: 0.4896 - auc: 0.4833 - accuracy: 0.4839 - val_loss: 0.7370 - val_f1: 0.2122 - val_auc: 0.4653 - val_accuracy: 0.4427\n",
            "Epoch 78/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7368 - f1: 0.4862 - auc: 0.4825 - accuracy: 0.4841 - val_loss: 0.7370 - val_f1: 0.2119 - val_auc: 0.4659 - val_accuracy: 0.4416\n",
            "Epoch 79/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7374 - f1: 0.4888 - auc: 0.4797 - accuracy: 0.4828 - val_loss: 0.7370 - val_f1: 0.2113 - val_auc: 0.4670 - val_accuracy: 0.4405\n",
            "Epoch 80/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7371 - f1: 0.4854 - auc: 0.4817 - accuracy: 0.4789 - val_loss: 0.7370 - val_f1: 0.2109 - val_auc: 0.4681 - val_accuracy: 0.4394\n",
            "Epoch 81/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7363 - f1: 0.4969 - auc: 0.4902 - accuracy: 0.4898 - val_loss: 0.7370 - val_f1: 0.2120 - val_auc: 0.4682 - val_accuracy: 0.4399\n",
            "Epoch 82/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7375 - f1: 0.4869 - auc: 0.4812 - accuracy: 0.4792 - val_loss: 0.7371 - val_f1: 0.2120 - val_auc: 0.4686 - val_accuracy: 0.4399\n",
            "Epoch 83/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7365 - f1: 0.4947 - auc: 0.4881 - accuracy: 0.4893 - val_loss: 0.7371 - val_f1: 0.2120 - val_auc: 0.4692 - val_accuracy: 0.4399\n",
            "Epoch 84/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7379 - f1: 0.4885 - auc: 0.4809 - accuracy: 0.4822 - val_loss: 0.7371 - val_f1: 0.2120 - val_auc: 0.4702 - val_accuracy: 0.4399\n",
            "Epoch 85/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7370 - f1: 0.4923 - auc: 0.4851 - accuracy: 0.4821 - val_loss: 0.7371 - val_f1: 0.2120 - val_auc: 0.4717 - val_accuracy: 0.4399\n",
            "Epoch 86/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7363 - f1: 0.5013 - auc: 0.4903 - accuracy: 0.4927 - val_loss: 0.7371 - val_f1: 0.2120 - val_auc: 0.4722 - val_accuracy: 0.4394\n",
            "Epoch 87/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7366 - f1: 0.4964 - auc: 0.4885 - accuracy: 0.4905 - val_loss: 0.7371 - val_f1: 0.2119 - val_auc: 0.4731 - val_accuracy: 0.4383\n",
            "Epoch 88/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7370 - f1: 0.4909 - auc: 0.4834 - accuracy: 0.4856 - val_loss: 0.7372 - val_f1: 0.2133 - val_auc: 0.4731 - val_accuracy: 0.4383\n",
            "Epoch 89/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7357 - f1: 0.4964 - auc: 0.4931 - accuracy: 0.4865 - val_loss: 0.7372 - val_f1: 0.2132 - val_auc: 0.4738 - val_accuracy: 0.4377\n",
            "Epoch 90/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7354 - f1: 0.4994 - auc: 0.4935 - accuracy: 0.4912 - val_loss: 0.7372 - val_f1: 0.2148 - val_auc: 0.4741 - val_accuracy: 0.4372\n",
            "Epoch 91/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7361 - f1: 0.4871 - auc: 0.4887 - accuracy: 0.4828 - val_loss: 0.7372 - val_f1: 0.2158 - val_auc: 0.4738 - val_accuracy: 0.4372\n",
            "Epoch 92/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7356 - f1: 0.4966 - auc: 0.4925 - accuracy: 0.4890 - val_loss: 0.7372 - val_f1: 0.2152 - val_auc: 0.4743 - val_accuracy: 0.4355\n",
            "Epoch 93/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7359 - f1: 0.4994 - auc: 0.4924 - accuracy: 0.4891 - val_loss: 0.7373 - val_f1: 0.2162 - val_auc: 0.4756 - val_accuracy: 0.4360\n",
            "Epoch 94/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7363 - f1: 0.4921 - auc: 0.4878 - accuracy: 0.4860 - val_loss: 0.7373 - val_f1: 0.2162 - val_auc: 0.4757 - val_accuracy: 0.4360\n",
            "Epoch 95/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7355 - f1: 0.4976 - auc: 0.4919 - accuracy: 0.4881 - val_loss: 0.7373 - val_f1: 0.2162 - val_auc: 0.4765 - val_accuracy: 0.4360\n",
            "Epoch 96/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7367 - f1: 0.4941 - auc: 0.4873 - accuracy: 0.4870 - val_loss: 0.7373 - val_f1: 0.2175 - val_auc: 0.4773 - val_accuracy: 0.4360\n",
            "Epoch 97/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7354 - f1: 0.5009 - auc: 0.4945 - accuracy: 0.4934 - val_loss: 0.7373 - val_f1: 0.2175 - val_auc: 0.4789 - val_accuracy: 0.4349\n",
            "Epoch 98/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7353 - f1: 0.5007 - auc: 0.4945 - accuracy: 0.4915 - val_loss: 0.7373 - val_f1: 0.2171 - val_auc: 0.4803 - val_accuracy: 0.4338\n",
            "Epoch 99/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7350 - f1: 0.5023 - auc: 0.4949 - accuracy: 0.4909 - val_loss: 0.7374 - val_f1: 0.2173 - val_auc: 0.4809 - val_accuracy: 0.4344\n",
            "Epoch 100/100\n",
            "380/380 [==============================] - 5s 12ms/step - loss: 0.7363 - f1: 0.4978 - auc: 0.4874 - accuracy: 0.4871 - val_loss: 0.7374 - val_f1: 0.2185 - val_auc: 0.4813 - val_accuracy: 0.4355\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa5621cccd0>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##Over sampled training data model##\n",
        "\n",
        "from keras.layers import Dropout,Dense,LeakyReLU,PReLU,InputLayer, Activation\n",
        "from keras.regularizers import l1,l2,l1_l2\n",
        "from tensorflow.keras.optimizers import Adagrad, Adam, Adamax, Nadam, RMSprop, Adadelta\n",
        "from keras.models import Sequential\n",
        "\n",
        "#parameters\n",
        "dropout_rate = .4\n",
        "activation_function = 'swish'\n",
        "num_layers = 1\n",
        "num_neurons = 2000\n",
        "alpha_value = .038\n",
        "regularization_type = 'l1_l2'\n",
        "regularization_factor = 1e-7\n",
        "optomizer = 'adagrad'\n",
        "learning_rate = 1e-7\n",
        "epochs = 100\n",
        "\n",
        "num_columns = 25008\n",
        "model3= Sequential()\n",
        "model3.add(InputLayer(input_shape = (num_columns)))\n",
        "model3 = create_layers(model3,dropout_rate,activation_function,num_layers,\n",
        "    num_neurons,\n",
        "    regularization_wrapper(regularization_type,regularization_factor),\n",
        "    alpha_value)\n",
        "model3 = choose_optimizer(model3,optomizer,learning_rate)\n",
        "model3.add(Dropout(dropout_rate))\n",
        "model3.add(Dense(1,activation='sigmoid'))\n",
        "print(model3.summary())\n",
        "model3.fit(x_over,y_over,epochs = epochs,\n",
        "          validation_data=(x_val,y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fIjofgRx1laj",
        "outputId": "22ef658f-1f4e-4707-ef78-d00742dd1bac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation scores\n",
            "F1 score 0.30363036303630364\n",
            "Accuracy score 0.5305895439377085\n",
            "AUC score 0.5388880016144268\n",
            "Test scores\n",
            "F1 score 0.2726679712981083\n",
            "Accuracy score 0.5037828215398309\n",
            "Precision score 0.59375\n",
            "Recall score 0.17696867061812024\n",
            "AUC score 0.5214111645773528\n"
          ]
        }
      ],
      "source": [
        "eval_model(x_val,y_val,x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dp4Kt-ctgrJl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U6ay9fUpkquq"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "rus = RandomUnderSampler()\n",
        "x_under,y_under = rus.fit_resample(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d-bmUTmLi9Fd",
        "outputId": "7fd1a794-f00b-40ff-e8e5-60a4907f8cab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout_8 (Dropout)         (None, 25008)             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 2500)              62522500  \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 2500)              0         \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 2500)              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 2501      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,525,001\n",
            "Trainable params: 62,525,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "70/70 [==============================] - 3s 24ms/step - loss: 0.5431 - f1: 0.7796 - auc: 0.8020 - accuracy: 0.7543 - val_loss: 0.4907 - val_f1: 0.5451 - val_auc: 0.8842 - val_accuracy: 0.7881\n",
            "Epoch 2/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.4372 - f1: 0.8287 - auc: 0.8991 - accuracy: 0.8245 - val_loss: 0.4606 - val_f1: 0.5530 - val_auc: 0.8891 - val_accuracy: 0.7925\n",
            "Epoch 3/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.4045 - f1: 0.8377 - auc: 0.9075 - accuracy: 0.8384 - val_loss: 0.4179 - val_f1: 0.5606 - val_auc: 0.8926 - val_accuracy: 0.8109\n",
            "Epoch 4/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.3875 - f1: 0.8433 - auc: 0.9135 - accuracy: 0.8420 - val_loss: 0.4274 - val_f1: 0.5673 - val_auc: 0.8953 - val_accuracy: 0.8076\n",
            "Epoch 5/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.3752 - f1: 0.8390 - auc: 0.9175 - accuracy: 0.8411 - val_loss: 0.4703 - val_f1: 0.5529 - val_auc: 0.8970 - val_accuracy: 0.7875\n",
            "Epoch 6/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.3661 - f1: 0.8478 - auc: 0.9213 - accuracy: 0.8483 - val_loss: 0.4024 - val_f1: 0.5667 - val_auc: 0.8993 - val_accuracy: 0.8159\n",
            "Epoch 7/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.3573 - f1: 0.8510 - auc: 0.9254 - accuracy: 0.8518 - val_loss: 0.4389 - val_f1: 0.5603 - val_auc: 0.9007 - val_accuracy: 0.7987\n",
            "Epoch 8/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.3501 - f1: 0.8513 - auc: 0.9277 - accuracy: 0.8532 - val_loss: 0.4000 - val_f1: 0.5698 - val_auc: 0.9023 - val_accuracy: 0.8154\n",
            "Epoch 9/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.3475 - f1: 0.8521 - auc: 0.9289 - accuracy: 0.8550 - val_loss: 0.3803 - val_f1: 0.5775 - val_auc: 0.9037 - val_accuracy: 0.8231\n",
            "Epoch 10/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.3406 - f1: 0.8646 - auc: 0.9320 - accuracy: 0.8644 - val_loss: 0.3886 - val_f1: 0.5731 - val_auc: 0.9049 - val_accuracy: 0.8192\n",
            "Epoch 11/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.3331 - f1: 0.8554 - auc: 0.9355 - accuracy: 0.8603 - val_loss: 0.4102 - val_f1: 0.5654 - val_auc: 0.9057 - val_accuracy: 0.8092\n",
            "Epoch 12/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.3273 - f1: 0.8662 - auc: 0.9380 - accuracy: 0.8671 - val_loss: 0.3843 - val_f1: 0.5759 - val_auc: 0.9069 - val_accuracy: 0.8215\n",
            "Epoch 13/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.3234 - f1: 0.8690 - auc: 0.9396 - accuracy: 0.8697 - val_loss: 0.3924 - val_f1: 0.5763 - val_auc: 0.9076 - val_accuracy: 0.8198\n",
            "Epoch 14/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.3183 - f1: 0.8710 - auc: 0.9421 - accuracy: 0.8720 - val_loss: 0.3761 - val_f1: 0.5906 - val_auc: 0.9081 - val_accuracy: 0.8309\n",
            "Epoch 15/100\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.3108 - f1: 0.8779 - auc: 0.9452 - accuracy: 0.8787 - val_loss: 0.3728 - val_f1: 0.5980 - val_auc: 0.9086 - val_accuracy: 0.8359\n",
            "Epoch 16/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.3085 - f1: 0.8696 - auc: 0.9459 - accuracy: 0.8729 - val_loss: 0.4136 - val_f1: 0.5654 - val_auc: 0.9091 - val_accuracy: 0.8087\n",
            "Epoch 17/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.3024 - f1: 0.8818 - auc: 0.9483 - accuracy: 0.8823 - val_loss: 0.4288 - val_f1: 0.5603 - val_auc: 0.9095 - val_accuracy: 0.8031\n",
            "Epoch 18/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2994 - f1: 0.8755 - auc: 0.9499 - accuracy: 0.8787 - val_loss: 0.3745 - val_f1: 0.5937 - val_auc: 0.9101 - val_accuracy: 0.8331\n",
            "Epoch 19/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2930 - f1: 0.8789 - auc: 0.9522 - accuracy: 0.8814 - val_loss: 0.3792 - val_f1: 0.5917 - val_auc: 0.9105 - val_accuracy: 0.8315\n",
            "Epoch 20/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2911 - f1: 0.8812 - auc: 0.9530 - accuracy: 0.8841 - val_loss: 0.4164 - val_f1: 0.5643 - val_auc: 0.9108 - val_accuracy: 0.8081\n",
            "Epoch 21/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2891 - f1: 0.8883 - auc: 0.9535 - accuracy: 0.8899 - val_loss: 0.3905 - val_f1: 0.5834 - val_auc: 0.9109 - val_accuracy: 0.8254\n",
            "Epoch 22/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2787 - f1: 0.8908 - auc: 0.9578 - accuracy: 0.8908 - val_loss: 0.3650 - val_f1: 0.6048 - val_auc: 0.9113 - val_accuracy: 0.8393\n",
            "Epoch 23/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2778 - f1: 0.8938 - auc: 0.9583 - accuracy: 0.8953 - val_loss: 0.3884 - val_f1: 0.5887 - val_auc: 0.9114 - val_accuracy: 0.8281\n",
            "Epoch 24/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2772 - f1: 0.8922 - auc: 0.9576 - accuracy: 0.8939 - val_loss: 0.3991 - val_f1: 0.5816 - val_auc: 0.9114 - val_accuracy: 0.8220\n",
            "Epoch 25/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2729 - f1: 0.8893 - auc: 0.9594 - accuracy: 0.8939 - val_loss: 0.3605 - val_f1: 0.6075 - val_auc: 0.9116 - val_accuracy: 0.8415\n",
            "Epoch 26/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2714 - f1: 0.8897 - auc: 0.9600 - accuracy: 0.8908 - val_loss: 0.3598 - val_f1: 0.6067 - val_auc: 0.9120 - val_accuracy: 0.8409\n",
            "Epoch 27/100\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.2676 - f1: 0.8909 - auc: 0.9618 - accuracy: 0.8930 - val_loss: 0.3783 - val_f1: 0.5951 - val_auc: 0.9120 - val_accuracy: 0.8326\n",
            "Epoch 28/100\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.2641 - f1: 0.8950 - auc: 0.9631 - accuracy: 0.8970 - val_loss: 0.3809 - val_f1: 0.5936 - val_auc: 0.9120 - val_accuracy: 0.8315\n",
            "Epoch 29/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2589 - f1: 0.8957 - auc: 0.9650 - accuracy: 0.8966 - val_loss: 0.4141 - val_f1: 0.5783 - val_auc: 0.9119 - val_accuracy: 0.8176\n",
            "Epoch 30/100\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.2536 - f1: 0.9041 - auc: 0.9661 - accuracy: 0.9051 - val_loss: 0.3786 - val_f1: 0.5953 - val_auc: 0.9120 - val_accuracy: 0.8331\n",
            "Epoch 31/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2546 - f1: 0.9022 - auc: 0.9654 - accuracy: 0.9038 - val_loss: 0.3642 - val_f1: 0.6037 - val_auc: 0.9121 - val_accuracy: 0.8387\n",
            "Epoch 32/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2488 - f1: 0.9064 - auc: 0.9680 - accuracy: 0.9091 - val_loss: 0.4035 - val_f1: 0.5856 - val_auc: 0.9120 - val_accuracy: 0.8231\n",
            "Epoch 33/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2484 - f1: 0.8973 - auc: 0.9681 - accuracy: 0.9020 - val_loss: 0.3913 - val_f1: 0.5942 - val_auc: 0.9118 - val_accuracy: 0.8304\n",
            "Epoch 34/100\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.2486 - f1: 0.9075 - auc: 0.9678 - accuracy: 0.9109 - val_loss: 0.3760 - val_f1: 0.5994 - val_auc: 0.9121 - val_accuracy: 0.8354\n",
            "Epoch 35/100\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.2453 - f1: 0.9048 - auc: 0.9688 - accuracy: 0.9056 - val_loss: 0.4085 - val_f1: 0.5817 - val_auc: 0.9119 - val_accuracy: 0.8198\n",
            "Epoch 36/100\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.2410 - f1: 0.9148 - auc: 0.9702 - accuracy: 0.9154 - val_loss: 0.3912 - val_f1: 0.5938 - val_auc: 0.9119 - val_accuracy: 0.8304\n",
            "Epoch 37/100\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.2376 - f1: 0.9092 - auc: 0.9712 - accuracy: 0.9114 - val_loss: 0.3877 - val_f1: 0.5965 - val_auc: 0.9119 - val_accuracy: 0.8326\n",
            "Epoch 38/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2325 - f1: 0.9096 - auc: 0.9733 - accuracy: 0.9114 - val_loss: 0.4127 - val_f1: 0.5842 - val_auc: 0.9116 - val_accuracy: 0.8198\n",
            "Epoch 39/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2319 - f1: 0.9111 - auc: 0.9733 - accuracy: 0.9127 - val_loss: 0.3806 - val_f1: 0.6008 - val_auc: 0.9117 - val_accuracy: 0.8348\n",
            "Epoch 40/100\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.2297 - f1: 0.9161 - auc: 0.9738 - accuracy: 0.9185 - val_loss: 0.3889 - val_f1: 0.5938 - val_auc: 0.9117 - val_accuracy: 0.8304\n",
            "Epoch 41/100\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.2278 - f1: 0.9157 - auc: 0.9741 - accuracy: 0.9176 - val_loss: 0.4005 - val_f1: 0.5875 - val_auc: 0.9117 - val_accuracy: 0.8254\n",
            "Epoch 42/100\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.2261 - f1: 0.9189 - auc: 0.9749 - accuracy: 0.9190 - val_loss: 0.3760 - val_f1: 0.6058 - val_auc: 0.9115 - val_accuracy: 0.8387\n",
            "Epoch 43/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2264 - f1: 0.9182 - auc: 0.9743 - accuracy: 0.9185 - val_loss: 0.4135 - val_f1: 0.5860 - val_auc: 0.9114 - val_accuracy: 0.8215\n",
            "Epoch 44/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2214 - f1: 0.9189 - auc: 0.9757 - accuracy: 0.9194 - val_loss: 0.3904 - val_f1: 0.5957 - val_auc: 0.9115 - val_accuracy: 0.8315\n",
            "Epoch 45/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2188 - f1: 0.9223 - auc: 0.9767 - accuracy: 0.9230 - val_loss: 0.4051 - val_f1: 0.5896 - val_auc: 0.9113 - val_accuracy: 0.8248\n",
            "Epoch 46/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2158 - f1: 0.9156 - auc: 0.9771 - accuracy: 0.9190 - val_loss: 0.4059 - val_f1: 0.5911 - val_auc: 0.9114 - val_accuracy: 0.8259\n",
            "Epoch 47/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2144 - f1: 0.9210 - auc: 0.9781 - accuracy: 0.9244 - val_loss: 0.3864 - val_f1: 0.5992 - val_auc: 0.9113 - val_accuracy: 0.8343\n",
            "Epoch 48/100\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.2136 - f1: 0.9210 - auc: 0.9777 - accuracy: 0.9221 - val_loss: 0.4132 - val_f1: 0.5861 - val_auc: 0.9113 - val_accuracy: 0.8220\n",
            "Epoch 49/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2143 - f1: 0.9214 - auc: 0.9768 - accuracy: 0.9239 - val_loss: 0.4093 - val_f1: 0.5923 - val_auc: 0.9110 - val_accuracy: 0.8259\n",
            "Epoch 50/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2120 - f1: 0.9211 - auc: 0.9786 - accuracy: 0.9235 - val_loss: 0.3823 - val_f1: 0.5999 - val_auc: 0.9106 - val_accuracy: 0.8359\n",
            "Epoch 51/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2061 - f1: 0.9223 - auc: 0.9801 - accuracy: 0.9257 - val_loss: 0.4087 - val_f1: 0.5946 - val_auc: 0.9108 - val_accuracy: 0.8276\n",
            "Epoch 52/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2027 - f1: 0.9290 - auc: 0.9812 - accuracy: 0.9311 - val_loss: 0.4016 - val_f1: 0.5977 - val_auc: 0.9106 - val_accuracy: 0.8304\n",
            "Epoch 53/100\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.2033 - f1: 0.9227 - auc: 0.9808 - accuracy: 0.9261 - val_loss: 0.4042 - val_f1: 0.5977 - val_auc: 0.9104 - val_accuracy: 0.8298\n",
            "Epoch 54/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.2028 - f1: 0.9257 - auc: 0.9803 - accuracy: 0.9261 - val_loss: 0.4237 - val_f1: 0.5853 - val_auc: 0.9104 - val_accuracy: 0.8204\n",
            "Epoch 55/100\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.1988 - f1: 0.9262 - auc: 0.9820 - accuracy: 0.9293 - val_loss: 0.4109 - val_f1: 0.5947 - val_auc: 0.9104 - val_accuracy: 0.8276\n",
            "Epoch 56/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1997 - f1: 0.9306 - auc: 0.9813 - accuracy: 0.9311 - val_loss: 0.4040 - val_f1: 0.5913 - val_auc: 0.9102 - val_accuracy: 0.8276\n",
            "Epoch 57/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1995 - f1: 0.9304 - auc: 0.9811 - accuracy: 0.9311 - val_loss: 0.3894 - val_f1: 0.6055 - val_auc: 0.9101 - val_accuracy: 0.8387\n",
            "Epoch 58/100\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.1914 - f1: 0.9295 - auc: 0.9839 - accuracy: 0.9302 - val_loss: 0.4157 - val_f1: 0.5906 - val_auc: 0.9099 - val_accuracy: 0.8254\n",
            "Epoch 59/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1923 - f1: 0.9279 - auc: 0.9832 - accuracy: 0.9302 - val_loss: 0.4104 - val_f1: 0.5885 - val_auc: 0.9099 - val_accuracy: 0.8254\n",
            "Epoch 60/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1916 - f1: 0.9311 - auc: 0.9833 - accuracy: 0.9315 - val_loss: 0.4109 - val_f1: 0.5885 - val_auc: 0.9096 - val_accuracy: 0.8254\n",
            "Epoch 61/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1910 - f1: 0.9319 - auc: 0.9831 - accuracy: 0.9329 - val_loss: 0.3852 - val_f1: 0.6088 - val_auc: 0.9097 - val_accuracy: 0.8409\n",
            "Epoch 62/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1867 - f1: 0.9346 - auc: 0.9842 - accuracy: 0.9364 - val_loss: 0.3917 - val_f1: 0.6049 - val_auc: 0.9094 - val_accuracy: 0.8382\n",
            "Epoch 63/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1844 - f1: 0.9341 - auc: 0.9853 - accuracy: 0.9351 - val_loss: 0.4100 - val_f1: 0.5929 - val_auc: 0.9095 - val_accuracy: 0.8287\n",
            "Epoch 64/100\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.1828 - f1: 0.9369 - auc: 0.9853 - accuracy: 0.9391 - val_loss: 0.3911 - val_f1: 0.6067 - val_auc: 0.9091 - val_accuracy: 0.8387\n",
            "Epoch 65/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1791 - f1: 0.9363 - auc: 0.9862 - accuracy: 0.9373 - val_loss: 0.4078 - val_f1: 0.5974 - val_auc: 0.9093 - val_accuracy: 0.8320\n",
            "Epoch 66/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1786 - f1: 0.9358 - auc: 0.9863 - accuracy: 0.9378 - val_loss: 0.4245 - val_f1: 0.5865 - val_auc: 0.9091 - val_accuracy: 0.8231\n",
            "Epoch 67/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1791 - f1: 0.9371 - auc: 0.9862 - accuracy: 0.9396 - val_loss: 0.4323 - val_f1: 0.5857 - val_auc: 0.9090 - val_accuracy: 0.8209\n",
            "Epoch 68/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1820 - f1: 0.9387 - auc: 0.9846 - accuracy: 0.9409 - val_loss: 0.4070 - val_f1: 0.5983 - val_auc: 0.9085 - val_accuracy: 0.8326\n",
            "Epoch 69/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1746 - f1: 0.9422 - auc: 0.9872 - accuracy: 0.9432 - val_loss: 0.4101 - val_f1: 0.5969 - val_auc: 0.9085 - val_accuracy: 0.8315\n",
            "Epoch 70/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1723 - f1: 0.9437 - auc: 0.9876 - accuracy: 0.9440 - val_loss: 0.3901 - val_f1: 0.6090 - val_auc: 0.9085 - val_accuracy: 0.8415\n",
            "Epoch 71/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1750 - f1: 0.9425 - auc: 0.9866 - accuracy: 0.9432 - val_loss: 0.3925 - val_f1: 0.6100 - val_auc: 0.9086 - val_accuracy: 0.8426\n",
            "Epoch 72/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1715 - f1: 0.9415 - auc: 0.9877 - accuracy: 0.9458 - val_loss: 0.4336 - val_f1: 0.5848 - val_auc: 0.9083 - val_accuracy: 0.8220\n",
            "Epoch 73/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1726 - f1: 0.9425 - auc: 0.9873 - accuracy: 0.9427 - val_loss: 0.4201 - val_f1: 0.5931 - val_auc: 0.9081 - val_accuracy: 0.8287\n",
            "Epoch 74/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1694 - f1: 0.9440 - auc: 0.9877 - accuracy: 0.9449 - val_loss: 0.4149 - val_f1: 0.5953 - val_auc: 0.9080 - val_accuracy: 0.8309\n",
            "Epoch 75/100\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.1641 - f1: 0.9458 - auc: 0.9890 - accuracy: 0.9481 - val_loss: 0.4427 - val_f1: 0.5814 - val_auc: 0.9081 - val_accuracy: 0.8192\n",
            "Epoch 76/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1675 - f1: 0.9459 - auc: 0.9879 - accuracy: 0.9463 - val_loss: 0.3923 - val_f1: 0.6087 - val_auc: 0.9078 - val_accuracy: 0.8420\n",
            "Epoch 77/100\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.1652 - f1: 0.9413 - auc: 0.9881 - accuracy: 0.9445 - val_loss: 0.4126 - val_f1: 0.5987 - val_auc: 0.9077 - val_accuracy: 0.8331\n",
            "Epoch 78/100\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.1653 - f1: 0.9419 - auc: 0.9885 - accuracy: 0.9432 - val_loss: 0.4155 - val_f1: 0.5970 - val_auc: 0.9077 - val_accuracy: 0.8320\n",
            "Epoch 79/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1627 - f1: 0.9407 - auc: 0.9888 - accuracy: 0.9423 - val_loss: 0.4301 - val_f1: 0.5894 - val_auc: 0.9077 - val_accuracy: 0.8259\n",
            "Epoch 80/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1628 - f1: 0.9486 - auc: 0.9887 - accuracy: 0.9503 - val_loss: 0.4257 - val_f1: 0.5963 - val_auc: 0.9077 - val_accuracy: 0.8304\n",
            "Epoch 81/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1662 - f1: 0.9437 - auc: 0.9876 - accuracy: 0.9449 - val_loss: 0.4224 - val_f1: 0.5976 - val_auc: 0.9073 - val_accuracy: 0.8315\n",
            "Epoch 82/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1572 - f1: 0.9492 - auc: 0.9902 - accuracy: 0.9512 - val_loss: 0.4167 - val_f1: 0.5975 - val_auc: 0.9069 - val_accuracy: 0.8326\n",
            "Epoch 83/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1570 - f1: 0.9489 - auc: 0.9899 - accuracy: 0.9517 - val_loss: 0.4041 - val_f1: 0.6025 - val_auc: 0.9067 - val_accuracy: 0.8398\n",
            "Epoch 84/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1564 - f1: 0.9504 - auc: 0.9898 - accuracy: 0.9521 - val_loss: 0.4387 - val_f1: 0.5869 - val_auc: 0.9073 - val_accuracy: 0.8242\n",
            "Epoch 85/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1561 - f1: 0.9508 - auc: 0.9904 - accuracy: 0.9517 - val_loss: 0.4257 - val_f1: 0.5973 - val_auc: 0.9068 - val_accuracy: 0.8315\n",
            "Epoch 86/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1508 - f1: 0.9554 - auc: 0.9911 - accuracy: 0.9566 - val_loss: 0.4092 - val_f1: 0.6047 - val_auc: 0.9067 - val_accuracy: 0.8393\n",
            "Epoch 87/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1500 - f1: 0.9531 - auc: 0.9915 - accuracy: 0.9534 - val_loss: 0.4433 - val_f1: 0.5864 - val_auc: 0.9071 - val_accuracy: 0.8237\n",
            "Epoch 88/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1490 - f1: 0.9535 - auc: 0.9915 - accuracy: 0.9552 - val_loss: 0.4065 - val_f1: 0.6029 - val_auc: 0.9062 - val_accuracy: 0.8404\n",
            "Epoch 89/100\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.1507 - f1: 0.9492 - auc: 0.9911 - accuracy: 0.9503 - val_loss: 0.4334 - val_f1: 0.5933 - val_auc: 0.9063 - val_accuracy: 0.8287\n",
            "Epoch 90/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1487 - f1: 0.9558 - auc: 0.9916 - accuracy: 0.9557 - val_loss: 0.4277 - val_f1: 0.5956 - val_auc: 0.9061 - val_accuracy: 0.8304\n",
            "Epoch 91/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1531 - f1: 0.9484 - auc: 0.9903 - accuracy: 0.9503 - val_loss: 0.4321 - val_f1: 0.5943 - val_auc: 0.9062 - val_accuracy: 0.8293\n",
            "Epoch 92/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1492 - f1: 0.9524 - auc: 0.9911 - accuracy: 0.9552 - val_loss: 0.4286 - val_f1: 0.5979 - val_auc: 0.9061 - val_accuracy: 0.8320\n",
            "Epoch 93/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1474 - f1: 0.9561 - auc: 0.9918 - accuracy: 0.9566 - val_loss: 0.4386 - val_f1: 0.5928 - val_auc: 0.9059 - val_accuracy: 0.8281\n",
            "Epoch 94/100\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.1448 - f1: 0.9515 - auc: 0.9919 - accuracy: 0.9530 - val_loss: 0.4387 - val_f1: 0.5928 - val_auc: 0.9057 - val_accuracy: 0.8281\n",
            "Epoch 95/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1441 - f1: 0.9565 - auc: 0.9922 - accuracy: 0.9570 - val_loss: 0.4491 - val_f1: 0.5857 - val_auc: 0.9056 - val_accuracy: 0.8226\n",
            "Epoch 96/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1454 - f1: 0.9526 - auc: 0.9913 - accuracy: 0.9543 - val_loss: 0.4291 - val_f1: 0.5997 - val_auc: 0.9055 - val_accuracy: 0.8337\n",
            "Epoch 97/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1424 - f1: 0.9527 - auc: 0.9924 - accuracy: 0.9534 - val_loss: 0.4354 - val_f1: 0.5932 - val_auc: 0.9052 - val_accuracy: 0.8293\n",
            "Epoch 98/100\n",
            "70/70 [==============================] - 1s 15ms/step - loss: 0.1416 - f1: 0.9553 - auc: 0.9924 - accuracy: 0.9561 - val_loss: 0.4453 - val_f1: 0.5872 - val_auc: 0.9054 - val_accuracy: 0.8248\n",
            "Epoch 99/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1407 - f1: 0.9609 - auc: 0.9925 - accuracy: 0.9611 - val_loss: 0.4223 - val_f1: 0.6045 - val_auc: 0.9052 - val_accuracy: 0.8393\n",
            "Epoch 100/100\n",
            "70/70 [==============================] - 1s 14ms/step - loss: 0.1382 - f1: 0.9584 - auc: 0.9932 - accuracy: 0.9588 - val_loss: 0.4367 - val_f1: 0.5965 - val_auc: 0.9053 - val_accuracy: 0.8315\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa5d065af10>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##Under sampled training data model##\n",
        "\n",
        "from keras.layers import Dropout,Dense,LeakyReLU,PReLU,InputLayer, Activation\n",
        "from keras.regularizers import l1,l2,l1_l2\n",
        "from tensorflow.keras.optimizers import Adagrad, Adam, Adamax, Nadam, RMSprop, Adadelta\n",
        "from keras.models import Sequential\n",
        "\n",
        "#parameters\n",
        "dropout_rate = .1\n",
        "activation_function = 'elu'\n",
        "num_layers = 1\n",
        "num_neurons = 2500\n",
        "alpha_value = .038\n",
        "regularization_type = 'l2'\n",
        "regularization_factor = 5e-8\n",
        "optomizer = 'adagrad'\n",
        "learning_rate = 1e-3\n",
        "epochs = 100\n",
        "\n",
        "num_columns = 25008\n",
        "model4= Sequential()\n",
        "model4.add(InputLayer(input_shape = (num_columns)))\n",
        "model4 = create_layers(model4,dropout_rate,activation_function,num_layers,\n",
        "    num_neurons,\n",
        "    regularization_wrapper(regularization_type,regularization_factor),\n",
        "    alpha_value)\n",
        "model4 = choose_optimizer(model4,optomizer,learning_rate)\n",
        "model4.add(Dropout(dropout_rate))\n",
        "model4.add(Dense(1,activation='sigmoid'))\n",
        "print(model4.summary())\n",
        "model4.fit(x_under,y_under,epochs = epochs,\n",
        "          validation_data=(x_val,y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AV5Jk53X1xO_",
        "outputId": "789c6aa9-83e5-4a3f-9d42-9c6b82cbdcf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation scores\n",
            "F1 score 0.6083550913838119\n",
            "Accuracy score 0.8331479421579533\n",
            "AUC score 0.7233432788320007\n",
            "Test scores\n",
            "F1 score 0.6962025316455697\n",
            "Accuracy score 0.8718291054739653\n",
            "Precision score 0.9375\n",
            "Recall score 0.5536912751677853\n",
            "AUC score 0.7701830088740198\n"
          ]
        }
      ],
      "source": [
        "eval_model(x_val,y_val,x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41tIgRnUjBqK"
      },
      "outputs": [],
      "source": [
        "##SMOTE-NC data model##\n",
        "\n",
        "from keras.layers import Dropout,Dense,LeakyReLU,PReLU,InputLayer, Activation\n",
        "from keras.regularizers import l1,l2,l1_l2\n",
        "from tensorflow.keras.optimizers import Adagrad, Adam, Adamax, Nadam, RMSprop, Adadelta\n",
        "from keras.models import Sequential\n",
        "\n",
        "#parameters\n",
        "dropout_rate = .3\n",
        "activation_function = 'relu'\n",
        "num_layers = 3\n",
        "num_neurons = 4000\n",
        "alpha_value = .038\n",
        "regularization_type = 'l1_l2'\n",
        "regularization_factor = 5e-5\n",
        "optomizer = 'adamax'\n",
        "learning_rate = 1e-5\n",
        "epochs = 100\n",
        "\n",
        "num_columns = 25008\n",
        "model5= Sequential()\n",
        "model5.add(InputLayer(input_shape = (num_columns)))\n",
        "model5 = create_layers(model5,dropout_rate,activation_function,num_layers,\n",
        "    num_neurons,\n",
        "    regularization_wrapper(regularization_type,regularization_factor),\n",
        "    alpha_value)\n",
        "model5 = choose_optimizer(model5,optomizer,learning_rate)\n",
        "model5.add(Dropout(dropout_rate))\n",
        "model5.add(Dense(1,activation='sigmoid'))\n",
        "print(model5.summary())\n",
        "model5.fit(x_smote,y_smote,epochs = epochs,\n",
        "          validation_data=(x_val,y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Am4ctorJ15rx",
        "outputId": "27d2bb73-90fc-4604-b9f0-6e144bca3a4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation scores\n",
            "F1 score 0.6127167630057804\n",
            "Accuracy score 0.8509454949944383\n",
            "AUC score 0.7360642773881331\n",
            "Test scores\n",
            "F1 score 0.7915106117353309\n",
            "Accuracy score 0.9256786826880284\n",
            "Precision score 0.9005681818181818\n",
            "Recall score 0.7060133630289532\n",
            "AUC score 0.8432736448070238\n"
          ]
        }
      ],
      "source": [
        "eval_model(x_val,y_val,x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XGImtzgZlQ2n"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "#Intractable for large models\n",
        "def feature_pertubation_importance(model,x,y,metric,num_pred):\n",
        "    \"\"\"This function accepts a model which contains a predict method, x and y values and a callable metric of choice. It then\n",
        "        returns the feature importances of each feature with respect to the metric and the data given. This could be used for \n",
        "        training data, validation data or test data. Num_pred is the amount of predictions which you want to average over to get \n",
        "        the final feature importance\n",
        "    \"\"\"\n",
        "    feature_importances = np.empty((num_pred,x.shape[1]))\n",
        "    true_score = metric(y,model.predict(x).round())\n",
        "    for j in range(num_pred):\n",
        "        for i in tqdm(range(x.shape[1])):\n",
        "            z = np.copy(x)\n",
        "            z[:,i] = shuffle(z[:,i])\n",
        "            new_score = metric(y,model.predict(z).round())\n",
        "            importance = true_score - new_score\n",
        "            feature_importances[j,i] = importance\n",
        "    final_pred= np.sum(feature_importances,axis = 0)/num_pred\n",
        "    print(\"The importance of each features in order is: \" + str(final_pred))\n",
        "    return final_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WriEMpEulR08"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Y3ViKD5W2DEO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('psu_env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "1028fe41cec8654ebc71273de4774acc5bc526b98fa48d7193f02b81eae34220"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01a9c1ddd0c84be2b03fbb9cdf63d5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f48d4a57f994260be0b31e834500ff8",
              "IPY_MODEL_2b5e70e579d143ee8c0721b6b4f9e137"
            ],
            "layout": "IPY_MODEL_cf6c4fd7721d4026ba3d4ebd85ab7dc4"
          }
        },
        "02283f4cd4834f569561e1d1407b1192": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "031eecda2a3a49aeb1502a6a0a656900": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03c0dd3ebb25497d91f54de838a1bd90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "047be678707344ccbceb2a2740be51a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5890aa2c3a6f4356a8aa0aad5823d1d4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_221f05b1263b4f6cb4903b6040e2d613",
            "value": 1
          }
        },
        "04e77dc689054672b237c279c4352787": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a97f6c86cfc4d47b1afade750017f3b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46728db06ac6404b84def61490dca40b",
            "value": 1
          }
        },
        "0627bd48064748e8a458f6d0842056d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c20640a38cb40aeacdccff54535d6fb",
            "placeholder": "​",
            "style": "IPY_MODEL_4aa51e713c2a4f69952e4409c2c545dc",
            "value": "2289.786 MB of 2289.786 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "0aecb94ed7f24cf98b1c15eef520882e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f0b1a48e4fc48aa8582c4c1f99e1a40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "147f6db5ed964e47998a9eabb38ee630": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0627bd48064748e8a458f6d0842056d3",
              "IPY_MODEL_047be678707344ccbceb2a2740be51a4"
            ],
            "layout": "IPY_MODEL_a5ab169cd3624b7baed9ead3c49f0bdf"
          }
        },
        "1a97f6c86cfc4d47b1afade750017f3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c80390371ce412f9405dcfd78d818c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f2c3d2dc2de4e90a2b813b9969329dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0e3f703d2614c39bf0eea030a788078",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f0b1a48e4fc48aa8582c4c1f99e1a40",
            "value": 1
          }
        },
        "221f05b1263b4f6cb4903b6040e2d613": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "22416b49de2343539ea2226d7492ace6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "22c7c56dece94dfe9f4991a39a8946c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26c8f85d4d03426f8378d063ea206ea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a8632fed7a14bc09ccd964a1da71ddc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b5e70e579d143ee8c0721b6b4f9e137": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58d11786d32d4fbdbf0a2a1241c015f3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa478e4da1ef4a5b897af4d92a071bbb",
            "value": 1
          }
        },
        "2c5b1e9034914a07bc3cce8e91c5f5aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2cd8cabe28c346c69abde5aaf98fe76a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45adcf8bbffc40de812824ded8ca2ff0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dee339902dcf46a381f0af0d3fff2d7a",
            "value": 1
          }
        },
        "2e46da6294a249679a80abc9a88bb57f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ee1a27640aa4a48a70900d5e672f011",
              "IPY_MODEL_04e77dc689054672b237c279c4352787"
            ],
            "layout": "IPY_MODEL_8acf3909cabe4ffd8bd6e27592158aee"
          }
        },
        "304ec67ad5c1499c87c1b7d75d8f5378": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "328cf0d6f7e14dfbb2328414ab928c91": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33d54a6948da4af794050ede0f0b1c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8d7b044a5614a5abb7463bc0aaa4eeb",
            "placeholder": "​",
            "style": "IPY_MODEL_7fadf3018b2e412b8e1df86d937b951d",
            "value": "1167.993 MB of 1167.993 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "383c74abcc7b4228bb759b6c4a507499": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "429885073d27410e81a0b2517ee80fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44d8224562bd4a928229c2884c056414": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45adcf8bbffc40de812824ded8ca2ff0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46728db06ac6404b84def61490dca40b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4aa51e713c2a4f69952e4409c2c545dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c3ea7c97f814a53aa4f358a90c769d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03c0dd3ebb25497d91f54de838a1bd90",
            "placeholder": "​",
            "style": "IPY_MODEL_8422b371fb5e410fb6ae489de906d6b5",
            "value": "1751.904 MB of 1751.904 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "4f9295dab18e4f4681f85824b79f8e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33d54a6948da4af794050ede0f0b1c96",
              "IPY_MODEL_fd003816ba49410fafd8927cea07a103"
            ],
            "layout": "IPY_MODEL_d686ab381ea340f5ada4ca69de62bf9b"
          }
        },
        "50e11e8588b54904853d446c2b47f0f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c6e281e67584b76bc944607085c4f24",
              "IPY_MODEL_c8c4915b1b364314ba6e454e034b843d"
            ],
            "layout": "IPY_MODEL_a2bc251ff7594fa6b038b2e1dd106262"
          }
        },
        "5890aa2c3a6f4356a8aa0aad5823d1d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58d11786d32d4fbdbf0a2a1241c015f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63137b1d4e5d4723aebccb2eba4bf5f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65094cf336644ebc9f09b8b80abbcfce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "656423f5b93549a9b3ff088eac96d1a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dbba3d8d3e8c4c88bea9c3a108122197",
              "IPY_MODEL_a5a269f56b2e45379c962b469b57d246"
            ],
            "layout": "IPY_MODEL_f023046112d24eb39383fb4fcba7b784"
          }
        },
        "672ffa62ecb040779fd42336dcd51640": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0221487d8104b19be66a3c770fd7ab4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2dbda7b2ddf439496e803b7880907eb",
            "value": 1
          }
        },
        "67977e64e1d244538c3b82631486d4b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "691318705c7049beac18cc35c9384842": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f48d4a57f994260be0b31e834500ff8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdfafeb8cfed436f96273dc83209a98c",
            "placeholder": "​",
            "style": "IPY_MODEL_67977e64e1d244538c3b82631486d4b7",
            "value": "1167.871 MB of 1167.871 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "70cc82d0b6204eb48d261491d547386c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "746be641f4eb4336810a370937529ec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80e4c88a3fcd404a856986326c30841c",
            "placeholder": "​",
            "style": "IPY_MODEL_44d8224562bd4a928229c2884c056414",
            "value": "2575.976 MB of 2575.976 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "7fadf3018b2e412b8e1df86d937b951d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80e4c88a3fcd404a856986326c30841c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8422b371fb5e410fb6ae489de906d6b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8501b1e875024a45a85bdcaa7dea7713": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "886b94f6e0f040d19a097498370fb909": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c3ea7c97f814a53aa4f358a90c769d0",
              "IPY_MODEL_d2dbb4fbd77649aaaa067da91d855284"
            ],
            "layout": "IPY_MODEL_304ec67ad5c1499c87c1b7d75d8f5378"
          }
        },
        "8a694d4988f445899c738d1dcd332d5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8acf3909cabe4ffd8bd6e27592158aee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c20640a38cb40aeacdccff54535d6fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c6e281e67584b76bc944607085c4f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02283f4cd4834f569561e1d1407b1192",
            "placeholder": "​",
            "style": "IPY_MODEL_b83779855373437a92ddc30ec78173bc",
            "value": "1001.898 MB of 1001.898 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "8eb32e380189472bb1124be188eb6fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22c7c56dece94dfe9f4991a39a8946c0",
            "placeholder": "​",
            "style": "IPY_MODEL_8501b1e875024a45a85bdcaa7dea7713",
            "value": "1167.877 MB of 1167.877 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "8ee1a27640aa4a48a70900d5e672f011": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_691318705c7049beac18cc35c9384842",
            "placeholder": "​",
            "style": "IPY_MODEL_e7064a75f959434b9980e989e39c063d",
            "value": "1511.335 MB of 1511.335 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "933032410d84441488f9e80f56cff944": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d81b0e8882c24ab4997cabed3f2af7f7",
            "placeholder": "​",
            "style": "IPY_MODEL_bf408c930cbd46e98e945eb415cb5ad3",
            "value": "1001.861 MB of 1001.861 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "97f0b47eec9c418b8239b28326034c8b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "984022d453294177915a103822b1b221": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2bc251ff7594fa6b038b2e1dd106262": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a58bc5bb5ecd48c6b1cd9e21f2af7e07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfc5cdfc034d4b6aa5186c5191e04376",
              "IPY_MODEL_2cd8cabe28c346c69abde5aaf98fe76a"
            ],
            "layout": "IPY_MODEL_97f0b47eec9c418b8239b28326034c8b"
          }
        },
        "a5a269f56b2e45379c962b469b57d246": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_daa182b8727048e59ae9b96dcb76e22d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b64662943a954a149d327d59525adc9d",
            "value": 1
          }
        },
        "a5ab169cd3624b7baed9ead3c49f0bdf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa478e4da1ef4a5b897af4d92a071bbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa5ef451cf1b41ee89fe659d6eaf2ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8eb32e380189472bb1124be188eb6fba",
              "IPY_MODEL_af3fec8c40a2439baceb6862f7f3ad5f"
            ],
            "layout": "IPY_MODEL_984022d453294177915a103822b1b221"
          }
        },
        "af3fec8c40a2439baceb6862f7f3ad5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7bb658bb2a543cba63af1d7ee02e24c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_031eecda2a3a49aeb1502a6a0a656900",
            "value": 1
          }
        },
        "b0e3f703d2614c39bf0eea030a788078": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b64662943a954a149d327d59525adc9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b814ca6c413a42eca069224122360bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_933032410d84441488f9e80f56cff944",
              "IPY_MODEL_672ffa62ecb040779fd42336dcd51640"
            ],
            "layout": "IPY_MODEL_383c74abcc7b4228bb759b6c4a507499"
          }
        },
        "b83779855373437a92ddc30ec78173bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8d7b044a5614a5abb7463bc0aaa4eeb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf408c930cbd46e98e945eb415cb5ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0221487d8104b19be66a3c770fd7ab4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0b612939aaa4130be0a3aa9641e5c8d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c15ab0c3d260486ea401151be534d522": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7bb658bb2a543cba63af1d7ee02e24c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8c4915b1b364314ba6e454e034b843d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70cc82d0b6204eb48d261491d547386c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26c8f85d4d03426f8378d063ea206ea7",
            "value": 1
          }
        },
        "cf6c4fd7721d4026ba3d4ebd85ab7dc4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfc5cdfc034d4b6aa5186c5191e04376": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_328cf0d6f7e14dfbb2328414ab928c91",
            "placeholder": "​",
            "style": "IPY_MODEL_d0e562ddf8644f9f8f3a4935ad3109a9",
            "value": "1064.901 MB of 1064.901 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "d0e562ddf8644f9f8f3a4935ad3109a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2dbb4fbd77649aaaa067da91d855284": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0aecb94ed7f24cf98b1c15eef520882e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_429885073d27410e81a0b2517ee80fd4",
            "value": 1
          }
        },
        "d686ab381ea340f5ada4ca69de62bf9b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d78ed3cdf26c4919ab928b79936a8d26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_746be641f4eb4336810a370937529ec3",
              "IPY_MODEL_fb3307f0a6054589ad2bd7e8ba75091a"
            ],
            "layout": "IPY_MODEL_65094cf336644ebc9f09b8b80abbcfce"
          }
        },
        "d81b0e8882c24ab4997cabed3f2af7f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daa182b8727048e59ae9b96dcb76e22d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbba3d8d3e8c4c88bea9c3a108122197": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0b612939aaa4130be0a3aa9641e5c8d",
            "placeholder": "​",
            "style": "IPY_MODEL_c15ab0c3d260486ea401151be534d522",
            "value": "572.552 MB of 572.552 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "dee339902dcf46a381f0af0d3fff2d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2dbda7b2ddf439496e803b7880907eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e640ed38938f4bb69b54c0b8ef2a682a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a8632fed7a14bc09ccd964a1da71ddc",
            "placeholder": "​",
            "style": "IPY_MODEL_1c80390371ce412f9405dcfd78d818c6",
            "value": "1562.915 MB of 1562.915 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "e7064a75f959434b9980e989e39c063d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e955c6a610214907b94507ee631403db": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef42712a0646452abf974574a0b857a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e640ed38938f4bb69b54c0b8ef2a682a",
              "IPY_MODEL_1f2c3d2dc2de4e90a2b813b9969329dc"
            ],
            "layout": "IPY_MODEL_63137b1d4e5d4723aebccb2eba4bf5f7"
          }
        },
        "f023046112d24eb39383fb4fcba7b784": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb3307f0a6054589ad2bd7e8ba75091a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a694d4988f445899c738d1dcd332d5d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22416b49de2343539ea2226d7492ace6",
            "value": 1
          }
        },
        "fd003816ba49410fafd8927cea07a103": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e955c6a610214907b94507ee631403db",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c5b1e9034914a07bc3cce8e91c5f5aa",
            "value": 1
          }
        },
        "fdfafeb8cfed436f96273dc83209a98c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
